https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

FOUNDATIONS OF PROBABILISTIC PROGRAMMING
What does a probabilistic program actually compute? How can one formally reason about
such probabilistic programs? This valuable guide covers such elementary questions and
more. It provides a state-of-the-art overview of the theoretical underpinnings of modern
probabilistic programming and their applications in machine learning, security, and other
domains, at a level suitable for graduate students and non-experts in the ﬁeld. In addition,
the book treats the connection between probabilistic programs and mathematical logic,
security (what is the probability that software leaks conﬁdential information?), and presents
three programming languages for different applications: Excel tables, program testing, and
approximate computing. This title is also available as Open Access on Cambridge Core.
gilles barthe is Scientiﬁc Director at the Max Planck Institute for Security and
Privacy and Research Professor at the IMDEA Software Institute, Madrid. His recent
research develops programming language techniques and veriﬁcation methods for
probabilistic languages, with a focus on cryptographic and differentially private
computations.
joost-pieter katoen is Professor at RWTH Aachen University and University of
Twente. His research interests include formal veriﬁcation, formal semantics, concurrency
theory, and probabilistic computation. He co-authored the book Principles of Model
Checking (2008). He received an honorary doctorate from Aalborg University, is member
of the Academia Europaea, and is an ERC Advanced Grant holder.
alexandra silva is Professor of Algebra, Semantics, and Computation at University
College London. A theoretical computer scientist with contributions in the areas of
semantics of programming languages, concurrency theory, and probabilistic network
veriﬁcation, her work has been recognized by multiple awards, including the Needham
Award 2018, the Presburger Award 2017, the Leverhulme Prize 2016, and an ERC Starting
Grant in 2015.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

FOUNDATIONS OF PROBABILISTIC
PROGRAMMING
Edited by
GILLES BARTHE
Max-Planck-Institut f¨ur Cybersicherheit und Schutz der Privatsph¨are, Bochum, Germany
JOOST-PIETER KATOEN
Rheinisch-Westf¨alische Technische Hochschule, Aachen, Germany
ALEXANDRA SILVA
University College London
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

University Printing House, Cambridge CB2 8BS, United Kingdom
One Liberty Plaza, 20th Floor, New York, NY 10006, USA
477 Williamstown Road, Port Melbourne, VIC 3207, Australia
314-321, 3rd Floor, Plot 3, Splendor Forum, Jasola District Centre, New Delhi - 110025, India
79 Anson Road, #06-04/06, Singapore 079906
Cambridge University Press is part of the University of Cambridge.
It furthers the University's mission by disseminating knowledge in the pursuit of
education, learning, and research at the highest international levels of excellence.
www.cambridge.org
Information on this title: www.cambridge.org/9781108488518
DOI: 10.1017/9781108770750
© Gilles Barthe, Joost-Pieter Katoen and Alexandra Silva 2021
This work is in copyright. It is subject to statutory exceptions and to the provisions of
relevant licensing agreements; with the exception of the Creative Commons version the
link for which is provided below, no reproduction of any part of this work may
take place without the written permission of Cambridge University Press.
An online version of this work is published at doi.org/10.1017/9781108770750 under a
Creative Commons Open Access license CC-BY which permits re-use, distribution and
reproduction in any medium for any purpose providing appropriate credit to the original
work is given, any changes made are indicated. To view a copy of this license, visit
https://creativecommons.org/licenses/by/4.0
All versions of this work may contain content reproduced under license from third parties.
Permission to reproduce this third-party content must be obtained from these third-parties directly.
When citing this work, please include a reference to the DOI 10.1017/9781108770750
First published 2021
Printed in the United Kingdom by TJ Books Limited, Padstow Cornwall
A catalogue record for this publication is available from the British Library.
ISBN 978-1-108-48851-8 Hardback
Cambridge University Press has no responsibility for the persistence or accuracy of
URLs for external or third-party internet websites referred to in this publication
and does not guarantee that any content on such websites is, or will remain,
accurate or appropriate.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

Contents
Contributors
page vii
Preface
xi
1
Semantics of Probabilistic Programming: A Gentle Introduction
Fredrik Dahlqvist, Alexandra Silva and Dexter Kozen
1
2
Probabilistic Programs as Measures
Sam Staton
43
3
Application of Computable Distributions to the Semantics of Prob-
abilistic Programs
Daniel Huang, Greg Morrisett and Bas Spitters
75
4
On Probabilistic λ-Calculi
Ugo Dal Lago
121
5
Probabilistic Couplings from Program Logics
Gilles Barthe and Justin Hsu
145
6
Expected Runtime Analyis by Program Veriﬁcation
Benjamin Lucien Kaminski, Joost-PieterKatoenandChristophMath-
eja
185
7
Termination Analysis of Probabilistic Programs with Martingales
Krishnendu Chatterjee, Hongfei Fu and Petr Novotný
221
8
Quantitative Analysis of Programs with Probabilities and Concen-
tration of Measure Inequalities
Sriram Sankaranarayanan
259
9
The Logical Essentials of Bayesian Reasoning
Bart Jacobs and Fabio Zanasi
295
v
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

vi
Contents
10
Quantitative Equational Reasoning
Giorgio Bacci, Radu Mardare, Prakash Panangaden and Gordon
Plotkin
333
11
Probabilistic Abstract Interpretation: Sound Inference and Appli-
cation to Privacy
José Manuel Calderón Trilla, Michael Hicks, Stephen Magill,
Piotr Mardziel and Ian Sweet
361
12
Quantitative Information Flow with Monads in Haskell
Jeremy Gibbons, Annabelle McIver, Carroll Morgan and
Tom Schrijvers
391
13
Luck: A Probabilistic Language for Testing
Lampropoulos Leonidas, Benjamin C. Pierce, Li-yao Xia, Diane
Gallois-Wong, Cătălin Hriţcu, John Hughes
449
14
Tabular: Probabilistic Inference from the Spreadsheet
Andrew D. Gordon, Claudio Russo, Marcin Szymczak, Johannes
Borgström, Nicolas Rolland, Thore Graepel and Daniel Tarlow
489
15
Programming Unreliable Hardware
Michael Carbin and Sasa Misailovic
533
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

Contributors
Giorgio Bacci
Department of Computer Science, Aalborg University, Selma
Lagerlöfs Vej 300, DK-9220 Aalborg, Denmark
Gilles Barthe
Max Planck Institute for Cybersecurity and Privacy, Exzenterhaus,
Universitätsstr. 60, 44789 Bochum, Germany
Johannes Borgström
Department of Information Technology, Uppsala University,
752 37 Uppsala, Sweden
Jose Manuel Calderón Trilla
Galois, Inc., Arlington, VA 22203, USA
Michael Carbin
MIT CSAIL, 77 Massachusetts Ave, 32-G782 Cambridge, MA
02139, USA
Krishnendu Chatterjee
Am Campus 1, IST Austria, A-3400 Klosterneuburg, Aus-
tria
Fredrik Dahlqvist
University College London, Department of Computer Science,
Gower Street, London WC1E 6BT, UK
Ugo Dal Lago
Dipartimento di Informatica - Scienza e Ingegneria Università
degli Studi di Bologna, Mura Anteo Zamboni, 7, 40127 Bologna, Italy
Hongfei Fu
John Hopcroft Center for Computer Science, Shanghai Jiao Tong
University, 800 Dongchuan Road, MinhangDistrict,Shanghai200240,China
Diane Gallois-Wong
Inria de Paris 2, rue Simone Iﬀ, CS 42112, 75589 Paris
CEDEX 12, France
Jeremy Gibbons
University of Oxford, Department of Computer Science, Parks
Road, Oxford OX1 3QD, UK
Andrew D. Gordon
Microsoft Research Ltd, 21 Station Road, Cambridge CB1
2FB, UK
Thore Graepel
University College London, Department of Computer Science,
Gower Street, London WC1E 6BT, UK
Michael Hicks
Department of Computer Science, University of Maryland, Col-
lege Park, MD 20742, USA
vii
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

viii
Contributors
Cătălin Hriţcu
Inria de Paris 2, rue Simone Iﬀ, CS 42112, 75589 Paris CEDEX
12, France
John Hughes
Department of Computer Science and Engineering, SE-412 96,
Gothenburg, Sweden
Justin Hsu
School of Computer, Data and Information Sciences, 1210 W. Dayton
Street Madison, WI 53706-1613, USA
Daniel Huang
EECS, University of California,Berkeley,CA94720-1770,USA
Benjamin Lucien Kaminski
Software Modeling and Veriﬁcation Group, RWTH
Aachen University D-52056 Aachen, Germany
Joost-Pieter Katoen
Software Modeling and Veriﬁcation Group, RWTH Aachen
University D-52056 Aachen, Germany
Dexter Kozen
Computer Science Department, 436 Gates Hall, Cornell Univer-
sity, Ithaca, New York 14853-7501, USA
Bart Jacobs
Interdisciplinary Hub for Security, Privacy, and Data Governance,
Radboud University Nijmegen, Erasmusplein 1, 6525 HT Nijmegen, The
Netherlands
Lampropoulos Leonidas
University of Pennsylvania, Department of Computer
and Information Science, 3330 Walnut Street, Philadelphia, PA 19104-6389,
USA
Stephen Magill
Galois, Inc., Arlington, VA 22203, USA
Radu Mardare
Computer and Information Sciences University of Strathclyde, 26
Richmond Street, Glasgow G1 1XH, UK
Piotr Mardziel
Electrical and Computer Engineering Department, Carnegie Mel-
lon University, 5000 Forbes Avenue, Pittsburgh, PA 15213, USA
Christoph Matheja
Software Modeling and Veriﬁcation Group, RWTH Aachen
University D-52056 Aachen, Germany
Annabelle McIver
Department of Computing, Macquarie University, Sydney,
NSW 2109, Australia
Sasa Misailovic
Department of Computer Science, University of Illinois, 4110
Siebel Center, Urbana, IL 61801, USA
Carroll Morgan
Faculty of Engineering, UNSW,Sydney,NSW2052,Australia
Greg Morrisett
Cornell Tech, Cornell University, 2 West Loop Road, New York,
New York 10044, USA
Petr Novotný
Faculty of Informatics, Masaryk University, Botanickà 68a, 60200
Brno, Czech Republic
Prakash Panangaden
School of Computer Science, McGill University, 3480 rue
University, Montreal, Quebec H3A 0E9, Canada
Benjamin C. Pierce
University of Pennsylvania, Department of Computer and
Information Science, 3330 Walnut Street, Philadelphia, PA 19104-6389,
USA
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

Contributors
ix
Gordon Plotkin
Laboratory for Foundations of Computer Science, School of
Informatics, Informatics Forum, 10 Crichton Street, Edinburgh EH8 9AB,
UK
Nicolas Rolland
University College London, Department of Computer Science,
Gower Street, London WC1E 6BT, UK
Claudio Russo
DFINITY, Stockerstrasse 47, 8002 Zürich, Switzerland
Sriram Sankaranarayanan
Department of Computer Science, University of Col-
orado, Boulder CO 80309-0430, USA
Tom Schrijvers
Department of Computer Science. KU Leuven. Celestijnenlaan
200A. 3001 Leuven. Belgium
Alexandra Silva
University College London, Department of Computer Science,
Gower Street, London WC1E 6BT, UK
Bas Spitters
Department of Computer Science, Aarhus University, Nygaard-268
Aabogade 34, DK-8200 Aarhus N, Denmark
Sam Staton
Department of Computer Science, University of Oxford Wolfson
Building, Parks Road, Oxford OX1 3QD, UK
Ian Sweet
Department of Computer Science, University of Maryland, College
Park, MD 20742, USA
Marcin Szymczak
Lehrstuhl für Informatik 2, RWTH Aachen University, 52056
Aachen, Germany
Daniel Tarlow
Google Research, Brain Team, Montreal, Quebec H3B 2Y5,
Canada
Li-yao Xia
University of Pennsylvania, Department of Computer and Information
Science, 3330 Walnut Street, Philadelphia, PA 19104-6389, USA
Fabio Zanasi
University College London, Department of Computer Science,
Gower Street, London WC1E 6BT, UK
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

Preface
Probabilistic programs
Probabilistic programs describe recipes for inferring statistical conclusions from a
complex mixture of uncertain data and real-world observations. They can represent
probabilistic graphical models far beyond the capabilities of Bayesian networks
and are expected to have a major impact on machine intelligence. Probabilistic
programs are ubiquitous. They steer autonomous robots and self-driving cars, are
key to describe security mechanisms, naturally code up randomised algorithms
for solving NP-hard or even unsolvable problems, and are rapidly encroaching on
AI. Probabilistic programming aims to make probabilistic modelling and machine
learning accessible to the programmer.
What is this book all about?
Probabilistic programs, though typically relatively small in size, are hard to grasp,
let alone check automatically. Elementary questions are notoriously hard - even the
most elementary question "does a program halt with probability one? - is "more un-
decidable" than the halting problem. This book is about the theoretical foundations
of probabilistic programming. It is primarily concerned with fundamental questions
such as the following: What is Bayesian probability theory? What is the precise
mathematical meaning of probabilistic programs? How show almost-sure termi-
nation? How determine the (possibly inﬁnite) expected runtime of probabilistic
programs? How can two similar programs be compared? It covers several analy-
sis techniques on probabilistic programs such as abstract interpretation, algebraic
reasoning and determining concentration measures.
These chapters are complemented with chapters on the formal deﬁnition of
concrete probabilistic programming languages and some possible applications of
the use of probabilistic programs.
xi
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

xii
Preface
How to read this volume?
The volume consists of ﬁve parts: semantics, veriﬁcation, logic, security, and pro-
gramming languages.
Semantics.
The ﬁrst part on semantics consists of four chapters on diﬀerent aspects of the
formal semantics of probabilistic programming languages. Dahlqvist et al. start oﬀ
in Chapter 1 by presenting an operational and denotational semantics of an imper-
ative language with discrete and continuous distributions. The chapter by Staton
presents a compositional measure-theoretic semantics for a ﬁrst-order probabilis-
tic language with arbitrary soft conditioning. Chapter 3 by Huang et al. studies
semantics with a focus on computability. Motivated by the tension between the
discrete and the continuous in probabilistic modelling, type-2 computable distribu-
tions are introduced as the elementary mathematical objects to give semantics to
probabilistic languages. Dal Lago's Chapter 4 completes the semantics part by treat-
ing a probabilistic version of the λ-calculus, the backbone language for functional
programming languages.
Veriﬁcation.
The second part on formal veriﬁcation starts with a chapter by Barthe and Hsu
on the use of couplings, a well-known concept in probability theory for verifying
probabilistic programs. Kaminski et al. present a weakest pre-condition calculus
in the style of Dijkstra for determining the expected run-time of a probabilistic
program. This can be used to determine whether a program needs inﬁnitely many
steps to terminate with probability one. Chapter 7 by Chatterjee et al. presents var-
ious techniques based on supermartingales to decide the almost-sure termination
of a probabilistic program, i.e., does a program terminate with probability one on
all possible inputs? The veriﬁcation part ends with a chapter by Sankaranarayanan
about the quantitative analysis of probabilistic programs by means of concentration
of measure inequalities. This includes Chernoﬀ-Hoeﬀding and Bernstein inequal-
ities.
Logic.
The third part focuses on logic and consists of two chapters. In Chapter 9, Ja-
cobs and Zanasi present an insightful new perspective on fundamental aspects of
probability theory which are relevant for probabilistic programming. Their chapter
introduces a category-theoretic formalization of Bayesian reasoning, and in particu-
lar a string-diagram-friendly one. This contribution is complemented by the chapter
by Bacci et al. which surveys some recent contributions on extending the classical
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

Preface
xiii
Birkhoﬀ/Lawvere theory of equational reasoning to the quantitative setting. In that
setting, compared entities are not necessarily equal but rather treated by a notion of
distance.
Security.
Part four is concerned with security, an important application ﬁeld in which prob-
abilities are pivotal. Chapter 11 by Calderon et al. collects together results on
probabilistic abstract interpretation and applies them to probabilistic programming
in the context of security. Chapter 12 by Gibbons et al. presents an embedded
domain-speciﬁc language in Haskell to compute hyper-distributions induced by
programs. This is used to compute the amount of leakage of a program by measur-
ing variations on post-distributions that include Shannon entropy and Bayes' risk
(that is, the maximum information an attacker can learn in a single run).
Programming languages.
The ﬁnal part of this volume is concerned with three concrete probabilistic pro-
gramming languages: Luck, Tabular, and Rely. Chapter 13 describes Luck, pro-
posed by Lampropoulos et al., a language for test generation and a framework for
property-based testing of functional programs. Luck combines local instantiation of
unknown variables and global constraint solving to make test generation more eﬃ-
cient than existing approaches. Gordon et al. introduce Tabular, a domain-speciﬁc
programming language designed to express probabilistic models and to perform
probabilistic inference over relational data. Tabular can be used from Microsoft
Excel or as stand-alone software. Chapter 14 presents the syntax, semantics and
type system of Tabular and shows how it can be used to design probabilistic models
and to perform probabilistic inference. Chapter 15, the last chapter of this volume,
by Carbin and Misailovic, presents Rely, a programming language that enables
reasoning about the probability that a program produces the correct result when
executed on unreliable hardware.
How this volume emerged
This book consists of 15 contributed chapters and a preface. The idea for this
volume emerged at the ﬁrst summer school on Foundations of Programming and
Software Systems held in Braga, Portugal, May-June 2017. This biennial school
series is supported by EATCS (European Association for Theoretical Computer
Science), ETAPS (European Conference on Theory and Practice of Software),
ACM SIGPLAN (Special Interest Group on Programming Languages) and ACM
SIGLOG (Special Interest Group on Logic and Computation). It was felt that there is
no comprehensive book on the theoretical foundations of probabilistic programming
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

xiv
Preface
languages. We sincerely hope that this volume contributes to ﬁlling this gap. Enjoy
reading!
Acknowledgements
Many people have helped us to make this volume possible. First and foremost, we
like to thank all authors for their ﬁne contributions and for their patience in this
book process. All chapters have been subject to peer reviews. We thank the review-
ers Alejandro Aguirre, Krishnendu Chatterjee, Ugo Dal Lago, Thomas Ehrhard,
Claudia Faggian, Marco Gaboardi, Francesco Gavazzo, Jeremy Gibbons, Andrew
D. Gordon, Ichiro Hasuo, Jan Hoﬀmann, Justin Hsu, Bart Jacobs, Benjamin Lu-
cien Kaminski, Pasquale Malacaria, Radu Mardare, Christoph Matheja, Annabelle
McIver, Sasa Misailovic, Petr Novotný, Prakash Panangaden, Corina Pasareanu,
Alejandro Russo, Sriram Sankaranarayanan, Steﬀen Smolka, and Marcin Szym-
czak for their thorough reviewing work.
We thank Luis Barbosa, Catarina Fernandes and Renato Neves for their invaluable
eﬀorts in the local organisation of the FoPPS 2017 summer school. We thank Joshua
Moerman for his eﬀorts in the editing process. David Tranah and Anna Scriven
from Cambridge University Press are thanked for their support during this process.
We thank Hanna Schraﬀenberger for designing the cover of the book. Finally, we
are grateful for the ﬁnancial support from the ERC (AdG FRAPPANT and StG
ProFoundNet) and the MPI on Security and Privacy which enabled to publish this
volume under gold open access.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

1
Semantics of Probabilistic Programming:
A Gentle Introduction
Fredrik Dahlqvist and Alexandra Silva
University College London
Dexter Kozen
Cornell University
Abstract:
Reasoning about probabilistic programs is hard because it compounds
the diﬃculty of classic program analysis with sometimes subtle questions of prob-
ability theory. Having precise mathematical models, or semantics, describing their
behaviour is therefore particularly important. In this chapter, we review two prob-
abilistic semantics. First an operational semantics which models the local, step-
by-step, behaviour of programs, then a denotational semantics describing global
behaviour as an operator transforming probability distributions over memory states.
1.1 Introduction
A probabilistic program is any program whose execution is probabilistic. This
usually means that there is a source of randomness that allows weighted choices
to be made during execution. Given an initial machine-state, in the event that the
program halts, there will be a distribution describing the probability of output
events. Any deterministic program is trivially a probabilistic program that does
not make any random choices. The source of randomness is typically a random
number generator, which is assumed to provide independent samples from a known
distribution. In practice, these are often pseudo-random number generators, which
do not provide true randomness, but only an approximation; however, it is possible
to construct hardware random number generators that provide true randomness, for
example by measuring a noisy electromagnetic process.
Reasoning about deterministic programs usuallyinvolvesansweringbinaryyes/no
questions: Is the postcondition always satisﬁed? Does this program halt on all in-
puts? Does it always halt in polynomial time? On the other hand, reasoning about
probabilistic programming usually involves more quantitative questions: What is
the probability that the postcondition is satisﬁed? What is the probability that this
a From Foundations of Probabilistic Programming, edited by Gilles Barthe, Joost-Pieter Katoen and Alexandra
Silva published 2020 by Cambridge University Press.
1
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

2
Dahlqvist, Kozen and Silva: Semantics of Probabilistic Programming
program halts? Is its expected halting time polynomial? In order to answer questions
like these, the ﬁrst step should be to develop a formal mathematical semantics for
probabilistic programs, which will allow us to formalise such questions precisely.
This is the main purpose of this chapter.
Reasoning about probabilistic programs is in general diﬃcult because it com-
pounds the diﬃculty of deterministic program analysis with questions of probability
theory, which can sometimes be counterintuitive. We will use examples to illustrate
all the main ideas presented in this chapter. We introduce these examples here and
will return to them as we develop the semantics of probabilistic programs. We
start with two examples involving discrete probabilities for which naive probability
theory provides a suﬃcient framework for reasoning. We will then present two
programs that involve continuous distributions for which a more general theory
known as measure theory is needed. The requisite background for understanding
these concepts is presented in Section 1.2.
x:=0;
while x==0 do
x:=coin()
start
[x →?]
[x →0]
[x →1]
x := 0
1/2 : x := 1
1/2 : x := 0
Figure 1.1 A simple coin-toss program
We start with the simple program of Fig. 1.1 displayed next to the small proba-
bilistic automaton it implements. Here the construct coin() is our random number
generator; each successive call returns 0 or 1, each with probability 1/2, and succes-
sive calls are independent, which means that n successive calls will yield one of the
2n possible sequences of n binary digits, each with probability 2−n. A distribution
on {0,1} that takes value 1 with probability p and 0 with probability 1 −p is called
a Bernoulli distribution with (success) parameter p. Thus coin() is a Bernoulli
distribution with success parameter 1/2.
It is intuitively clear that this program eventually halts with probability 1. Looking
at the automaton of Fig. 1.1, one can see that the probability of the program going
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

1.1 Introduction
3
through n iterations of the body of the loop is 2−n. Moreover, the expected number
of iterations of the body of the loop is given by
∞

n=1
n2−n = 2.
This type of simple probabilistic process involving repeated independent trials until
some ﬁxed "success" event occurs is called a Bernoulli process. If the probability
of success in each trial is p, then the expected time until success is 1/p. In this
example, p = 1/2. We will show in Section 1.3 how the mathematical interpretation
of this program (its semantics) can be constructed compositionally, that is to say
line-by-line, and how it agrees with these simple observations.
Our second example is also discrete, but intuitively less obvious. The program
of Fig. 1.2 implements a random walk on the two-dimensional grid Z × Z. In each
iteration of the body of the loop, the function step updates the current coordinates
by moving left, right, down, or up, each with equal probability 1/4.
main{
u:=0;
v:=0;
step(u,v);
while u!=0 || v!=0 do
step(u,v)
}
step(u,v){
x:=coin();
y:=coin();
u:=u+(x-y);
v:=v+(x+y-1)
}
Figure 1.2 A random walk on a two-dimensional grid
The loop continues until the random walk returns to the origin. The ﬁrst call to
step outside the loop ensures that the program takes at least one step, so it does not
halt immediately. The question of the halting probability is now much less obvious.
The state space is inﬁnite, and there is no constraint on how far the random walk can
travel from the origin. Indeed, for any distance, there is a nonzero probability that
it goes at least that far. However, it turns out that the probability that the program
halts is 1. In the terminology of probability theory, we would say that the two-
dimensional random walk is recurrent at every point. This example illustrates how
the analysis of probabilistic programs can rely on results from probability theory
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

4
Dahlqvist, Kozen and Silva: Semantics of Probabilistic Programming
that are far from obvious. Indeed, the three-dimensional version is not recurrent;
the probability that a random walk on Z3 eventually returns to the origin is strictly
less than 1.
We now consider two programs that require continuous distributions. The se-
mantics of such programs cannot be deﬁned without the full power of measure
theory, the mathematical foundation of probabilities and integration. The program
of Fig. 1.3 approximates the constant π using Monte Carlo integration, a probabilis-
tic integration method. The program works by taking a large number of independent,
uniformly distributed random samples from the square [0,1] × [0,1] and counting
the number that fall inside the unit circle. As the area of the square is 1 and the area
of the part of the unit circle inside that square is π/4, by the law of large numbers
we expect to see a π/4 fraction of sample points lying inside the circle.
i:=0;
n:=0;
while i<1e9 do
x:=rand();
y:=rand();
if (x*x+y*y) < 1 then n:=n+1;
i:=i+1
i:=4*n/1e9;
Figure 1.3 Probabilistic computation of π.
In this example, the random number generator rand() samples from the uniform
distribution on the interval [0,1]. This distribution is often called Lebesgue mea-
sure. Here the state space [0,1] is uncountable and the probability of drawing any
particular x ∈[0,1] is zero. Such probability distributions are called continuous.
The natural question to ask about this program is not whether it terminates (it clearly
does) but whether it returns a good approximation of π with high probability. We
will answer this question in Section 1.3.
Finally, the program in Fig. 1.4 generates a real number between [0,1] whose
expansion in base 3 does not contain any 1's. This program is not like the others
in that it does not halt (nor is it meant to). The program generates a sample from
a curious and in many respects counterintuitive distribution called the Cantor
distribution. It cannot be described using discrete probability distributions (i.e.
ﬁnite or countable weighted sums of point masses), although the program only
uses a discrete fair coin as a source. The Cantor distribution is also an example of
continuous probability distribution, which assigns probability zero to every element
of the state space. It is also an example of a so-called singular distribution, since
it can be shown that the set of all its possible outcomes—that is to say the set of
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

1.2 Measure theory: What you need to know
5
all real numbers whose base-3 expansion contains no 1's—has measure 0 in the
Lebesgue measure on [0,1].
x:=0;
d:=1;
while true do
d:=d/3;
x:=x+2*coin()*d
Figure 1.4 Cantor distribution program.
1.2 Measure theory: What you need to know
Measures are a generalization of the concepts of length, area, or volume of Euclidean
geometry to other spaces. They form the basis of probability and integration theory.
In this section, we explain what it means for a space to be a measurable space, we
deﬁne measures on these spaces, and we examine the rich structure of spaces of
measures, which will be essential to the semantics of probabilistic programs deﬁned
in Section 1.3.5. When not speciﬁed otherwise we use the word measure to refer to
ﬁnite measures.
1.2.1 Some intuition
The concepts of length, area, and volume on Euclidean spaces are examples of
(positive) measures. These are suﬃcient to illustrate most of the desired properties
of measures and some pitfalls to avoid. For the sake of simplicity, let us examine
the concept of length. Given an interval [a, b] ⊆R, its length is of course ℓ([a, b]) =
b−a. But the length function ℓmakes sense for other subsets of R besides intervals.
So we will begin with two related questions:
(a) Which subsets of R can meaningfully be assigned a "length" consistent with
the length of intervals? I.e., what should the domain of ℓbe?
(b) Which properties should the length function ℓsatisfy?
The answer to question (a) will give rise to the notion of measurable space, and the
answer to question (b) will give rise to the notion of measure, both deﬁned formally
in Section 1.2.2.
Note that larger intervals have larger lengths: if [a, b] ⊆[c, d], then we have that
ℓ([a, b]) = b −a ≤d −c = ℓ([c, d]). This intuitively obvious property is a general
feature of all positive measures: they associate nonnegative real numbers to subsets
monotonically with respect to set inclusion. Let us now take two disjoint intervals
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

6
Dahlqvist, Kozen and Silva: Semantics of Probabilistic Programming
[a1, b1] and [a2, b2] with b1 < a2. It is natural to deﬁne the length of [a1, b1]∪[a2, b2]
as the sum of the length of the respective intervals, i.e.
ℓ([a1, b1] ∪[a2, b2]) = ℓ([a1, b1]) + ℓ([a2, b2]) = (b1 −a1) + (b2 −a2).
We can draw two conclusions from this natural deﬁnition. First, if A, B are two
disjoint subsets of R in the domain of ℓ, then their union should also belong to the
domain of ℓ, and the measure of the union should be the sum of the measures. More
generally, if Ai, 1 ≤i ≤n, is any ﬁnite collection of pairwise disjoint sets in the
domain of ℓ, then n
i=1 Ai should also be in the domain of ℓ, and the measure of
the union should be the sum of the measures of the Ai; that is,
ℓ
 n

i=1
Ai

=
n

i=1
ℓ(Ai).
(1.1)
A real-valued function on subsets satisfying (1.1) is called (ﬁnitely) additive. All
measures will be ﬁnitely additive, and in fact more. Consider the countable col-
lection of pairwise disjoint intervals [n,n + 2−n),n ∈N. Generalising (1.1), it is
natural to deﬁne ℓon the union of these intervals as
ℓ
 ∞

n=0
[n,n + 2−n)

=
∞

n=0
2−n = 2.
Again, we can draw two conclusions from this natural deﬁnition. First, if Ai for
i ∈N is a countable collection of pairwise disjoint sets in the domain of ℓ, then

i∈N Ai should be in the domain of ℓ; second, that (1.1) should be extended to such
countable collections, so that
ℓ
 ∞

i=0
Ai

=
∞

i=0
ℓ(Ai).
(1.2)
A function ℓsatisfying (1.2) is called countably additive or σ-additive. Every
measure will be countably additive. The reader will now legitimately ask: what
happens if the sum in (1.2) diverges? To deal with this behaviour, one simply allows
∞as a possible length, that is to say the codomain of ℓcan be the extended real line
R+ ∪{∞}. In particular, this allows us to deﬁne the length of R via (1.2) as:
ℓ(R) = ℓ

n∈Z
[n,n + 1)

= ∞.
However, for the purpose of semantics of probabilistic programs, we will not need
measures taking the value ∞. A measure is called ﬁnite if it only assigns ﬁnite
values in R to any set in its domain. For the remainder of this chapter, the term
"measure", otherwise unqualiﬁed, will refer to ﬁnite measures.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

1.2 Measure theory: What you need to know
7
Consider now subsets A ⊆B of R in the domain of ℓsuch that ℓ(A) ≤ℓ(B) < ∞.
From ﬁnite additivity, it would make sense to deﬁne ℓ(B \ A) = ℓ(B) −ℓ(A), since
B = A ∪(B \ A) is a partition of B. In other words, it would also be natural to
require that if A ⊆B and A and B are in the domain of ℓ, then so should be
B \ A, and ℓ(B \ A) = ℓ(B) −ℓ(A). Thus the domain of ℓshould be closed under
complementation.
The reader may now be wondering: If the domain of ℓcontains all intervals and
is closed under countable pairwise disjoint unions and complementation, that is
already a very large set of subsets of R. Is it possible that a length can be sensibly
assigned to all subsets of R? In other words, can we extend ℓto domain P(R)?
Alas, it turns out that this is not possible. An important and desirable property of
the length function ℓis that it is translation invariant: given a set A with length
ℓ(A) (for example an interval), if the entire set A is translated a ﬁxed distance, say
d, then its length should be unchanged; that is, ℓ(A) = ℓ({x + d | x ∈A}). Vitali
(1905) constructed a countable set of subsets of the interval [0,1), called Vitali sets,
which are pairwise disjoint, translates of each other (modulo 1), and whose union
is [0,1). They would all have to have the same measure, which would break the
countable additivity axiom (1.2). Vitali sets are examples of non-measurable sets.
They provide an example of subsets of R which are incompatible with the basic
assumptions of how the length function should behave. Thus the domain of the
length function cannot be P(R), because it cannot contain the Vitali sets.
The length functionℓdescribed in the precedingparagraphsiscalledtheLebesgue
measure on R. We now turn our attention to axiomatizing the intuitive ideas pre-
sented thus far.
1.2.2 Measurable spaces and measures
We start by axiomatizing the closure properties of the domain of a measure (such
as the length function) which we have described informally in the previous section.
A σ-algebra B on a set S is a collection of subsets of S containing the empty set
∅and closed under complementation in S and countable union (hence also under
countable intersection). A pair (S,B), where S is a set and B is a σ-algebra on S,
is called a measurable space. The elements of B are called the measurable sets of
the space. In a probabilistic setting, elements of S and B are often called outcomes
and events, respectively. The domain of a measure, for example the length function,
will always be a σ-algebra. If the σ-algebra is obvious from the context, we simply
say that S is a measurable space. The set of all subsets P(S) is a σ-algebra called
the discrete σ-algebra, but as noted above, it may not be an appropriate choice
since it may not allow the deﬁnition of certain measures. However, it is always an
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

8
Dahlqvist, Kozen and Silva: Semantics of Probabilistic Programming
acceptable choice for ﬁnite or countable sets, and we will always assume that ﬁnite
and countable sets are equipped with the discrete σ-algebra.
If F is a collection of subsets of a set S, we deﬁne σ(F ), the σ-algebra generated
by F , to be the smallest σ-algebra containing F . That is, σ(F ) is the smallest
collection of subsets of S containing F and ∅and closed under countable union
and complement. Equivalently,
σ(F ) ≜{A | F ⊆A and A is a σ-algebra}.
Note that σ(F ) is well-deﬁned, since the intersection is nonempty, as F ⊆P(S)
and P(S) is a σ-algebra. If (S,B) is a measurable space and B = σ(F ), we say that
the space is generated by F .
Measurable functions. Let (S,BS) and (T,BT) be measurable spaces. A function
f : S →T is measurable if the inverse image f −1(B) = {x ∈S | f (x) ∈B} of
every measurable subset B ∈BT is a measurable subset of S. When BT is generated
by F , then f is measurable if and only if f −1(B) is measurable for every B ∈F .
An example of a measurable function is χB : S →{0,1}, the characteristic
function of a measurable set B:
χB(s) =

1,
s ∈B,
0,
s  B.
Here, (S,B) is a measurable space, B ∈B, and {0,1} is the discrete space.
Measures. A signed (ﬁnite) measure on (S,B) is a countably additive map μ: B →
R such that μ(∅) = 0. Recall that countably additive means that if A is a count-
able set of pairwise disjoint events, then μ( A) = 	
A∈A μ(A). Equivalently, if
A0, A1, A2,. . . is a countable chain of events (a countable collection of measurable
sets such that An ⊆An+1 for all n ≥0), then limn μ(An) exists and is equal to
μ(
n An).
A signed measure on (S,B) is called positive if μ(A) ≥0 for all A ∈B. A positive
measure on (S,B) is called a probability measure if μ(S) = 1 and a subprobability
measure if μ(S) ≤1. A measurable set B such that μ(B) = 0 is called a μ-nullset,
or simply a nullset if there is no ambiguity. A property is said to hold μ-almost
surely (μ-a.s.) or μ-almost everywhere (μ-a.e.) if the set of points on which it does
not hold is contained in a nullset.
In probability theory, measures are sometimes called distributions. We will use
the terms measure and distribution synonymously.
For s ∈S, the Dirac measure, or Dirac delta, or point mass on s is the probability
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

1.2 Measure theory: What you need to know
9
measure
δs(B) =

1,
s ∈B,
0,
s  B.
A measure is discrete if it is a countable weighted sum of Dirac measures. In par-
ticular a convex sum of Dirac measures is a discrete probability measure. These are
ﬁnite or countable sums of the form 	
s∈C asδs, where all as ≥0 and 	
s∈C as = 1.
A measure μ on a measurable set (S,B) is called continuous if μ ({s}) = 0 for
all singleton sets {s} in B. The Lebesgue measures on Rn for n ∈N, that is, the
lengths, areas, volumes, etc., are the best known examples of continuous measures.
Pushforward measure. Given f : (S,BS) →(T,BT) measurable and a measure μ
on BS, one deﬁnes the pushforward measure f∗(μ) on BT by
f∗(μ)(B) = μ( f −1(B)), B ∈BT .
(1.3)
This measure is well deﬁned: since f is measurable, f −1 maps measurable sets of
BT to measurable sets of BS.
Lebesgue integration. An important operation on measures and measurable func-
tions is Lebesgue integration. Let (S,B) be a measurable space. Given a measure
μ: B →R and bounded measurable function f : S →R, say bounded above by M
and below by m, the Lebesgue integral of f with respect to μ, denoted
∫
f dμ, is a
real number obtained as the limit of ﬁnite weighted sums of the form
n

i=0
f (si)μ(Bi),
(1.4)
where B0,. . ., Bn is a measurable partition of S, the value of f does not vary more
than (M−m)/n in any Bi, and si ∈Bi, 1 ≤i ≤n. The limit is taken over increasingly
ﬁner measurable partitions of the space. For the details of this construction, see for
example (Dudley, 2002, Ch. 4) or (Aliprantis and Border, 1999, Ch. 11).
For a ﬁnite discrete space n = {1,2,. . .,n}, the integral reduces simply to a
weighted sum:
∫
f dμ = 	n
i=1 f (i)μ(i).
The bounded integral
∫
B f dμ, where B ∈B, is obtained by integrating over the
set B instead of all of S; equivalently,
∫
B
f dμ ≜
∫
χB · f dμ,
(1.5)
where χB is the characteristic function of B and χB · f is the pointwise product of
real-valued functions.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

10
Dahlqvist, Kozen and Silva: Semantics of Probabilistic Programming
Absolute continuity. Given two measures μ,ν, we say that μ is absolutely contin-
uous with respect to ν and write μ ≪ν if for all measurable sets B, if ν(B) = 0,
then μ(B) = 0. Informally, if ν assigns no mass to B, then neither does μ. Although
we will not need it, we cannot fail to mention the following theorem, which is one
the pillars of probability theory.
Theorem 1.1 (Radon-Nikodym)
Let μ,ν be two ﬁnite measures on a measurable
space (S,B) and assume that μ is absolutely continuous with respect to ν. Then
there exists a measurable function f : S →R deﬁned uniquely up to a μ-nullset
such that
μ(B) =
∫
B
f dν.
The function f is called the Radon-Nikodym derivative of μ with respect to ν.
Radon-Nikodym derivatives are known in probability theory as probability den-
sity functions. For example, the standard Gaussian probability measure is abso-
lutely continuous with respect to Lebesgue measure (the length function) on R.
Its Radon-Nikodym derivative with respect to Lebesgue measure is the Gaussian
density function f (t) =
1
√
2π e−t2/2.
Products. Given two measurable spaces (S1,B1) and (S2,B2), one can construct
the product space (S1 × S2,B1 ⊗B2), where S1 × S2 is the cartesian product and
B1 ⊗B2 is the σ-algebra on S1 × S2 generated by all measurable rectangles B1 × B2
for B1 ∈B1 and B2 ∈B2. In other words,
B1 ⊗B2 ≜σ ({B1 × B2 | B1 ∈B1, B2 ∈B2}) .
(1.6)
The measurable rectangles B1 × B2 are a generalisation of the case where S1 =
S2 = R and B1, B2 are intervals. The product of two measurable spaces is thus the
measurable space generated by the corresponding measurable rectangles.
A measure on the product space (S1 × S2,B1 ⊗B2) is sometimes called a joint
distribution. Due to the inductive construction (1.6) of B1 ⊗B2 from measurable
rectangles B1 × B2, joint distributions are uniquely determined by their values on
measurable rectangles. For details of this extension, see (Dudley, 2002, §4.4).
A special class of joint distributions are the product measures μ1 ⊗μ2 formed
from a measure μ1 on (S1,B1) and a measure μ2 on (S2,B2), deﬁned on measurable
rectangles by
(μ1 ⊗μ2)(B1 × B2) ≜μ1(B1)μ2(B2).
As mentioned, this extends uniquely to a joint distribution μ1 ⊗μ2 : B1 ⊗B2 →R.
Product measures capture the idea of independence: sampling μ1 ⊗μ2 to obtain an
element of S1 × S2 is equivalent to independently sampling μ1 on S1 and μ2 on S2.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

1.2 Measure theory: What you need to know
11
Markov Kernels. Let (S,BS) and (T,BT) be measurable spaces. A function P: S×
BT →R is called a Markov kernel (also called a Markov transition, measurable
kernel, stochastic kernel, or stochastic relation) if
• for ﬁxed A ∈BT, the map λs.P(s, A): S →R is a measurable function on
(S,BS); and
• for ﬁxed s ∈S, the map λA.P(s, A): BT →R is a probability measure on (T,BT).
These properties allow integration on the left and right, respectively.
The measurable spaces and Markov kernels form a category, the Kleisli category
of the Giry monad; see Panangaden (1998, 2009); Doberkat (2007); Giry (1982).
In this context, we occasionally write P: (S,BS) →(T,BT) or just P: S →T.
Composition is given by integration: for P: S →T and Q: T →U,
(P ; Q)(s, A) =
∫
t ∈T
P(s, dt) · Q(t, A).
(1.7)
Associativity of composition follows essentially from Fubini's theorem (see Chung,
1974, or Halmos, 1950). Markov kernels were introduced in Lawvere (1962) and
were proposed as a model of probabilistic while programs in Kozen (1985).
The deﬁnition of the pushforward of a measure can be extended to Markov
kernels as follows. Given a measure μ on BS, its pushforward under the Markov
kernel P: (S,BS) →(T,BT) is the measure P∗(μ) on BT deﬁned by
P∗(μ)(B) =
∫
s∈S
P(s, B) μ(ds).
(1.8)
Any measurable map f : (S,BS) →(T,BT) determines a trivial Markov kernel
s →δf (s), and under this deﬁnition the pushforward operation deﬁned in Eq. (1.3)
is just a special case of Eq. (1.8).
The reader will note that we changed notation in displaying the Lesbegue integrals
in Equations (1.7) and (1.8) when compared to Eq. (1.5). This is standard notation
in measure theory, in particular in the presence of Markov kernels, but for clarity
we note that these could have been written as:
(P ; Q)(s, A) =
∫
T
Q(−, A) dP(s,−)
P∗(μ)(B) =
∫
S
P(−, B) dμ.
Recall that because P and Q are Markov kernels the functions Q(−, A) and P(−, B)
are measurable and P(s,−) is a probability measure.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12
Dahlqvist, Kozen and Silva: Semantics of Probabilistic Programming
1.2.3 Spaces of measures
The set of all (ﬁnite, signed) measures on a measurable set (S,B) will be denoted
M(S,B), or simply MS if B is understood. The spaces MS carry a very rich struc-
ture which lies at the heart of the denotational semantics described in Section 1.3.5.
We now describe this structure.
Vector space structure. First, MS is always a real vector space whose addition
operation and scalar multiplication are deﬁned pointwise:
(μ + ν)(B) ≜μ(B) + ν(B)
(aμ)(B) ≜aμ(B)
for B ∈B, μ,ν ∈MS, and a ∈R. It is easily argued that μ + ν and aμ deﬁned in
this way are measures whenever μ,ν are.
The set of measures on a ﬁnite set n = {0,1,. . .,n −1} is isomorphic as a real
vector space to Rn: the mass μ(i) of the element i corresponds to the ith coordinate
of a vector in Rn in the standard basis. This perspective is well established in the
theory of Markov chains, where initial or stationary distributions are represented
as row or column vectors depending on the convention (see e.g. Norris (1997)).
Normed space structure. The second important structure carried by MS is its
norm. Combined with the vector space structure, this makes MS a Banach space.
The norm ∥μ∥of a measure μ is called the total variation norm and deﬁned by
∥μ∥≜sup
 n

i=1
|μ(Bi)| : {B1,. . ., Bn} is a ﬁnite measurable partition of S

. (1.9)
For a positive measure μ, the norm is always ∥μ∥= μ(S), and for a probability
measure, ∥μ∥= 1. In other words, probability measures lie on the boundary of the
unit ball of the space of measures. However, a general (signed) measure can assign
positive mass to some regions of S and negative mass to others, hence the idea of
partitioning the space and the presence of the absolute value in (1.9).
The total variation norm interacts with the vector space structure to make MS a
normed vector space: ∥x∥≥0, ∥x∥= 0 iﬀx = 0, ∥aμ∥= |a| ∥μ∥, and ∥μ + ν∥≤
∥μ∥+ ∥ν∥. Moreover, the normed vector space MS is complete, which means that
all Cauchy sequences of measures converge to a limit in MS. A complete normed
vector space is called a Banach space.
In the case of a ﬁnite set n, using the vector space representation of Mn described
above, the norm of a ﬁnite measure μ ∈Mn is simply the usual ℓ1-norm, sometimes
also called Manhattan or taxicab norm ∥μ∥= 	n
i=1 |μ(i)|. A probability measure
on n is thus always a vector in Rn of ℓ1-norm 1.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

1.2 Measure theory: What you need to know
13
Order structure. The ﬁnal piece of structure is a partial order. Measures have a
natural pointwise order: μ ≤ν if μ(B) ≤ν(B) for every B ∈B.
Any pair of distinct probability measures are incomparable in this order, as
μ(B) < ν(B) for a some B ∈B implies ν(Bc) < μ(Bc), where Bc is the complement
of B, since μ(B)+ μ(Bc) = 1 = ν(B)+ ν(Bc). A measure μ is positive if 0 ≤μ. The
set of all positive measures is called the positive cone of MS and denoted (MS)+.
Probability measures are of course positive measures, so the probability measures in
MS are precisely the positive measures of norm 1, and the subprobability measures
are the positive measures of norm at most 1. In other words, the subprobability
measures comprise the positive orthant of the unit ball of MS.
The partial order is compatible with the vector space structure in the sense that
• if μ ≤ν, then μ + ρ ≤ν + ρ; and
• if 0 ≤a ∈R and μ ≤ν, then aμ ≤aν.
We say that the operations of addition and multiplication by a positive scalar are
monotone. Moreover, the partial order in fact deﬁnes a lattice structure, that is to
say every pair of measures μ,ν have a least upper bound and a greatest lower bound
with respect to the partial order, deﬁned explicitly by
(μ ∨ν)(B) ≜sup {μ(A ∩B) + ν(Ac ∩B) | A ∈B}
(μ ∧ν)(B) ≜inf {μ(A ∩B) + ν(Ac ∩B) | A ∈B} .
In particular, the positive part of a measure μ can be deﬁned as μ+ = μ ∨0, and its
negative part as μ−= (−μ)∨0. Note that both μ+ and μ−are positive measures, and
in fact every measure can be decomposed as the diﬀerence of two positive measures,
since μ = μ+ −μ−. Moreover, there is a measurable set C such that μ+ = μC and
μ−= −μCc, where μC is the measure μC(A) = μ(A ∩C); equivalently, μ(B) ≥0
for all measurable sets B ⊆C and μ(B) ≤0 for all measurable sets B ⊆Cc. The set
C is essentially unique in the sense that if C′ is any other measurable set satisfying
these properties, then all measurable subsets of the symmetric diﬀerence C △C′
are μ-nullsets. This is known as the Hahn-Jordan decomposition theorem; see e.g.
(Dudley, 2002, Th. 5.6.1). The sum of the positive and negative part is called the
modulus of μ and is denoted |μ| = μ+ + μ−.
The order is compatible with the norm in the sense that |μ| ≤|ν| implies
∥μ∥≤∥ν∥. A Banach space with a lattice structure that is compatible with both the
linear and normed structures in the sense detailed above is called a Banach lattice.
Thus MS is always a Banach lattice.
In order to interpret while loops in Section 1.3.5, we will need one last order-
theoretic concept. A Banach lattice is said to be σ-order-complete or σ-Dedekind-
complete if every countable order-bounded set of measures in MS has a supremum
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

14
Dahlqvist, Kozen and Silva: Semantics of Probabilistic Programming
in MS. From the perspective of theoretical computer science, this notion is similar
to the completeness property for ω-complete partial orders (ω-CPOs) in domain
theory, the key diﬀerence being that only sets of elements with a common upper
bound are considered. In particular, the set M1  R is σ-order complete but is not
an ω-CPO, because this would require adding a point at inﬁnity, thereby losing the
vector space structure. In fact, every space of measures MS is σ-order complete.
In the case of a ﬁnite set {1,. . .,n}, the order is just the usual pointwise order
on Rn: (x1,. . ., xn) ≤(y1,. . ., yn) if xi ≤yi, 1 ≤i ≤n, and the lattice structure
on Mn  Rn simpliﬁes to (μ ∨ν)({i}) = max{μ({i}),ν({i})} and (μ ∧ν)({i}) =
min{μ({i}),ν({i})}.
Operators. One of the advantages of working with spaces of measures is that, since
they are vector spaces, we can do linear algebra on them. In the case of measure
spaces over ﬁnite sets, i.e. spaces of the form Rn, this means the usual matrix-based
linear algebra. In the general case, we have the inﬁnite-dimensional generalisation
in terms of linear operators.
A linear operator (or simply an operator) T : V →W between two vector spaces
over the reals is a map satisfying T(x + y) = T(x) + T(y) and T(ax) = aT(x) for
x, y ∈V and a ∈R. In the ﬁnite-dimensional case, if we choose bases (v1,. . .,vm)
and (w1,. . .,wn) for V and W respectively, T can be represented as an n × m matrix
T whose ijth component Tij is the jth coordinate of T(vi) in the basis of W.
We will be mostly interested in operators that send probability measures to
subprobability measures. Recall that probability measures are precisely the positive
measures of norm 1. A positive operator between Banach lattices is an operator that
sends positive vectors to positive vectors, i.e. Tv ≥0 whenever v ≥0. A stochastic
operator is a positive operator preserving the norm of positive vectors, i.e. such
that ∥Tv∥= ∥v∥whenever v ≥0. Similarly, an operator sending probabilities
to subprobabilities is characterised as a positive operator contracting the norm of
positive vectors, i.e. such that ∥Tv∥≤∥v∥whenever v ≥0.
In the case of measures over ﬁnite spaces Mn  Rn, we can represent stochastic
operators as (right) stochastic matrices, matrices with nonnegative entries whose
rows each sum to 1.1 Indeed, any operator A sending probability measures p =
(p1,. . ., pn) to probability measures must be stochastic, as the kth row of A is the
result of applying A to the Dirac delta δk:
(δk A)j =
n

i=1
δk(i)Aij = Ak j.
1 We follow the convention adopted in the literature on Markov chains, where measures are represented as row
vectors and operators are applied from the right (hence "right stochastic").
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

1.3 Semantics of a simple imperative probabilistic language
15
1.3 Semantics of a simple imperative probabilistic language
Now we are ready to give the formal semantics of a simple imperative programming
language with two types of probabilistic operations: a function sampling from a
Bernoulli distribution with parameter p = 1/2, and a function sampling from the
uniform distribution on the interval [0,1]. This simple language will cover the
examples in Figs. 1.1, 1.2, 1.3, and 1.4.
1.3.1 Syntax
We start by deﬁning the syntax of the language.
(i) Deterministic terms:
d ::= a
a ∈R, constants
| x
x ∈Var, a countable set of variables
| d op d
op ∈{+,−,∗,÷}
(ii) Terms:
t ::= d
d a deterministic term
| coin() | rand()
sample in {0,1} and [0,1], respectively
| t op t
op ∈{+,−,∗,÷}
(iii) Tests:
b ::= true | false
| d == d | d < d | d > d
comparison of deterministic terms
| b && b | b || b | !b
Boolean combinations of tests
(iv) Programs:
e ::= skip
| x := t
assignment
| e ; e
sequential composition
| if b then e else e
conditional
| while b do e
while loop
Remark 1.2
We disallow probabilistic terms in tests for simplicity in the pre-
sentation. This restriction is without loss of generality, as one could consider such
expressions as syntactic sugar; the probabilistic term can always be removed using
auxiliary variables. For example, the right-hand program below is the de-sugared
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

16
Dahlqvist, Kozen and Silva: Semantics of Probabilistic Programming
version of the left-hand program using a fresh auxiliary variable x:
if coin() == 1 then e1 else e2
x := coin() ; if x == 1 then e1 else e2
1.3.2 Operational versus denotational semantics
As we outlined in the introduction, the main purpose of this chapter is to deﬁne
a formal mathematical interpretation—a semantics—for probabilistic programs.
Having a semantics provides the tools necessary to reason about the properties of
programs, as we will show with a few concrete examples. However, the focus of
this chapter will primarily be on deﬁning the semantics itself.
We will present two classical types of semantics: operational and denotational.
The purpose of operational semantics is to model the step-by-step executions of the
program on a machine. It will model the evolution of the state of the machine de-
scribed by its memory-state, the values assigned to each variable and to each random
number generator in a program, together with a stack of instructions. On the other
hand, the purpose of denotational semantics is to model the intended mathematical
meaning of a probabilistic program in terms of probability distributions.
1.3.3 Operational semantics of probabilistic programs
The random number generator coin() is represented by an independent and iden-
tically distributed (i.i.d.) sequence of random variables distributed according to
the Bernoulli distribution on {0,1} with parameter p = 1/2. Similarly, rand()
is represented by an i.i.d. sequence distributed according to the uniform distribu-
tion on [0,1]. When a program runs, we ﬁx at the beginning two inﬁnite streams
m0m1m2 · · · and p0p1p2 · · · , where each mi ∈{0,1} is an independent sample from
the Bernoulli distribution with p = 1/2 and each pi ∈[0,1] is an independent
sample from the uniform distribution on [0,1]. Intuitively, these sequences rep-
resent inﬁnite stacks of random numbers that are available to the program. Each
time the function coin() or rand() is called, the next random number is popped
from the stack. We use the auxiliary head and tail functions hd(m0m1m2 · · · ) = m0
and tl(m0m1m2 · · · ) = m1m2m3 · · · to implement this. This deterministic behaviour
reﬂects the behaviour of pseudo-random number generators which, given a seed,
deterministically generate such sequences (or to be precise, seemingly random
cyclical sequences with very long periods).
Given a program containing n variables {x1,. . ., xn}, as described in Sec-
tion 1.3.1, a memory-state is modelled as a triple (s,m, p) consisting of a store
s: n →R and a pair of inﬁnite streams m ∈{0,1}ω and p ∈[0,1]ω representing the
current streams of available random digits. A machine-state is a 4-tuple (e, s,m, p),
where e corresponds to a stack of instructions and (s,m, p) is a memory-state.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

1.3 Semantics of a simple imperative probabilistic language
17
We can now deﬁne the operational semantics of our language. The operational
semantics is deﬁned in terms of a single-step reduction relation (e, s,m, p) −→
(e′, s′,m′, p′) between machine-states. The reduction relation describes the step-
by-step evaluation of a program and its corresponding eﬀect on the state of the
machine. The reﬂexive transitive closure of this relation will be denoted
∗
−→and
will be used to talk about multi-step transitions.
In order to deﬁne the reduction relation, we ﬁrst deﬁne the semantics of terms.
Each term t will be interpreted as a function
[[t]]: Rn × Nω × Nω →R × Nω × Nω.
Intuitively, the value of [[t]] on (s,m, p) is a triple (a,m′, p′), where a is the real value
of the term and m′ and p′ are the new stacks of random numbers. Formally, [[t]] is
deﬁned inductively:
[[r]] : (s,m, p) →(r,m, p)
[[xi]] : (s,m, p) →(s(i),m, p)
[[coin()]] : (s,m, p) →(hd m,tl m, p)
[[rand()]] : (s,m, p) →(hd p,m,tl p)
[[t1 op t2]] : (s,m, p) →let (a1,m′, p′) = [[t1]](s,m, p) in
let (a2,m′′, p′′) = [[t2]](s,m′, p′) in
(a1 op a2,m′′, p′′)
where op ∈{+,−,∗,÷}. In other words, we evaluate t1 ﬁrst, which produces a value
a1 but might consume some values from m and p, popping those stacks to leave m′
and p′; these new stacks are then used in the evaluation of t2, which in turn changes
them to m′′ and p′′ and yields a value a2. The values a1 and a2 are combined with
the appropriate arithmetic operation, and that is returned with the stacks m′′ and
p′′.
There is already an interesting question to consider. Note that we are evaluating
t1 op t2 from left to right, i.e. starting with t1. This is an arbitrary decision. Would
evaluation from right to left be equally valid? It clearly would not always give
the same value; e.g., the program rand() ÷ rand() evaluated on (s,m,(.2,.5, p))
from left to right would give (.4,m, p), but evaluated from right to left would
give (2.5,m, p). However, perhaps surprisingly, the two methods of evaluation are
probabilistically equivalent, which means they give the same values with equal
probability. The denotational semantics to be given below will allow us to reason
more easily about such facts.
We now deﬁne the semantics of tests. Each test b will be interpreted as a function
[[b]]: Rn × Nω × Nω →{true,false}
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

18
Dahlqvist, Kozen and Silva: Semantics of Probabilistic Programming
deﬁned inductively by
[[t1 == t2]] : (s,m, p) →

true
if [[t1]](s,m, p) = [[t2]](s,m, p)
false
otherwise
[[t1 < t2]] : (s,m, p) →

true
if [[t1]](s,m, p) < [[t2]](s,m, p)
false
otherwise
[[t1 > t2]] : (s,m, p) →

true
if [[t1]](s,m, p) > [[t2]](s,m, p)
false
otherwise
[[b1 && b2]] : (s,m, p) →[[b1]](s,m, p) ∧[[b2]](s,m, p)
[[b1 || b2]] : (s,m, p) →[[b1]](s,m, p) ∨[[b2]](s,m, p)
[[!b]] : (s,m, p) →¬[[b]](s,m, p)
where ∧,∨and ¬ are the usual Boolean operations on {true,false}. Note that in
the deﬁnition of the three base cases above, m, p are arguments of both [[t1]] and
[[t2]], unlike in the semantics of terms. This is because we only allow deterministic
terms in tests, thus [[t1]] does not consume any random numbers, leaving the stacks
m, p unchanged for the evaluation of [[t2]]. For the same reason, it is unnecessary to
include m, p in the output of [[b]].
We can now deﬁne the reduction relation −→. The relation is given by the rules
gathered in Table 1.1. We use the traditional notation s[i →l] to denote the n-tuple
deﬁned exactly as s apart from at position i where value l is used instead. We will
say that the execution of a program e terminates from the memory-state (s,m, p) if
there exists a memory-state (s′,m′, p′) such that
(e, s,m, p)
∗
−→(skip, s′,m′, p′).
We will say that a program e diverges from a state (s,m, p) if it does not terminate.
1.3.4 Operational semantics through examples
To illustrate how the system described above works concretely, let us examine the
operational semantics of the programs described in Section 1.1.
Example 1: A simple Markov chain
We start with the very simple program displayed in Fig. 1.1. Using the rule
for assignments, the rule for sequential composition and the deﬁnition of the
reﬂexive transitive closure
∗
−→we get the following derivation, where for nota-
tional convenience we write e for while x == 0 do x := coin():
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

1.3 Semantics of a simple imperative probabilistic language
19
Assignment:
[[t]](s,m, p) = (a,m′, p′)
(xi := t, s,m, p) −→(skip, s[i →a],m′, p′)
Sequential composition:
(e1, s,m, p) −→(e′
1, s′,m′, p′)
(e1 ; e2, s,m, p) −→(e′
1 ; e2, s′,m′, p′)
(skip ; e, s,m, p) −→(e, s,m, p)
Conditional:
[[b]](s,m, p) = true
(if b then e1 else e2, s,m, p) −→(e1, s,m, p)
[[b]](s,m, p) = false
(if b then e1 else e2, s,m, p) −→(e2, s,m, p)
while loops:
(while b do e, s,m, p) −→(if b then (e ; while b do e) else skip, s,m, p)
Reﬂexive-transitive closure:
(e, s,m, p)
∗
−→(e, s,m, p)
(e1, s1,m1, p1) −→(e2, s2,m2, p2)
(e1, s1,m1, p1)
∗
−→(e2, s2,m2, p2)
(e1, s1,m1, p1)
∗
−→(e2, s2,m2, p2)
(e2, s2,m2, p2)
∗
−→(e3, s3,m3, p3)
(e1, s1,m1, p1)
∗
−→(e3, s3,m3, p3)
Table 1.1 Rules of the operational semantics
(x := 0, s, m, p) −→(skip, s[x →0], m, p)
(x := 0 ; e, s, m, p) −→(skip ; e, s[x →0], m, p)
(x := 0 ; e, s, m, p)
∗
−→(skip ; e, s[x →0], m, p)
(skip ; e, s[x →0], m, p) −→(e, s[x →0], m, p)
(skip ; e, s[x →0], m, p)
∗
−→(e, s[x →0], m, p)
(x := 0 ; e, s, m, p)
∗
−→(e, s[x →0], m, p)
We now turn our attention to (e, s[x →0],m, p). Using the rule for while loops
and conditionals we get (using the same deﬁnition of e as above)
(e, s[x →0],m, p)
∗
−→(x := coin() ; e, s[x →0],m, p)
(1.10)
since [[x == 0]](s[x →0],m, p) = true. We now encounter our ﬁrst probabilistic
behaviour:
(x := coin() ; e, s[x →0],m, p)
∗
−→(e,[s →hd m],tl m, p).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

20
Dahlqvist, Kozen and Silva: Semantics of Probabilistic Programming
If hd m = 0, then s does not change, and we are back at the left-hand state of (1.10),
but with tl m instead of m. This same sequence of steps continues until encountering
a suﬃx of m of the form 1m′, at which time, combining the rule for while loops and
conditionals, we get
(e, s[x →1],m′, p)
∗
−→(skip, s[x →1],m′, p)
since [[x == 0]](s[x →1],m′, p) = false. If no such suﬃx 1m′ exists, then (1.10)
continues forever. We can conclude that
(x := 0 ; e, s,m, p)
∗
−→(skip, s[x →1],m′, p)
for some m′, that is, the program terminates in some state (s[x →1],m′, p) when
started in state (s,m, p), if and only if there exists a suﬃx of m of the form 1m′, that
is, there exist k ≥0 and m′ ∈{0,1}ω such that m = 0k1m′. We can compute the
probability of termination with a simple calculation:
P

∃m′ (x := 0 ; e, s,m, p)
∗
−→(skip, s[x →1],m′, p)

= P

∃k ≥0 ∃m′ m = 0k1m′
=
∞

k=1
2−k = 1
as claimed in the introduction.
Example 2: A random walk on Z2
We now turn our attention to the program of Fig. 1.2, which implements a random
walk on the set Z2. We show fewer details, since the previous example already
described some of the simplest derivations. The program is written with the function
step for readability and notational convenience, but it is of course equivalent to the
inline program where each instance of step in main is substituted by its deﬁnition.
For any s ∈R4 and m, p ∈N, there can be one of four actions:
(step, s,00m, p)
∗
−→(skip, s[(u,v) →(0,−1),(x,y) →(0,0)],m, p)
(step, s,01m, p)
∗
−→(skip, s[(u,v) →(−1,0),(x,y) →(0,1)],m, p)
(step, s,10m, p)
∗
−→(skip, s[(u,v) →(1,0),(x,y) →(1,0)],m, p)
(step, s,11m, p)
∗
−→(skip, s[(u,v) →(0,1),(x,y) →(1,1)],m, p)
The probability of each of these outcomes is 1/4, and in all cases the program enters
the loop, since [[!(u == 0) || !(v == 0)]] = true.
Now deﬁne the i.i.d. random variables X1, X2,. . . on Z2 such that each Xi takes
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

1.3 Semantics of a simple imperative probabilistic language
21
one of the values (0,1),(0,−1),(1,0),(−1,0), each with probability 1/4, as well as
the random variables
Sn =
n

i=1
Xi
where the sum is the usual componentwise sum on Z2. With these deﬁnitions in
place, and since the loop is entered at least once, the ﬁrst few steps of the reduction
relation give
(main, s,m, p)
∗
−→
(while !(u == 0) || !(v == 0) do step(u,v), s[(u,v) →(i, j)],tl4(m), p)
where (i, j) is distributed according to S2 and the tl4(m) indicates that four random
bits were consumed. The program will exit the loop if there exists n such that
S2n = (0,0); the factor 2 is because a return to 0 is only possible after an even
number of calls to the function step. If such an n exists, then the rule for while
loops gives
(main, s,m, p)
∗
−→(skip, s[(u,v) →(0,0)],tl4n(m), p).
It follows that to compute the probability that the program terminates amounts to
computing
P

∃n (main, s,m, p)
∗
−→(skip, s[(u,v) →(0,0)],tl4n(m), p)

= P
 ∞

n=0
S2n = (0,0)

(1.11)
In order for S2n = (0,0), there must exist m such that the walk performed m steps
up, m steps down, n −m steps left and n −m steps right. Following Durrett (1996),
P [S2n = (0,0)] = 4−2n
n

m=0
(2n)!
m!m!(n −m)!(n −m)!
= 4−2n
2n
n

n

m=0
n
m
2
= 4−2n
2n
n
2
.
(1.12)
Since the events S2n = (0,0) for n ∈N are not disjoint—one can return to (0,0)
twice in 2n steps if n > 1—one cannot simply sum these contributions to get the
probability of termination as we did in the previous example. However, it can be
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

22
Dahlqvist, Kozen and Silva: Semantics of Probabilistic Programming
shown that
∞

n=0
P [S2n = (0,0)] =
∞

m=0
P
 ∞

n=0
S2n = (0,0)
m
,
(1.13)
as both expressions describe the expected number of visits to the origin in an
inﬁnite random walk (Durrett, 1996, Ch. 3, Thm. 2.2). Moreover, using Stirling's
approximation with (1.12), it can be shown that the sums in (1.13) diverge (Durrett,
1996, Ch. 2, Thm. 1.4), which occurs iﬀthe probability (1.11) is 1; that is, the
program of Fig. 1.2 terminates with probability one. However, the expected time to
termination is inﬁnite: in probabilistic terms, the random walk on Z2 is recurrent
but not positively recurrent.
Example 3: Probabilistic computation of π
The program given in Fig. 1.3 is diﬀerent from the previous two examples in several
ways. First of all, it samples from a continuous distribution, therefore relies on the
full power of measure theory. Secondly, it clearly terminates, so the question this
time is not to determine the probability of termination, but rather to evaluate the
correctness of the program. Considering the intended purpose of the program,
which is to compute an approximation of π, the question we will answer is the
following: Given an error tolerance ε > 0, what is the probability that the ﬁnal
numerical value of pi is within ε of π?
Let N = 1e9 (one billion), the number of iterations of the loop. It is not diﬃcult
to see that, starting from a state (s,m, p), the program halts in a state
(prog, s,m, p)
∗
−→(skip, s[i →4n/N,n →n,. . .],m,tl2N(p))
for some integer 0 ≤n ≤N. The value n/N is the average of N samples of the
random variable
Z =

1
if X2 + Y2 < 1
0
else
where X and Y are independent random variables distributed uniformly on [0,1].
Let us compute the expected value of Z. First, it is easy to compute the density
function for X2 (and thus Y2):
P

X2 ≤t

= P

X ≤
√
t

=
∫√t
0
1[0,1](x) dx =
√
t
for 0 ≤t ≤1. The density of X2 is thus given by
f (t) =
∂P

X2 ≤t

∂t
=
1
2√t
1[0,1](t)
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

1.3 Semantics of a simple imperative probabilistic language
23
It is well known that the density of the sum of two independent distributions is
given by the convolution of their densities, i.e.
( f ∗f )(t) =
∫∞
−∞
1
2√x 1[0,1](x)
1
2√t −x
1[0,1](t −x) dx
=
⎧⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩
∫t
0
1
4√x√t −x
dx
if 0 ≤t ≤1
∫1
t−1
1
4√x√t −x
dx
if 1 < t ≤2
Since we are only interested in computing P

X2 + Y2 ≤1

, we need only compute
the ﬁrst expression above, which under the substitution u =

x/t yields:
∫t
0
1
4√x√t −x
dx =
∫1
0
1
2
√
1 −u2 du = 1
2(sin−1(1) −sin−1(0)) = π
4 .
Thus
P

X2 + Y2 ≤1

=
∫1
0
( f ∗f )(t) dt =
∫1
0
π
4 dt = π
4 .
We have therefore computed that Z is a Bernoulli variable with probability of
success π/4. In particular, its variance is σ2 = π/4 −(π/4)2. We can now use
Chebyshev's inequality to get:
P
 n
N −π
4
 > ε

≤σ2
Nε2 .
For example, for ε = 0.0005 and N = 1e9, the program outputs an approximation
of π which is correct up to 2 signiﬁcant digits with probability greater than 99.9%.
In terms of the operational semantics, we can write the probability of the informal
Hoare triple
P

{} (prog, s,m, p)
∗
−→(skip, s′,m′, p′) {s′(i) ∈[3.139,3.144]}

≥0.999.
We will show in Section 1.3.6 that much tighter bounds can be obtained using a
more sophisticated inequality than Chebyshev's inequality.
Example 4: The Cantor distribution
The ﬁnal example given in Fig. 1.4 constructs a curious object know as the Cantor
distribution. This is a distribution on [0,1] that has uncountable support (it is
therefore continuous), yet this support has Lebesgue measure (that is to say length)
zero. It is an example of a so-called singular distribution.
A simple look at the program given by Fig. 1.4 shows that it does not terminate.
However, it is possible to give it an operational (and denotational) semantics.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

24
Dahlqvist, Kozen and Silva: Semantics of Probabilistic Programming
Starting from an initial conﬁguration (s,m, p) where m = m0m1m2 · · · , it is not
diﬃcult to see from the rules of the operational semantics that the program generates
an the inﬁnite sequence
(x := 0; d := 1; w, s,m, p)
∗
−→
(w, s [x →0,d →1],m, p)
∗
−→
(w, s

x →2m0
3 ,d →1
3

,tl(m), p)
∗
−→
(w, s

x →
k

i=1
2mi−1
3i
,d →1
3k

,tlk(m), p)
∗
−→· · ·
(1.14)
The program can thus be understood as generating a random real number between
0 and 1 whose base-3 expansion does not contain any ones. After k iterations of the
loop, the probability that the base-3 expansion of the number is given by a particular
sequence a1 · · · ak, where ai ∈{0,2}, is 2−k. We now show how this interpretation
of the program relates to the Cantor measure.
We ﬁrst look at a σ-algebra. For a1 · · · ak ∈{0,1,2}k, each set
Ca1···ak := {x ∈[0,1] | the base-3 expansion of x starts with a1 · · · ak}
is a measurable set for the usual σ-algebra on [0,1]. Moreover, it can be shown that
the σ-algebra generated by all these sets is in fact the usual σ-algebra on [0,1].
With the σ-algebra in place, we can deﬁne a measure. Following the behaviour
of the program above, it makes sense to deﬁne
μ(Ca1···ak) =

2−k
if a1 · · · ak ∈{0,2}k
0
otherwise.
(1.15)
It can be shown that this deﬁnition extends to the entire σ-algebra on [0,1], thereby
deﬁning a bona ﬁde measure (in the same way that the deﬁnition of the product
measure on rectangles extends to the entire product σ-algebra, see Section 1.2.2).
This measure is the Cantor measure, which we shall denote by κ. Note that for any
x ∈[0,1], the probability of any singleton must satisfy κ({x}) ≤2−k for all k, thus
κ({x}) = 0 and the Cantor measure is therefore continuous. If the base-3 expansion
of x contains a 1, the inequality above is trivially satisﬁed. If it does not, it follows
from the fact that {x} ⊆Ca1···ak, where a1 · · · ak consists of the ﬁrst k digits in the
base-3 expansion of x. It can also be shown that the set
C = {x ∈[0,1] | the base-3 expansion of x has no ones}
has Lebesgue measure 0, but Cantor measure 1. This set, called the Cantor set, is
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

1.3 Semantics of a simple imperative probabilistic language
25
clearly in one-to-one correspondence with the set of possible traces described by
the operational semantics described by (1.14).
1.3.5 Denotational semantics of probabilistic programs
Consider the simple program x := coin(). As we have just seen, the operational se-
mantics models the two possible machine-state transitions deﬁned by this program,
viz.
(x := coin(), s,m, p) −→(skip, s[x →0],tl m, p)
(x := coin(), s,m, p) −→(skip, s[x →1],tl m, p)
depending on the value of hd m, each associated with the probability 1/2. Thus two
possible executions are explored separately. The denotational approach explores
both possibilities simultaneously. It does so by changing the notion of state. Opera-
tionally, a state is a machine state, i.e. a mathematical representation of the memory
state and of the stack of instructions. Denotationally, a state is a probability distribu-
tion over memory states. The two possible memory states s[x →0] and s[x →1],
which correspond operationally to two distinct executions, are combined into a
single state 1
2s[x →0] + 1
2s[x →1]. As a consequence, the program x := coin()
can be interpreted as the operation which associates to a state s the distribution over
states 1
2s[x →0] + 1
2s[x →1].
More generally, since a state s can be identiﬁed with the Dirac measure δs (see
Section 1.2.2), the denotational semantics will view the program x := coin() as
an operator (we will justify this term in a moment) which maps the probability
distribution δs to the probability distribution 1
2s[x →0] + 1
2s[x →1]. This is the
essence of the denotational perspective: a program is interpreted as an operator
mapping probability distributions to (sub)probability distributions. It follows that
denotationally, a program has a single trace (or execution) for a given input, but
this trace keeps track of all possible memory state transitions and their probabilities
simultaneously. It also follows that an input state could be a nontrivial distribution,
for example 1
2s[x →0]+ 1
2s[x →1] could be an input for the program x := coin().
We now formalize the intuition given above following Kozen (1981). Given a
program obeying the syntax of Section 1.3.1 and containing n variables {x1,. . ., xn}
ranging over R, a state will be modelled as a probability distribution μ on Rn and
a program e will be interpreted as an operator [[e]]: MRn →MRn called a state
transformer. To deﬁne this interpretation formally, we start with the semantics of
terms. Each term t denotes a map [[t]]: Rn →MR deﬁned inductively as follows.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

26
Dahlqvist, Kozen and Silva: Semantics of Probabilistic Programming
Here ai represents the value of the variable xi, 1 ≤i ≤n.
[[r]](a1,. . .,an) = δr, r ∈R
[[xi]](a1,. . .,an) = δai
[[coin()]](a1,. . .,an) = 1
2δ0 + 1
2δ1
[[rand()]](a1,. . .,an) = λ
[[t1 op t2]](a1,. . .,an) = op∗([[t1]](a1,. . .,an) ⊗[[t2]](a1,. . .,an))
where op ∈{+,−,×,÷} and λ is the Lebesgue (uniform) measure on [0,1]. Re-
call that μ ⊗ν is the product of the measures μ and ν and that op∗denotes the
pushforward operation (see Section 1.2.2). In this case, [[t1]](a1,. . .,an) ∈MR and
[[t2]](a1,. . .,an) ∈MR, [[t1]](a1,. . .,an)⊗[[t2]](a1,. . .,an) ∈M(R2), op: R2 →R,
and op∗: M(R2) →MR. By deﬁnition, for B a measurable subset of R,
op∗([[t1]](a1,. . .,an) ⊗[[t2]](a1,. . .,an))(B)
= [[t1]](a1,. . .,an) ⊗[[t2]](a1,. . .,an)

(u,v) ∈R2 | u op v ∈B

.
It follows almost immediately from this deﬁnition that:
Proposition 1.3
The denotational semantics of any term is a Markov kernel
Rn →MR.
The denotational semantics of tests is given by subsets of Rn deﬁned inductively
as follows:
[[t1 == t2]] = {(a1,. . .,an) ∈Rn | [[t1]](a1,. . .,an) = [[t2]](a1,. . .,an)}
[[t1 < t2]] = {(a1,. . .,an) ∈Rn | [[t1]](a1,. . .,an) < [[t2]](a1,. . .,an)}
[[t1 > t2]] = {(a1,. . .,an) ∈Rn | [[t1]](a1,. . .,an) > [[t2]](a1,. . .,an)}
[[b1 && b2]] = [[b1]] ∩[[b2]]
[[b1 || b2]] = [[b1]] ∪[[b2]]
[[!b]] = [[b]]c.
Note that since we limit ourselves to deterministic guards, the comparisons in the
right-hand side of the ﬁrst three cases above are between Dirac deltas, thus between
elements of Rn, as one would expect. It is not hard to show the following result:
Proposition 1.4
The denotational semantics of any test is a measurable subset of
Rn.
Each measurable subset B ⊆Rn deﬁnes a linear operator TB : MRn →MRn
deﬁned as
TB(μ)(C) = μ(B ∩C).
(1.16)
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

1.3 Semantics of a simple imperative probabilistic language
27
In particular, every test deﬁnes such an operator. Note that the operator TB does
not in general send probability distributions to probability distributions, since the
mass outside of B is lost. Thus TB sends probability distributions to sub-probability
distributions, that is to say measures whose total mass is at most 1.
We can now deﬁne the denotational semantics of programs. Programs will be
interpreted as (linear) operators MRn →MRn. The inductive deﬁnition is as
follows:
(i) [[skip]] = IdMRn : MRn →MRn, the identity operator μ →μ.
(ii) Assignments: Prop. 1.3 interprets terms t as Markov kernels [[t]] : Rn →MR.
Given such a term t and an index 1 ≤i ≤n, we deﬁne the Markov kernel
Fi
t : Rn →MRn as
Fi
t (x1,. . ., xn) = δx1 ⊗. . . ⊗δi−1 ⊗[[t]](x1,. . ., xn) ⊗δxi+1 ⊗. . . ⊗δxn
Using this deﬁnition, we deﬁne [[xi := t]] as the operator
[[xi := t]](μ) = (Fi
t )∗(μ)
(1.17)
where (Fi
t )∗is the pushforward of Markov kernels deﬁned in (1.8). It is useful to
consider special cases of this formula. Consider ﬁrst the expression xi := r for
some constant r ∈R. The deﬁnition above becomes
[[xi := r]](μ)(B1 × · · · × Bn)
=
∫
Rn δx1 ⊗· · · ⊗δxi−1 ⊗δr ⊗δxi+1 ⊗· · · ⊗δxn(B1 ⊗· · · ⊗Bn) dμ
=
∫
Rn δx1(B1) · · · δxi−1(Bi−1)δr(Bi)δxi+1(Bi+1) · · · δxn(Bn) dμ
= μ(B1 × · · · × Bi−1 × R × Bi+1 × · · · × Bn)δr(Bi).
Similarly, for xi := coin() we get
[[xi := coin()]](μ)(B1 × · · · × Bn)
= μ(B1 × · · · × Bi−1 × R × Bi+1 × · · · × Bn)
1
2δ0 + 1
2δ1

(Bi).
(iii) [[e1 ; e2]] = [[e2]] ◦[[e1]], the usual composition of operators.
(iv) if b then e1 else e2 is the operator deﬁned by
[[if b then e1 else e2]] = [[e1]] ◦T[[b]] + [[e2]] ◦T[[b]]c
(1.18)
where T[[b]] and T[[b]]c are deﬁned as in (1.16).
(v) To deﬁne the semantics of while loops, we use the equivalence of the following
two programs,
while b do e
if b then (e ; while b do e) else skip,
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

28
Dahlqvist, Kozen and Silva: Semantics of Probabilistic Programming
to write a ﬁxpoint equation which will deﬁne the semantics of [[while b do e]].
Formally, and following (1.18), the equivalence of programs above implies that
[[while b do e]] = [[while b do e]] ◦[[e]] ◦T[[b]] + T[[b]]c
We therefore deﬁne [[while b do e]] to be the least ﬁxpoint of the transformation
on operators deﬁned by
τ(S) = S ◦[[e]] ◦T[[b]] + T[[b]]c
(1.19)
This least ﬁxpoint can be constructed explicitly by the familiar construction
[[while b do e]] =

n≥0
τn(0) =
∞

k=0
T[[b]]c ◦ [[e]] ◦T[[b]]
!k ,
(1.20)
invoking the fact that countable norm-bounded directed sets have suprema and
that τ preserves such suprema.
Theorem 1.5
The denotational semantics of any program given by the syntax of
Section 1.3.1 is a positive operator of norm at most one.
A comment on non-terminating programs
As we will see when examining the Cantor program (see Fig. 1.4) in Section 1.3.6,
the construction of the least ﬁxpoint via Eq. (1.20) returns the constant linear
operator 0 for non-terminating programs of the form
while true do e.
This is in complete agreement with what happens in the formalism of Kleene
Algebras with Tests (Kozen, 1997) where the following equivalence holds:
while true do e ≜(true; e)∗; false = false.
Here, false is the program that always aborts corresponding to the constant linear
operator 0.
Recall that we also saw in Section 1.3.4 that the Cantor program can be given a
non-trivial operational semantics in terms of inﬁnite traces. How can we reconcile
these two seemingly conﬂicting semantics?
There are (at least) two ways. The ﬁrst is to declare that inﬁnite traces are
not valid, and identify diverging executions with a crash behaviour. The second,
mathematically much more interesting solution, is not to consider the least ﬁxpoint
solution to the equation τ(S) = S (where τ is deﬁned in Eq. (1.19)), but another
ﬁxpoint given by the mean ergodic theorem. When the guard of the while loop
is true, Eq. (1.19) simpliﬁes to τ(S) = S ◦[[e]]. Now suppose for simplicity's
sake that e does not contain any while loop, and note that by Theorem 1.5 [[e]] :
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

1.3 Semantics of a simple imperative probabilistic language
29
MRn →MRn is a is a positive operator of norm at most one. It can be shown (see
e.g. Dunford et al., 1971; Eisner et al., 2015) that [[e]] is mean ergodic, that is to say
that for any measure μ ∈Rn the limit
P[[e]](μ) ≜lim
n→∞
1
n
n−1

j=0
[[e]]j(μ)
(1.21)
exists. Moreover, P[[e]] is a projection MRn →ﬁx([[e]]), the subspace of [[e]]-
invariant measures, and satisﬁes the ﬁxpoint equation deﬁning the while loop:
τ  P[[e]]
! = P[[e]] ◦[[e]] = P[[e]].
This provides an alternative ﬁxpoint semantics in the case of the non-terminating
while true program, which is the denotational counterpart to the operational se-
mantics in terms of inﬁnite traces. In fact, it would be tempting to decompose the
semantics of any while loop into its terminating component, deﬁned via the least
ﬁxpoint construction of Eq. (1.20), and its non-terminating component, deﬁned via
the mean ergodic theorem as we have just described. We leave this possibility to be
explored in future work.
1.3.6 Denotational semantics through examples
Example 1: Simple Markov chain
We start by looking at the very simple program of Fig. 1.1. Since it contains a single
variable, its denotational semantics is given by an operator
[[x := 0 ; while x == 0 do x := coin()]] : MR →MR
which we compute compositionally, that is to say line-by-line. Following the deﬁ-
nition of the denotational semantics of assignments given in the previous section,
the ﬁrst line of the program is interpreted as:
[[x := 0]]: MR →MR
μ →μ(R)δ0,
since [[0]] = δ0. Note how the presence of the term μ(R) is what makes this operator
linear: the constant function μ →δ0—which might be a tempting semantics for
assignments—would not be linear; assignments must be weighted by the total mass
of the input measure. Analogously, we have
[[x := coin()]]: MR →MR
μ →μ(R)(1
2δ0 + 1
2δ1).
Next, we evaluate the interpretation of the while loop using (1.20). It is easy
to see from the deﬁnition that the denotation of the test [[x == 0]] is simply the
measurable singleton {0}. Now consider the ﬁrst two nonzero terms in the join of
(1.20):
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

30
Dahlqvist, Kozen and Silva: Semantics of Probabilistic Programming
τ0(0)(μ) = 0
τ1(0)(μ) = T{0}c(μ) = μ(−∩{0}c)
τ2(0)(μ) =  T{0}c + T{0}c ◦[[x := coin()]] ◦T{0}
! (μ)
= μ(−∩{0}c) + μ({0})
2
δ1.
One can show by induction that
τk(0)(μ) = μ(−∩{0}c) +
k−1

i=1
μ(0)
2i δ1
= μ(−∩{0}c) + (1 −2−(k−1))μ({0})δ1,
which for positive μ is an increasing sequence with limit μ(−∩{0}c) + μ({0})δ1. It
follows that [[while x == 0 do x := coin()]]: MR →MR is the operator deﬁned
by
μ →μ(−∩{0}c) ∩μ({0})δ1 = μ({0,1})δ1 + μ(−∩{0,1}c).
The interpretation of the entire program is now obtained by operator composition:
[[x := 0 ; while x == 0 do x := coin()]]: MR →MR
μ →μ(R)δ1.
In other words, given any input measure, the program outputs the Dirac delta over 1
up to the scalar factor required to make the operator linear. In particular, if the input
is a probability distribution, then the output is simply δ1, which is clearly consistent
with the behaviour of the Markov chain of Fig. 1.1.
Example 2: Random walk on Z2
We start by computing the semantics of step. Since there are four variables u,v,x,y,
we will get an operator MR4 →MR4 (assume that the variables are ordered
alphabetically; i.e., u corresponds to the ﬁrst component of R4, etc.) Working line-
by-line, we get
(1) [[x := coin()]]: MR4 →MR4
μ →λ(B1 × B2 × B3 × B4).μ(B1 × B2 × R × B4)
1
2δ0 + 1
2δ1

(B3)
(2) [[x := coin() ; y := coin()]]: MR4 →MR4
μ →λ(B1 × B2 × B3 × B4).
μ(B1 × B2 × R × R)
1
2δ0 + 1
2δ1

(B3)
1
2δ0 + 1
2δ1

(B4)
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

1.3 Semantics of a simple imperative probabilistic language
31
(3) [[x := coin() ; y := coin() ; u := u + (x −y)]]: MR4 →MR4
μ →λ(B1 × B2 × B3 × B4).
∫
R4 δu+(x−y)(B1)δv(B2)δx(B3)δy(B4) d[[x := coin() ; y := coin()]](μ)
= μ(R4)
1
4 μ(B1 × B2 × R2)δ0(B3)δ0(B4)
+1
4 μ(B1 −1 × B2 × R2)δ0(B3)δ1(B4)
+1
4 μ(B1 + 1 × B2 × R2)δ1(B3)δ0(B4)
+1
4 μ(B1 × B2 × R2)δ1(B3)δ1(B4)

(4) [[x := coin() ; y := coin() ; u := u + (x −y) ; v := v + (x + y −1)]]:
MR4 →MR4
μ →λ(B1 × B2 × B3 × B4).μ(R4)
1
4 μ(B1 × B2 −1 × R2)δ0(B3)δ0(B4)
+ 1
4 μ(B1 −1 × B2 × R2)δ0(B3)δ1(B4)
+ 1
4 μ(B1 + 1 × B2 × R2)δ1(B3)δ0(B4)
+1
4 μ(B1 × B2 + 1 × R2)δ1(B3)δ1(B4)

where B1 + 1 = {x + 1 | x ∈B1} and similarly for the other combinations. It now
follows that
[[u := 0 ; v := 0 ; step(u,v)]](μ)(B1 × B2 × B3 × B4)
= μ(R4)
4
(δ0(B1)δ−1(B2)δ0(B3)δ0(B4) + δ−1(B1)δ0(B2)δ0(B3)δ1(B4)
+ δ1(B1)δ0(B2)δ1(B3)δ0(B4) + δ0(B1)δ1(B2)δ1(B3)δ1(B4)),
(1.22)
where each summand corresponds to one of the four possible execution paths. This
will be the input distribution to the operator denoted by the while loop. Let us now
compute this operator. For notational clarity, we write
E ≜[[!(u == 0) || !(v == 0)]]c = {0} × {0} × R × R
As in the previous example, we look at the ﬁrst terms of the formula (1.20).
TE
TE + TE ◦[[step]] ◦TE c
TE + TE ◦[[step]] ◦TE c + TE ◦([[step]] ◦TE c)2
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

32
Dahlqvist, Kozen and Silva: Semantics of Probabilistic Programming
For notational clarity, we consider measurable rectangles of the form A × B, where
A, B are measurable subsets of R2 corresponding to events involving the variables
u,v and x,y, respectively. For such an A × B ⊆R4, we have
TE(μ)(A × B) = μ((A × B) ∩E) = δ(0,0)(A)μ({(0,0)} × B).
This is the probability that the while loop exits immediately. Similarly,
TE ◦[[step]] ◦TE c(μ)(A × B)
= δ(0,0)(A)[[step]] ◦TE c(μ)((0,0) × B)
= δ(0,0)(A)
4
(μ((0,−1) × R2)δ(0,0)(B) + μ((−1,0) × R2)δ(0,1)(B)
+ μ((1,0) × R2)δ(1,0)(B) + μ((0,1) × R2))δ(1,1)(B)
where we have omitted curly brackets around singletons for readability's sake, i.e.
(1,0) stands for {(1,0)}, etc. We can already see that μ is evaluated at the points of
Z2 which can reach (0,0) in exactly one step. Similarly, we have
TE ◦[[step]] ◦TE c ◦[[step]] ◦TE c(μ)(A × B)
= δ(0,0)(A)[[step]] ◦TE c ◦[[step]] ◦TE c(μ)((0,0) × B)
= δ(0,0)(A)
4
([[step]] ◦TE c(μ)((0,−1) × R2)δ(0,0)(B)
+ [[step]] ◦TE c(μ)((−1,0) × R2)δ(0,1)(B)
+ [[step]] ◦TE c(μ)((1,0) × R2)δ(1,0)(B)
+ [[step]] ◦TE c(μ)((0,1) × R2)δ(1,1)(B))
= δ(0,0)(A)
4
δ(0,0)(B)
4
μ((0,−2) ∪(−1,−1) ∪(1,−1) × R2)
+ δ(0,1)(B)
4
μ((−1,−1) ∪(−2,0) ∪(−1,1) × R2)
+ δ(1,0)(B)
4
μ((1,−1) ∪(2,0) ∪(1,1) × R2)
+ δ(1,1)(B)
4
μ((−1,1) ∪(1,1) ∪(0,2) × R2)

.
The expression above enumerates all the points that can reach (0,0) in exactly two
steps and keeps track of the last move via the terms δ(i,j)(B). The operators TE c
annihilate any combination of two steps corresponding to a path visiting (0,0) in
two or fewer steps. For example, the path "down followed by up" from (0,0) also
reaches (0,0) in zero steps, so is excluded. Note also that there is some double
counting, as some paths are more likely than others.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

1.3 Semantics of a simple imperative probabilistic language
33
To describe the operator corresponding to the kth iteration of the loop, we deﬁne
P(x, y, k,l) as the set of paths of length k −1 from (x, y) to (1,0) that do not visit
(0,0). A single additional "left" (l) step thus deﬁnes a path of length k to (0,0)
which only visits (0,0) at the last step, hence the notation. We similarly deﬁne the
obvious corresponding sets where l is replaced by d for "down", u for "up" and r
for "right". With this notation, we get for k ≥1
TE ◦([[step]] ◦TE c)k (μ)(A × B)
= δ(0,0)(A)
4k
"#
$
δ(0,0)(B)

(x,y)∈Z2
#P(x, y, k,l)μ((x, y) × R2)
+ δ(0,1)(B)

(x,y)∈Z2
#P(x, y, k, d)μ((x, y) × R2)
+ δ(1,0)(B)

(x,y)∈Z2
#P(x, y, k,u)μ((x, y) × R2)
+ δ(1,1)(B)

(x,y)∈Z2
#P(x, y, k,r)μ((x, y) × R2)%&
'
.
(1.23)
Of course, P(x, y, k,l) is nonempty for only ﬁnitely many (x, y). The expression
(1.23) is uniquely determined by its values on B replaced by one of:
{(0,0)}, {(0,1)}, {(1,0)}, and {(1,1)}.
Since this holds for any k, it also holds for the full expansion
∞

k=0
TE ◦([[step]] ◦TE c)k (μ)(A × B).
By plugging (1.23) into the above expression and regrouping the coeﬃcients of
each term μ((x, y) × R2), we get for B = {(0,0)}
δ(0,0)(A) "#
$
μ((0,0) × R2) +

(x,y)∈Z2\(0,0)
μ((x, y) × R2)
 ∞

k=1
#P(x, y, k,l)
4k

%&
'
,
(1.24)
and similarly for B = {(0,1)}, {(1,0)}, {(1,1)}. Since #P(x,y,k,l)
4k
is precisely the
probability that the random walk reaches (0,0) from (x, y) in exactly k steps by
avoiding (0,0) until the last step, it follows that (1.24) simpliﬁes to

(x,y)∈Z2
μ((x, y) × R2) = μ(Z2 × R2),
since the probability of reaching (0,0) from (x, y) in some number of steps is 1. We
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

34
Dahlqvist, Kozen and Silva: Semantics of Probabilistic Programming
conclude that the semantics of the entire loop is the operator which sends μ to
μ(Z2 × R2)δ(0,0) ⊗1
4
 δ(0,0) + δ(0,1) + δ(1,0) + δ(1,1)
! .
Intuitively, if the starting point is in Z2, then (0,0) is reached with probability one.
By applying the loop operator to the initialized measure described in (1.22), it
now follows that the denotation of the entire program is simply the operator mapping
a measure μ to the measure
μ(R4)δ(0,0),
as expected from the operational semantics.
Example 3: Probabilistic computation of π
Before computing the denotational semantics of the program in Fig. 1.3, it is
instructive as a warm-up exercise to compute the denotational semantics of the
frequent loop-iterator pattern
[[while i < N do i := i + 1]],
where N is some arbitrary constant. There is a single variable, so the semantics will
be given by a linear operator MR →MR. It is not hard to see from the deﬁnitions
that
[[i := i + 1]](μ)(B) = μ({x | x + 1 ∈B}) = μ(B −1).
Let us compute the ﬁrst few terms of (1.20) applied to [[i := i + 1]]. For n = 1 we
get
τ1(0)(μ)(B) = μ(B≥N) + μ((B≥N −1)<N)
where X ≥N ≜{x ∈X | x ≥N}, X<N ≜{x ∈X | x < N}, and
(B≥N −1)<N = {x ∈R | N ≤x + 1 ∈B}<N = {x | x < N ≤x + 1 ∈B} ,
where x < N ≤x + 1 ∈B is shorthand for x < N ≤x + 1 and x + 1 ∈B. Similarly,
τ2(0)(μ)(B) = μ(B≥N) + μ((B≥N −1)<N) + μ(((B≥N −1)<N) −1)<N)
= μ(B≥N) + μ({x | x < N ≤x + 1 ∈B})
+ μ({x | x + 1 < N ≤x + 2 ∈B}).
More generally, for n ≥1:
τn(0)(μ)(B) = μ(B≥N) +
n

k=0
μ({x | x + k < N ≤x + (k + 1) ∈B}).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

1.3 Semantics of a simple imperative probabilistic language
35
It follows that the operator [[while i < N do i := i + 1]] maps a measure μ to the
measure
[[while i < N do i := i + 1]](μ)(B)
= μ(B≥N) +
∞

k=0
μ({x | x + k < N ≤x + (k + 1) ∈B}).
The intuition behind this operator is as follows. Considering the interval B =
[N, N + 1], it is clear that if x + k ≤N < x + k + 1, then it will hold that
x + k + 1 ∈[N, N + 1], and thus
[[while i < N do i := i + 1]](μ)([N, N + 1])
= μ([N, N + 1]) +
∞

k=0
μ((N −k −1, N −k])
= μ ((−∞, N + 1]) .
In other words, all the μ-mass below N accumulates in [N, N + 1] because it
corresponds to the program exiting the loop from an initial state not satisfying its
guard. Conversely,
[[while i < N do i := i + 1]](μ)((N + 1,∞)) = μ((N + 1,∞)),
since this is the μ-mass of states that never enter the loop. It follows that [[while i <
N do i := i + 1]](μ)([N,∞)) = μ(R), i.e. any measure gets mapped to a measure
whose support is [N,∞), which makes good semantic sense. Note also that if the
input distribution is a Dirac delta δx with x < N, then as expected, the deﬁnition
above gives
[[while i < N do i := i + 1]](δx) = δx+⌈N−x⌉,
where ⌈N −x⌉is the ceiling function applied to N −x, i.e. the smallest integer
above N −x.
With this understanding of the interpretation of the common loop-iterator pattern,
let us turn to the program in Fig. 1.3. We start by examining the body of the loop,
namely:
x:=rand();
y:=rand();
if (x*x+y*y) < 1 then n:=n+1;
i:=i+1
which we will denote by body. By applying the rules deﬁning the denotational
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

36
Dahlqvist, Kozen and Silva: Semantics of Probabilistic Programming
semantics, we see that the operator [[body]]: MR4 →MR4 is
[[body]](μ)(Bi × Bn × Bx × By)
= λ(Bx × By ∩D)μ(Bi −1 × Bn −1 × R × R)
+ λ(Bx × By ∩Dc)μ(Bi −1 × Bn × R × R),
where D =

(x, y) | x2 + y2 ≤1

is the unit disk and λ is the two-dimensional
Lebesgue measure (area) restricted to [0,1]2, which is equivalently given by the
product of two copies of the uniform distribution on [0,1] corresponding to the two
occurrences of rand().
We iteratively compute [[while i < N do body]] by evaluating the terms in
the monotone sequence (1.20). The computation is similar to the simple warmup
loop-iterator pattern above, with the operator [[body]] replacing [[i := i + 1]] as
body of the loop.
τ1(0)(μ)(Bi × Bn × Bx × By)
= μ(B≥N
i
× Bn × Bx × By)
+ λ(Bx × By ∩D)μ((B≥N
i
−1)<N × Bn −1 × R × R)
+ λ(Bx × By ∩Dc)μ((B≥N
i
−1)<N × Bn × R × R).
Iterating once more, we get
τ2(0)(μ)(Bi × Bn × Bx × By)
= τ1(0)(ν)(Bi × Bn × Bx × By)
+ λ(Bx × By ∩D)
 π
4 μ(((B≥N
i
−2)<N −1)<N × Bn −2 × R × R)
+
(
1 −π
4
)
μ(((B≥N
i
−1)<N −1)<N × Bn −1 × R × R)

+ λ(Bx × By ∩Dc)
 π
4 μ(((B≥N
i
−1)<N −1)<N × Bn −1 × R × R)
+
(
1 −π
4
)
μ(((B≥N
i
−1)<N −1)<N × Bn × R × R)

https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

1.3 Semantics of a simple imperative probabilistic language
37
since λ(D) = π/4 and λ(Dc) = 1 −π/4. Generally,
τn+1(0)(μ)(Bi × Bn × Bx × By)
= τn(0)(ν)(Bi × Bn × Bx × By)
+ λ(Bx × By ∩D)
 n

k=0
n
k
 ( π
4
)k (
1 −π
4
)n−k
μ(Bi(n + 1, N) × Bn −k −1 × R2)]
+ λ(Bx × By ∩Dc)
 n

k=0
n
k
 ( π
4
)k (
1 −π
4
)n−k
μ(Bi(n + 1, N) × Bn −k × R2)]
where we have deﬁned Bi(n, N) ≜{x | x + n −1 < N ≤x + n ∈Bi}. The limit
distribution can be seen as an inﬁnite sum of disjoint cases indexed by n, the
number of iterations of the loop. To each n corresponds a binomial distribution
with parameters ( π
4,n) counting the number of times (x ∗x + y ∗y < 1)—and thus
the increment n := n + 1—was realized.
The denotation simpliﬁes considerably when we pre-compose with the two ini-
tialisation steps of the program, namely i := 0; n := 0. Assuming a probability
distribution μ ∈MR4 as input, the denotational semantics is then given by
[[i := 0 ; n := 0 ; while i < 1e9 do body]](μ)(Bi × Bn × Bx × By)
= [[while i < 1e9 do body]]μ(R × R × Bx × By)δ0(Bi)δ0(Bn)
= λ(Bx × By ∩D)
 1e9

k=0
1e9
k
 ( π
4
)k (
1 −π
4
)n−k
δ1e9(Bi)δk+1(Bn)

+ λ(Bx × By ∩Dc)
 1e9

k=0
1e9
k
 ( π
4
)k (
1 −π
4
)n−k
δ1e9(Bi)δk(Bn)

.
Finally, we compose with [[i := 4 ∗n/1e9]]. Since we are only interested in the
register i containing the approximation of π, we compute the i-marginal given by
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

38
Dahlqvist, Kozen and Silva: Semantics of Probabilistic Programming
(πi)∗([[i := 0 ; n := 0 ; while i < 1e9 do body ; i := 4 ∗n/1e9]]) (μ)(Bi)
= [[i := 0 ; n := 0 ; while i < 1e9 do body ; i := 4 ∗n/1e9]](μ)(Bi × R3)
= λ(D)
 1e9

k=0
1e9
k
 ( π
4
)k(
1 −π
4
)n−k
δk+1({x | 4x/1e9 ∈Bi})

+ λ(Dc)
 1e9

k=0
1e9
k
 ( π
4
)k(
1 −π
4
)n−k
δk({x | 4x/1e9 ∈Bi})

=
1e9+1

k=0
1e9 + 1
k
 ( π
4
)k(
1 −π
4
)n−k
δk({x | 4x/1e9 ∈Bi})
= Binomial
( π
4,1e9 + 1
)
({x | 4x/1e9 ∈Bi}) .
In other words, from a denotational standpoint, our program returns a distribution
whose i-marginal is the pushforward under the rescaling map x →4x/1e9 of
the binomial distribution Binomial (π/4,1e9 + 1). Since the binomial distribution
is just a sum of Bernoulli distributions with parameter π/4, the connection with
the operational semantics of Section 1.3.4 is evident. However, note that the ﬁnal
output of the denotational semantics captures all possible branches of the operational
semantics in one single object, namely the distribution Binomial (π/4,1e9 + 1).
As promised in Section 1.3.4, we will provide a tighter bound on the probability of
getting a good approximation of π via the program of Fig. 1.3. Hoeﬀding's inequality
(Hoeﬀding (1994)) with X a random variable distributed as Binomial (p,n) says that
P [|X −pn| ≤εn] ≥1 −2 exp(−2ε2n).
For example, with error tolerance ε = 0.00007, we get that
Binomial
( π
4,1e9 + 1
)
({x | 4x/1e9 ∈[π −ε, π + ε]}) ≥0.999,
which is a much tighter bound than the one provided by the Chebyshev inequality
in Section 1.3.4. This shows that proving probabilistic guarantees about a program
such as
(πi)∗[[prog]]([π −ε,π + ε]) ≥0.999
can depend on the diﬃcult and purely mathematical problem of ﬁnding suﬃciently
tight bounds to concentration of measure inequalities.
Example 4: The Cantor distribution
We ﬁnish by computing the denotational semantics of the program of Fig. 1.4. As
mentioned at the end of Section 1.3.5, the least ﬁxpoint denotational semantics of
any program containing a while true loop is simply the constant operator to 0
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

1.3 Semantics of a simple imperative probabilistic language
39
since the program never halts. Formally, if we denote by cantor the program of
Fig. 1.4, then for every μ ∈MR2 (since the program contains two variables)
[[cantor]](μ) = 0.
However, as we also discussed above, the mean ergodic theorem provides an
alternative semantics to non-terminating while true programs. We compute this
semantics explicitly for the cantor program and, as expected, recover the Cantor
measure which we encountered when we computing the operational semantics of
cantor in Section 1.3.4.
Once again we start by examining the body of the loop. By unravelling the
deﬁnition of the denotational semantics of terms, it is not hard to compute the
semantics of the body of the loop which is given by the operator sending μ to the
measure
[[body]](μ)(Bx × Bd) = 1
2 μ
*
(x, d) | x ∈Bx, d
3 ∈Bd
+
+ 1
2 μ
*
(x, d) | x + 2d
3 ∈Bx, d
3 ∈Bd
+
.
It is much easier to reason about the semantics of cantor in terms of Markov
kernels. The body of the loop in particular is the pushforward (deﬁned in Eq. (1.8))
of the kernel [[body]]ker : R2 →MR2 deﬁned by
[[body]]ker(x, d) ≜1
2δ(x, d
3 ) + 1
2δ(x+ 2d
3 , d
3 )
It is easy to check that [[body]]ker
∗
= [[body]], and since the pushforward operation
(−)∗is functorial we can compose these kernels to get a kernel representation
 [[body]]j!ker of the operator [[body]]j for each j ≥1:
(
[[body]]j)ker
(x, d) = 1
2j

w∈{0,2} j
δ(x+	j
i=1
wi d
3i , d
3j )
Using this kernel representation of [[body]]j it becomes relatively straightforward
to compute the mean ergodic limit given by Eq. (1.21), viz.
lim
n→∞
1
n
n−1

j=0
[[body]]j
(1.25)
In order to compute this limit we start by deﬁning the σ-algebra Bx,d generated by
the sets
Cx,d
w
=

y | x +
|w|

i=1
wid
3i
≤y < x +
|w|

i=1
wid
3i +
d
3|w|

,
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

40
Dahlqvist, Kozen and Silva: Semantics of Probabilistic Programming
where w is a word of {0,1,2}∗, |w| is the length of this word, and wi is the ith letter in
w. The sets Cx,d
w
are variants of the sets Ca1···ak which we deﬁned when discussing
the operational semantics of the cantor program in Section 1.3.4, stretched and
shifted to ﬁt the intervals [x, x + d]. In particular, Cw1···wk = C0,1
w1···wk. In exactly
the same way, these sets generate the usual (Borel) σ-algebra on each interval
[x, x + d].
Consider now the Markov kernel on R2 deﬁned at each (x, d) by the measure
γ(x, d) on [x, x + d] speciﬁed uniquely by its values on the generators Cx,d
w
via
γ(x, d)(Cx,d
w
× Bd) =

2−|w|δ(0)(Bd)
if w ∈{0,2}∗,
0
otherwise
where δ(0) is a curious measure deﬁned as follows:
δ(0)(B) =

1
if B contains an interval (0,ϵ)
0
otherwise
We will see in an instant how δ(0) arises, but note ﬁrst that, modulo the δ(0) term,
the measure γ(x, d) is simply a stretched and shifted version of the Cantor measure
deﬁned in Eq. (1.15), Section 1.3.4. In particular, γ(0,1) is simply the product
κ ⊗δ(0) of the Cantor measure κ with δ(0). We claim that γ is the Markov kernel
corresponding to the mean ergodic limit Eq. (1.25). To see this we simply compute
that
1
n
n−1

j=0
(
[[body]]j)ker
(x, d)(Cx,d
w
× Bd) =

0
n < |w|
1
2|w|
1
n
	−1n
i=|w| δ d
3i
otherwise.
It follows that for any rectangle Cx,d
w
× Bd
lim
n→∞
1
n
n−1

j=0
(
[[body]]j)ker
(x, d)(Cx,d
w
× Bd) = γ(x, d)(Cx,d
w
× Bd)
(1.26)
Indeed, the Cx,d
w
contribution to the product is the constant
1
2|w| as soon as n ≥
|w|, and it is not hard to convince oneself that limn→∞1
n
	n
i=|w| δ d
3i (Bd), the Bd
contribution, is precisely given by δ(0)(Bd): if Bd contains an interval (0,ϵ) then
there will exist an N such that
d
3n ∈(0,ϵ) ⊆Bd for all n ≥N and the limit
1
n
	n−1
i=|w| δ d
3i (Bd) will thus converge to 1. In all other cases the limit converges to 0.
We can then conclude that the measures on the LHS and RHS of Eq. (1.26) agree
on the usual (Borel) product σ-algebra on [x, x +d]×R (this follows from Dynkin's
π-λ lemma (Aliprantis and Border, 1999, 4.11) because the collection of sets Cx,d
w
are closed under intersection, i.e. form a π-system).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
41
We can now conclude that the mean ergodic denotational semantics of the pro-
gram [[while true do body]] is the operator given by the pushforward of the kernel
γ. In particular, the semantics of the entire cantor program is given by
[[cantor]](μ) = [[x := 0; d := 1; while true do body]](μ)
= γ∗([[x := 0; d := 1]])(μ)
= μ(R2)γ∗(δ(0,1))
= μ(R2)γ(0,1)
= μ(R2)(κ ⊗δ(0))
and we recover the Cantor measure which we obtained from the operational seman-
tics in Section 1.3.4, as expected.
References
Aliprantis, C., and Border, K. 1999. Inﬁnite Dimensional Analysis. Springer.
Chung, K. L. 1974. A Course in Probability Theory. 2nd edn. Academic Press.
Doberkat, Ernst-Erich. 2007. Stochastic Relations: Foundations for Markov Tran-
sition Systems. Studies in Informatics. Chapman Hall.
Dudley, R.M. 2002. Real Analysis and Probability. Cambridge Studies in Advanced
Mathematics. Cambridge University Press.
Dunford, N., Schwartz, J. T., Bade, W. G, and Bartle, R. G. 1971. Linear Operators
I. Wiley-interscience New York.
Durrett, R. 1996. Probability: Theory and Examples. The Wadsworth & Brooks/-
Cole Statistics/Probability Series. Duxbury Press.
Eisner, T., Farkas, B., Haase, M., and Nagel, R. 2015. Operator Theoretic Aspects
of Ergodic Theory. Vol. 272. Springer.
Giry, Michele. 1982. A categorical approach to probability theory. Pages 68-85
of: Categorical Aspects of Topology and Analysis. Springer.
Halmos, P. R. 1950. Measure Theory. Van Nostrand.
Hoeﬀding, Wassily. 1994. Probability inequalities for sums of bounded random
variables.
Pages 409-426 of: The Collected Works of Wassily Hoeﬀding.
Springer.
Kozen, Dexter. 1981. Semantics of probabilistic programs. J. Comput. Syst. Sci.,
22(3), 328-350.
Kozen, Dexter. 1985. A probabilistic PDL. J. Comput. Syst. Sci., 30(2), 162-178.
Kozen, Dexter. 1997. Kleene algebra with tests. ACM Trans. Programming Lan-
guages and Systems (TOPLAS), 19(3), 427-443.
Lawvere, W. 1962. The category of probabilistic mappings. Manuscript, 12 pages.
Norris, J. R. 1997. Markov Chains. Cambridge Series in Statistical and Probabilistic
Mathematics. Cambridge University Press.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

42
References
Panangaden, Prakash. 1998. Probabilistic relations. Pages 59-74 of: Proceedings
of PROBMIV.
Panangaden, Prakash. 2009. Labelled Markov Processes. Imperial College Press.
Vitali, Giuseppe. 1905. Sul problema della misura dei Gruppi di punti di una retta:
Nota. Tip. Gamberini e Parmeggiani.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

2
Probabilistic Programs as Measures
Sam Staton
University of Oxford
Abstract: This chapter is a tutorial about some of the key issues in semantics of the
ﬁrst-order aspects of probabilistic programming languages for statistical modelling -
languages such as Church, Anglican, Venture and WebPPL. We argue that s-ﬁnite
measures and s-ﬁnite kernels provide a good semantic basis.
2.1 Introduction
This Chapter is about a style of probabilistic programming for building statis-
tical models, the basis of languages such as Church (Goodman et al., 2008),
WebPPL (Goodman and Stuhlmüller, 2014), Venture (Mansinghka et al., 2014),
Anglican (Wood et al., 2014) and Hakaru (Narayanan et al., 2016).
The key idea of these languages is that the model is a combination of three things:
Sample: A generative model is described by a program involving not only bi-
nary random choices but also by sampling from continuous real-valued
distributions. In Bayesian terms, we think of this as describing the prior
probabilities.
Observe: Observations about data can be incorporated into the model, and these
are typically used as weights in a Monte Carlo simulation. In Bayesian
terms, we think of this as describing the likelihood of the data.
Normalize: Given a model, we run an inference algorithm over it to calculate the
posterior probabilities.
Probabilistic programming languages bring many of the abstract ideas of high-level
programming to bear on statistical modelling. Perhaps the most compelling aspect is
the idea of rapid development, ﬁrst of quickly creating models, and second quickly
combining them with inference algorithms.
a From Foundations of Probabilistic Programming, edited by Gilles Barthe, Joost-Pieter Katoen and Alexandra
Silva published 2020 by Cambridge University Press.
43
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

44
Staton: Probabilistic Programs as Measures
There remain many practical and theoretical challenges with probabilistic lan-
guages of these kinds. The purpose of this chapter is to explain, for simple ﬁrst order
programs, how we can understand them as measures in a compositional way.
We begin in Section 2.2 by introducing the general approach to probabilistic
programming and giving informal consideration to various aspects of the semantics
of probabilistic programs. We are led to the issue of unnormalizable posteriors
(§2.2.4). In Section 2.3 we develop the informal semantics from a measure-theoretic
perspective, demonstrating through examples why a naive semantics is not so
straightforward (§2.3.3).
In Section 2.4 we give a formal semantics for ﬁrst order probabilistic programs as
measures. We do this by understanding expressions with free variables as s-ﬁnite
kernels (Def. 2.6). An s-ﬁnite kernel is, roughly, a parameterized measure that is
uniformly built from ﬁnite measures. Once this semantics is given, one can easily
reason about probabilistic programs in a compositional way by using measure theory,
the standard basis of probability. We give some simple examples in Section 2.5.
2.2 Informal semantics for probabilistic programming
2.2.1 A ﬁrst example: discrete samples, discrete observation
To illustrate the key ideas of probabilistic programming, consider the following
simple problem, which we explain in English, then in statistical notation, and then
as a probabilistic program.
(i) I have forgotten what day it is.
(ii) There are ten buses per hour in the week and three buses per hour at the weekend.
(iii) I observe four buses in a given hour.
(iv) What is the probability that it is the weekend?
This is a very simple scenario, to illustrate the key points, but in practice, probabilistic
programming is used for scenarios with dozens of interconnected random parameters
and thousands of observations.
We assume that buses arrive as a Poisson process, meaning that their rate is given
but they come independently. So the number of buses forms a Poisson distribution
(Figure 2.1). We model the idea that the day is unknown by putting a prior belief that
all the days are equiprobable. The problem would be written in statistical notation
as follows:
(i) Prior: x ∼Bernoulli( 2
7)
(ii) Observation: d ∼Poisson(r) where r = 3 if x and r = 10 otherwise;
(iii) d = 4;
(iv) What is the posterior distribution on x?
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

2.2 Informal semantics for probabilistic programming
45
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
0
0.1
0.2
4
Rate = 3
Rate = 10
Number of buses
Probability
Figure 2.1 The Poisson distributions with rates 3 and 10.
We describe this as a probabilistic program as follows:
1.
normalize(
2.
let x = sample(bernoulli( 2
7)) in
3.
let r = if x then 3 else 10 in
4.
observe 4 from poisson(r);
5.
return(x))
Lines 2-5 describe the combination of the likelihood and the prior. First, on line 2,
we sample from the prior: the chance that it is the weekend is 2
7; this matches line (i)
above. On line 3, we set the rate r of buses, depending on whether it is a week day.
On line 4 we record the observation that four buses passed when the rate was r,
using the Poisson distribution. So lines 3 and 4 match lines (ii) and (iii) above (but
not individually). The normalize command on line 1 is wrapped around the whole
program up to the return value on line 5, and corresponds to line (iv) above.
There are three naive ways to calculate the answer:
Posterior calculation 1: direct calculation using Bayes' law. The ﬁrst approach
is to calculate the posterior probability using Bayes' law directly
Posterior ∝Likelihood × Prior.
(2.1)
For a discrete distribution, the likelihood is the probability of the observation
point d, which for the Poisson distribution with rate r is 1
d!rde−r.
• The prior probability that it is the weekend is 2
7, and then the likelihood of the
observation is 1
4!34e−3 ≈0.168; so the posterior probability that it is the weekend
is proportional to 0.168 × 2
7 ≈0.048 (likelihood×prior).
• The prior probability that it is a week day is 5
7, and then the rate is 10 and the
likelihood of the observation is 1
4!104e−10 ≈0.019. So the posterior probability
that it is a week day is proportional to 0.019 × 5
7 ≈0.014.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

46
Staton: Probabilistic Programs as Measures
• The measure (true →0.048,false →0.014) is not a probability measure because
it doesn't sum to 1. To build a probability measure we divide by 0.048 + 0.014 =
0.062, to get a posterior probability measure (true →0.22,false →0.78).
The normalizing constant, 0.062, is sometimes called model evidence; it is an
indication of how well the data ﬁts the model.
Posterior Calculation 2: Monte Carlo simulation with rejection. In more com-
plicated scenarios, it is often impractical to manage a direct numerical calculation
like the above, and so people often turn to approximate simulation methods. A
simulation with rejection works as follows:
• We run through the inner program (lines 2-5) a large number of times (say N).
• At a sample statement, we randomly sample from the given distribution. In Line 2,
there is a Bernoulli trial that produces true with probability 2
7 and false with
probability 5
7. We might perform this by uniformly generating a random number
between 1 and 7 (the day of the week) and then returning true if the number is 6
or 7.
• At an observe statement, we also randomly sample from the given distribution,
but we reject the run if the sample does not match the observation. In Line 4, we
would sample a number k from the Poisson distribution with rate either 3 or 10,
depending on the outcome of Line 2 (according to Line 3) and then reject the run if
k  4. This amounts to running a simulation of the bus network, but then rejecting
the run if the outcome of the simulation did not match our observation. That is to
say, we disregard or ignore the runs where the prior sample is inconsistent with
the observation.
• Line 5 says that the result of the run is x = true if it is the weekend on that run.
• Line 1, wrapped around the whole program, says that of the non-rejected runs,
we see what proportion of runs returns x = true. As N →∞, the ratio will
tend towards (0.22 : 0.78), the true posterior distribution. Thus the normalize
command converts the sampler described by Lines 2-5 into a proper probability
distribution.
Posterior Calculation 3: Monte Carlo simulation with weights. The rejection
method is rather wasteful, and doesn't scale clearly to the continuous situations that
we turn to later. An alternative is a simulation with likelihood weights, which works
as follows:
• We run through the inner program (Lines 2-5) a large number N of times.
• As before, at a sample statement, we randomly sample from the given distribution.
• At an observe statement, we do not sample. Rather, we use the density function
of the given distribution to weight the run. In Line 4, the density function of the
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

2.2 Informal semantics for probabilistic programming
47
0
0.25
0.5
0.75
1
0
2
4
6
8
10
0.25
r = 10
r = 3
Time between buses (hours)
Probability density
Figure 2.2 The exponential distributions with rates r = 3 and r = 10.
Poisson distribution is 1
d!rde−r, so we weight the run by either 0.168 or 0.019,
depending on the outcome of Line 2. In a program with multiple observations,
we accumulate the weights multiplicatively. (In practice it is numerically prudent
to use log-weights and add them.)
• Looking at all the runs, we see what weighted proportion of runs returns x = true.
As N →∞, the ratio will tend towards (0.22 : 0.78).
In this discrete setting we can encode rejection sampling using a Monte Carlo
simulation with weights, by replacing Line 4 with
4′.
let d = sample(poisson(r)) in observe 4 from dirac(d)
so that the weight will be either 1 (if d = 4) or 0 (if d  4). When the weight is zero
the run is as good as rejected.
2.2.2 A second example: discrete samples, continuous observation
Now consider the following situation, which is almost the same but the observation
is diﬀerent: we observe a 15 minute gap rather than four buses.
(i) I have forgotten what day it is.
(ii) There are ten buses per hour in the week and three buses per hour at the weekend.
(iii) I observe a 15 minute gap between two buses.
(iv) What is the probability that it is a week day?
In this example, since the buses are run as a Poisson process, the gap between them
is exponentially distributed (Figure 2.2). The exponential distribution is a continuous
probability measure on the positive reals; when the rate is r it has density function
t →re−rt. which means that the probability that the gap between events will lie in a
given interval U is given by
∫
U re−rt dt.
In statistical notation, this example would be described as follows:
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

48
Staton: Probabilistic Programs as Measures
(i) Prior: x ∼Bernoulli( 2
7)
(ii) Observation: d ∼Exponential(r) where r = 3 if x and r = 10 otherwise;
(iii) d = 15
60 = 0.25;
(iv) What is the posterior distribution on x?
The program for this example diﬀers from the previous one only on Line 4:
4′′.
observe 0.25 from exponential(r);
Posterior calculation 1 (direct mathematical calculation) is easily adapted to this
situation. Here the likelihood of the observation (15 mins) is again the value
of the density function, which is 3 × e−3×0.25 ≈1.42 when it is the weekend
and 10 × e−10×0.25 ≈0.82 when it is a week day. So the unnormalized
posterior has (true →2
7 × 1.42 ≈0.405,false →5
7 × 0.82 ≈0.586). In this
example the normalizing constant is 0.991, and the normalized posterior is
(0.408 : 0.592). Notice that likelihood is not the same as probability — it is
not even less than 1.
Posterior calculation 2 (rejection sampling) cannot easily be adapted to this situa-
tion. The problem is that although sampling from an exponential distribution
will often produce numbers that are close to 0.25, it will almost never produce
exactly 0.25, so almost all the runs will be rejected.
Posterior calculation 3 (weighted sampling) is easily adapted to this situation. The
weight on Line 4′′ will either be 1.42 or 0.82.
Calculation Method 2 (Rejection) is perhaps the most intuitive, so it is unfortunate
that it does not apply to this situation - not even theoretically. One way to resolve
this is to say that our observation is not precisely 15 minutes, but 15 ± ϵ minutes.
For all ϵ > 0 we can make a rejection sampling algorithm which rejects all runs
where the gap is not within 15 ± ϵ. In an analogous way to line 4′, we can encode
rejection sampling in an interval with weighted sampling, by replacing line 4′′ by
4′′′a.
let d = sample(exponential(r)) in
4′′′b.
observe d from uniform(0.25 −ϵ,0.25 + ϵ)
As ϵ →0, in this example, the posterior probability from rejection sampling tends
to the posterior probability from weighted sampling.
(This is not a practical approach at all because, for small ϵ, the vast majority of
runs will be rejected. One practical solution to soften the hard rejection constraint
using noise from a normal distribution, e.g.
4′′′b′.
observe d from normal(0.25, ϵ
2)
Here we use ϵ
2 as a small standard deviation.)
The correctness of this argument depends on some continuity issues, which have
been investigated in the setting of conditional probability by Tjur (1980, §9.12) and
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

2.2 Informal semantics for probabilistic programming
49
0 1 2 3 4 5 6 7 8 9 10 11 12
0
0.1
0.2
US GPA
Probability
0 1 2 3 4 5 6 7 8 9 10 11 12
0
0.1
0.2
Indian GPA
Probability
Figure 2.3 Discontinuous density functions for the GPA problem. See also Wu et al. (2018) and
Section 2.3.2. The idea is this: suppose that grades are distributed uniformly, except the top 1%
are given the maximum grade, which is 4 in the US and 10 in India. The problem is: given that I
observe a GPA of 4, what is probable nationality of the student? The answer: certainly US.
Ackerman et al. (2015). On the other hand, densities that arise in practice are not
always continuous: the GPA problem is an example of this that has been studied in
the probabilistic programming context (see e.g. Figure 2.3, and §2.3.2, and Nitti
et al., 2016; Wu et al., 2018).
In order to describe a situation as a program in this way, especially in a way that
is amenable to Calculation Method 3 (Weighted sampling), the likelihood function
of the observation distribution must be known. Research on automatic density
calculation is ongoing (Bhat et al., 2017; Gehr et al., 2016; Ismail and chieh Shan,
2016).
2.2.3 A third example: continuous samples, continuous observations
For a third example, we use a similar story but now with bikes rather than buses,
and rather than guess the day of the week we guess the time of day.
(i) I have forgotten what time it is.
(ii) The rate of bikes per hour is determined by a function of the time of day.
(iii) I observe a 1 minute gap between two bikes.
(iv) What time is it?
We model the idea that the time is unknown by picking the uniform distribution on
the continuous interval (0,24). Suppose that we have some idea of the number of
bikes per hour; the rate f (t) will vary according to the time t. A possible f is given
in Figure 2.4. In statistics notation, we would write:
(i) Prior: t ∼Uniform(0,24);
(ii) Observation: d ∼Exponential( f (t));
(iii) d = 0.0167;
(iv) What is t?
The program for this example has the same outline as the previous one:
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

50
Staton: Probabilistic Programs as Measures
0000
0100
0200
0300
0400
0500
0600
0700
0800
0900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
0
5
10
Time of day
Bikes/minute
Figure 2.4 The rate of bikes as a function of the current time. The function is ﬁctitious but based
on real observations by "Bells on Bloor" in Toronto (Koehl et al., 2017).
1.
normalize(
2.
let t = sample(uniform(0,24)) in
3.
let r = f (t) in
4.
observe 0.0167 from exponential(r);
5.
return(x))
Now to make Calculation Method 3 (weighted sampling) work, we need to accept
that the prior and posterior distributions are on an uncountable space. On a discrete
computer it is not really possible to sample from an uncountable continuous
distribution. One way to deal with this is to approximate the prior (and hence
the posterior) by discrete distributions; the ﬁner the granularity the closer the
approximation is to the continuous distribution.
A secondary problem is that even a discretized sample space is too large to explore
naively; many runs will have low weights (i.e. improbable) which is a waste of
resources. There are Monte Carlo algorithms that perform this more eﬃciently, and
can be applied to probabilistic programs, for example:
• Markov Chain Monte Carlo / Metropolis Hastings: with each run, we do not
resample all the random choices, but only some, and we randomly reject or accept
the resample depending on the change in weight. In other words, we build a
Markov chain from the program and perform a random walk over it.
• Sequential Monte Carlo: we can run N times up to a checkpoint (typically an
observation), pause, and redistribute the eﬀort so that not too many of the running
threads have low weight.
There are elaborations and combinations of these methods, together with other
methods (such as variational ones). The introduction by van de Meent et al. (2018)
covers many of these diﬀerent methods.
For Posterior Calculation 1 (direct mathematical calculation), in this instance, we
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

2.2 Informal semantics for probabilistic programming
51
0000
0100
0200
0300
0400
0500
0600
0700
0800
0900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
0
0.05
0.1
0.15
Time of day
Posterior probability density
Figure 2.5 Posterior density for the current time given that I noticed a one minute gap between
bikes when the rate is as shown in Figure 2.4. The probability that the time is between 4am and
7am is the purple area.
can give a posterior probability in terms of a probability density function. Recall that
the meaning of density functions applied to probabilities (as opposed to likelihoods)
is as follows: although the probability that the time is exactly 05:30 is zero, we can
give a probability that the time is in some interval (more generally, a measurable
set), as the integral of the density function. For instance, the posterior probability
that the time is between 4am and 7am is shaded in Figure 2.5. The density function
in this case is given by multiplying the likelihood function by the density of the prior
distribution, which is uniform:
Posterior
∝
Likelihood
×
Prior
posterior-pdf(t)
∝
f (t)e−0.016×f (t)
×
1
24
The density function t →f (t)e−0.016×f (t) × 1
24 is not normalized, but we can divide
by the normalizing constant to get a true posterior density function:
t →
f (t)e−0.016×f (t) × 1
24
∫24
0
f (t)e−0.016×f (t) × 1
24 dt
=
f (t)e−0.016×f (t)
∫24
0
f (t)e−0.016×f (t) dt
(2.2)
In general, we cannot naively use density functions for a full compositional
semantics because some basic programs do not have density functions. We return to
this point in Section 2.3.
Aside on probabilistic programming for rapid prototyping
To brieﬂy demonstrate the power of probabilistic programming for rapid prototyping,
we consider a few elaborations on the last example. Supposing that the frequency
f (t) is uncertain, say we only know the frequency ±1, then we can quickly introduce
an extra random variable by changing line 3 to
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

52
Staton: Probabilistic Programs as Measures
3'.
let r = sample(normal( f (t),1)) in . . .
If the error in the frequency f (t) is itself unknown, we can introduce yet another
random variable σ for the error, for example,
3"a.
let σ = sample(inv-gamma(2,1)) in
3"b.
let r = sample(normal( f (t),σ)) in . . .
2.2.4 Unnormalizable posteriors
This chapter is about semantics of probabilistic programs and so it is informative to
consider some corner cases. Recall that when we calculate a posterior we must divide
by a normalizing constant. If this constant is 0 or ∞, we cannot ﬁnd a posterior. In
practice, if the constant is very low or very high, it suggests the model is bad, and it
is numerically inconvenient to ﬁnd the posterior, but if it is 0 or ∞it is impossible
even in theory.
Zero normalizing constant
A normalizing constant of 0 occurs when an observation is not only improbable, but
impossible. For example, in the ﬁrst example, suppose that we say that we claim to
observe (−42) buses - a negative number of buses. This is impossible, nonsense,
and the likelihood is not just very small but 0. In the rejection sampling semantics,
all runs will be rejected.
Whether a normalizing constant is 0 is undecidable in general. For example,
consider a Turing machine M with initial tape, and the following scenario.
(i) We toss a coin repeatedly until the outcome is heads. Call the number of tosses
k.
(ii) We observe that Turing machine M terminates after exactly k steps.
(iii) What is k?
The prior distribution on k is a geometric distribution. The normalizing constant is
non-0 if and only if the machine M terminates, in which case the posterior probability
is the Dirac distribution on the number of steps required. For this reason, ﬁnding the
normalizing constant is undecidable in general.
This manifests in practice as follows. For many Monte Carlo methods, it is
guaranteed that sampling will converge eventually. However, it is diﬃcult in practice
to know when a Monte Carlo process has converged, and as this example shows, it
may be impossible to know.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

2.2 Informal semantics for probabilistic programming
53
Inﬁnite normalizing constant
Very high normalizing constants can occur when the observations are considerably
more likely for improbable prior parameters. To demonstrate this we consider a
scenario of a similar shape to the previous stories. An astronomer has invented a
telescopic device which she is using to measure the distance between two stars,
which are in fact precisely 1 light-year apart.
(i) The device is unreliable and breaks down every hour on average.
(ii) Every 2.89 hours that she uses the device, she is able to double the precision
(inverse variance) of her measurement; the initial precision is 6.3 ly−2. At the
point that the machine breaks down, she estimates that the distance is 1 light-year
- coinciding with the true distance.
(iii) How long was the scientist using the machine for?
The story is set up so that the likelihood is inverse to the prior. The numbers have
been chosen so that the initial precision (6.3) is approximately 2π, and the precision
doubles every
2
ln 2 hours (≈2.9), so that the precision τt at time t is approximately
τt = 2πe2t. If we model the measurement inaccuracy by a normal distribution, the
likelihood function of data d is
,
τt
2π e−1
2(d−1)2τt. When d = 1, the likelihood is et.
So the prior density is e−t, but the likelihood is et.
In statistical notation:
(i) Prior: t ∼Exponential(1);
(ii) Likelihood: d ∼Normal(1,(2πe2t)−1
2 ), with d = 1;
(iii) What is the posterior probability on t?
As a probabilistic program:
1.
normalize(
2.
let x = sample(exponential(1)) in
3.
observe 1 from normal(1,(2πe2t)−1
2 );
4.
return(x))
In the Posterior Calculation Method 3, the problem is that we are very unlikely to
pick long times, but when we do they receive very high weights.
In the Calculation Method 1, the unnormalized posterior density is
Posterior
∝
Likelihood
×
Prior
posterior-pdf(t)
∝
et
×
e−t
and so the probability that the time lies in a set U is
∫
U
ete−t dt =
∫
U
1 dt
(2.3)
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

54
Staton: Probabilistic Programs as Measures
0
1
2
0
1
2
0
0.5
1
Time (t)
Observation (d)
Unnormalized posterior density
0
0.5
1
1.5
2
0
1
2
3
Observation (d)
Normalization constant
Figure 2.6 The posterior distribution on time spent using the device t given the observation d,
in the context of the story about the scientist measuring the distance between stars. Notice that
when d = 1 the unnormalized posterior density is constant, and the normalization constant is
inﬁnite.
which is the Lebesgue measure. For instance, on an interval (a, b), the unnormalized
posterior is b −a. Across the entire positive reals (0,∞), the normalizing constant
is inﬁnite. So the question does not have an answer. We cannot form a posterior
probability on the time that the scientist used the device: every time is equiprobable.
There are several contrivances in the story, the most ridiculous of which is
that the observed distance happens to perfectly match the true distance. If the
observed distance had been even slightly diﬀerent from the true distance, the inﬁnite
normalization constant would not occur. Indeed, if the observed distance was very
diﬀerent from the true distance, we could easily conclude that the device broke
quickly (see Fig. 2.6). This means that in practice we do not need to worry about
the story, because a problem-causing observation almost never occurs. In principle,
however, we do need to consider inﬁnite measures like this, in part because they
can legitimately arise as fragments of reasonable programs, as we now discuss.
(For further examples of improper posteriors such as this, see e.g. Robert, 2007,
Ex. 1.49-1.52.)
Improper priors and posteriors
When a normalizing constant is inﬁnite, this is sometimes called an 'improper'
distribution. Although an improper distribution is problematic as the end result of
an inference problem, the distributions are incredibly useful when used as part of
a model. To analyze this we consider a construction score(r) which weights the
current run by r. This is equivalent to observe 0 from exponential(r).
Suppose for a moment that we have a program Lebesgue, such as Lines 2-4 of
our astronomy example, that behaves as the Lebesgue measure. Suppose too that
we have a probability distribution on [0,∞) that has a probability density function
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

2.3 Introduction to measurability issues
55
f : [0,∞) →[0,∞), and we want to sample from it. We can do this by:
let x = Lebesgue in score( f (x)); return(x)
since this is the deﬁnition of density functions. This composite program has
normalizing constant 1. In fact, when we expand the deﬁnition of Lebesgue as above,
this becomes the "importance sampling algorithm":
let x = sample(exponential(1)) in score(ex); score( f (x)); return(x)
In words: to build a sampler for one distribution from a sampler for another
distribution, sample from the ﬁrst distribution and then weight each run by the ratio
of the density functions.
So although inﬁnite normalizing constants are problematic at the top level, it
is often useful to reason about programs where subexpressions do have inﬁnite
normalizing constants.
2.2.5 Summary of informal semantics
We have discussed three approaches to semantics for probabilistic programs:
• mathematical semantics deﬁned using densities and measures;
• Monte Carlo semantics with rejection;
• Monte Carlo semantics with weighting.
In Section 2.2.4, we have seen that, no matter what approach is taken, some care is
needed because the normalizing constant may be inﬁnite or zero.
2.3 Introduction to measurability issues
In Section 2.4 we will give a formal semantics for probabilistic programs in terms of
measures. In this section, we introduce the basics of a measure-theoretic approach
to probability (see also Pollard, 2002) and use it to illustrate why such a formal
semantics is not entirely trivial.
The idea of weighted simulation already gives us an interpretation of a probabilistic
program. We deﬁne an underlying probability space Ω = [0,1]d where d is the
number of sample statements in the program. If the program includes recursion,
d may be countably inﬁnite, but that is not a problem. We can think of each
element of Ω as a list of random seeds. Given such a list, we can execute a
program deterministically, leading to a weight (the product of all the observes) and
a deterministic result, because the results of the sample statements are ﬁxed.
(Here we are using the fact that uniform random numbers in [0,1] are a suﬃcient
seed for sampling from any probability distribution with parameters. For example,
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

56
Staton: Probabilistic Programs as Measures
20
1
18
4
13
6
10
15
2
17
3
19
7
16
8
11
14
9
12
5
Figure 2.7 A dartboard with the areas scoring 20 highlighted in black. Reproduced under a
Creative Commons Licence from Robert Bonvallet.
sampling from a Bernoulli distribution can be simulated by testing the position of a
uniform random number,
sample(bernoulli(r)) = let x = sample(uniform) in return(x < r)
and more generally, sampling from a general distribution can be simulated using the
inverse-cdf method, e.g.:
sample(normal(m, s)) =
let x = sample(uniform) in return(norm-invcdf(m, s, x)).)
Thus a probabilistic program of type X determines two functions:
result : Ω →X
weight : Ω →[0,∞)
(2.4)
and each run of the weighted simulation corresponds to randomly picking seeds
ω ∈Ω and returning the pair (weight(ω),result(ω)).
In general this (2.4) is a very intensional representation of a probabilistic program:
programs that describe the same probabilistic scenarios have diﬀerent diﬀerent
representations, because the functions result and weight will diﬀer. For example, the
following two programs implementing sample(bernoulli2/7):
let x = sample(uniform) in return(x < 2
7)
let x = sample(uniform) in return(x > 5
7)
will have diﬀerent representations; introducing redundant sample statements will
give diﬀerent representations; and so on. What we ultimately care about is the
posterior probability on the results. In general, this will be a measure.
Measure theory generalizes the ideas of size and probability distribution from
countable discrete sets to uncountable sets. To motivate, think of the game of darts.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

2.3 Introduction to measurability issues
57
No matter how good a player I am, the chance of hitting the point at the centre of
the dartboard is zero. The chance of hitting any given point is zero. Nonetheless
I will hit a point when I throw. We resolve this apparent paradox by giving a
probability of hitting each region. The probability of scoring 20 points is the sum of
the probabilities of hitting one of the three regions that score 20 points (Figure 2.7).
And so on. We can think of these regions of the dartboard as measurable sets with
positive probability.
With this in mind, we are interested in the posterior probability that the result of a
probabilistic program is within a certain set; for example, that the day is a weekend
day, or that the time is between 4am and 7am, or that I scored 20 on the dartboard.
If we run a weighted simulation k times, picking seeds ω1 . . . ωk ∈Ω, we obtain an
empirical posterior probability that the result is in the set U:
	k
i=1[result(ωi) ∈U] · weight(ωi)
	k
i=1 weight(ωi)
(2.5)
(Here and elsewhere we regard a property, e.g. [x ∈U], as its characteristic function
X →{0,1}.) Although this empirical probability is itself random, in that it depends
on the choices ωi, we would like to use the law of large numbers to understand that
as k →∞the empirical posterior (2.5) converges to a true posterior
∫
Ω[result(ω) ∈U] · weight(ω) dω
∫
Ω weight(ω) dω
.
(2.6)
Then two programs should be regarded as the same if they give the same posterior
probability measure. There are two issues:
• We need to understand why the integrals in (2.6) exist;
• We need to also understand program fragments in this way, so that we can reason
about program equality bit by bit, compositionally.
To address these, we interpret probabilistic programs as unnormalized measures and
kernels.
2.3.1 Rudiments of measure-theoretic probability
We recall some basic deﬁnitions of measure theory. These are well-motivated by the
illustration in Figure 2.7: the probability of scoring 20 is the sum of the probabilities
of hitting the three regions shown. Thus countable disjoint unions are crucial for
formulating measures.
Deﬁnition 2.1
A σ-algebra on a set X is a collection of subsets of X that contains
∅and is closed under complements and countable unions. A measurable space
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

58
Staton: Probabilistic Programs as Measures
is a pair (X,ΣX) of a set X and a σ-algebra ΣX on it. The sets in ΣX are called
measurable sets.
For example, we equip the set R of reals with the Borel sets. The Borel sets are
the smallest σ-algebra on R that contains the intervals. The plane R2 is equipped
with the least σ-algebra containing the rectangles (U × V) with U and V Borel. For
example, the dartboard (Fig 2.7) is a subset of R2, and the set of points that would
score 20 points is measurable.
Deﬁnition 2.2
A measure on a measurable space (X,ΣX) is a function μ : ΣX →
[0,∞] into the set [0,∞] of extended non-negative reals that is σ-additive, i.e. μ(∅) =
0 and μ(-
n∈N Un) = 	
n∈N μ(Un) for any N-indexed sequence of disjoint measurable
sets U. A probability measure is a measure μ such that μ(X) = 1.
For example, the Lebesgue measure λ on R is determined by saying that the
measure of a line segment is its length (λ(a, b) = b −a), and the Lebesgue measure
on R2 is determined by saying that the measure of a rectangle is its area. For any
x ∈X, the Dirac measure δx has δx(U) = [x ∈U]. To give a measure on a countable
discrete measurable space X it is suﬃcient to assign an element of [0,∞] to each
element of X. For example, the counting measure γ is determined by γ({x}) = 1 for
all x ∈X.
Measures can be equivalently understood as integration operators. A function
between measurable spaces, f : X →Y, is said to be measurable if f -1(U) ∈ΣX
when U ∈ΣY. If f : X →[0,∞] is measurable and μ is a measure on X then we
can integrate f with respect to μ, written
∫
μ f (x) dx, giving a number in [0,∞].
2.3.2 Relationship to Bayesian statistics
The measure-theoretic semantics that we discuss in this chapter is inspired by
Bayes' law, but it is not tied to it. Indeed, sometimes a language for weighted
Monte Carlo simulation is useful without a formal Bayesian intuition; for example,
one might use weights coming from image similarity without making a formal
connection to likelihood. Nonetheless in this section we make a connection with the
measure-theoretic treatment of Bayes' law.
Measures are closely related to density functions.
Deﬁnition 2.3
If f : X →[0,∞] is measurable, and μ is a measure on X, then
ν(U) =
∫
μ
[x ∈U] f (x) dx
is also a measure. We say that ν has density f with respect to μ. A density is sometimes
called a Radon-Nikodym derivative. If ν(X) = 1, it is a probability density. If a
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

2.3 Introduction to measurability issues
59
measurable function f : X × Y →[0,∞] has the property that
∫
μ f (x, y) dx = 1 for
all y then it is a conditional probability density with respect to μ.
For example, the density function of the exponential distribution (r, x) →re−x
is a conditional density with respect to the Lebesgue measure, and this induces
the exponential probability measures on R. The Dirac measure has no density with
respect to the Lebesgue measure, but it does have a density with respect to itself, as
does every measure.
Throughout the above analysis, we have used densities as weights. The observed
data has been ﬁxed in our examples, for example, 4 buses or 15 minutes, but
it would be reasonable to make the function weight: Ω →[0,∞) parametrized
in the data. Thus, supposing our data lies in a space D, the data-parameterized
weight function is a measurable function likelihood: D × Ω →[0,∞), such that
weight(ω) = likelihood(d,ω) where d is the speciﬁc data that is hard-coded into
the program. The Bayesian approach is that likelihood should be a conditional
probability density with respect to some measure λ on D.
The posterior (2.6) can then be made a measurable function of y ∈D, i.e. a
regular conditional probability:
qy(U) =
∫
Ω[result(ω) ∈U] · likelihood(y,ω) dω
∫
Ω likelihood(y,ω) dω
.
This can also now be connected formally to Bayes' theorem of conditional probability,
see e.g. Schervish (1995, Thm. 1.31). In Section 2.2.4 we discussed the point that
although the denominator may be 0 or ∞, for a whole program, this almost-never
happens. This can now be made precise:
γ(U0,∞) = 0
where γ(V) =
∫
D
∫
Ω[y ∈V] · likelihood(y,ω) dω dy is the prior predictive measure,
and U0,∞= {y |
∫
Ω likelihood(y,ω) dω ∈{0,∞}}.
We conclude by mentioning, as an aside, that in complex situations, the Bayesian
requirement of a single base measure λ on D can be subtle. The density functions
for the GPA problem in Figure 2.3 are densities with respect to the mixed measure
(lebesgue + δ4 + δ10). The theory of conditional probability densities requires a
single common base measure for all the diﬀerent parameters. The following program
will only give the right result if we use the same base measure (lebesgue + δ4 + δ10)
on R for the likelihood functions for all the diﬀerent if-then-else branches.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

60
Staton: Probabilistic Programs as Measures
let american = sample(bernoulli(0.5)) in
let brilliant = sample(bernoulli(0.01)) in
ifamerican then
ifbrilliant then observe 4 from dirac(4) else observe 4 from uniform(0,4)
else
ifbrilliant then observe 4 from dirac(10) else observe 4 from uniform(0,10)
return(american)
This is subtle because the density of the Indian distribution uniform(0,10) with
respect to the base lebesgue measure is the constant 0.1 function, but the density
of uniform(0,10) with respect to the base measure (lebesgue + δ4 + δ10) must take
value 0 at 4, as in Figure 2.3. Overall, then, the program is a Dirac measure at
american = true.
In summary, the meaning of a closed probabilistic program is an unnormalized
measure, thought of as the nominator in Bayes' rule. For a program expression that
has free variables, its interpreation should be measurable in the valuation of those
variables.
• Sampling from a probability measure is a measure.
• An observation observe x from d is a one point measure whose value is the density
of d at x.
• The sequencing let x = t in u means, roughly, integration:
∫
t u dx.
• The simple statement return(t) means the Dirac delta measure.
We make this precise in Section 2.4.
2.3.3 Obstacles to measurability
We now illustrate why measurability of programs is not entirely trivial. Our
counterexamples are based on the counting measure on the real numbers. This
is an unnormalized distribution that assigns 1 to every singleton set. It turns out
that although some inﬁnite measures are deﬁnable in a probabilistic programming
language, the counting measure on R is not deﬁnable - we show this in Section 2.5.2.
But for now let us suppose that we add it to our language, as a command counting,
and see what chaos ensues. (For now, we retain an intuitive view of measurability;
precise deﬁnitions are in Section 2.4, with a precise version of the arguments in this
section given in Section 2.5.2.)
As before, for any set U we can consider a function [x ∈U] which returns true if
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

2.3 Introduction to measurability issues
61
x ∈U and false otherwise. For example, we might write [x ∈{0,1,2,3}], [x > 0],
[x = 42], and so on. The following lemma gives some intuition for the counting
measure.
Lemma 2.4
For any (measurable) set U, the program
let r = counting in return[r ∈U]
gives weight #U to true and #(R \ U) to false, where #U is the cardinality of U if U
is ﬁnite, or ∞otherwise.
In this extended language, the fundamental law of exchangeability is violated: the
order of draws matters, as we now explain. Notice that let s = counting in return[r =
s] has the same semantics as return(true), for all r, because there is exactly one s
that is equal to any given r (Lemma 2.4). So
let r = uniform(0,1) in let s = counting in return[r = s]
(2.7)
is an equivalent program to return(true). But
let r = uniform(0,1) in return[r = s]
has the same semantics return(false), for all s, because any r is almost surely diﬀerent
from a given s. So
let s = counting in let r = uniform(0,1) in return[r = s]
(2.8)
has the same semantics as return(false). Comparing (2.8) to (2.7), we see that
programs involving the counting measure cannot be reordered.
In fact, the measure-theoretic semantics of the language extended with counting is
not always even fully deﬁned. For an example of this, we recall that there exist Borel-
measurable subsetsU of the plane R2 for which the projection π[U]
def= {x | ∃y. (x, y) ∈
U} is not Borel-measurable in R. (In general π[U] is called 'analytic'.) Now the
program
let s = counting in return[(r, s) ∈U]
puts a non-zero weight on true if and only if r ∈π[U]. So this program is not
measurable in r, and so programs built from it, such as
let r = uniform(0,1) in let s = counting in return[(r, s) ∈U]
are not well deﬁned.
As we will see in Section 2.4 (Lemma 2.7), this problem cannot arise in the
language without the counting measure: every term is compositionally well-behaved.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

62
Staton: Probabilistic Programs as Measures
2.4 Formal semantics of probabilistic programs as measures
We now turn to give a precise semantics of probabilistic programs. To this end we
set up a typed language with a precise syntax.
In the previous section we have considered programs as Bayesian statistical
models. However, this is only an intuition, and the semantics is given in terms of
weighted simulations and measure theory. Moreover, some applications of weighted
simulation are beyond the realms of Bayesian statistics.
For these reasons, the precise language that we now consider will have the keyword
score(r), which weights the run by r, instead of the keyword observe. The two are
inter-deﬁnable:
observe r from p = score( f (r)),
where f is the density of p
score(r) = observe 0 from exponential(r)
2.4.1 Types
In what follows it is helpful to consider a typed programming language. We will
consider types such as natural numbers, real numbers, tuples of real numbers, and
lists of real numbers. In practice many probabilistic programming languages do
not perform type checking, but having a type greatly simpliﬁes the mathematical
semantics. Moreover, types play an intuitive role, because a probabilistic program
may describe a measure on the space of natural numbers, or the space of real
numbers, or on the real plane. With this intuition, a type is just a syntactic description
of a space. For instance, we can understand an expression of real type as a measure
on the real line; an expression of integer type as a measure on the space of integers,
and so on.
Our types are generated by the following grammar:
A,B ::= R | P(A) | 1 | A × B | .
i∈I Ai
where I ranges over countable, non-empty sets. The type .
i∈I Ai is sometimes
called a labelled variant or a tagged union. The type P(A) is a type of distributions
on A. Here are some examples of types in the grammar:
• The type R of the real line, and type R × R of the plane;
• The type (1 + 1) of booleans (true/false), the type .
i∈N 1 of natural numbers;
• The type .
i∈N Ri of sequences of reals of arbitrary length;
• The type P(1 + 1) of probability distributions over the booleans, and the type
P(R) of probability distributions on the reals.
To keep things simple we do include function types such as (R →R) and (R →
R) →R. Also, this is not a type system that can be automatically checked in a
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

2.4 Formal semantics of probabilistic programs as measures
63
computer because we include inﬁnite sum types rather than recursion schemes. We
do this primarily because countably inﬁnite disjoint unions play such a crucial role
in classical measure theory, and constructive measure theory is an orthogonal issue
(but see e.g. (Ackerman et al., 2011)).
2.4.2 Types as measurable spaces
Types A are interpreted as measurable spaces A, by induction on their structure,
as follows. To be precise we distinguish between the syntactic name of the type A
and the space A which interprets it.
• R is the measurable space of reals, with its Borel sets. The Borel sets are the
smallest σ-algebra on R that contains the intervals. We will always consider R
with this σ-algebra.
• 1 is the unique measurable space with one point.
• A × B is the product space A × B. The σ-algebra ΣA×B is the least one
containing the rectangles (U × V) with U ∈ΣA and V ∈ΣB (e.g. Pollard,
2002, Def. 16)).
• .
i∈I Ai is the coproduct space -
i∈IAi, the disjoint union. The σ-algebra
Σ.
i∈I Ai is least one containing the sets {(i,a) | a ∈U} for U ∈ΣAi. For
example, the type N is interpreted as the space N of natural numbers with the
discrete σ-algebra, where all sets are measurable.
• We let P(A) be the set P(A) of probability measures on A together with the
least σ-algebra containing the sets {μ | μ(U) < r} for each U ∈ΣX and r ∈[0,1]
(the 'Giry monad' (Giry, 1982)).
2.4.3 Typed program expressions
We consider programs built from the following grammar:
t,t0,t1 ::= (i,t) | case t of {(i, x) ⇒ui}i∈I | () | (t0,t1) | projj(t) | f (t) | x
| return(t) | let x = t in u | sample(t) | score(t) | normalize(t)
(2.9)
The ﬁrst line of (2.9) contains standard deterministic expressions, for example
destructing union and product types, with intended equations such as the following:
(
case (j,t) of {(i, x) ⇒ui}
)
= uj[t/x]
projj(t0,t1) = tj.
We also include some basic functions f , and in fact, we may as well include all
measurable functions in our language, including arithmetic operations and constants
(e.g. +, ×, k10), comparison predicates (e.g. =, <), and parameterized probability
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

64
Staton: Probabilistic Programs as Measures
measures (e.g. normal, bernoulli). There are also variables x that are bound by case
and let.
In a real computer language, operations over inﬁnite structures such as lists and
numbers are given by induction or recursion. In this chapter, rather than worry about
this, we simply allow the programmer to give a diﬀerent case for every index into
the inﬁnite structure. This means that the case syntax is potentially inﬁnite, since
the set I might be (countably) inﬁnite. It is routine to build a ﬁnite language with
inductive primitives and translate it into this one.
The second line of (2.9) contains ways of combining programs (let) and sequencing,
as well as the three crucial primitives of probabilistic programming: sample, score
and normalize.
In this simple language, there is little syntactic sugar, and so the program about
buses in Section 2.2.1 would be written:
1.
normalize(
2.
let x = sample(bernoulli(2
7)) in
3.
let r = case x of {(1,_) ⇒return(k3()),(2,_) ⇒return(k10())} in
4.
let _ = score( 1
4!r4e−r) in
5.
return(x))
(2.10)
where k3, k10 : 1 →R are the obvious constant functions, which are measurable.
Typed terms. We distinguish typing judgements: Γ ⊢d t : A for deterministic
terms, and Γ ⊢p t : A for probabilistic terms. Here the context Γ is of the form
(x1 : B1,. . ., xn : Bn). The intuition is that if Γ ⊢z t : A then the free variables of t
are contained in x1 . . . xn, and given values of the right type for each free variable,
then the expression t will return something of type A, either deterministically or
probabilistically. For example, the entire program in (2.10) is a deterministic term
returning a distribution, whereas lines 2-5 form a probabilistic term of type (1 + 1).
Neither have any free variables. The term score( 1
4!r4e−r) is a probabilistic term with
a real free variable r : real, so we write r : real ⊢p score( 1
4!r4e−r): 1.
We have already explained that each type A is understood as a measurable space.
Formally, a context Γ = (x1 : A1,. . ., xn : An) is also interpreted as a measurable
space Γ
def= /n
i=1Ai of well-typed valuations for the variables. As will be seen in
the next section, deterministic terms Γ ⊢d t : A denote measurable functions from
Γ →A, closed probabilistic terms ⊢p t′: A denote measures on A, and open
probabilistic terms Γ ⊢p t′: A denote kernels Γ ⇝A. We give a syntax and type
system here, and a semantics in Section 2.4.4.
We specify the valid judgements Γ ⊢d t : A and Γ ⊢p t : A as the least relations
closed under the following rules.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

2.4 Formal semantics of probabilistic programs as measures
65
Sums and products. The type system allows variables, and standard constructors
and destructors for sum and product types.
Γ, x : A,Γ′ ⊢d x : A
Γ ⊢d t : Ai
Γ ⊢d (i,t): .
i∈I Ai
Γ ⊢d t : .
i∈I Ai
(Γ, x : Ai ⊢z ui : B)i∈I
Γ ⊢z case t of {(i, x) ⇒ui}i∈I : B
(z ∈{d,p})
Γ ⊢d (): 1
Γ ⊢d t0 : A0
Γ ⊢d t1 : A1
Γ ⊢d (t0,t1): A0 × A1
Γ ⊢d t : A0 × A1
Γ ⊢d projj(t): Aj
If the reader is not familiar with type systems, they might consult the early chapters
of (Harper, 2016). We give an example of a typing derivation later, in (2.12). For
instance, the rule for (t0,t1) says that "if term t0 has type A0 and term t1 has type A1
then the pair (t0,t1) has type (A0 × A1)".
In the rules for sums, I may be inﬁnite. In the last rule, j is 0 or 1. We use
some standard syntactic sugar, such as false and true for the injections in the type
bool = 1 + 1, and if for case in that instance. The continuations of case expressions
may be either deterministic or probabilistic, as indicated.
Sequencing. We include the standard constructs for sequencing (e.g. Levy et al.,
2003; Moggi, 1991).
Γ ⊢d t : A
Γ ⊢p return(t): A
Γ ⊢p t : A
Γ, x : A ⊢p u: B
Γ ⊢p let x = t in u: B
Notice that, in this simple language, everything probabilistic must be explicitly
sequenced. For example, if Γ ⊢p t0 : A0 and Γ ⊢p t1 : A1, we cannot conclude that
Γ ⊢p (t0,t1): A0 × A1. Rather, we have to explicitly write
Γ ⊢p let x0 = t0 in let x1 = t1 in return(x0, x1): A0 × A1
or
Γ ⊢p let x1 = t1 in let x0 = t0 in return(x0, x1): A0 × A1
Later (§2.5.1) we will show that the order of evaluation doesn't matter, so we could
use (t0,t1) as an unambiguous syntactic sugar, but it makes the formal semantics
simpler to insist that the order of evaluation is given explicitly.
Language-speciﬁc constructs. We also include constant terms for all measurable
functions. Recall that a function f : X →Y between measurable spaces is itself
measurable if the inverse image of a measurable set is again measurable.
Γ ⊢d t : A
Γ ⊢d f (t): B ( f : A →B measurable)
(2.11)
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

66
Staton: Probabilistic Programs as Measures
Thus we assign suitable types to the arithmetic operations and constants (e.g. + :
R × R →R, k10 : 1 →R), predicates (e.g. (=) : R × R →bool) and probability
measures (e.g. normal : R × R →P(R)). For instance, we have a judgement
μ : R,σ : R ⊢d normal(μ,σ): P(R). (Some families are not deﬁned for all parameters,
e.g. the standard deviation should be positive, but we make ad-hoc safe choices
throughout rather than using exceptions or subtyping.)
For example, the expression (if x then 3 else 10) is shorthand for
(case x of {(1,_) ⇒k3() ; (2,_) ⇒k10()})
We derive that the expression has type R when x has type bool, by deriving it from
the rules as follows.
−
x : bool ⊢d x : bool
−
x : bool, z: 1 ⊢d (): 1
x : bool, z: 1 ⊢d k3(): R
−
x : bool, z: 1 ⊢d (): 1
x : bool, z: 1 ⊢d k10(): R
x : bool ⊢d case x of {(1, z) ⇒k3() ; (2, z) ⇒k10()}: R
(2.12)
The core of the language is the constructs corresponding to the terms in Bayes'
law: sampling from prior distributions, recording likelihood scores,
Γ ⊢d t : P(A)
Γ ⊢p sample(t): A
Γ ⊢d t : R
Γ ⊢p score(t): 1
and calculating the normalizing constant and a normalized posterior.
Γ ⊢p t : A
Γ ⊢d normalize(t): R × P(A) + 1 + 1
As we discussed in Section 2.2.4, normalization will fail if the normalizing constant
is zero or inﬁnity; so it produces either a normalization constant together with
a normalized posterior distribution (R × P(A)), or exceptionally one of the two
failure possibilities (+1 + 1). In a complex model the normalized posterior could
subsequently be used as a prior and sampled from. This is sometimes called a 'nested
query' (see for instance Stuhlmuller and Goodman, 2014), but it remains to be seen
whether it is computationally practical (Rainforth et al., 2018).
2.4.4 Expressions as s-ﬁnite kernels, programs as measures
In this section we will give an interpretation of closed programs ⊢p t : A as measures
on A. To do this, we must also interpret open programs Γ ⊢p t : A, which will be
families of measures on A that are indexed by the valuations of the context Γ.
These are called kernels. (Warning: the word kernel is over-used and has other
meanings.)
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

2.4 Formal semantics of probabilistic programs as measures
67
s-Finite kernels
A kernel k from X to Y is a function k : X × ΣY →[0,∞] such that each k(x,−) :
ΣY →[0,∞] is a measure and each k(−,U) : X →[0,∞] is measurable. Because
each k(x,−) is a measure, we can integrate any measurable function f : Y →[0,∞]
to get
∫
k(x) f (y) dy ∈[0,∞]. We write k : X ⇝Y if k is a kernel. We say that k is a
probability kernel if k(x,Y) = 1 for all x ∈X.
We need to further reﬁne the notion of kernels, because arbitrary kernels do not
behave well. The following result is a step towards the central notion of s-ﬁnite
kernel.
Proposition 2.5
Let X,Y be measurable spaces. If k1 . . . kn · · · : X ⇝Y are
kernels then the function (	∞
i=1 ki) : X × ΣY →[0,∞] given by
(	∞
i=1 ki)(x,U)
def=
∞

i=1
(ki(x,U))
is a kernel X ⇝Y. Moreover, for any measurable function f : Y →[0,∞],
∫
(	∞
i=1 ki)(x)
f (y) dy =
∞

i=1
∫
ki(x)
f (y) dy.
Deﬁnition 2.6
Let X,Y be measurable spaces. A kernel k : X ⇝Y is ﬁnite if there
is ﬁnite r ∈[0,∞) such that, for all x, k(x,Y) < r.
A kernel k : X ⇝Y is s-ﬁnite if there is a sequence k1 . . . kn . . . of ﬁnite kernels
and 	∞
i=1 ki = k.
Note that the bound in the ﬁniteness condition, and the choice of sequence in the
s-ﬁniteness condition, are uniform, across all arguments to the kernel.
If the reader is familiar with the notion of σ-ﬁnite measure, they will note that this
is diﬀerent. In fact, an s-ﬁnite measure is the same thing as the push-forward of a
σ-ﬁnite measure (Getoor, 1990; Sharpe, 1988). The deﬁnition of s-ﬁnite kernel is not
so common but appears in recent work by (Kallenberg, 2014) and Last and Penrose
(2016, App. A). It was proposed as a foundation for probabilistic programming by
the author (Staton, 2017), but it has since attracted further use and development (e.g.
Bichsel et al., 2018; Ong and Vákár, 2018).
Composition of kernels
Before we give the semantics of our language, we need a lemma which is central to
the interpretation of let.
Lemma 2.7
Let X,Y, Z be measurable spaces, and let k : X × Y ⇝Z and
l : X ⇝Y be s-ﬁnite kernels (Def. 2.6). Then we can deﬁne a s-ﬁnite kernel
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

68
Staton: Probabilistic Programs as Measures
(k ⋆l) : X ⇝Z by
(k ⋆l)(x,U)
def=
∫
l(x)
k(x, y,U) dy
so that
∫
(k⋆l)(x)
f (z) dz =
∫
l(x)
∫
k(x,y)
f (z) dz dy
A proof is given in (Staton, 2017), building on a well-known fact that the the
property holds for ﬁnite kernels (e.g. Pollard, 2002, Thm. 20(ii)). The example in
Section 2.3.3 shows that if we generalize to arbitrary kernels, we cannot construct
k ⋆l in general. In detail, let X = Y = R and let Z = 1 = {∗}. Pick a Borel subset
U ⊆R × R whose projection is not Borel. Let k(x, y, {∗}) = [(x, y) ∈U], and let
l(x,−) be the counting measure on R. Then (k ⋆l)(x, {∗}) is non-zero if and only if
x ∈π[U], and so it is not measurable in x, and so it is not a kernel.
Semantics
Recall that types A are interpreted as measurable spaces A. We now explain how
to interpret a deterministic term in context, Γ ⊢d t : A, as a measurable function
t : Γ →A, and how to interpret a probabilistic term in context, Γ ⊢p t : A, as
an s-ﬁnite kernel t : Γ ⇝A.
The semantics of the language, beginning with variables, sums and products, is
roughly the same as a set-theoretic semantics. For each typed term Γ ⊢d t : A, and
each valuation γ ∈Γ of values for variables, we deﬁne an element tγ of A, in
such a way that the assignment is measurable in γ. We do this by induction on the
structure of typing derivations:
xγ
def= γx
(i,t)γ
def= (i,tγ)
case t of {(i, x) ⇒ui}i∈Iγ
def= uiγ,d
if tγ = (i, d)
()γ
def= ()
(t0,t1)γ
def= (t0γ,t1γ)
πj(t)γ
def= di
if tγ = (d0, d1)
Here we have only treated the case expressions when the continuation ui is
deterministic; we return to the probabilistic case later.
For each typed probabilistic term Γ ⊢p t : A, and each valuation γ ∈Γ, and each
measurable set U ∈ΣA, we deﬁne a measure tγ;U ∈[0,∞], in such a way that t
is an s-ﬁnite kernel Γ ⇝A (Def. 2.6). The semantics of sequencing are perhaps
the most interesting: return is the Dirac delta measure, and let is integration.
return(t)γ;U
def=

1
if tγ ∈U
0
otherwise
let x = t in uγ;U
def=
∫
tγ
uγ,x;U dx
The interpretation return(t) is ﬁnite, hence s-ﬁnite. The fact that let x = t in u is
an s-ﬁnite kernel is Lemma 2.7: this is the most intricate part of the semantics.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

2.4 Formal semantics of probabilistic programs as measures
69
We return to the case expression where the continuation is probabilistic:
case t of {(i, x) ⇒ui}i∈Iγ;U
def= uiγ,d;U
if tγ = (i, d).
We must show that this is an s-ﬁnite kernel. Recall that ui : Γ × Ai ⇝B,
s-ﬁnite. We can also form ui : Γ × -
jAj ⇝B with
uiγ,(j,a);U
def=

uiγ,a;U
i = j
0
otherwise
and it is easy to show that ui is an s-ﬁnite kernel. Another easy fact is that a
countable sum of s-ﬁnite kernels is again an s-ﬁnite kernel, so we can build an
s-ﬁnite kernel (	
i ui) : Γ × -
jAj ⇝B. Finally, we use a simple instance
of Lemma 2.7 to compose (	
i ui) with t : Γ →-
jAj and conclude that
case t of {(i, x) ⇒ui}i∈I is an s-ﬁnite kernel.
The language speciﬁc constructions are straightforward.
sample(t)γ;U
def= tγ(U)
score(t)γ;U
def=

|tγ|
if U = {()}
0
if U = ∅.
In the semantics of sample, we are merely using the fact that to give a measurable
function X →P(Y) is to give a probability kernel X ⇝Y. Probability kernels are
ﬁnite, hence s-ﬁnite.
The semantics of score is a one point space whose measure is the argument.
(We take the absolute value of tγ because measures should be non-negative. An
alternative would be to somehow enforce this in the type system.) We need to show
that score(t) is an s-ﬁnite kernel. Although score(t)γ;1 is always ﬁnite, score(t)
is not necessarily a ﬁnite kernel because we cannot ﬁnd a uniform bound. To show
that it is s-ﬁnite, for each i ∈N0, deﬁne a kernel ki : Γ ⇝1
ki(γ,U)
def=

score(t)γ;U
if score(t)γ;U ∈[i,i + 1)
0
otherwise
So each ki is a ﬁnite kernel, bounded by (i + 1), and score(t) = 	∞
i=0 ki, so it is
s-ﬁnite.
We give a semantics to normalization by ﬁnding the normalizing constant and
dividing by it, as follows. Consider Γ ⊢p t : A and let evidenceγ,t
def= tγ;A.
normalize(t)γ
def=
⎧⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩
(0,(evidenceγ,t,
tγ;(−)
evidenceγ,t ))
evidenceγ,t ∈(0,∞)
(1,())
evidenceγ,t = 0
(2,())
evidenceγ,t = ∞
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

70
Staton: Probabilistic Programs as Measures
2.5 Reasoning with measures
Once a formal semantics of probabilistic programs as measures is given, one can
reason about programs by reasoning about measures. Moreover, since the semantics
is compositional, one can build up properties of programs in a compositional way.
We consider two examples.
2.5.1 Reasoning example: Commutativity
We can quickly verify the following law
let x0 = t0 in let x1 = t1 in return(x0, x1)
=
let x1 = t1 in let x0 = t0 in return(x0, x1)
(2.13)
whenever Γ ⊢p t0 : A0 and Γ ⊢p t1 : A1. To do this we recall that t0γ;−and t1γ;−are
measures on A0 and A1 respectively, and calculate that
let x0 = t0 in let x1 = t1 in return(x0, x1)γ;U
=
∫
t0(γ)
∫
t1(γ)
[(x0, x1) ∈U] dx1 dx0
is the deﬁnition of the product measure on A0 × A1. Product measures are not
well-deﬁned in general, but they are well-deﬁned for ﬁnite measures, and this extends
to s-ﬁnite measures. Indeed to conclude (2.13), one would notice that for any s-ﬁnite
measures μ0, μ1 on A0 and A1, the product measures on A0 × A1 are equal:
∫
μ0
∫
μ1
[(x0, x1) ∈U] dx1 dx0 =
∫
μ1
∫
μ0
[(x0, x1) ∈U] dx0 dx1
This is known as the Fubini-Tonelli theorem, which holds for s-ﬁnite measures (e.g.
Sharpe, 1988; Staton, 2017).
2.5.2 Reasoning example: Non-deﬁnability
We have seen in Section 2.3.3 that the counting measure on R, which assigns to
each set its size, is problematic for a probabilistic programming language. We now
show that it is not deﬁnable. It is suﬃcient to show that it is not s-ﬁnite, since every
deﬁnable program describes an s-ﬁnite measure. To show this we show that for every
s-ﬁnite measure μ, the set {r | μ({r}) > 0} is countable. The counting measure
violates this invariant. Since a countable union of countable sets is countable, it
suﬃces to show that {r | μ({r}) > 0} is countable when μ is a ﬁnite measure. To see
this, notice that for each positive integer n the set {r | μ({r}) > 1
n} must be ﬁnite,
and so {r | μ({r}) > 0} = 
n∈Z+{r | μ({r}) > 1
n} must be countable.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

2.6 Other approaches to semantics and open questions
71
2.6 Other approaches to semantics and open questions
2.6.1 Diﬀerent approaches to semantic deﬁnitions
In other work (Staton et al., 2016) we have considered a semantics based on a monad
X →P([0,∞) × X)
on the category of measurable spaces. This arises from combining the writer monad
for the monoid ([0,∞),+,0) of scores with the probability monad P. This naturally
matches the two constructions (score for [0,∞) and sample for P), and it ﬁts the
weighted simulation semantics: the meaning of a program is a distribution over runs,
each of which has a weight and a result. This semantics distinguishes things that
should arguably be considered equal. For example, the semantics will distinguish
let x = sample(bernoulli(0.5)) in if x then score(4) else score(6); return(42)
from
score(5); return(42)
This semantics can be translated to the less discriminating semantics in this chapter
as follows. Every measurable function
f : Y →P([0,∞) × X)
can be translated to an s-ﬁnite kernel f ♯: Y ⇝X where
f ♯(y,U) =
∫
f (y)
r · [x ∈U] d(r, x).
In fact, every s-ﬁnite kernel arises in this way. This translation preserves all the
structure. Thus the monadic interpretation of the language can be translated into the
s-ﬁnite semantics compositionally.
In Section 2.3 we considered an even more ﬁne-grained approach, where a
program −⊢p t : A is interpreted as a measurable function Ω →A, i.e. a random
variable on some basic probability space, together with a separate likelihood function
Ω →[0,∞). (See also e.g. Holtzen et al., 2018; Hur et al., 2015). By considering
the law of the pairing Ω →[0,∞) × A we arrive at a probability measure in
P([0,∞) × A), and every such probability measure arises as the law of some
such pairing. Another way to include weightings is to consider Ω to be a subset of
some plane Rn with an unnormalized Lebesgue measure. It turns out that an s-ﬁnite
measure on a standard Borel space X is the same thing as the pushforward measure
of a Lebesgue measure along a measurable function Ω →X, where Ω ⊆Rn. So
these diﬀerent semantic methods all agree on what can be considered.
Although s-ﬁnite measures and kernels behave very well and have many charac-
terizations, it is currently an open question whether the category of s-ﬁnite kernels is
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

72
References
itself the Kleisli category for a monad. Recently we have proposed to use quasi-Borel
spaces as generalized measurable spaces. S-ﬁnite kernels between quasi-Borel spaces
do form the Kleisli category for a monad (Scibior et al., 2018).
2.6.2 Other semantic issues
In this chapter we have focused on giving a simple, measure-theoretic semantics
to the programs in the simple ﬁrst-order language through s-ﬁnite kernels. The
semantics is clear, but subtle, because of issues of inﬁnite normalization constants
and measurability issues. But this simple semantics is only a very ﬁrst step. Beyond:
• Statisticians and probabilists are interested in other issues such as convergence and
relative entropy, which might also be analyzed in a compositional way, together
with their relationships to computability (e.g. Ackerman et al., 2011; Huang and
Morrisett, 2017).
• We might also add diﬀerent modes of conditioning, such as conditioning by
disintegration rather than density (e.g. Shan and Ramsey, 2016).
• We might add other typical language features such as higher order functions (e.g.
Staton et al., 2016; Heunen et al., 2017), higher order recursion (e.g. Ehrhard
et al., 2018; Vákár et al., 2019), and abstract types (e.g. Staton et al., 2018).
• Other languages have additional, non-functional primitives, based on logic
programming (e.g. Nitti et al., 2016; Wu et al., 2018).
Acknowledgements.
I have beneﬁted from discussing this topic with a great many people at various
meetings over the last three years. I would particularly like to thank Chris Heunen,
Ohad Kammar, Sean Moss, Matthijs Vákár, Frank Wood, Hongseok Yang. The
examples in Sections 2.2 and 2.3 arose in preparing various invited talks lectures
on the subject, including ICALP 2018 and OPLSS 2019, and I am grateful for
these opportunities. The material in Section 2.4 is based on my paper in ESOP
2017 (Staton, 2017), and I am grateful to the reviewers of that article.
My research is supported by a Royal Society University Research Fellowship.
Dartboard image (Fig. 2.7) based on TikZ example by Roberto Bonvallet (Creative
Commons attribution license), with changes made.
References
Ackerman, N L, Freer, Cameron E, and Roy, Daniel M. 2011. Noncomputable
Conditional Distributions. In: Proc. LICS 2011.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
73
Ackerman, Nathanael L., Freer, Cameron E., and Roy, Daniel M. 2015.
On
computability and disintegration.
Bhat, Sooraj, Borgström, Johannes, Gordon, Andrew D., and Russo, Claudio V.
2017. Deriving Probability Density Functions from Probabilistic Functional
Programs. Logical Methods in Computer Science, 13(2).
Bichsel, Benjamin, Gehr, Timon, and Vechev, Martin. 2018. Fine-Grained Semantics
for Probabilistic Programs. In: Proc. ESOP 2018.
Ehrhard, Thomas, Pagani, Michele, and Tasson, Christine. 2018. Measurable
cones and stable, measurable functions: a model for probabilistic higher-order
programming. In: Proc. POPL 2018.
Gehr, Timon, Misailovic, Sasa, and Vechev, Martin T. 2016. PSI: Exact Symbolic
Inference for Probabilistic Programs. Pages 62-83 of: Proc. CAV 2016.
Getoor, R K. 1990. Excessive Measures. Birkhäuser.
Giry, M. 1982. A Categorical Approach to Probability Theory. Categorical Aspects
of Topology and Analysis, 915, 68-85.
Goodman, N. D., and Stuhlmüller, A. 2014. The Design and Implementation of
Probabilistic Programming Languages.
Goodman, Noah, Mansinghka, Vikash, Roy, Daniel M, Bonawitz, Keith, and
Tenenbaum, Joshua B. 2008. Church: a language for generative models. In:
UAI.
Harper, Robert. 2016. Practical Foundations for Programming Languages. CUP.
Heunen, C, Kammar, O, Staton, S, and Yang, H. 2017. A convenient category for
higher-order probability theory. arXiv:1701.02547.
Holtzen, Steven, den Broeck, Guy Van, and Millstein, Todd D. 2018. Sound
Abstraction and Decomposition of Probabilistic Programs. In: Proc. ICML
2018.
Huang, Daniel, and Morrisett, Greg. 2017. An application of computable distributions
to the semantics of probabilistic programs: part 2. In: Proc. PPS 2017.
Hur, Chung-Kil, Nori, Aditya V., Rajamani, Sriram K., and Samuel, Selva. 2015. A
Provably Correct Sampler for Probabilistic Programs. In: FSTTCS.
Ismail, Wazim Mohammed, and chieh Shan, Chung. 2016. Deriving a probability
density calculator (functional pearl). In: Proc. ICFP 2016.
Kallenberg, O. 2014. Stationary and invariant densities and disintegration kernels.
Probab. Theory Relat. Fields, 160, 567-592.
Koehl, Albert, Rupasinghe, Kevin, and Lee, Rachel. 2017 (Sept.). Bloor St. bike
lane used by over 6,000 cyclists per day.
Press release.
Available at
https://bellsonbloor.wordpress.com.
Last, G, and Penrose, M. 2016. Lectures on the Poisson process. CUP.
Levy, Paul Blain, Power, John, and Thielecke, Hayo. 2003. Modelling environments
in call-by-value programming languages. Inf. Comput., 185(2).
Mansinghka, Vikash K., Selsam, Daniel, and Perov, Yura N. 2014. Venture: a higher-
order probabilistic programming platform with programmable inference.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

74
References
Moggi, Eugenio. 1991. Notions of computation and monads. Inf. Comput., 93(1),
55-92.
Narayanan, P, Carette, J, Romano, W, Shan, C-C, and Zinkov, R. 2016. Probabilistic
inference by program transformation in Hakaru (system description). In:
Proc. FLOPS 2016.
Nitti, Davide, Laet, Tinne De, and Raedt, Luc De. 2016.
Probabilistic logic
programming for hybrid relational domains. Mach. Learn., 103, 407-449.
Ong, Luke, and Vákár, Matthijs. 2018. S-ﬁnite Kernels and Game Semantics for
Probabilistic Programming. In: Proc. PPS 2018.
Pollard, D. 2002. A user's guide to measure theoretic probability. CUP.
Rainforth, Tom, Cornish, Robert, Yang, Hongseok, Warrington, Andrew, and Wood,
Frank. 2018. On Nesting Monte Carlo Estimators. In: Proc. ICML 2018.
Robert, Christian P. 2007. The Bayesian Choice: From Decision-Theoretic Founda-
tions to Computational Implementation. Springer.
Schervish, Mark J. 1995. Theory of Statistics. Springer.
Scibior, Adam, Kammar, Ohad, Vákár, Matthijs, Staton, Sam, Yang, Hongseok, Cai,
Yufei, Ostermann, Klaus, Moss, Sean K., Heunen, Chris, and Ghahramani,
Zoubin. 2018. Denotational validation of higher-order Bayesian inference. In:
Proc. POPL 2018.
Shan, Chung-Chieh, and Ramsey, Norman. 2016. Symbolic Bayesian Inference by
Symbolic Disintegration.
Sharpe, M. 1988. General theory of Markov Processes. Academic Press.
Staton, S., Yang, H., Heunen, C., Kammar, O., and Wood, F. 2016. Semantics for
probabilistic programming: higher-order functions, continuous distributions,
and soft constraints. In: Proc. LICS 2016.
Staton, Sam. 2017. Commutative semantics for probabilistic programming. In:
Proc. ESOP 2017.
Staton, Sam, Stein, Dario, Yang, Hongseok, and Nathanael L.. Ackerman,
Cameron Freer, Daniel M Roy. 2018. The Beta-Bernoulli Process and Algebraic
Eﬀects. In: Proc. ICALP 2018.
Stuhlmuller, Andreas, and Goodman, Noah D. 2014. Reasoning about reasoning
by nested conditioning: Modeling theory of mind with probabilistic programs.
Cognitive Systems Research, 28, 80-99.
Tjur, Tue. 1980. Probability based on Radon measures. Wiley.
Vákár, Matthijs, Kammar, Ohad, and Staton, Sam. 2019. A domain theory for
statistical probabilistic programming. In: Proc. POPL 2019.
van de Meent, Jan-Willem, Paige, Brooks, Yang, Hongseok, and Wood, Frank. 2018.
An Introduction to Probabilistic Programming. arxiv:1809.10756.
Wood, Frank, van de Meent, Jan Willem, and Mansinghka, Vikash. 2014. A New
Approach to Probabilistic Programming Inference. In: AISTATS.
Wu, Yi, Srivastava, Siddharth, Hay, Nicholas, Du, Simon, and Russell, Stuart J. 2018.
Discrete-Continuous Mixtures in Probabilistic Programming: Generalized
Semantics and Inference Algorithms. Pages 5339-5348 of: Proc. ICML 2018.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

3
An Application of Computable Distributions to the
Semantics of Probabilistic Programs
Daniel Huang
University of California, Berkeley
Greg Morrisett
Cornell University
Bas Spitters
Aarhus University
Abstract:
In this chapter, we explore how (Type-2) computable distributions
can be used to give both (algorithmic) sampling and distributional semantics to
probabilistic programs with continuous distributions. Towards this end, we sketch
an encoding of computable distributions in a fragment of Haskell and show how
topological domains can be used to model the resulting PCF-like language. We also
examine the implications that a (Type-2) computable semantics has for implementing
conditioning. We hope to draw out the connection between an approach based on
(Type-2) computability and ordinary programming throughout the chapter as well
as highlight the relation with constructive mathematics (via realizability).
3.1 Overview
Probabilistic programs exhibit a tension between the continuous and the discrete.
On one hand, we are interested in using probabilistic programs to model natural
phenomena—phenomena that are often modeled well with reals and continuous
distributions (e.g., as in physics and biology). On the other hand, we are also bound
by the fundamentally discrete nature of computation, which limits how we can (1)
represent models as programs and then (2) compute the results of queries on the
model. The aim of this chapter1 2 3 is to keep this tension in the fore by using the
notion of a (Type-2) computable distribution as a lens through which to understand
probabilistic programs. We organize our exploration via a series of questions.
a From Foundations of Probabilistic Programming, edited by Gilles Barthe, Joost-Pieter Katoen and Alexandra
Silva published 2020 by Cambridge University Press.
1 This chapter contains material from Huang (2017) and Huang and Morrisett (2016).
2 Daniel Huang was supported by DARPA FA8750-17-2-0091.
3 Bas Spitters was partially supported by the Guarded homotopy type theory project, funded by the Villum
Foundation, project number 12386 and partially by the AFOSR project 'Homotopy Type Theory and Probabilistic
Computation', 12595060. Any opinions, ﬁndings and conclusions or recommendations expressed in this material
are those of the authors and do not necessarily reﬂect the views of the AFOSR.
75
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

76
Huang, Morrisett and Spitters: Computable Distributions
(i) What is a (Type-2) computable distribution (Section 3.2)? First, we review
Type-2 computability (e.g., see Weihrauch, 2000) and how it applies to reals and
continuous distributions. The high-level idea is to represent continuum-sized
objects as a sequence of discrete approximations that converge to the appropriate
object instead of abstracting the representation of such an object.
(ii) How do we implement continuous distributions as a library in a general-purpose
programming language (Section 3.3)? After we have seen the basic idea behind
Type-2 computability, we sketch an implementation of reals and continuous
distributions in a fragment of Haskell. We emphasize that the implementation
does not assume any reals, continuous distributions, or operations on them as
black-box primitives.
(iii) What mathematical structures can we use to model such a library (Section 3.4)?
Our next step is to ﬁnd mathematical structures that can be used to faithfully model
the implementation. Towards this end, we review topological domains (e.g., see
Battenfeld et al., 2007; Battenfeld, 2008), which are an alternative to traditional
structures used in denotational semantics. Topological domains support all the
standard domain-theoretic constructions needed to model PCF-like4 languages as
well as capture the notion of (Type-2) computability. In particular, we can encode
reals and continuous distributions as topological domains so that they are suitable
for our purposes of giving semantics.
(iv) What does a semantics for a core language look like (Section 3.5)? In this section,
we make the connection between the implementation and the mathematics more
concrete by using the constructs described previously to give both (algorithmic)
sampling and distributional semantics to a core PCF-like language extended with
reals and continuous distributions (via a probability monad) called λCD.5 The
sampling semantics can be used to guide implementation while the distributional
semantics can be used for equational reasoning.
(v) What are the implications of taking a (Type-2) computable viewpoint for
Bayesian inference (Section 3.6)? Perhaps surprisingly, at least to those who
employ Bayesian inference in practice, it can be shown that conditioning is not
(Type-2) computable (see Ackerman et al., 2011). Hence, there is a sense in
which a "Turing-complete" probabilistic programming language cannot support
conditional queries for every expressible probabilistic model. Fortunately, we
do not run into these pathologies in practice and can recover conditioning in
suﬃciently general settings.
We hope to draw out the connection between an approach based on (Type-2)
4 Recall that the PCF (Programming Computable Functions) language is a core calculus that can be used to
model typed functional languages such as Haskell.
5 λC D also supports distributions on any countably based space. This means that λC D does not (in general)
have distributions on function spaces, although the language itself contains higher-order functions.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

3.2 Computability Revisited
77
computability with ordinary programming (i.e., programming in a fragment of
Haskell) throughout the chapter as well as highlight the relation with constructive
mathematics via realizability (e.g., see Streicher, 2008) (Section 3.4.4).
Prerequisites We assume basic knowledge of programming language seman-
tics (e.g., at the level of Gunter, 1992). For our purposes, this primarily includes (1)
the application of category theory to programming language semantics and (2) the
use of complete partial orders (CPOs) to model the semantics of PCF. As we will
be giving examples in Haskell, familiarity with the Haskell programming language
will also be assumed.6 Finally, we assume basic knowledge of measure-theoretic
probability (e.g., see Durrett, 2010).
3.2 Computability Revisited
What is a computable distribution? One approach to studying computability is
based on Turing machines (e.g., see Sipser, 2012). Under this approach, we deﬁne
(1) a machine model (i.e., the Turing machine) and (2) conditions under which
the machine model is said to compute. More concretely, a Turing machine is
said to compute a (partial) function f : Σ∗⇀Σ∗if it halts with f (w) ∈Σ∗
on the output tape given w ∈Σ∗on an input tape, where Σ is a ﬁnite set and
Σ∗≜{a0 . . . an | ai ∈Σ,0 ≤i ≤n} is a collection of words comprised of characters
from Σ. The two element set 2 ≜{0,1} for bits (or booleans) is a commonly used
alphabet.
This deﬁnition of computability reveals that traditional computation is fundamen-
tally discrete. We can see this directly in the deﬁnition of a computable function
(with type Σ∗⇀Σ∗), which maps elements of a discrete domain (i.e., a set of ﬁnite
words Σ∗) to elements of a discrete codomain (i.e., a set of ﬁnite words Σ∗again).
As Σ∗is countable, it cannot be put in bijection with the reals R; hence, we cannot
encode all the reals on a Turing machine.
One immediate issue that this highlights for probabilistic programs is how one
should handle reals and continuous distributions while maintaining the connection
back to computation. A pragmatic solution to this is to use ﬂoating point arithmetic,
i.e., discretize and ﬁnitize the reals. From this perspective, we can model the
semantics of probabilistic programs using ﬂoating point numbers and ﬁnitely-
supported discrete distributions (on ﬂoats) so that the semantics more faithfully
models an actual implementation. Nevertheless, we sacriﬁce the correspondence
between the program and the mathematics that we use on pencil-paper. An alternative
to the situation above is to generalize the notion of computability to continuum-sized
6 Familiarity with other typed functional languages such as ML should also suﬃce, although we should remind
ourselves that Haskell has call-by-need semantics so that it has a lazy order-of-evaluation.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

78
Huang, Morrisett and Spitters: Computable Distributions
sets in such a way that the computations can still by implemented by a standard
machine.
3.2.1 Type-2 Computability
Type-Two Theory of Eﬀectivity (abbreviated TTE, see Weihrauch, 2000) changes
the conditions under which a machine is said to compute an answer but keeps
the machine model as is. In this setting, a machine is said to compute a function
f : Σω ⇀Σω if it can write any initial segment of f (w) ∈Σω on the output tape in
ﬁnite time given w ∈Σ∗on an input tape, where Σω ≜{a0a1 . . . | ai ∈Σ,i ∈N}
is the set of streams composed of symbols from the ﬁnite set Σ. The set Σω has
continuum cardinality, and hence, can represent the reals and a class of distributions
(Section 3.2.2). Once we represent continuum-sized objects on a machine, we have
an avenue for studying which functions are Type-2 computable. Throughout the rest
of the chapter, we will abbreviate Type-2 computable as computable7 and use Type-2
computable for emphasis. We now review computable reals and distributions.
3.2.2 Computability, Reals and Distributions
Computability and reals Intuitively, we can represent a real on a machine by
encoding its binary expansion. More formally, we represent a real x ∈R on a
machine by encoding a fast Cauchy sequence of rationals that converges to x. Recall
that a sequence (qn)n∈N where each qn ∈Q is Cauchy if for every ϵ > 0, there is
an N such that |qn −qm| < ϵ for every n,m > N. Thus, the elements of a Cauchy
sequence become closer and closer to one another as we traverse the sequence. When
|qn −qn+1| < 2−n for all n, we call (qn)n∈N a fast Cauchy sequence. Hence, the
representation of a real as a fast Cauchy sequence evokes the idea of enumerating its
binary expansion. A real x ∈R is computable if we can enumerate (uniformly in an
enumeration of rationals) a fast Cauchy sequence that converges to x.
We give some examples of reals encoded as fast Cauchy sequences now.
Example 3.1 (Rational)
Consider two encodings of 0 as a fast Cauchy sequence
below.
(Constant) Let (xn)n∈N where xn ≜0 for n ∈N.
(Thrashing) Let (yn)n∈N where yn ≜
1
(−2)n+1 for n ∈N.
As 0 itself is also a rational number, we can simply represent it as a constant 0
sequence given by (xn)n∈N. We can also represent 0 as the sequence (yn)n∈N, where
7 Computability in the ordinary sense refers to Type-1 computability.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

3.2 Computability Revisited
79
the sequence jumps back and forth between positive and negative fractional powers
of two as it converges towards 0. 0 is clearly a computable real.
Example 3.2 (Irrational)
Let xn ≜2 + 	2+n
k=2
1
k!. Then (xn)n∈N is a fast Cauchy
encoding of e. It is easy to see that e is a computable real.
Example 3.3 (Non-computable)
Every real can be expressed as a fast Cauchy
sequence so there are necessarily non-computable reals as well. Let (Mn)n∈N be
some enumeration of Turing machines. Let t0 ≜1 and
tn+1 ≜

2 · tn
Mn halts
1 + tn
Mn does not halt.
Then (xn)n∈N where xn ≜	n
i=0
1
2ti is a fast Cauchy sequence that is not computable
because the Halting problem is not decidable.
A function f : R →R is computable if given a (fast Cauchy) sequence converging
to x ∈R, there is an algorithm that outputs a (fast Cauchy) sequence converging to
f (x).8 We emphasize that the algorithm must work generically for any input (fast
Cauchy) sequence including the non-computable ones. we give some examples now.
Example 3.4 (Addition)
The function +0 : R →R that adds 0 is computable
because an algorithm can obtain a (fast Cauchy) output sequence by adding the (fast
Cauchy) input sequence element-wise to a (fast Cauchy) sequence of 0.
Most familiar functions are computable (e.g., subtraction, multiplication, inverses,
exponentiation, logarithms on non-negative reals, and trigonometric functions such
as sines and cosines) so that there is an algorithm that transforms (fast Cauchy)
inputs into (fast Cauchy) outputs. Nevertheless, there are familiar functions that are
not computable.
Example 3.5 (Non-computable)
Consider the function =0: R →2 that tests if the
input is equal to 0 or not. Intuitively, this function is not computable because we
need to check the entire input sequence. For example, to check that the constant
sequence is equivalent to the thrashing sequence, we have to check the entirety of
both sequences, which cannot be done in ﬁnite time.
Computable metric spaces Topological spaces enable us to build a more general
notion of computability on a space.9 For the purposes of introducing reals and
distributions, we consider topological spaces with a notion of distance, i.e., metric
spaces. As a reminder, a metric space (X, d) is a set X equipped with a metric
8 A function f : Rn →R is computable if given (fast Cauchy) sequences converging to x1, . . . , xn ∈R, there is
an algorithm that outputs a (fast Cauchy) sequence converging to f (x1, . . . , xn).
9 For more background on topology, we refer the reader to Munkres (2000).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

80
Huang, Morrisett and Spitters: Computable Distributions
d : X × X →R. A metric induces a collection of sets called (open) balls, where
a ball centered at c ∈X with radius r ∈R is the set of points within r of c,
i.e., B(c,r) ≜{x ∈X | d(c, x) < r}. The topology O(X) associated with a metric
space X is the one induced by the collection of balls. Hence, the open balls of
a metric space provide a notion of distance in addition to providing a notion of
approximation.
Example 3.6
(N, dDiscrete) endows the naturals N with the discrete topology (i.e.,
O(N) = 2N), where dDiscrete is the discrete metric (i.e., d(n,m) ≜0 if n = m and
d(n,m) ≜1 otherwise for n,m ∈N).
Example 3.7
(R, dEuclid) endows the reals R with the familiar Euclidean topology,
where dEuclid is the standard Euclidean metric (i.e., dEuclid(x, y) ≜|x −y|).
Example 3.8
(2ω, dCantor) endows the set of bit-streams 2ω with the Cantor
topology, where dCantor is deﬁned as
dCantor(x, y) ≜inf{ 1
2n | xn  yn}.
One can check that a basic open set of the Cantor topology is of the form
a1 . . . an2ω ≜{b1b2 · · · ∈2ω | bi = ai,1 ≤i ≤n}. That is, basic open sets
of Cantor space ﬁx ﬁnite-preﬁxes.
A computable metric space imposes additional conditions on a metric space so
that a machine can enumerate successively more accurate approximations (according
to the metric) of a point in the metric space. We need two additional deﬁnitions
before we can state the deﬁnition. First, we say S is dense in X if for every x ∈X,
there is a sequence (sn)n∈N that converges to x, where sn ∈S for every n. Second,
we say that (X, d) is complete if every Cauchy sequence comprised of elements from
X also converges to a point in X.
Deﬁnition 3.9
A computable metric space is a tuple (X, d,S) such that (1) (X, d)
is a complete metric space, (2) S is a countable, enumerable, and dense subset, and
(3) the real d(si, sj) is computable for si, sj ∈S (see Hoyrup and Rojas, 2009, Def.
2.4.1).
Example 3.10
(R, dEuclid,Q) is a computable metric space for the reals where we
use the rationals Q as the approximating elements. Note that we can equivalently
use dyadic rationals as the approximating elements instead of Q.
Computability and distributions A distribution over the computable metric space
(X, d,S) can be formulated as a point of the computable metric space
(M(X), dρ,D(S)),
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

3.2 Computability Revisited
81
where M(X) is the set of Borel probability measures on a computable metric space
(X, d,S), dρ is the Prokhorov metric (see Hoyrup and Rojas, 2009, Defn. 4.1.1), and
D(S) is the class of distributions with ﬁnite support at ideal points S and rational
masses (see Hoyrup and Rojas, 2009, Prop. 4.1.1). The Prokhorov metric is deﬁned
as
dρ(μ,ν) ≜inf{ϵ > 0 | μ(A) ≤ν(Aϵ) + ϵ for every Borel A} ,
where Aϵ ≜{x ∈X | d(x, y) < ϵ for some y ∈A}. One can check that the sequence
below converges (with respect to the Prokhorov metric) to the (standard) uniform
distribution U(0,1).
*
0 →1
2, 1
2 →1
2
+
,
*
0 →1
4, 1
4 →1
4, 2
4 →1
4, 3
4 →1
4
+
,. . .,
Thus, a uniform distribution can be seen as the limit of a sequence of increasingly ﬁner
discrete, uniform distributions. As with a computable real, we say that a distribution
μ ∈M(X) is computable if we can enumerate (uniformly in an enumeration of a
basis and rationals) a fast Cauchy sequence that converges to μ.
Although the idea of constructing a (computable) distribution as a (computable)
point is fairly intuitive for the standard uniform distribution, it may be more diﬃcult
to perform the construction for more complicated distributions. Fortunately, we
can also think of a distribution on a computable metric space (X, d,S) in terms
of sampling, i.e., as a Type-2 computable function 2ω ⇀X. To make this more
concrete, we sketch an algorithm that samples from the standard uniform distribution
given a stream of fair coin ﬂips. The idea is to generate a value that can be queried
for more precision instead of a sample x in its entirety.
Let μiid(a1 . . . an2ω) ≜1/2n be the distribution associated with a stream of fair
coin ﬂips where 0 corresponds to heads and 1 corresponds to tails. A sampling
algorithm will interleave ﬂipping coins with outputting an element to the desired
precision, such that the sequence of outputs (sn)n∈N converges to a sample. For
instance, one binary digit of precision for a standard uniform distribution corresponds
to obtaining the point 1/2 because it is within 1/2 of any point in the unit interval.
Demanding another digit of precision produces either 1/4 or 3/4 according to
the result of a fair coin ﬂip. This is encoded below using the function bisect10,
which recursively bisects an interval n times, starting with (0,1), using the random
bit-stream u to select which interval to recurse on.
uniform : (Nat →Bool) →(Nat →Rat)
uniform ≜λu. λn. bisect u 0 1 n
In the limit, we obtain a single point corresponding to the sample.
10 See the implementation of stdUniform in Section 3.3.2 for the full deﬁnition.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

82
Huang, Morrisett and Spitters: Computable Distributions
The sampling view is (computably) equivalent to the view of a computable
distribution as a point in an appropriate computable metric space. To state the
equivalence, we need a few deﬁnitions. A computable probability space (X, μ) is a
pair where X is a computable metric space and μ is a computable distribution (see
Hoyrup and Rojas, 2009, Def. 5.0.1). We call a distribution μ on X samplable if there
is a computable function s : (2ω, μiid) ⇀(X, μ) such that s is computable on dom(s)
of full-measure (i.e., μ(X) = 1) and is measure-preserving (i.e., μ = μiid ◦s−1).
Proposition 3.11
(Computable iﬀsamplable, see Freer and Roy, 2010, Lem. 2
and Lem. 3). A distribution μ ∈M(X) on computable metric space (X, d,S) is
computable iﬀit is samplable.
Thus we can equivalently specify computable distributions by writing sampling
algorithms.
3.3 A Library for Computable Distributions
How do we implement continuous distributions as a library in a general-purpose
programming language? Our goal in this section is to translate the concepts about
reals and distributions we saw previously in Section 3.2 into code. Towards this end,
we sketch a Haskell library (Figure 3.1) that encodes reals and the sampling view of
distributions.11 We emphasize that the library does not assume any reals, continuous
distributions, or operations on them as black-box primitives.
3.3.1 Library
The library consists of three modules. The ﬁrst module ApproxLib provides the
interface for computable metric spaces. The second module RealLib implements
reals using the operations in ApproxLib and the third module CompDistLib
implements (continuous) distributions. We go over the modules in turn now.
As we mentioned previously, the module ApproxLib provides abstractions for
expressing elements as a sequence of approximations in a computable metric space.
The core type exposed by the module is Approx τ, which models an element of a
computable metric space and can be read as an approximation by a sequence of
values of type τ. For example, a real can be given the type Real ≜Approx Rat,
meaning it is a sequence of rationals (Rat) that converges to a real. We form values
of type Approx τ using mkApprox :: (Nat →α) →Approx α, which requires us
to check12 that the function we are coercing describes a fast Cauchy sequence, and
project out approximations using nthApprox :: Approx α →Nat →α.
11 The code is available at https://github.com/danehuang/cdist-sketch.
12 We do not use the Haskell type system to enforce that the function to coerce contains a fast Cauchy sequence so
the caller of mkApprox needs to perform this check manually.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

3.3 A Library for Computable Distributions
83
module ApproxLib (Approx(..), CMetrizable(..), mkApprox,
nthApprox) where
newtype Approx a = Approx { getApprox :: Nat -> a }
mkApprox :: (Nat -> a) -> Approx a
-- fast Cauchy sequence
nthApprox :: Approx a -> Nat -> a
-- project n-th approx.
class CMetrizable a where
enum :: [a]
-- countable, dense subset
metric :: a -> a -> Approx Rat
-- computable metric
module CompDistLib (RandBits, Samp(..), mkSamp) where
import ApproxLib
type RandBits = Nat -> Bool
newtype Samp a = Samp { getSamp :: RandBits -> a }
mkSamp :: (CMetrizable a) => (RandBits -> Approx a) -> Samp (
Approx a)
mkSamp = Samp
instance Monad Samp where
...
-- see text
Figure 3.1 A Haskell library interface for expressing approximations in a computable metric
space (module ApproxLib) and encoding (continuous) distributions (module CompDistLib).
The library interface for reals (module RealLib) is not shown.
In order to form the type Approx τ, values of type τ should support the operations
required of a computable metric space. We can indicate the required operations
using Haskell's type-class mechanism.
class CMetrizable a where
enum :: [a]
metric :: a -> a -> Approx Rat
As a reminder, Haskell has lazy semantics so that the type [α] denotes a stream as
opposed to a list. Thus enum corresponds to an enumeration of type α where α is
the type of the dense subset. When we implement an instance of CMetrizable τ,
we should check that the implementation of enum enumerates a dense subset and
metric computes a metric as a computable metric space requires (see Section 3.2.2).
Below, we give an instance of Approx Rat for computable reals.
instance CMetrizable Rat where
enum = 0 : [ toRational m / 2^n
| n <- [1..]
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

84
Huang, Morrisett and Spitters: Computable Distributions
, m <- [-2^n * n..2^n * n]
, odd m || abs m > 2^n * (n-1) ]
metric x y = A (\_ -> abs (x - y))
This instance enumerates the dyadic rationals, which are a dense subset of the
reals. Note that there are many other choices here for the dense enumeration.13 In
this instance, we can actually compute the metric as a dyadic rational, whereas a
computable metric requires the weaker condition that we can compute the metric as
a computable real.
Next, we can use the module ApproxLib to implement computable operations on
commonly used types. For example, a library for computable reals will contain the
CMetrizable τ instance implementation above and other computable functions.
However, some operations are not realizable (e.g., equality of reals) and so this
module does not contain all operations one may want to perform on reals (e.g.,
equality is deﬁned on ﬂoats).
module RealLib (Real, pi, (+), ...) where
import ApproxLib
type Real = Approx Rat
instance CMetrizable Rat where
...
pi :: Real
(+) :: Real -> Real -> Real
-- etc.
The module CompDistLib contains the implementation of distributions. A
sampler Samp α is a function from a bit-stream to values of type α.14
type RandBits = Nat -> Bool
newtype Samp a = Samp { getSamp :: RandBits -> a }
We can implement an instance of the sampling monad as below.
instance Monad Samp where
return x = Samp (const x)
(>>=) s f = Samp ((uncurry (getSamp . f)) . (pair (getSamp
s . fst) snd) . split)
where pair f g = \x -> (f x, g x)
split = pair even odd
even u = (\n -> u (2 * n))
odd u = (\n -> u (2 * n + 1))
As expected, return corresponds to a constant sampler (const) that ignores its
input randomness. The bind operator »= corresponds to a composition of samplers;
13 Algorithms that operate on computable metric spaces compute by enumeration so the algorithm is sensitive to
the choice of enumeration.
14 The type RandBits is represented isomorphically as Nat →Bool instead of [Bool].
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

3.3 A Library for Computable Distributions
85
we ﬁrst split (split) the input randomness into two independent streams (via even
and odd), use one to sample from s, and continue with the other in f.
The module CompDistLib provides the function mkSamp to coerce an arbitrary
Haskell function of the appropriate type into a value of type Samp α.
mkSamp :: (CMetrizable a) => (RandBits -> Approx a) -> Samp (
Approx a)
mkSamp = Samp
We should call mkSamp only on sampling functions realizing Type-2 computable
sampling algorithms.
3.3.2 Examples
We now encode discrete and continuous distributions using the constructs provided by
library. These examples demonstrate how familiar distributions used in probabilistic
modeling can be encoded in a Type-2 computable manner. As we walk through the
examples, we will encounter some semantic issues that we would like a denotational
semantics of probabilistic programs to handle. We will ﬂag these in italics and revisit
them after introducing a semantics for probabilistic programs (Section 3.5).
Discrete distribution Discrete distributions are much simpler compared to contin-
uous distributions. Nevertheless, when paired with recursion, semantic issues do
arise. For instance, consider the encoding of a geometric distribution with bias 1/2,
which returns the number of fair Bernoulli trials until a success. The distribution
stdBernoulli denotes a Bernoulli distribution with bias 1/2.
stdGeometric :: Samp Nat
stdGeometric = do
b <- stdBernoulli
if b then return 1
else stdGeometric >>= return . (\n -> n + 1)
One possibility, although it occurs with zero probability, is for the draw from
stdBernoulli to always be false. Consequently, stdGeometric diverges with
probability zero. A semantics should clarify the criterion for divergence and show
that this recursive encoding actually denotes a geometric distribution.
Continuous distributions Next, we ﬁll in the sketch of the standard uniform
distribution we presented earlier. As a reminder, we need to convert a random
bit-stream into a sequence of (dyadic) rational approximations.
stdUniform :: Samp Real
stdUniform = mkSamp (\u -> mkApprox (\n -> bisect (n+1) u 0 1
0))
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

86
Huang, Morrisett and Spitters: Computable Distributions
where
bisect n u (l :: Rat) (r :: Rat) m
| m < n && u m
=
bisect n u l (midpt l r) (m+1)
| m < n && not (u m) =
bisect n u (midpt l r) r (m+1)
| otherwise
=
midpt l r
midpt l r = l + (r - l) / 2
The function bisect repeatedly bisects an interval speciﬁed by (l,r). By construc-
tion, the sampler produces a sequence of dyadic rationals. We can see that this
sampling function is uniformly distributed because it inverts the binary expansion
speciﬁed by the uniformly distributed input bit-stream. Once we have the standard
uniform distribution, we can encode other primitive distributions (e.g., normal,
exponential, etc.) as transformations of the uniform distribution as in standard
statistics using return and bind.
For example, we give an encoding of the standard normal distribution using the
Marsaglia polar transformation.
stdNormal :: Samp Real
stdNormal = do
u1 <- uniform (-1) 1
u2 <- uniform (-1) 1
let s = u1 * u1 + u2 * u2
if s < 1 then return (u1 * sqrt (log s / s))
else stdNormal
The distribution uniform (−1) 1 is the uniform distribution on the interval (−1,1)
and can be encoded by shifting and scaling a draw from stdUniform. One subtle
issue here concerns the semantics of <. As a reminder, equality on reals is not
decidable. Consequently, although we have used < at the type Real →Real →
Bool in the example, it cannot have the standard semantics of deciding between <
and ≥.
Singular distribution Next, we give an encoding of the Cantor distribution. The
Cantor distribution is singular so it is not a mixture of a discrete component and a
component with a density. Perhaps surprisingly, this distribution is computable. The
distribution can be deﬁned recursively. It starts by trisecting the unit interval, and
placing half the mass on the leftmost interval and the other half on the rightmost
interval, leaving no mass for the middle, continuing in the same manner with each
remaining interval that has positive probability. We can encode the Cantor distribution
by directly transforming a random bit-stream into a sequence of approximations.
cantor :: Samp Real
cantor = mkSamp (\u -> mkApprox (\n -> go u 0 1 0 n))
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

3.3 A Library for Computable Distributions
87
where
go u (left :: Rat) (right :: Rat) n m
| n < m && u n
=
go u left (left + pow) (n + 1) m
| n < m && not (u n) =
go u (right - pow) right (n + 1) m
| otherwise
=
right - (1 / 2) * pow
where pow = 3 ^^ (-n)
The sampling algorithm keeps track of which interval it is currently in speciﬁed by
left and right. If the current bit is 1, we trisect the left interval. Otherwise, we
trisect the rightmost interval. The number of trisections is bounded by the precision
we would like to generate the sample to. Crucially, the encoding makes use of the
idea of generating a sample to arbitrary accuracy using a representation instead of
the sample in its entirety.
Partiality and distributions The next series of examples explores issues concerning
distributions and partiality.
botSamp :: (CMetrizable a) => Samp (Approx a)
botSamp = botSamp
botSampBot :: (CMetrizable a) => Samp (Approx a)
botSampBot = mkSamp (\_ -> bot)
where bot = bot
In the term botSamp, we deﬁne an inﬁnite loop at the type of samplers. Intuitively,
this corresponds to the case where we fail to provide a sampler, i.e., an error in
the worst possible way. In the term botSampBot, we produce a sampler that fails
to generate a sample to any precision. In other words, we provide a sampler that
is faulty in the worst possible way. We can try to observe the diﬀerences in the
implementation (if any).
alwaysDiv :: Samp Real
alwaysDiv = do
_ <- botSamp ::
Samp Real
stdUniform
neverDiv :: Samp Real
neverDiv = do
_ <- botSampBot ::
Samp Real
stdUniform
If we run the term alwaysDiv on the left, we will see that the program always
diverges. When we run the term neverDiv on the right, we will draw from the
sampler botSampBot but discard the result. Due to Haskell's lazy semantics, this
computation is ignored and the entire term behaves as a standard uniform distribution.
We would like a denotational semantics to reﬂect the diﬀerences in the operational
behavior between these two terms.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

88
Huang, Morrisett and Spitters: Computable Distributions
Commutativity and independence We end by considering the diﬀerence between
a sampling and distributional interpretation of probabilistic programs. Below, we
give equivalent encodings of distributions by commuting the order of sampling from
independent distributions, but leaving everything else ﬁxed.
myNormal :: Samp Real
myNormal = do
x <- normal (-1) 1
y <- normal (1) 1
return (x + y)
myNormal' :: Samp Real
myNormal' = do
y <- normal (1) 1
x <- normal (-1) 1
return (x + y)
From a sampling perspective, the two distributions are not strictly equivalent because
the stream of random bits is consumed in a diﬀerent order; consequently, the samples
produced by myNormal and myNormal' may be diﬀerent. Thus, while a sampling
semantics is easily implementable, we would also like a distributional semantics to
enable reasoning about the distributional equivalence of programs. For instance,
this would enable us to reason that two diﬀerent sampling algorithms for the same
distribution are equivalent.
3.3.3 Notes
The implementation we have sketched is a proof of concept that shows that we can
realize the interface by implementing computable distributions and operations on
them as Haskell code. We note that there are multiple approaches to coding up
Type-2 computability as a library. One prominent alternative is given by synthetic
topology (Escardó, 2004), which assumes that the function space in the programming
language used to code up topological results is continuous and derives the notion of
an open set. These ideas can be used to help us structure an implementation.
One shortcoming of the library, and implementations of Type-2 computability
more generally, is eﬃciency. We intend the presentation of the library as a means to
sketch the connection of the computation with the mathematics. In practice, there
are still reasons for using ﬂoating point arithmetic. First, inference algorithms are
computationally intensive, even assuming operations on reals and distributions are
constant-time, so one is willing to make tradeoﬀs for eﬃciency. Second, it is not
necessary to compute answers to arbitrary accuracy for most applications. Notably,
most inference algorithms already make approximations as the solutions to many
interesting models are analytically intractable. Thus, there is still a (large) gap in
practice between semantics and implementation. For ideas on how to implement
Type-2 computability eﬃciently, we refer the reader to Bauer and Kavkler (2008)
and Lambov (2007).
Lastly, in our description of the library, we have elided one important detail. One
computable function we need to encode is the modulus of a computable function
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

3.4 Mathematical Structures for Modeling the Library
89
between computable metric spaces. The modulus g : (X →Y) →N →N of a
computable function f : X →Y between computable metric spaces (X, dX,SX)
and (Y, dY,SY) is a function that computes the number of input approximations
consumed to produce an output approximation to a speciﬁed precision. For example,
if the algorithm realizing f looks at sX
i0,. . ., sX
i41 to compute an output sY
in such that
dY(sY
in, f (x)) < 2−(n+1) and (sX
im)m∈N →x, then the modulus g( f )(n) is 42. Within
a machine model, one can simply "look at the tape and head location" to obtain the
modulus. However, one can show that the modulus of continuity is not expressible
in a functionally-extensional language. This in essence follows from the fact that the
modulus of two extensionally equivalent functions may not be equivalent. We can
use Haskell's imprecise exceptions mechanism (see Peyton Jones et al., 1999), an
impure feature, in a restricted manner to express the modulus.15
3.4 Mathematical Structures for Modeling the Library
What mathematical structures can we use to model such a library? Now that we
have seen that we can implement reals and continuous distributions in code, our
next task is to ﬁnd mathematical structures that can be used to faithfully model
the implementation. In doing so, we will set ourselves up for giving denotational
semantics to probabilistic programs under the additional constraint that the model
takes computability into account (Section 3.5).
Towards this end, we review topological domains, an alternative to traditional
domain theory (Section 3.4.1). Topological domains support all the standard domain-
theoretic constructions needed to model PCF-like languages as well as capture the
notion of Type-2 computability, and hence, can form the basis of a semantics for
PCF-like languages. Next, we encode distributions as topological domains. We do
this for a sampling view (Section 3.4.2) and a distributional view (Section 3.4.3)
based on valuations, a topological variant of a measure. We also construct a
probability monad (Giry, 1982) on countably based topological (pre)domains, which
includes computable metric spaces, so we can model the monadic implementation
of distributions in the library.
Finally, we put the approach proposed here, which emphasizes Type-2 computabil-
ity, in perspective. We begin by exploring an alternative approach to capturing
Type-2 computability via realizability (Section 3.4.4). Roughly speaking, we can
view a constructive logic as a "programming language" that we can use to program
computable distributions. We end by reviewing alternative structures that can be
used to model the semantics of probabilistic programs (Section 3.4.5).
15 See http://math.andrej.com/2006/03/27/sometimes-all-functions-are-continuous.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

90
Huang, Morrisett and Spitters: Computable Distributions
3.4.1 Domains and Type-2 Computability
In this section, we review topological domains. Unlike a CPO, a topological domain
in general does not carry the Scott topology, and hence, does not consider the partial
order primary. Instead, topological domains start with the topology as primary and
derive the order. For a complete treatment, we refer the reader to Battenfeld (2008)
and the references within (e.g., see Battenfeld, 2004; Battenfeld et al., 2006, 2007).
Towards this end, we will follow the overview given by Battenfeld et al. (2007) to
introduce the main ideas, which constructs topological domains in two steps: (1)
connecting computability to topology and (2) relating topology to order. Most of this
overview can be skimmed upon a ﬁrst read, although the examples will be helpful.
At the end, we will summarize the relevant structure that makes topological domains
good candidates for modeling probabilistic programs. In Section 3.5, we will use
this structure to give semantics to a core language.
Computability to topology Topological domain theory starts with the observation
that topological spaces provide a good model of datatypes. In short, a point in a
topological space corresponds to an inhabitant of a datatype and the open sets of
the topology describe the observable properties of points. Consequently, one can
test if an inhabitant of a datatype satisﬁes an observable property by performing a
(potentially diverging) computation that tests if the point is contained in an open set.
To make use of this observation, topological domain theory builds oﬀof the Cartesian
closed category of qcb0 spaces16 (e.g., see Escardó et al., 2004), a subcategory of
topological spaces that makes the connection between computation and topology
precise. It is helpful to introduce a qcb0 space by way of a represented space which
starts with the idea of realizing computations on a machine model before adding
back the topological structure.
Deﬁnition 3.12
A represented space (X,δX) is a pair of a set X with a partial
surjective function δX : 2ω ⇀X called a representation.
We call p ∈2ω a name of x when δX(p) = x. Thus, a name encodes an element of
the base set X as a bit-stream which in turn can be computed on by a Turing machine.
A realizer for a function f : (X,δX) →(Y,δY) is a (partial) function F : 2ω ⇀2ω
such that δY(F(p)) = f (δX(p)) for p ∈dom( f ◦δX). A function f : X →Y between
represented spaces is called computable if it has a computable realizer. It is called
continuous if it has a continuous realizer (with respect to the Cantor topology).17
Unfolding the deﬁnition of continuity of a (partial) function f : 2ω ⇀2ω on Cantor
space shows that it encodes a ﬁnite preﬁx property—this means that a machine can
16 qcb0 stands for a T0 quotient of a countably based space.
17 Note that a continuous function f : X →Y between represented spaces does not mean that f : X →Y is a
topologically continuous function with respect to the ﬁnal topologies induced by the respective representations.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

3.4 Mathematical Structures for Modeling the Library
91
compute f (p) to arbitrary precision after consuming a ﬁnite amount of bits of p in
ﬁnite time when f is continuous.
In order to relate the machine-model view to a topology so we can deﬁne a qcb0
space, we will need a notion of an admissible representation. A representation δX
of X is admissible if for any other representation δ′
X of X, the identify function on
X has a continuous realizer (Battenfeld et al., 2007, Defn. 3.10).
Deﬁnition 3.13
A qcb0 space is a represented space (X,δX) with admissible
representation δX.
The topology is the quotient topology (or ﬁnal topology) induced by the representation
δX. If X and Y are qcb0 spaces, then the topologically continuous functions between
them coincide with those that have continuous realizers (Battenfeld et al., 2007, Cor.
3.13), which gives the same characterization as an admissible represented space.
We give two examples of qcb0 spaces to illustrate the corresponding realizers and
topologies.
Example 3.14
Deﬁne the set S ≜{⊥,⊤} with representation δS(⊥) ≜00 . . . and
δS(⊤) ≜p for p  00 . . . . Then (S,δS) is a qcb0 space known as Sierpinski space.
In particular, Sierpinski space encodes the notion of semi-decidability—a Turing
machine semi-decides that a proposition holds (encoded as ⊤) only if it eventually
outputs a non-zero bit.
Example 3.15
Let (X, d,S) be a computable metric space. Then (X,δMetric) is a
qcb0 space with admissible representation δmetric that uses fast Cauchy sequences as
names. More concretely, (δQ(wn))n∈N →δmetric(p) where δ(p) = ⟨w1,w2,. . . ⟩. As
a special case, (R,δR) is a represented space, where δR is a representation that uses
fast Cauchy sequences of rationals as names.
Topology to order The next piece of structure topological domain theory imposes
is the order-theoretic aspect. The idea is to use the standard interpretation of recursive
functions as the least upper bound of an ascending chain of the approximate functions
obtained by unfolding. Because topological domain theory takes the topology as
primary and the order as secondary, this task requires some additional work.
Recall that we can convert a topological space into a preordered set via the
specialization preorder, which orders x ⊑y if every open set that contains x also
contains y. We write S to convert a topological space into a preordered set. Intuitively,
x ⊑y if x contains less information than y. For a metric space, we can always ﬁnd
an open ball that separates two distinct points x and y (because the distance between
two distinct points is positive). Hence, the specialization preorder of a metric space
always gives the discrete order (i.e., information ordering), and hence degenerately,
a CPO.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

92
Huang, Morrisett and Spitters: Computable Distributions
Deﬁnition 3.16
(Battenfeld et al., 2007, Defn. 5.1). A qcb0 space is called
a topological predomain if every ascending chain (xi)i∈N (with respect to the
specialization preorder ⊑) has an upper bound x such that (xi)i∈N →x (with respect
to its topology).
Thus, we see in the deﬁnition that a topological predomain (1) builds oﬀof a
qcb0 space and (2) ensures that least upper bounds of increasing chains exist. The
former condition provides the topology and theory of eﬀectivity while the latter
condition prepares us for modeling least ﬁxed-points. The following provides a
useful characterization of qcb0 spaces that relates the topology back to the order.
Deﬁnition 3.17
(Battenfeld et al., 2007, Defn. 5.3). A topological space (X, O(X))
is a monotone convergence space if its specialization order is a CPO and every open
is Scott open.
Proposition 3.18
(Battenfeld et al., 2007, Prop. 5.4). A qcb0 space is a topological
predomain iﬀit is a monotone convergence space.
Hence, we see that the Scott topology is in general ﬁner than the topology associated
with a topological predomain.
Analogous to standard domain theory, a topological predomain is called a
topological domain if it has least element, written ⊥, under its specialization
order (Battenfeld et al., 2007, Defn. 5.6).
Proposition 3.19
(Battenfeld et al., 2007, Thm. 5.7). Every continuous endofunc-
tion on a topological domain has a least ﬁxed-point.
We look at the relation between order and topology more closely through a series
of examples below.
Example 3.20
Consider the discrete CPO (N,⊑discrete) with discrete ordering
⊑discrete, (i.e., n ⊑discrete m if n = m). The Scott topology on this CPO gives the
discrete topology, i.e., O(N) = {{n} | n ∈N}. The specialization preorder applied
to the resulting topology gives back the original CPO. Thus, we additionally see
that the topological predomain coincides with the CPO.
Example 3.21
Consider the CPO ({[a,1) | a ∈R} ∪{[0,1]}, ⊆) with ordering
given by set inclusion. The Scott topology on this CPO gives the lower topology,
i.e., O([0,1]) = {(a,1] | a ∈[0,1)} ∪{[0,1]}. Like the previous example, the
specialization preorder applied to the resulting topology gives back the original
CPO. Hence, the topological domain also coincides with the CPO.
In the two examples above, we saw instances where the order and topology coincide.
In the next two examples, we will see cases where they diﬀer, thus highlighting
diﬀerences between CPOs and topological (pre)domains.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

3.4 Mathematical Structures for Modeling the Library
93
Construction
D × E
D ⇒E
D + E
D ⊗E
D ⇛E
D ⊕E
D⊥
TP
✓+
✓+
✓+
✓
TD
✓+
✓+
✓
✓
✓
✓
TD!
✓+
✓
✓
✓+
✓+
✓
Figure 3.2 Summary of constructs on topological predomains (category TP), topological do-
mains (category TD), and topological domains with strict morphisms (category TD!). (Compare
this ﬁgure with one for CPOs (Abramsky and Jung, 1994, pg. 46).) The symbol ✓indicates
that the category is closed under that construct and the symbol + additionally indicates that it
corresponds to the appropriate categorical construct.
Example 3.22
The reals R with Euclidean topology is a metric space, and hence,
the specialization preorder gives a discrete CPO (R,⊑discrete). However, the Scott
topology of the resulting discrete CPO is the discrete topology. Hence, the topologies
do not coincide.
Example 3.23
The Scott continuous functions from R to R contain all functions.
However, the space of functions between the topological predomains R and R contain
just the continuous ones.
The last example concerns modeling divergence for reals.
Example 3.24
The partial reals ˜R (e.g., see Escardó, 1996) can be modeled as
(closed) intervals [l,u] ordered by reverse inclusion where l is a lower-real and a u is
an upper-real. The subspace of the maximal elements yields the familiar Euclidean
topology. Note that ˜R⊥ R⊥.
Categorical structure We end by summarizing the categorical structure of topolog-
ical domains (Figure 3.2) applicable to giving semantics to probabilistic programs.18
In short, topological (pre)domains possess essentially the same categorical structure
as their CPO counterparts. Hence, we will be able to give semantics to programming
languages using topological domains in much the same way that we use CPOs.
The relevant categories include TP (topological predomains and continuous
functions),19 TD (topological domains and continuous functions),20 and TD!
(topological domains and strict continuous functions).21 We will use the notation
below for categorical constructions with the usual semantics.
18 We include sums (D + E) and coalesced sums (D ⊕E) for completeness. Similar to a smash product, a
coalesced sum D ⊕E identiﬁes the least element of D with the least element of E.
19 TP is a full reﬂective exponential ideal of QCB (category with qcb0 spaces as objects and continuous functions
as morphisms) (Battenfeld et al., 2007, Thm. 5.5).
20 TD is an exponential ideal of QCB and is closed under countable products in QCB (Battenfeld et al., 2007,
Thm. 5.9).
21 TD! (1) is countably complete (limits inherited from QCB), (2) has countable coproducts, and (3) ⊕and ⇛
(with S as unit) provides symmetry monoidal closed structure on TD! (Battenfeld et al., 2007, Thm. 6.1, Thm.
6.2, Prop. 6.4).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

94
Huang, Morrisett and Spitters: Computable Distributions
(Function) We write D ⇒E for continuous functions (D ⇛E for strict continuous
functions); the corresponding operation includes eval : (D ⇒E) × D ⇒E,
uncurry : (D ⇒E ⇒F) ⇒(D × E ⇒F), and curry : (D × E ⇒F) ⇒
D ⇒E ⇒F. We will subscript function space ⇒with the appropriate category
when it is not clear from context which function space we are referring to, e.g.,
D ⇒TD E.
(Product) We write D × E for products (D ⊗E for smash products);22 the corre-
sponding operations include ﬁrst projection π1 : D × E ⇒D, second projection
π2 : D × E ⇒E, and pairing ⟨·,·⟩: (D ⇒E) × (D ⇒F) ⇒(D ⇒E × F).
(Lift) D⊥lifts a (pre)domain; the corresponding operations include lifting elements
⌊·⌋: D ⇒D⊥, lifting the domain of a function liftD : (D ⇒E⊥) ⇒(D⊥⇒E⊥),
lifting the codomain of a function liftC : (D ⇒E) ⇒(D ⇒E⊥), and unlifting
elements ⌈·⌉: D⊥⇒D for D (⌈⌊d⌋⌉= d and undeﬁned otherwise). Given a
morphism f : D ⇒E, we write f⊥: D⊥⇒E⊥to refer to the morphism with
lifted domain and codomain.
3.4.2 Sampling
As a reminder, the library implementation converts an input bit-stream into a sample
in the desired space. Hence, we begin by encoding the sampling implementation of
distributions from the library as a topological domain.
Deﬁne an (endo)functor S that sends a topological predomain D to a sampler on
D and a morphism to one that composes with the underlying sampler. Then, the
topological domain S(D) is a sampler producing values in the lifted topological
domain D⊥.
Proposition 3.25
The functor S deﬁned as
S(D : TP) ≜2ω ⇒D⊥
S( f : D ⇒E) ≜s →f⊥◦s ,
is well deﬁned, where 2ω is the topological predomain equipped with the Cantor
topology.
The least element is one that maps all bit-streams to ⊥. Next, we deﬁne three
operations on samplers. The ﬁrst operation creates a sampler that ignores its input
bit-randomness and always returns d:
det : D ⇒S(D)
det(d) ≜const(⌊d⌋)
22 A smash product D ⊗E identiﬁes the least element of D with the least element of E.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

3.4 Mathematical Structures for Modeling the Library
95
where const : D ⇒(E ⇒D) produces a constant function.
The second operation splits an input bit-stream u into the bit-streams indexed by
the even indices ue and the odd indices uo:
split : 2ω ⇒2ω × 2ω
split(u) ≜(ue,uo) .
Note that if u is a sequence of independent and identically distributed bits, then both
ue and uo will be as well.
The third operation sequences two samplers:
samp : S(D) × (D ⇒S(E)) ⇒S(E)
samp(s, f ) ≜uncurry(liftD( f )) ◦⟨s ◦π1, π2⟩◦split .
It splits the input bit-randomness and runs the sampler s on one of the bit-streams
obtained by splitting to produce a value. That value is fed to f , which in turn
produces a sampler that is run on the other bit-stream obtained by splitting.
3.4.3 Valuations and a Probability Monad
Our goal now is encode distributions as valuations in the framework of topological
domains. Once we have done so, we can interpret distribution terms in the library
as elements of the appropriate topological domain. Next, we deﬁne the probability
monad, which will be restricted to countably based topological (pre)domains.
Consequently, the probability monad in λCD will be restricted to distributions on
countably based spaces, which includes commonly used spaces such as reals and
products of countably based spaces (Section 3.5).
Valuations and measures A valuation shares many of the same properties as a
measure, and hence, can be seen as a topological variation of distribution.
Deﬁnition 3.26
A valuation ν : O(X) →[0,1] is a function that assigns to
each open set of a topological space X a probability such that it is (1) strict
(ν(∅) = 0), (2) monotone (ν(U) ≤ν(V) for U ⊆V), and (3) modular (ν(U) + ν(V) =
ν(U ∪V) + ν(U ∩V) for every open U and V).
One key diﬀerence between valuations and measures is that valuations are not
required to satisfy countable additivity. Indeed, countable additivity is perhaps one
of the deﬁning features of a measure. We can rectify this situation for valuations
by restricting attention to the ω-continuous valuations. As a reminder, a valuation
ν is called ω-continuous if ν(
n∈N Vn) = supn∈N ν(Vn) for (Vn)n∈N an increasing
sequence of opens. Hence, the countable additivity of μ encodes the ω-continuous
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

96
Huang, Morrisett and Spitters: Computable Distributions
property. Importantly, note that every Borel measure μ can be restricted to the
lattice of opens, written μ|O(X), resulting in an ω-continuous valuation. Every
Borel measure μ on X can be restricted to an ω-continuous valuation μ|O(X) :
[O ⊆(X) ⇒CPO [0,1]↑] (see Schröder, 2007, Sec. 3.1). Moreover, μ is uniquely
determined by its restriction to the opens μ|O(X).23 In other words, we can identify
distributions on topological spaces with ω-continuous valuations.
Encoding valuations The presence of topological and order-theoretic structure
suggests two strategies for encoding valuations as topological domains. In the ﬁrst
approach, we would take a realizer point of view as every topological domain is also a
qcb0 space. Under this approach, we would (1) deﬁne an admissible representation of
the space of opens O(X), (2) deﬁne an admissible representation of the interval [0,1],
and (3) verify that a representation of a valuation O(X) →[0,1] using the canonical
function space representation is admissible and properly encodes a valuation. In
the second approach, we would take an order-theoretic point of view. Under this
approach, we would (1) verify that the space of opens O(X) is a topological domain,
(2) verify that the interval [0,1] is a topological domain, and (3) verify that the
continuous functions O(X) ⇒[0,1] encodes a valuation correctly. In either strategy,
a common thread is that we need to encode the opens O(X) and the interval [0,1].
We start with the realizer perspective.
Let todo(X,S) be the space of continuous functions between the represented spaces
X and S. Let [0,1]< ≜([0,1],δ<) be the represented space with representation δ< that
represents r ∈[0,1] as all the rational lower bounds. Next, we deﬁne the opens O(X)
and the interval [0,1] for the order-theoretic perspective. Let O ⊆(X) ≜(O(X), ⊆)
be the lattice of opens (and hence a CPO) of a topological space X ordered by
subset inclusion. Let [0,1]↑≜([0,1], ≤) be the interval [0,1] ordered by ≤. The next
proposition shows that the realizer perspective and the order-theoretic perspective
are equivalent.
Proposition 3.27
(i) [0,1]<  [0,1]↑and
(ii) todo(X,S)  O ⊆(X) when X is an admissible represented space.24
The next proposition shows that the realizer and order-theoretic views are equivalent
under the additional assumption that the base topological space is countably based.
Proposition 3.28
Let (X, O(X)) be a countably based topological space.
(i) [O ⊆(X) ⇒CPO [0,1]↑]  todo(O(X),[0,1]<) and
23 Note that the ω-continuous condition encodes what it means for a function to be ω-Scott continuous, i.e., an
ω-CPO continuous function.
24 The second item is due to Schröder (2007, Thm. 3.3).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

3.4 Mathematical Structures for Modeling the Library
97
(ii) [O ⊆(X) ⇒CPO [0,1]↑]  [O ⊆(X) ⇒TD [0,1]↑].25
Proposition 3.28 gives three equivalent views of a valuation as (1) a CPO continuous
function, (2) a continuous map between represented spaces, and (3) a continuous
function between topological domains. View (2) indicates that there is an associated
theory of eﬀectivity on valuations. We will use this view to give semantics to
probabilistic programs.
Integration Similar to how one can integrate a measurable function with respect
to a measure, one can integrate a lower semi-continuous function with respect to
a valuation. Let X be a represented space and μ ∈M1(X) where M1(X) is the
collection of Borel measures on X that have total measure 1.
Proposition 3.29
The integral of a lower semi-continuous function f
∈
todo(X,[0,1]<) with respect to a Borel measure μ
∫
: todo(X,[0,1]<) × M1(X) →[0,1]<
is lower semi-continuous (see Schröder, 2007, Prop. 3.6). In fact, it is even lower
semi-computable (Schröder, 2007, Prop. 3.6) (Hoyrup and Rojas, 2009, Prop. 4.3.1).
The integral is deﬁned in an analogous manner to the Lebesgue integral, i.e., as the
limit of step functions on opens instead of measurable sets. The integral possesses
many of the same properties, including Fubini and monotone convergence.
Probability monad Finally, we combine the results about valuations and integration
to deﬁne a probability monad. Let TPω be the full subcategory of TP where
the objects are countably based. Deﬁne the (endo)functor P on countably based
topological predomains that sends an object D to the space of valuations on D and a
morphism to one that computes the pushforward.
Proposition 3.30
The functor P deﬁned as
P(D : TPω) ≜O ⊆(D) ⇒[0,1]↑
P( f : D ⇒E) ≜μ →μ ◦f −1
is well deﬁned.
It is straightforward to check that P is a functor. We can construct a probability
monad using the functor P.
25 The ﬁrst item is due to Schröder (2007, Sec. 3.1, Thm 3.5, Cor. 3.5). For the second item, recall that every
ω-continuous pointed CPO with its Scott topology coincides with a topological domain (Battenfeld et al.,
2007). The least element is the valuation that maps every open set to 0.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

98
Huang, Morrisett and Spitters: Computable Distributions
Proposition 3.31
The triple (P,η,≻♭) is a monad, where
η(x)(U) ≜1U(x)
(μ ≻♭f )(U) ≜
∫
fU dμ where fU(x) = f (x)(U).
It is largely straightforward to check that (P,η,≻♭) is a monad.26
3.4.4 Realizability
Sections 3.4.1, 3.4.2, and 3.4.3 taken together provide enough structure for giving
semantics to probabilistic programs with continuous distributions. Thus, the reader
interested in seeing the semantics "in action" in a core language can skip ahead to
Section 3.5.
In this section, we explore another approach to Type-2 computability based on
realizability. The primary motivation for doing so is that we will obtain another
perspective on computability (i.e., in addition to the topological and order-theoretic
ones) that highlights the connection with constructive mathematics. Intuitively, we
have a constructive object if we can realize the object as a program. As another
source of motivation, it is also possible to give semantics to programming languages
directly using the realizability approach (e.g., see Longley, 1995). Hence, we will
gain another method of giving semantics in addition to the traditional order-theoretic
one.
Under the realizability approach, we will approach Type-2 computability using
an abstract machine model, i.e., a partial combinatory algebra (PCA) as opposed to
a concrete machine model (i.e., a Turing machine). A PCA consists of an underlying
set X and a partial application function · : X × X ⇀X subject to certain laws that
ensure combinatorial completeness, i.e., that a PCA can simulate untyped lambda
calculus. Hence, we can think of a PCA as an algebraic take on substitution. We
obtain ordinary Type-1 computability by instantiating a PCA over the naturals
N; the partial application function of a PCA · : N × N ⇀N can be deﬁned to
simulate the computation of partial recursive functions. By extension, we obtain
a Type-2 machine by instantiating a PCA over Baire space B ≜N →N; the
partial application function of a PCA · : B × B ⇀B can be deﬁned to simulate the
computation over streams of naturals. In the rest of this section, our goal is to unpack
the (well-known) connection between computability and constructive mathematics
via realizability, and to show that the base spaces and constructions that are useful
for giving semantics to probabilistic programs with continuous distributions can be
realized appropriately.
26 In the case of bind, we can check that the identities involving integrals holds via standard arguments (e.g., see
Jones, 1989).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

3.4 Mathematical Structures for Modeling the Library
99
Overview The phrase we have in mind is: "Computability is the realizability
interpretation of constructive mathematics" (Bauer, 2005). The high-level idea
is to encode familiar mathematical objects in an appropriate logic and derive
computability as a consequence of having a sound interpretation. Programming up
mathematical spaces and their operations will then correspond to encoding the space
and their operations in the logic.
(Logic) The logic for our setting is elementary analysis (e.g., see Lietz, 2004, Sec.
1.3.3) called EL. EL extends an intuitionistic predicate logic with (1) Heyting
arithmetic, (2) a sort for Baire space Baire for encoding continuum-sized objects,
and (3) primitive-recursion and associated operators.
(Semantics) The semantics for this setting includes the category Asm(K2) of
assemblies over Kleene's second algebra K2 (i.e., a PCA over Baire space) and the
full subcategory Mod(K2) of modest sets over K2. For more details on assemblies
and modest sets, we refer the reader to the relevant literature (e.g., see Streicher,
2008; Bauer, 2000a; Birkedal, 1999). For our purposes, it suﬃces to recall that
a modest set can be identiﬁed with a represented space and that an assembly
is a represented space with a multi-representation. Hence, modest sets model
datatypes and assemblies model intuitionistic logic.
Because we take a constructive vantage point, we will need to check that the
semantics induced by the relevant encodings of familiar mathematical objects in the
logic coincides with the usual interpretation. For our purposes, this means checking
that encodings of objects such as reals and distributions in EL produce the expected
semantics. Towards this end, recall that we can associate a theory of eﬀectivity with
a space by deﬁning it as a quotient of Baire space B0
∼by a partial equivalence
relation (PER) ∼. A quotient by a PER allows us to construct quotients and subsets
of Baire space in one go. We recall the conditions required of the relation ∼for the
constructive encoding to coincide with the classical interpretation below.
Deﬁnition 3.32
(Lietz, 2004, Prop. 3.3.2). We write ∼∗if
(RF conservative class) antecedents of implications contained in ∼are almost
negative;27
(partial equivalence relation) EL ⊢sym(∼) ∧trans(∼) where sym(∼) ≜∀α β :
Baire. α ∼β ↔β ∼α and trans(∼) ≜∀α β γ : Baire. α ∼β →β ∼γ →
α ∼γ; and
(stability) EL ⊢∀x y : Baire. ¬¬(x ∼y) →x ∼y.
27 More formally, whenever A →B is a subformula of ∼, then the antecedant A is almost negative. As a reminder,
a formula is almost negative if it only contains existential quantiﬁers in front of prime (i.e., atomic) formulas.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

100
Huang, Morrisett and Spitters: Computable Distributions
Now we recall a suﬃcient condition for the constructive interpretation to coincide
with the classical interpretation.
Proposition 3.33
(Lietz, 2004, Prop. 3.3.2). If ∼∗, then the interpretations of B0
∼
in the categories Asm(K2) and Asmt(K2) (i.e., the truth or classical interpretation)
yield computably equivalent realizability structures.
Encodings Before proceeding to the encodings of the sets of interest in EL, we
deﬁne two enumerations that will be useful for constructing the encodings. Let
π1⟨n,m⟩= n and π2⟨n,m⟩= m so that they are pairing functions on naturals (e.g.,
Cantor pairing function). We also overload the notation ⟨α, β⟩to pair α ∈B and
β ∈B.
(Integers) Encode the integers as
Z = N × N0
=N
where ⟨a, b⟩=N ⟨c, d⟩if a −d = c −b (e.g., as in Bauer, 2000a, Sec. 5.5.1). In
words, we can think of an integer as a diﬀerence of two naturals. We write Int to
refer to the enumeration on N × N.
(Rationals) Encode the rationals as
Q = Z × (N\{0})0
=Q
where ⟨p,q⟩=Q ⟨s,t⟩if p ·t = s · q (e.g., as in Bauer, 2000a, Sec. 5.5.1). In words,
we can think of a rational as a ratio of an integer and a non-negative natural. We
write Rat to refer to the enumeration on Z × (N\{0}). We write ≤Q and <Q to
implement ≤and < respectively on rationals.28
(Non-negative rationals) Encode the non-negative rationals similarly to the rationals,
where we replace Z with N. We write NonNegRat to refer to the enumeration on
N × (N\{0}). We write <Q+ to implement < on the non-negative rationals.
We now encode the base spaces as quotients of Baire space. In deﬁning the
quotient ∼, it is helpful to recall the encoding of the space ﬁrst. For example, a lower
real is an encoding of a real that enumerates all of its rational lower bounds. Hence,
two lower reals will be related if their encodings enumerate the same lower bounds.
As another example, we can encode reals as a fast Cauchy sequences. Hence, two
reals will be related if their fast Cauchy sequences are suitably close to one another.
We summarize useful quotient encodings of base spaces below.
Proposition 3.34
(Sierpinski) Let α ∼S β if (∀n : Nat. α n = 0) ↔(∀n : Nat. β n = 0).
28 Note that we have that ⟨p, q⟩< ⟨s, t⟩if p · t < s · q (e.g., as in Bauer, 2000a, Sec. 5.5.1).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

3.4 Mathematical Structures for Modeling the Library
101
(Lower real) Let α ∼R< β if ∀q : Rat. (∀n : Nat. q <Q α n) ↔(∀n : Nat. q <Q
β n).
(Lower non-negative real) Let α ∼R+
< β if ∀q : NonNegRat. (∀n : Nat. q <Q+
α n) ↔(∀n : Nat. q <Q+ β n).
(Upper real) Let α ∼R> β if ∀q : Rat. (∀n : Nat. α n <Q q) ↔(∀n : Nat. β n <Q
q).
(Lifted partial real) Let ⟨αl,αu,α<,α>⟩∼˜R ⟨βl, βu, β<, β>⟩if αl ∼R< βl ∧αu ∼R>
βu ∧α< ∼S β< ∧α> ∼S β>.
(Real) Let α ∼R β if ∀n : Nat. |α n −β n| ≤Q 2−n+2.
We have ∼∗
S, ∼∗
R<, ∼∗
R+
<, ∼∗
R>, ∼∗
˜R, and ∼∗
R.
It is largely straightforward to check that ∼∗holds for the ∼deﬁned above.29 Next,
we state that semantic constructs can be encoded as quotients of Baire space as well.
Proposition 3.35
Suppose ∼∗
X and ∼∗
Y.
(Lift) Let ⟨αC,αX⟩∼⊥⟨βC, βX⟩if αC ∼S βC ∧αX ∼X βX.
(Product) Let ⟨αX,αY⟩∼X×Y ⟨βX, βY⟩if αX ∼X βX ∧αY ∼Y βY.
(Function) Let α ∼X→Y β if ∀γ : Baire, α | γ ∼Y β | γ where α | γ applies α to γ
(in K2).
We have ∼∗
⊥, ∼∗
X×Y, and ∼∗
X→Y.
It is straightforward to check that ∼∗for the ∼deﬁned above.
We end by encoding valuations as quotients of Baire space. First, we need
an enumeration of the open sets of a topological space. For a topological space
(X, O(X)), we can encode the collection of open sets as the function space X →S. As
the measure of an open set is lower-semi computable (Proposition 3.4.3), a valuation
can be encoded as an enumeration of pairs of a basic open and a non-negative lower
real. For a countably based topological space with basis B(X), we have B(X)  N;
hence, we can code a valuation as a sequence of non-negative lower reals.
Proposition 3.36
Let ⟨α1,α2,. . . ⟩∼V(X) ⟨β1, β2,. . . ⟩if ∀n : Nat. αn ∼R+
< βn.
Then ∼∗
V(X).
Summary In summary, one view of what we have just seen is that we can use EL
as a "programming language" (i.e., a constructive logic as opposed to Haskell) for
coding up mathematical structures relevant for probabilistic programs that have
a notion of eﬀectivity associated with them. In particular, the witnesses in the
semantics of EL are given by elements of a PCA and modest sets over K2 can be
identiﬁed with represented spaces (see Battenfeld et al., 2007, Sec. 8).
29 For Sierpinski, see Lietz (2004, Defn. 3.2.4). For reals, see Bauer (2000b, Sec. 5.5.2). It is also useful to recall
the notion of a negative formula (Bauer, 2000b, pg. 92) for checking the stability of ∼.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

102
Huang, Morrisett and Spitters: Computable Distributions
3.4.5 Alternative Approaches
Probabilistic programs have a long history, and indeed, many structures have been
proposed for modeling their semantics. Naturally, the choice of mathematical
structure aﬀects the language features that we can model. We close this section by
reviewing a few of these alternative approaches as a point of comparison to the
perspective given here that emphasizes Type-2 computability. We will focus on
denotational approaches. There are also operational approaches to modeling the
semantics of probabilistic programs (e.g., see Park et al., 2005; Dal Lago and Zorzi,
2012).
One natural idea is to extend semantics based on CPOs to the probabilistic setting
by putting distributions on CPOs. Saheb-Djahromi (1978) develops a probabilistic
version of LCF by considering distributions on CPOs corresponding to base types
(i.e., booleans and naturals). Saheb-Djahromi also gives operational semantics as
a Markov chain (described as a transition matrix) and shows that the operational
semantics is equivalent to the denotational semantics. Jones (1989), in her seminal
work, develops the theory of valuations on CPOs to further the study of distributions
on CPOs via a probabilistic powerdomain P. The probabilistic powerdomain is not
closed under the function space; consequently, Jones interprets the function space
D ⇒E probabilistically as D ⇒P(E) (not P(D) ⇒P(E)).
Instead of taking order-theoretic structure as primary and extending it with
probabilistic concepts, another idea is to take the probabilistic structure as primary
and derive structure that models programming language constructs (e.g., order-
theoretic structure to model recursion). Kozen (1981) takes a structure amenable for
modeling probability as primary (i.e., Banach spaces) and imposes order-theoretic
structure. This approach supports standard continuous distributions, although it
does not support higher-order functions. In addition to the distributional semantics,
Kozen also gives a sampling semantics and shows it equivalent to the distributional
semantics. Danos and Ehrhard (2011) identify the category of probabilistic coherence
spaces (PCSs) and use it to give denotational semantics to a probabilistic variant
of PCF extended with (countable) choice. Hence, their approach supports discrete
distributions. Ehrhard et al. (2014) show that PCSs provide a fully abstract model for
probabilistic PCF so that the connection between the operational and denotational
semantics is tight. Ehrhard et al. (2018) identify a Cartesian closed category of
measurable cones and stable, measurable maps that is also order complete. They
also provide an operational sampling semantics and show an adequacy result to link
the denotational with operational semantics. This category can be used to model
higher-order probabilistic languages with continuous distributions and recursion.
Crubillé (2018) shows that the category of PCSs embeds into the (Cartesian closed)
category of measurable cones with stable, measurable maps.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

3.5 A Semantics for a Core Language
103
One can also use measure-theoretic structure directly, although the category of
measurable spaces with measurable maps is not Cartesian closed so higher-order
functions cannot be modeled. Panangaden (1999) identiﬁes a category of stochastic
relations and shows how to use it to give denotational semantics to Kozen's ﬁrst-order
while language. The category has measurable spaces as objects and probability
kernels as morphisms. Panangaden identiﬁes (partially) additive structure in this
category and uses it to interpret ﬁx-points for Kozen's while language. Borgström
et al. (2011) also interpret a type as a measurable space and use it to give denotational
semantics to a ﬁrst-order language without recursion based on measure transformers.
They also show how to compile this language into a factor graph, which supports
inference as well as provides an operational semantics. Staton (2017) shows how the
category of measurable spaces with s-ﬁnite kernels can be used to give commutative
semantics to a ﬁrst-order language.
Another interesting approach considers alternatives to a measure-theoretic treat-
ment of probability, but still considers the probabilistic structure as primary. Heunen
et al. (2017) develop the theory of quasi-Borel spaces, which importantly, form a
Cartesian closed category and show how quasi-Borel spaces can be used to model a
higher-order probabilistic language with continuous distributions but without recur-
sion. Vákár et al. (2019) show how to extend quasi-Borel spaces with order-theoretic
structure so they can be used to model languages with recursion.
3.5 A Semantics for a Core Language
What does a semantics for a core language look like? Our goal in this section is
to use the mathematical structures (i.e., topological domains) we reviewed in the
previous section to model a PCF-like language extended with reals and continuous
distributions (via a probability monad) called λCD. We begin by introducing the
syntax and statics of λCD (Section 3.5.1). As we might expect, the language features
that we can model are restricted to the structure of the relevant topological domains.
For instance, as we only deﬁne a probability monad on countably based spaces,
the probability monad in λCD will be restricted to supporting only distributions
on countably based spaces. This includes distributions on reals and products of
countably based spaces, but does not include function spaces (although the language
itself contains higher-order functions). Next, we give both (algorithmic) sampling
and distributional semantics to λCD (Section 3.5.2). This illustrates more concretely
the connection between the semantics and the library implementation of computable
distributions. The structure of the semantics follows the usual one for PCF. Finally,
we can use the core language and its semantics to resolve the semantic issues we
raised when we sketched a library for computable distributions (Section 3.5.3).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

104
Huang, Morrisett and Spitters: Computable Distributions
τ ::= Nat | τ →τ | τ × τ | Real | Dist τ
M ::= O | succ | pred | if0 M M M
(PCF-1)
| x | λx : τ. M | M N | fix M
(PCF-2)
| (M, M) | fst M | snd M
(products)
|
r
|
rop
(reals)
|
dist
|
return M
|
x ←M ; M
(distributions)
Figure 3.3 λC D extends a PCF-like language with products, reals, and distributions using a
probability monad. The constructs for reals and distributions are shaded.
3.5.1 Syntax and Statics
Syntax The language λCD extends a PCF-like language with reals and distributions
(Figure 3.3). The terms on lines PCF-1 and PCF-2 are standard PCF terms. The
terms on the line marked products extend PCF with the usual constructions for pairs;
(M, N) forms a pair of terms M and N, fst M takes the ﬁrst projection of the pair
M, and snd M takes the second projection of the pair M. The terms on the line
marked reals add syntax for (1) constant reals r and (2) the application of primitive
real functions rop. The terms on the line marked distributions add syntax for (1)
primitive distributions dist and (2) return return M and bind x ←M ; N for an
appropriate probability monad.
Statics Like PCF, λCD is a typed language. In addition to PCF types (i.e., Nat and
τ →τ), λCD includes the type of products (τ × τ), reals (Real), and distributions
(Dist τ). Figure 3.4 summarizes the type-system for λCD. The expression typing
judgement Γ ⊢M : τ is parameterized by a context Ψ (omitted in the rules) that
contains the types of primitive distributions and functions.30 The typing rules for
the fragments marked PCF-1, PCF-2, and products is standard. The typing rules for
the fragments marked reals and distributions are not surprising; nevertheless, we go
over them as the constructs are less standard.
As expected, constant reals r are assigned the type Real. Primitive operations
on reals rop (for real operation) have the type Realn →Real where Realn ≜
Real × · · · × Real (n-times).
For expressions that operate on distributions, the judgement ⊢D τ additionally
enforces that the involved types are well formed. The distribution type Dist τ is well
formed if the space denoted by τ is a computable metric space (Deﬁnition 3.9). This
30 The full expression typing judgement would be written Ψ; Γ ⊢M : τ. We omit Ψ because it is constant across
typing rules.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

3.5 A Semantics for a Core Language
105
⊢D τ
Well-formed distribution type
⊢D Nat
⊢D Real
⊢D τ1
⊢D τ2
⊢D τ1 × τ2
Γ ⊢M : τ
Expression typing judgement
Γ ⊢O : Nat
Γ ⊢succ : Nat →Nat
Γ ⊢pred : Nat →Nat
Ψ(r) = Real
Γ ⊢r : Real
Ψ(rop) = Realn →Real
Γ ⊢rop : Realn →Real
Γ ⊢M1 : Nat
Γ ⊢M2, M3 : τ
Γ ⊢n : if0 M1 M2 M3 : τ
Γ(x) = τ
Γ ⊢x : τ
Γ, x : τ1 ⊢M : τ2
Γ ⊢λx : τ1. M : τ1 →τ2
Γ ⊢M1 : τ2 →τ
Γ ⊢M2 : τ2
Γ ⊢M1 M2 : τ
Γ ⊢M : τ →τ
Γ ⊢fix M : τ
Γ ⊢M1 : τ1
Γ ⊢M2 : τ2
Γ ⊢(M1, M2) : τ1 × τ2
Γ ⊢M : τ1 × τ2
Γ ⊢fst M : τ1
Γ ⊢M : τ1 × τ2
Γ ⊢snd M : τ2
Ψ(dist) = Dist τ
⊢D τ
Γ ⊢dist : Dist τ
Γ ⊢M : τ
⊢D τ
Γ ⊢return M : Dist τ
Γ ⊢M1 : Dist τ1
Γ, x : τ1 ⊢M2 : Dist τ2
⊢D τ1,τ2
Γ ⊢x ←M1 ; M2 : Dist τ2
Figure 3.4 The type-system for λC D. The judgement ⊢D τ checks that distribution types are
well formed. The judgement Γ ⊢M : τ checks that expressions are well typed. The judgement
is parameterized by a context Ψ (omitted), which contains that types of primitive distributions
and functions. The typing rules for reals and distributions are shaded.
includes the type Nat, the type Real (Example 3.10), and products of well-formed
types τ1 × τ2.31
Given a term M that has a well-formed type, the construct return M corresponds
to return in a probability monad and returns a point-mass centered at M. The typing
rule for x ←M ; N is the usual one for bind in a probability monad. The rule ﬁrst
checks that M has type Dist τ1 and that τ1 is well formed. Next, the rule checks
that N under a typing context extended with x : τ1 has type Dist τ2 and that τ2 is
well formed. The result is an expression of type Dist τ2.
31 As a reminder, we can also support distributions on any countably-based space (e.g., distributions on
distributions), but restrict our attention to these types for simplicity.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

106
Huang, Morrisett and Spitters: Computable Distributions
VNat ≜N⊥
Vτ1 →τ2 ≜(Vτ1 ⇒Vτ2)⊥
Vτ1 × τ2 ≜(Vτ1 × Vτ2)⊥
VReal ≜˜R⊥
VDist τ ≜{(s,pshVτ(s)) | s ∈S(Vτ)}
Figure 3.5 The interpretation of types V· denotes types as topological domains. We have
shaded the interpretation of reals and distributions. Note that we are using a call-by-name
interpretation.
3.5.2 Semantics
Interpretation of types The interpretation of types Vτ ∈TD interprets a type
τ as a topological domain and is deﬁned by induction on types (Figure 3.5).
The interpretation of types is similar to what one obtains from a standard CPO
call-by-name interpretation.
For example, the interpretation of Nat lifts the topological domain N. This is
similar to the CPO interpretation of naturals as the lifted naturals. The interpretation
of functions and products are the usual call-by-name interpretations, the diﬀerence
being that we use the topological domain counterparts instead. The interpretation
of the type of reals Real is a lifted partial real ˜R⊥(recall Example 3.24). The
interpretation of the type of distributions Dist τ is a pair of a sampler and a
distribution such that the sampler realizes the distribution. The (continuous) function
pshD : S(D) ⇒P(D) computes the pushforward32 and converts a sampler into its
corresponding valuation. The well-formed distribution judgement ⊢D τ ensures that
the probability monad P is applied to only the countably based topological domains.
Denotation function The expression denotation function EΓ ⊢M : τ : VΓ ⇒
Vτ (see Proposition 3.38) is deﬁned by induction on the typing derivation and
is summarized in Figure 3.6. It is parameterized by a global environment Υ that
interprets constant reals r, primitive functions rop, and primitive distributions dist.
The global environment Υ should be well formed (deﬁned shortly) with respect to
the global context Ψ used in the expression typing judgement. After we introduce
the notion of a well-formed global environment, we walk though the semantics and
connect it with the library implementation, with a particular focus on the relation
between a sampling and distributional view of probabilistic programs.
32 We have that pshD(s) ≜U →
∫
1U(·) dμs where μs ≜μiid ◦s−1.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

3.5 A Semantics for a Core Language
107
EΓ ⊢x : τ ≜πx
EΓ ⊢zero : Nat ≜liftC ◦const ◦Υ(zero)
EΓ ⊢succ : Nat →Nat ≜liftC ◦const ◦Υ(succ)
EΓ ⊢pred : Nat →Nat ≜liftC ◦const ◦Υ(pred)
EΓ ⊢λx : τ1. M : τ1 →τ2 ≜liftC ◦curry(EΓ, x : τ1 ⊢M : τ2)
EΓ ⊢M1 M2 : τ2 ≜eval ◦⟨unlift(EΓ ⊢M1 : τ1 →τ2),EΓ ⊢M2 : τ1⟩
EΓ ⊢if0 M1 M2 M3 : τ ≜if0 ◦⟨EΓ ⊢M1 : Nat,EΓ ⊢M2 : τ,EΓ ⊢M3 : τ⟩
EΓ ⊢fix M : τ ≜ﬁx ◦unlift(EΓ ⊢M : τ →τ)
EΓ ⊢(M1, M2) : τ1 × τ2 ≜liftC ◦⟨EΓ ⊢M1 : τ1,EΓ ⊢M2 : τ2)⟩
Efst Γ ⊢M : τ1 ≜π1 ◦unlift ◦EΓ ⊢M : τ1 × τ2
Esnd Γ ⊢M : τ2 ≜π2 ◦unlift ◦EΓ ⊢M : τ1 × τ2
EΓ ⊢r : Real ≜liftC ◦const ◦Υ(r)
EΓ ⊢rop : Realn →Real ≜liftC ◦const ◦Υ(rop)
EΓ ⊢dist : Dist τ ≜liftC ◦const ◦Υ(dist)
EΓ ⊢return M : Dist τ ≜⟨det ◦f,η ◦f ⟩where f = EΓ ⊢M : τ
EΓ ⊢x ←M1 ; M2 : Dist τ2 ≜⟨samp ◦⟨π1 ◦f,π1 ◦curry(g)⟩,
(π2 ◦f ) ≻♭(π2 ◦g)⟩
where f = EΓ ⊢M1 : Dist τ1
where g = EΓ, x : τ1 ⊢M2 : τ2
Figure 3.6 The denotational semantics of λC D is given by induction on the typing derivation
(semantics of additional constructs are shaded). The structure of the semantics is similar to one
where we use CPOs. Υ is a global environment used to interpret constants. The function πx
projects the variable x from the environment.
Well-formed global environment To ensure that we do not introduce non-comput-
able constants into λCD (e.g., non-computable operations on reals rop) and that
the constants have the appropriate types, the global environment Υ should be well
formed with respect to the global context Ψ. To distinguish the semantic value
obtained from a global environment lookup from the syntax, we will put a bar over
the constant (e.g., Υ(r) = ¯r) to refer to the semantic value. We say that Υ is well
formed with respect to Ψ, written Ψ ⊢Υ, if the conditions below hold.
(real-wf) For any r ∈dom(Ψ), Υ(r) is the realizer of a real ¯r when Ψ(r) = Real.
(dist-wf) For any dist ∈dom(Ψ), Υ(dist) is the name of a pair dist that realizes a
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

108
Huang, Morrisett and Spitters: Computable Distributions
sampler over values in Vτ and the corresponding distribution when Ψ(dist) =
Dist τ.
(rop-wf) For any rop ∈dom(Ψ), the corresponding semantic function rop is
strict, continuous on its domain, and a n-ary real-valued function on reals when
Ψ(rop) = Realn →Real.
Denotation function and sampling The denotation of terms corresponding to the
PCF fragment are standard. Hence, we will focus on the constructs λCD introduces.
The denotation of a constant real r is a global environment lookup.
EΓ ⊢r : Real ≜liftC ◦const ◦Υ(r)
By the well-formedness of the global environment, Υ(r) will have a realizer. Likewise,
the denotation of a primitive function on reals rop is a global environment lookup
and corresponds to a representation of the code implementing the function.
EΓ ⊢rop : Realn →Real ≜liftC ◦const ◦Υ(rop)
The well-formedness of the global environment Υ enforces these conditions. Our
next task is to explain the denotation of distribution constructs in λCD.
As a reminder, the interpretation of types is a pair of a sampler and the distribution
that it realizes. As we will see shortly, the semantics of the sampling component
and the semantics of the distribution component do not depend on one another
(besides the fact that we want the distribution to be realized by the sampler). Hence,
we could have given two diﬀerent semantics and related them. Nevertheless, in
this form, we will obtain that the valuation is the pushforward along the sampler,
and consequently, make the connection between what is given by a distributional
semantics and what was implemented in the sampling library. We walk through the
distribution constructs now.
The denotation of a constant primitive distribution dist is a global environment
lookup. Note that the interpretation of Dist τ is a pair of a sampler and valuation
so the lookup should also produce a pair.
EΓ ⊢dist : Dist τ ≜liftC ◦const ◦Υ(dist)
The denotation of return M produces a pair of a sampler that ignores the input
bit-randomness and a point mass valuation centered at M.
EΓ ⊢return M : Dist τ ≜⟨det ◦f,η ◦f ⟩where f = EΓ ⊢M : τ
The meaning of x ←M ; N also gives a sampler and a valuation.
EΓ ⊢x ←M1 ; M2 : Dist τ2 ≜
⟨samp ◦⟨π1 ◦f, π1 ◦curry(g)⟩,(π2 ◦f ) ≻♭(π2 ◦g)⟩
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

3.5 A Semantics for a Core Language
109
where f = EΓ ⊢M1 : Dist τ1 and g = EΓ, x : τ1 ⊢M2 : τ2. Under the
sampling view, we use samp to compose the sampler obtained by π1 ◦f with the
function π1 ◦g. Under the valuation component, we reweigh π2 ◦g according to
the valuation π2 ◦f using monad bind ≻♭from P. We can check that the valuation
given by the semantics is indeed the pushforward along the sampler.
Proposition 3.37 (Push)
Let D and E be countably based topological predomains
(qcb0 spaces more generally).
(i) pshD(det(d)) = η(d) for any d ∈D.
(ii) pshE(samp(s)( f )) = pshD(s) ≻♭v →pshE( f (v)) for any s ∈S(D) and
f : D ⇒S(E).
In the case of bind (the second item), it is necessary that the split operation used in
samp (Section 3.4.2) produces an independent stream of bits.
We end by checking that the expression denotation function is well deﬁned.
Proposition 3.38 (Well deﬁned)
The expression denotation function E· is well
deﬁned, i.e., EΓ ⊢M : τ : VΓ ⇒Vτ for any well-typed term Γ ⊢M : τ and
well-formed global environment Ψ ⊢Υ.
The structure of the argument showing that the expression denotation function is
well deﬁned is similar to the argument for showing that the CPO semantics of PCF
is well deﬁned. The interesting cases correspond to return M and x ←M1 ; M2
where we need to relate the sampling component with the valuation it denotes, which
is given by Proposition 3.37.
3.5.3 Reasoning About Programs
We now return to resolving some semantic issues that were raised when we
used the library to implement distributions. Throughout this section, we overload
EΓ ⊢M : Dist τ to mean π2 ◦EΓ ⊢M : Dist τ so that it just provides the
distributional view. As shorthand, we write E·ρ instead of E·(ρ) where the
meta-variable ρ ranges over environments.
Reasoning about distributions We ﬁrst show that the encoding of the standard
geometric distribution is correct. Let μB be an unbiased Bernoulli distribution and
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

110
Huang, Morrisett and Spitters: Computable Distributions
μn correspond to n un-foldings of stdGeometric:
EstdGeometricρ(U) = sup
n∈N
∫
v →

1U(1)
v = t
∫
w →1U(w + 1)dμn
v = f

dμB
= sup
n∈N
(1U(1)1
2 +
∞

w=0
1U(w + 1)μn({w}))
= 1U(1)1
2 +
∞

w=0
1U(w + 1)(sup
n∈N
μn({w})) .
By induction on n, we can show that μn is the measure
μn = {0} →0, {1} →(1/2),. . ., {n} →(1/2)n .
Hence, we can conclude that supn∈N μn is a geometric distribution and that the
encoding of stdGeometric is correct (for any environment ρ).
Primitive functions In our encoding of the standard normal distribution via the
Marsaglia polar transformation, we used < as if it had a return type of Bool even
though equality on reals is not computable. Indeed, the well-formedness conditions
imposed on the global environment would disallow < at the current type. To resolve
the semantics of <, we can think in terms of an implementation. In particular, we
can encode < as dovetailing computations that semi-decides x < y (i.e., return () if
x < y and diverge otherwise) and semi-decides x > y (i.e., returns () if x > y and
diverge otherwise)). On the case of equality, which occurs with probability 0 in the
Marsaglia polar transform, the function diverges.
Partiality and divergence We investigate the semantics of divergence more closely
now. For convenience, we repeat the two expressions from Section 3.3 that provided
two diﬀering notions of divergence below.
botSamp :: (CMetrizable a) => Samp (Approx a)
botSamp = botSamp
botSampBot :: (CMetrizable a) => Samp (Approx a)
botSampBot = mkSamp (\_ -> bot)
where bot = bot
In the former, we obtain the bottom valuation, which assigns 0 mass to every open
set. This corresponds to the sampling function u ∈2ω →⊥and can be interpreted
as failing to provide a sampler. In the latter, we obtain the valuation that assigns
0 mass to every open set, except for the set {⌊X⌋∪⊥} which is assigned mass 1.
This corresponds to the sampling function u ∈2ω →⌊⊥⌋and can be interpreted as
providing a sampling function that fails to produce a sample.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

3.5 A Semantics for a Core Language
111
As before, we can check that laziness works in the appropriate manner by
selectively ignoring the results of draws from the distributions above.
alwaysDiv :: Samp Real
alwaysDiv = do
_ <- botSamp ::
Samp Real
stdUniform
neverDiv :: Samp Real
neverDiv = do
_ <- botSampBot ::
Samp Real
stdUniform
We can check that the denotation of the former is equivalent to that of botSamp:
EalwaysDivρ(U) =
∫
(· →μU(U)) dEbotSampρ
= 0
where μU is the standard uniform distribution. Note that EbotSampρ maps every
open set to 0 so the integral is 0 as well. However, the denotation of the latter is
equivalent to that of stdUniform:
EneverDivρ(U) =
∫
(· →μU(U)) dEbotSampBotρ
=
sup
s simple
{
∫
s dEbotSampBotρ | s ≤· →μU(U)}
= μU(U) .
As a reminder, EbotSampBotρ(U) = 1 when U = VReal. Hence, the integral
takes its largest value on the simple function33 μU(U) 1VReal(·).
As a ﬁnal example, consider the program below that uses a coin ﬂip to determine
its diverging behavior.
maybeBot :: Samp Bool
maybeBot = do
b <- stdBernoulli
if b then return bot else stdBernoulli
Intuitively, this distribution returns a sampler that always generates diverging
samples with probability 1/2 and returns an unbiased Bernoulli distribution with
probability 1/2. If we changed return bot to botSamp as below
maybeBot' :: Samp Bool
maybeBot' = do
b <- stdBernoulli
if b then bot else stdBernoulli
then the semantics would change to a distribution that returns a diverging sampler
with probability 1/2 and an unbiased Bernoulli distribution with probability 1/2.
33 As a reminder, a simple function in our context is a linear combination of indicator functions on open sets.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

112
Huang, Morrisett and Spitters: Computable Distributions
Independence and commutativity In Section 3.3.2, we saw that we could not argue
that two distributions that commuted the order in which we sampled independent
normal distributions were equivalent. As a reminder, the issue was that commuting
the order of sampling meant that the underlying random bit-stream was consumed
in a diﬀerent order. Consequently, the values produced by the two terms may be
diﬀerent. However, as the semantics we just saw relates the sampling view with the
distributional view by construction, we can easily see that these two terms will be
distributionally equivalent by Fubini.
3.6 Bayesian Inference
What are the implications of taking a computable viewpoint for Bayesian inference?
In this section, we discuss the implications of taking a computable viewpoint for
Bayesian inference. Perhaps surprisingly, one can show that conditioning is not
computable in general. Nevertheless, conditioning in practical settings does not run
into these pathologies. It will be important for probabilistic programming languages
to support conditioning in these cases. Note that these results say nothing about
the eﬃciency of inference. In practice, we will still need approximate inference
algorithms to compute conditional distributions.
3.6.1 Conditioning is not Computable
Figure 3.7 gives an encoding in λCD of an example by Ackerman et al. (2011)
that shows that conditioning is not always computable. Similar to other results
nonComp :: Samp (Nat, Real)
nonComp = do
n <- geometric (1/2)
c <- bernoulli (1/3)
u <- uniform 0 1
v <- uniform 0 1
x <- return (mkApprox
(\k -> select u v c k (tmHaltsIn n)))
return (n, x)
where select u v c k m
| m > k = nthApprox v k
| m == k = if c then 1 else 0
| m < k = nthApprox u (k - m - 1)
Figure 3.7 A Haskell encoding of a counter-example given by Ackerman et al. (2011) that shows
that conditioning is not always computable. The function tmHaltsIn in the code outputs the
number of steps the n-th Turing machine halts in or ∞(for diverges) if the n-th Turing machine
does not halt. The idea is that an algorithm that could compute this conditional distribution would
imply a decision procedure for the Halting problem.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

3.6 Bayesian Inference
113
in computability theory, the example demonstrates that an algorithm computing
the conditional distribution would also solve the Halting problem. The function
tmHaltsIn accepts a natural n specifying the n-th Turing machine and outputs the
number of steps the n-th Turing machine halts in or ∞(for diverges) if the n-the
Turing machine does not halt. Upon inspection, we see the function nthApprox
produces the binary expansion (as a dyadic rational) of a real, using tmHaltsIn
to select diﬀerent bits of the binary expansion of u or v, or the bit c depending on
whether the n-th Turing machine halts within k steps or not.
Consider computing the conditional distribution P(N | X), where the random
variable N corresponds to the program variable n and X to x. Thus, computing
the conditional distribution P(N | X) corresponds to determining the value of the
program variable n given the value of the program variable x. We informally discuss
why this distribution is not computable now. Observe that (1) the value of x depends
on the value of n—whether the n-th Turing machine halts within k steps or not
for every k (hence whether the n-th Turing machine halts or not)—and (2) the
geometric distribution is supported on N\{0} so we need to consider every Turing
machine. Consequently, we would require a decision procedure for the Halting
problem in order to compute the posterior distribution on n. Thus, nonComp encodes
a computable distribution P(N,X) whose conditional P(N | X) is not computable.
We refer the reader to the full proof (see Ackerman et al., 2011) for more details.
3.6.2 Conditioning is Computable
Now, we add conditioning as a library to λCD (Figure 3.8). λCD provides only a
restricted conditioning operation obsDens, which requires a conditional density.
We will see that the computability of obsDens corresponds to an eﬀective version
of Bayes' rule. We have given only one conditioning primitive here, but it is possible
to identify other situations where conditioning is computable and add those to the
conditioning library. For example, conditioning on positive probability events is
computable (see Galatolo et al., 2010, Prop. 3.1.2).
The library provides the conditioning operation obsDens, which enables us to
condition on continuous-valued data when a bounded and computable conditional
density is available.
Proposition 3.39
(Ackerman et al., 2011, Cor. 8.8). Let U be a U-valued random
variable, V be a V-valued random variable, and Y be Y-valued random variable,
where Y is independent of V given U. Let U, V, and Y be computable. Moreover, let
pY |U(y | u) be a conditional density of Y given U that is bounded and computable.
Then the conditional distribution P[(U,V) | Y] is computable.
The bounded and computable conditional density enables the following integral
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

114
Huang, Morrisett and Spitters: Computable Distributions
module CondLib (BndDens, obsDens) where
import ApproxLib
import CompDistLib
import RealLib
newtype BndDens a b =
BndDens { getBndDens :: (Approx a -> Approx b -> Real, Rat)
}
-- Requires bounded and computable density
obsDens :: forall u v y.
(CMetrizable u, CMetrizable v, CMetrizable y) =>
Samp (Approx (u, v)) -> BndDens u y -> Approx y -> Samp (
Approx (u, v))
-- Extend with more conditioning operators below ...
Figure 3.8 An interface for conditioning (module CondLib). The function obsDens enables
conditioning on continuous-valued data when a bounded and computable conditional density is
available.
to be computed, which is in essence Bayes' rule. A version of the conditional
distribution P((U,V) | Y) is
κ(U,V)|Y(y, B) =
∫
B pY |U(y | u) dμ(U,V)
∫
pY |U(y | u) dμ(U,V)
where B is a Borel set in the space associated with U × V and μ(U,V) is the joint
distribution of U and V.34
Another interpretation of the restricted situation is that our observations have
been corrupted by independent smooth noise (Ackerman et al., 2011, Cor. 8.9). To
see this, consider the following generative model:
(U,V) ∼μ(U,V)
N ∼μnoise
Y = U + N
where μnoise has density pN(·). The random variable U can be interpreted as the ideal
model of how the data was generated and the random variable V can be interpreted
as the model parameters. The random variable Y can then be interpreted as the
data we observe that is smoothed by the noise N so that pY |U(y | u) = pN(y −u).
Notice that the model (U,V) is not required to have a density and can be an arbitrary
34 As a reminder, pY |(U ,V)(y | u, v) = pY |U(y | u) due to the conditional independence of Y and V given U.
Hence, the conditional density pY |U(y | u) in the integral written more precisely is (u, v) →pY |U(y | u).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

3.6 Bayesian Inference
115
computable distribution. The idea is that we condition on Y (i.e., the smoothed data)
as opposed to U (i.e., the ideal data) when we compute the posterior distribution for
the model parameters V.35 Indeed, probabilistic programming systems proposed by
the machine learning community impose a similar restriction (e.g., see Goodman
et al., 2008; Wood et al., 2014).
Now, we describe obsDens, starting with its type signature. Let the type
BndDens τ σ represent a bounded computable density:
newtype BndDens a b =
BndDens { getBndDens :: (Approx a -> Approx b -> Real, Rat)
}
Conditioning thus takes a samplable distribution, a bounded computable density
describing how observations have been corrupted, and returns a samplable distribu-
tion representing the conditional. In the context of Bayesian inference, it does not
make sense to condition distributions such as maybeBot that diverge with positive
probability. Hence, we do not give semantics to conditioning on those distributions.
The implementation of obsDens is in essence a λCD program that implements
the proof that conditioning is computable in this restricted setting. This is possible
because results in computability theory have computable realizers.36
obsDens :: forall u v y.
(CMetrizable u, CMetrizable v, CMetrizable y) =>
Samp (Approx (u, v)) -> BndDens u y -> Approx y -> Samp (
Approx (u, v))
obsDens dist (BndDens (dens, bnd)) d =
let f :: Approx (u, v) -> Real = \x -> dens (approxFst x) d
mu :: Prob (u, v) = sampToComp dist
nu :: Prob (u, v) = \bs ->
let num
= integrateBndDom mu f bnd bs
denom = integrateBnd mu f bnd
in map fst (cauchyToLU (num / denom))
in
compToSamp nu
The parameter dist corresponds to the joint distribution of the model (both model
parameters and likelihood), dens corresponds to a bounded conditional density
35 As an illustrative example, consider the following situation where we hope to model how a scene in an image is
constructed so we can identify objects in the image (see Kulkarni et al., 2015, for a probabilistic programming
language designed for scene perception). The model parameters V contain all the information describing
the objects in the scene, including their optical properties and their positions. The resulting image U is then
rendered by a graphics engine. The caveat is that the graphics engine uses an enumeration of the Halting set
to add artifacts to the image so it is pathological. (Thus, this distribution is a version of nonComp.) Instead
of attempting to compute the posterior distribution P(U | V), which is not computable, we smooth out the
rendered image U with some noise given by pY |U(y | u). In other words, we apply some ﬁltering to the image
U so we obtain an image Y free of artifacts introduced by the pathological graphics engine. The posterior
P((U, V) | V) is then computable. In this example, the posterior would give the positions and optical properties
of objects given an image so it could be used in computer vision applications.
36 That is, we implement the Type-2 machine code as a Haskell program.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

116
Huang, Morrisett and Spitters: Computable Distributions
describing how observation of data has been corrupted by independent noise,
and d is the observed data. Next, we informally describe the undeﬁned functions
in the sketch. The function approxFst projects out the ﬁrst component of a
product of approximations. The functions sampToComp and compToSamp witness
the computable isomorphism between samplable and computable distributions.37
The functions integrateBndDom and integrateBnd compute an integral (see
Hoyrup and Rojas, 2009, Prop. 4.3.1), and correspond to an eﬀective Lebesgue
integral. cauchyToLU converts a Cauchy description of a computable real into an
enumeration of lower and upper bounds.
Because obsDens works with conditional densities, we do not need to worry
about the Borel paradox. The Borel paradox shows that we can obtain diﬀerent
conditional distributions when conditioning on probability zero events (e.g., see
Rao and Swift, 2006). To illustrate this, suppose that X and Y are two independent
random variables with standard normal distributions. We can ask a (classic) question:
"What is the conditional distribution of Y given that X = Y?"
In statistics, the appropriate response is to notice that the question as posed
is ill-formed—one cannot condition on a measure zero event. The well-posed
formulation is to deﬁne an auxiliary random variable Z and condition on a constant.
For instance, Z = X −Y conditioned on Z = 0, Z = Y/X conditioned on Z = 1 ,
and Z = IY=X conditioned on Z = 1. Remarkably, all three versions lead to diﬀerent
answers (Proschan and Presnell, 1998).
A probabilistic programming language that does not provide a notion of random
variable such as λCD will need an alternative method of addressing this issue. Type-2
computability provides a straight-forward answer—it is not possible to create a
boolean value that distinguishes two probability zero events in λCD. For instance,
the operator == implementing equality on reals returns false if two reals are provably
not-equal and diverges otherwise because equality is not decidable.
3.7 Summary and Further Directions
We hope to have shown that we do not need to sacriﬁce traditional notions of
computation when modeling reals and continuous distributions by keeping their
representations in mind. The simple observation is that we can "program" them
in a general-purpose programming language. With this in mind, we can now ask a
basic question: "What does it mean for a probabilistic programming language to
be Turing-complete?" From the perspective of Type-2 computability, one answer is
that such a language can express all Type-2 computable distributions, analogous to
37 The computable isomorphism relies on the distributions being full-measure. The algorithm is undeﬁned
otherwise.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
117
how a Turing-complete language can express all computable functions. Indeed, this
resolution is somewhat tautological!
This answer raises another interesting question related to full-abstraction and
universality38 of probabilistic programs. In the standard setting of PCF, one approach
to the full-abstraction problem is to add parallel or por to the language so that
the operational behavior coincides with the denotational semantics. Additionally
adding a searching operator exists means that all computable functions will be
deﬁnable. One may wonder, if an analogous result holds for probabilistic programs.
In particular, a universality result would crystallize the thought that Turing-complete
probabilistic programming languages express Type-2 computable distributions.
As we are now back on familiar grounds with regards to computability, we can
turn our attention to the design of probabilistic programming languages. The design
of such languages will demand more from a semantics of probabilistic programs.
For example, for the purposes of automating Bayesian inference, it is crucial that the
inference procedure be eﬃcient (and not simply computable). One direction is to ﬁnd
compilation strategies that can eﬃciently realize Type-2 computable distributions or
approximate them (for some notion of approximation) using ﬂoating point numbers.
Another direction is to consider alternative language designs (in addition to PCF
with a probability monad) and the corresponding structures that we will need to
model these languages.
Acknowledgments
We thank our anonymous reviewers for their helpful comments and feedback.
References
Abramsky, Samson, and Jung, Achim. 1994. Domain Theory. Pages 1-168 of:
Abramsky, Samson, Gabbay, Dov M, and Maibaum, T S E (eds), Handbook of
Logic in Computer Science, vol. 3. Oxford University Press.
Ackerman, Nathanael Leedom, Freer, Cameron E, and Roy, Daniel M. 2011.
Noncomputable Conditional Distributions. Pages 107-116 of: Proceedings of
the 26th Annual Symposium on Logic in Computer Science. IEEE.
Battenfeld, Ingo. 2004. A Category of Topological Predomains. M.Phil. thesis, TU
Darmstadt.
Battenfeld, Ingo. 2008. Topological Domain Theory. Ph.D. thesis, University of
Edinburgh.
Battenfeld, Ingo, Schröder, Matthias, and Simpson, Alex. 2006. Compactly generated
domain theory. Mathematical Structures in Computer Science, 16(2), 141-161.
38 A programming language is universal if all computable elements in the domain of interpretation are deﬁnable.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

118
References
Battenfeld, Ingo, Schröder, Matthias, and Simpson, Alex. 2007. A Convenient
Category of Domains. Electronic Notes in Theoretical Computer Science, 172,
69-99.
Bauer, Andrej. 2000a. The Realizability Approach to Computable Analysis and
Topology. Ph.D. thesis, School of Computer Science, Carnegie Mellon Univer-
sity.
Bauer, Andrej. 2000b. The Realizability Approach to Computable Analysis and
Topology. Ph.D. thesis, Carnegie Mellon University.
Bauer, Andrej. 2005. Realizability as the connection between computable and
constructive mathematics. Unpublished lecture notes.
Bauer, Andrej, and Kavkler, Iztok. 2008. Implementing Real Numbers With RZ.
Electronic Notes in Theoretical Computer Science, 202, 365-384.
Birkedal, Lars. 1999. Developing Theories of Types and Computability via Realiz-
ability. Ph.D. thesis, School of Computer Science, Carnegie Mellon University.
Borgström, Johannes, Gordon, Andrew D, Greenberg, Michael, Margetson, James,
and Van Gael, Jurgen. 2011. Measure Transformer Semantics for Bayesian
Machine Learning. Pages 77-96 of: Programming Languages and Systems.
Springer.
Crubillé, Raphaëlle. 2018. Probabilistic Stable Functions on Discrete Cones are
Power Series. Pages 275-284 of: Proceedings of the 33rd Annual ACM/IEEE
Symposium on Logic in Computer Science. ACM.
Dal Lago, Ugo, and Zorzi, Margherita. 2012. Probabilistic operational semantics for
the lambda calculus. RAIRO-Theoretical Informatics and Applications, 46(3),
413-450.
Danos, Vincent, and Ehrhard, Thomas. 2011. Probabilistic coherence spaces as a
model of higher-order probabilistic computation. Information and Computation,
209(6), 966-991.
Durrett, Rick. 2010. Probability: Theory and Examples. 4 edn. Cambridge University
Press.
Ehrhard, Thomas, Tasson, Christine, and Pagani, Michele. 2014. Probabilistic
Coherence Spaces are Fully Abstract for Probabilistic PCF. Pages 309-320 of:
ACM SIGPLAN Notices, vol. 49. ACM.
Ehrhard, Thomas, Pagani, Michele, and Tasson, Christine. 2018. Measurable Cones
and Stable, Measurable Functions: A Model for Probabilistic Higher-Order
Programming. Proceedings of the ACM on Programming Languages, 2(POPL),
59.
Escardó, Martín Hötzel. 1996. PCF extended with real numbers. Theoretical
Computer Science, 162(1), 79-115.
Escardó, Martín Hötzel. 2004. Synthetic topology: of data types and classical spaces.
Electronic Notes in Theoretical Computer Science, 87, 21-156.
Escardó, Martín Hötzel, Lawson, Jimmie, and Simpson, Alex. 2004. Comparing
Cartesian closed categories of (core) compactly generated spaces. Topology
and its Applications, 143(1), 105-145.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
119
Freer, Cameron E, and Roy, Daniel M. 2010. Posterior distributions are computable
from predictive distributions. Pages 233-240 of: Proceedings of the 13th
International Conference on Artiﬁcial Intelligence and Statistics. SAIS.
Galatolo, Stefano, Hoyrup, Mathieu, and Rojas, Cristóbal. 2010. Eﬀective sym-
bolic dynamics, random points, statistical behavior, complexity and entropy.
Information and Computation, 208(1), 23-41.
Giry, Michèle. 1982. A categorical approach to probability theory. Pages 68-85 of:
Categorical Aspects of Topology and Analysis. Springer.
Goodman, Noah, Mansinghka, Vikash, Roy, Daniel M, Bonawitz, Keith, and
Tenenbaum, Joshua B. 2008. Church: A language for generative models. Pages
220-229 of: Proceedings of the 24th Conference on Uncertainty in Artiﬁcial
Intelligence. AUAI.
Gunter, Carl A. 1992. Semantics of Programming Languages: Structures and
Techniques. Foundations of Computing. The MIT Press.
Heunen, Chris, Kammar, Ohad, Staton, Sam, and Yang, Hongseok. 2017. A
Convenient Category for Higher-Order Probability Theory. Pages 1-12 of:
Logic in Computer Science (LICS), 2017 32nd Annual ACM/IEEE Symposium
on. IEEE.
Hoyrup, Mathieu, and Rojas, Cristóbal. 2009. Computability of probability measures
and Martin-Löf randomness over metric spaces. Information and Computation,
207(7), 830-847.
Huang, Daniel, and Morrisett, Greg. 2016. An Application of Computable Dis-
tributions to the Semantics of Probabilistic Programming Languages. Pages
337-363 of: Programming Languages and Systems.
Huang, Daniel Eachern. 2017. On Programming Languages for Probabilistic
Modeling. Ph.D. thesis, Harvard University.
Jones, Claire. 1989. Probabilistic Non-determinism. Ph.D. thesis, University of
Edinburgh.
Kozen, Dexter. 1981. Semantics of Probabilistic Programs. Journal of Computer
and System Sciences, 22(3), 328-350.
Kulkarni, Tejas D, Kohli, Pushmeet, Tenenbaum, Joshua B, and Mansinghka, Vikash.
2015. Picture: A Probabilistic Programming Language for Scene Perception.
Pages 4390-4399 of: Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition. IEEE.
Lambov, Branimir. 2007. RealLib: An Eﬃcient Implementation of Exact Real
Arithmetic. Mathematical Structures in Computer Science, 17(1), 81-98.
Lietz, Peter. 2004. From Constructive Mathematics to Computable Analysis via the
Realizability Interpretation. Ph.D. thesis, TU Darmstadt.
Longley, John R. 1995. Realizability Toposes and Language Semantics. Ph.D. thesis,
University of Edinburgh.
Munkres, James R. 2000. Topology. 2 edn. Prentice Hall.
Panangaden, Prakash. 1999. The Category of Markov Kernels. Electronic Notes in
Theoretical Computer Science, 22, 171-187.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

120
References
Park, Sungwoo, Pfenning, Frank, and Thrun, Sebastian. 2005. A Probabilistic
Language Based Upon Sampling Functions. Pages 171-182 of: Proceedings of
the 32nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming
Languages. ACM.
Peyton Jones, Simon, Reid, Alastair, Henderson, Fergus, Hoare, Tony, and Marlow,
Simon. 1999.
A Semantics for Imprecise Exceptions.
Pages 25-36 of:
Proceedings of the 1999 ACM SIGPLAN Conference on Programming Language
Design and Implementation. ACM.
Proschan, Michael A, and Presnell, Brett. 1998. Expect the Unexpected from
Conditional Expectation. The American Statistician, 52(3), 248-252.
Rao, Malempati M, and Swift, Randall J. 2006. Probability theory with applications.
2 edn. Mathematics and Its Applications, vol. 582. Springer.
Saheb-Djahromi, Nasser. 1978. Probabilistic LCF. Mathematical Foundations of
Computer Science, 64, 442-451.
Schröder, Matthias. 2007. Admissible Representations of Probability Measures.
Electronic Notes in Theoretical Computer Science, 167, 61-78.
Sipser, Michael. 2012. Introduction to the Theory of Computation. 3 edn. Cengage
Learning.
Staton, Sam. 2017. Commutative Semantics for Probabilistic Programming. Pages
855-879 of: European Symposium on Programming. Springer.
Streicher,
Thomas.
2008.
Realizability.
http://www.mathematik.
tu-darmstadt.de/~streicher/REAL/REAL.pdf. Course Lecture Notes.
Vákár, Matthijs, Kammar, Ohad, and Staton, Sam. 2019. A Domain Theory for Sta-
tistical Probabilistic Programming. Proceedings of the ACM on Programming
Languages, 3(POPL), 36.
Weihrauch, Klaus. 2000. Computable Analysis: An Introduction. 2000 edn. Texts in
Theoretical Computer Science. An EATCS Series. Springer.
Wood, Frank, van de Meent, Jan Willem, and Mansinghka, Vikash. 2014. A new
approach to probabilistic programming inference. Pages 2-46 of: Proceedings
of the 17th International Conference on Artiﬁcial Intelligence and Statistics.
SAIS.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

4
On Probabilistic λ-Calculi
Ugo Dal Lago
University of Bologna & INRIA Sophia Antipolis
Abstract:
This chapter is meant to be a gentle introduction to probabilistic λ-
calculi in their two main variations, namely randomised λ-calculi and Bayesian
λ-calculi. We focus our attention on the operational semantics, expressive power
and termination properties of randomised λ-calculi, only giving some hints and
references about denotational models and Bayesian λ-calculi.
4.1 Introduction
Probabilistic models are more and more pervasive in computer science and are
among the most powerful modelling tools in many areas like computer vision (Prince,
2012), machine learning (Pearl, 1988) and natural language processing (Manning
and Schütze, 1999). Since the early times of computation theory (De Leeuw
et al., 1956), the concept of an algorithm has been generalised from a purely
deterministic process to one in which certain elementary computation steps can have
a probabilistic outcome, this way enabling eﬃcient solutions to many computational
problems (Motwani and Raghavan, 1995). More recently, programs have been
employed as means to express probabilistic models rather than algorithms, with
program evaluation replaced by a form of inference which does not aim at looking for
the result of a computation, but rather at the probability of certain events in the model.
How can all this be taken advantage of in programming languages, and in particular
in higher-order functional programming languages? How is the underlying meta-
theory aﬀected? This Chapter is an attempt to give a brief introduction to this topic,
presenting some basic notions and results, and pointing to the relevant literature on
the subject. Although probabilistic λ-calculi have been known from four decades
now (Saheb-Djaromi, 1978; Jones and Plotkin, 1989), their study has been quite
scattered until very recently, and a uniﬁed view of their theory is, as a consequence,
still missing.
a From Foundations of Probabilistic Programming, edited by Gilles Barthe, Joost-Pieter Katoen and Alexandra
Silva published 2020 by Cambridge University Press.
121
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

122
Dal Lago: On Probabilistic λ-Calculi
A universally accepted paradigm for functional programs is Church's λ-calculus
(Barendregt, 1984), in which the processes of forming functions and of passing
parameters to them are modelled by dedicated constructs, namely by the λ-binder
and binary application. Probabilistic λ-calculi most often take the form of ordinary
λ-calculi in which the language of terms is extended with one or more constructs
allowing for a form of probabilistic evolution. There are at least two ways to do
that, which give rise to two diﬀerent styles of λ-calculi, depending on the additional
operators they provide.
Randomised λ-calculi. Here, the only new operator provided by the underlying
programming language is a form of probabilistic choice, whose evaluation can
produce diﬀerent outcomes, in a probabilistic fashion. Various choice operators can
be considered, the simplest one is a form of binary, fair, probabilistic choice. By
that, one can form terms such as M ⊕N, which evolves like M or N depending on
the outcome of a probabilistic process, typically corresponding to the ﬂipping of a
coin. The outcome of such a coin ﬂip is thus a probabilistic event and diﬀerent coin
ﬂips are taken as independent events. This new operator alone is perfectly suﬃcient
to model randomised algorithms (Motwani and Raghavan, 1995). We call λ-calculi
built along these lines randomised λ-calculi. As already mentioned, randomised
λ-calculi have been investigated since the seventies (Saheb-Djaromi, 1978; Jones
and Plotkin, 1989), but scatteredly until very recently, when they have been the
object of much work about denotational semantics (Jung and Tix, 1998; Danos
and Harmer, 2002; Danos and Ehrhard, 2011), program equivalence (Dal Lago
et al., 2014a; Crubillé and Dal Lago, 2014; Bizjak and Birkedal, 2015) and type
systems (Dal Lago and Grellois, 2017; Breuvart and Dal Lago, 2018).
Bayesian λ-calculi. In Bayesian λ-calculi, programs are not seen as modelling
algorithms, like in randomised λ-calculi, but rather as a way to describe a certain
kind of probabilistic models, namely bayesian networks (Pearl, 1988; Koller and
Friedman, 2009), also known as probabilistic graphical models. This paradigm has
been adopted in concrete programming languages like ANGLICAN (Tolpin et al.,
2015) and CHURCH (Goodman et al., 2008) and ultimately consists in endowing
the class of terms with two new constructs, the ﬁrst one modelling sampling and
thus conceptually similar to the probabilistic choice operator from randomised
λ-calculi, and the second one allowing to condition the underlying distribution based
on external evidence, this way giving rise to both an a priori and an a posteriori
distribution. Bayesian λ-calculi, contrarily to randomised λ-calculi, have been
introduced only relatively recently (Borgström et al., 2016), and their metatheory
is deﬁnitely not as stable as the one of randomised λ-calculi. Most often, but not
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

4.1 Introduction
123
always, the sampling and conditioning operators works on real numbers, this way
allowing to build continuous probabilistic models.
These two kinds of λ-calculi certainly have some similarities, but deserve to be
introduced and described independently. Randomised λ-calculi will be the subject
of Section 4.3, while Bayesian λ-calculi will be introduced in Section 4.4. As a
prologue to that, we will give an introduction to probabilistic λ-calculi by way of an
example, in Section 4.2.
Endowing programs with probabilistic primitives (e.g. an operator which models
sampling from a distribution) signiﬁcantly changes the underlying theory. The reader
is however invited to keep in mind that this domain is still under investigation by
the programming language and logic in computer science communities, and is thus
intrinsically unstable, in particular as for Bayesian λ-calculi. In the following, we
give some hints as for the challenges one needs to face when analysing randomised
and bayesian λ-calculi.
Operational Semantics and Contextual Equivalence. Formally describing the
computational process implicit in a λ-term becomes strictly more challenging
when the latter is allowed to ﬂip coins, thus evolving probabilistically rather than
deterministically. In particular, capturing the evaluation process in a ﬁnitary way,
like in ordinary λ-calculus, is impossible. When conditioning is present, the task
becomes even more diﬃcult, since computation is replaced by learning. Another
diﬃculty one encounters when dealing with the operational semantics of randomised
and bayesian λ-calculi is the necessity of some (admittedly basic) measure theory,
this of course only in presence of continuous rather than discrete distributions.
Expressive Power. Not much is known about the expressive power of probabilistic
higher-order calculi, as opposed to the extensive literature on the same subject
about deterministic calculi (see, e.g. (Statman, 1979; Sørensen and Urzyczyn,
2006; Longley and Normann, 2015)). What happens to the class of representable
functions if one enriches, say, a deterministic λ-calculus X with certain probabilistic
choice primitives? Are the expressive power or the good properties of X somehow
preserved? These questions have been given answers in the case in which X is
the pure, untyped, probabilistic λ-calculus (Dal Lago and Zorzi, 2012): in that
case, Turing-completeness continues to hold, i.e., fair binary probabilistic choice
is suﬃcient to encode of computable distributions. But what if one restricts the
underlying calculus, e.g., by way of a type system?
Termination. Termination is a key property already in deterministic functional
programs, but how should it be spelled out in probabilistic λ-calculi? There are at
least two diﬀerent ways to give an answer to this question, following a pioneering
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

124
Dal Lago: On Probabilistic λ-Calculi
work on probabilistic λ-calculus (Saheb-Djaromi, 1978) and recent extensive work
on probabilistic termination (McIver and Morgan, 2005; Bournez and Garnier,
2005). On the one hand, we can consider almost sure termination, by which we
mean termination with maximal likelihood. On the other hand, we can go for the
stronger positive almost sure termination, in which one requires the average number
of evaluation steps to be ﬁnite. Are there ways to enforce either form of termination
in probabilistic λ-calculi, similarly to what has been done in deterministic ones?
Denotational Semantics. Already for a simple, imperative probabilistic program-
ming language, giving a denotational semantics is nontrivial (Kozen, 1981). When
languages also have higher-order constructs, everything becomes even harder (Jung
and Tix, 1998) to the point of disrupting much of the beautiful theory known in the
deterministic case (Barendregt, 1984). This has stimulated research on denotational
semantics of higher-order probabilistic programming languages, with some surpris-
ing positive results coming out recently (Ehrhard et al., 2014; Heunen et al., 2017).
In the rest of this Chapter, we focus on the ﬁrst three aspects, leaving the task
of delving into the denotational semantics of probabilistic λ-calculi to some future
contribution. We are mainly interested in randomised λ-calculi, giving some hints
about bayesian λ-calculi in Section 4.4.
4.2 A Bird's Eye View on Probabilistic Lambda Calculi
M 0
0
M 1
1
2
1
2
1
M 2
...
1
2
1
2
Consider a λ-term M such that for every real
number r, the term M r deterministically
reduces to r ⊕(M (r + 1)), where ⊕is the
new operator for binary probabilistic choice
mentioned in the previous section. After
evolving deterministically, the term M r
thus ﬂips a fair coin, and either terminates
as r, with probability 1
2 or proceeds as M (r + 1), again with probability 1
2. In
Figure 4.2, the overall computational behaviour of the term M 0 is graphically
represented as an inﬁnite binary tree. This tree should not be confused with the
reduction tree of an ordinary λ-term, in which branching models the external
nondeterminism coming from the choice of the next redex to ﬁre, rather than the
internal nondeterminism coming from ⊕.
It should already be clear that some basic questions about the dynamics of term
reduction are bound to receiving answers which are fundamentally diﬀerent from
the ones one gets in the ordinary λ-calculus. Let us consider some of them. First of
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

4.2 A Bird's Eye View on Probabilistic Lambda Calculi
125
all, which value does M 0 evaluate to? Clearly, the result of the evaluation process
cannot just be one value, and must rather be a distribution of values. But which one?
One is tempted to say that the distribution to which M 0 evaluates is the geometric
distribution assigning probability
1
2n+1 to every natural number n. If this the correct
answer, then how could we prove that this is the case? Finitary, inductively deﬁned
formal systems are bound not to be the right tool here, since such derivations can by
construction only "prove" distributions having ﬁnite support to be those to which
terms evaluate. Finitary derivations are however used to derive approximations to
the operational semantics of the underlying term, as we will see in Section 4.3.2
below.
Another question then arises: should we consider M 0 as terminating? And why?
Actually, termination becomes a probabilistic event in presence of probabilistic
choices, and as such happens with a certain probability. The probability that the
evaluation of M 0 terminates is easily seen to be 	∞
i=0
1
2n+1 , namely 1. As such,
M 0 is an almost surely terminating term. This is not the end of the story, however:
what if we are rather interested in checking that the expected number of reduction
steps to termination for M 0 is ﬁnite? Again, the answer is positive, let us see
why. The expected number of reduction steps can be computed by counting the
number of internal nodes of the reduction tree of M 0 (again, see Figure 4.2), each
node weighted by the probability of reaching it. This way every computation step
is taken into account without having to deal directly with inﬁnite traces and their
probabilities, which requires measure theory. In the case at hand, internal nodes are
those labelled with M n and each of them has probability
1
2n . As a consequence,
the expected type to termination is 	∞
n=0
1
2n = 2, and this witnesses the fact that
M 0 is indeed positively almost surely terminating. Is there any relation between the
two concepts we have just introduced? We will have something to say about that in
Section 4.3.5 below.
One of the most interesting properties of the ordinary λ-calculus is conﬂuence:
the inherent nondeterminism induced by the presence of multiple redexes is of a
very benign form, i.e., if M rewrites to both N and L, then there is P to which both
N and L themselves rewrite. As consequence, the normal form of any term M if it
exists, is unique. The choice of a strategy does not inﬂuence the actual ﬁnal result of
the computation, although not all strategies are guaranteed to lead to a normal form.
Unfortunately, this nice picture is not there anymore if one endows the λ-calculus
with the ⊕operator. Consider the term M, deﬁned as (λx.add2(x, x)) (0 ⊕1) where
add2 is a operator computing addition modulo 2, which can be easily deﬁned.
Two redexes occur in M namely M itself and 0 ⊕1. Firing the latter ﬁrst leads,
independently on the outcome of the probabilistic choice, to 0. If M is ﬁred ﬁrst,
instead, one obtains either 0 or 1, each with probability 1
2. Please observe that the
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

126
Dal Lago: On Probabilistic λ-Calculi
failure of conﬂuence is not merely a consequence of the presence of probabilistic
choice, but holds even if considering all possible outcomes.
4.3 A Typed λ-Calculus with Binary Probabilistic Choice
In this section, we introduce randomised λ-calculi in their simplest form, namely one
in which the only probabilistic operator is one for binary probabilistic choice. We
have chosen to go typed rather than untyped, because this way examples are easier
to delineate. Most of the results we give here remain valid in an untyped setting, e.g.
the setting considered in many relevant works on the subject (Ehrhard et al., 2011;
Dal Lago and Zorzi, 2012; Dal Lago et al., 2014a). Going typed (Saheb-Djaromi,
1978; Jones and Plotkin, 1989; Danos and Harmer, 2002; Crubillé and Dal Lago,
2014; Bizjak and Birkedal, 2015) has also the advantage of allowing to present calculi
and type systems guaranteeing termination without the need to signiﬁcantly change
the underlying notation. Bayesian λ-calculi are, by the way, naturally presented as
typed calculi themselves (Culpepper and Cobb, 2017; Heunen et al., 2017; Wand
et al., 2018; Vákár et al., 2019), and this is precisely what we are going to do in
Section 4.4 below.
The calculus we introduce in the rest of Section 4.3, dubbed PCF⊕, can be seen
as being an extension of Plotkin's PCF in which an operator for binary probabilistic
choice is available, while the rest of the system (including types and typing rules)
remain essentially unaltered.
4.3.1 Types and Terms
The ﬁrst notion we need is the one of a type which, as we already mentioned, is not
diﬀerent from the one of other typed λ-calculi:
Deﬁnition 4.1 (PCF⊕: Types). The types of PCF⊕are the expressions derived by
way of the following grammar:
Types
τ, ρ ::= Unit | Num | τ →ρ;
There are two type constants Unit and Num, while type constructors only
include the arrow, modelling function spaces, and do not include, e.g., products or
coproducts. Including them in the calculus would be harmless, but would render the
underlying metatheory unnecessarily more complicated. The ground type Unit is to
be interpreted as the singleton set, while the type of numbers Num is interpreted as
a monoid (M,+,0M). As an example, M could be the natural numbers or the real
numbers. Taking real numbers as a ground type has the advantage of allowing a
smooth integration of sampling from continuous distributions, as we will see in
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

4.3 A Typed λ-Calculus with Binary Probabilistic Choice
127
Terms
M, N ::= V | V W | let M = x in N | M ⊕N
| if V then M else N | fn(V1,. . .,Vn)
Values
V,W ::= ⋆| x | r | λx.M | fix x.V
Figure 4.1 Terms and Values
Section 4.4 below. All we say in this section holds independently on M. In the
following sections, however, sticking to one particular monoid M will sometimes be
necessary. Whenever we want to insist on the underlying monoid to be M, we write
PCFM
⊕instead of PCF⊕.
We assume to reader to be familiar with the basic terminology and notation from
usual, pure λ-calculus. Good references for that are Barendregt (1984) or Hindley
and Seldin (2008), for example.
Deﬁnition 4.2 (PCF⊕: Terms and Values). Terms and values of PCF⊕are both
deﬁned in Figure 4.1, where r ranges over M, x ranges over a denumerable sets
of variables V, and fn ranges over a class of function symbols Fn, each of them
interpreted as a total function f ∗
n : Mn →M. Both terms and values, as customary,
are taken modulo α-equivalence. The set of all terms (respectively, all values) is
indicated as T (respectively, as V).
The calculus PCF⊕, is indeed a close relative of ordinary PCF. One diﬀerence is
the fact that terms are written in so-called A-normal form: one cannot form the
application MN of two arbitrary λ-terms M and N, but only of two values V and
W. The generic form of an application can however be recovered as follows:
M N = let M = x in let N = y in (x y)
where x and y are fresh variables not occurring free in M nor in N. The other
main diﬀerence, of course, is the presence of a binary choice operator ⊕, which
models fair binary probabilistic choice. A slightly more general form of binary
choice is sometimes used in the literature, namely one in which the left argument is
chosen with probability p and the right argument is chosen with probability 1 −p,
the number p being any rational number between 0 and 1. Choice then becomes
biased, and takes the form of a family of operators {⊕p}p∈Q[0,1]. Fair binary choice
is however perfectly suﬃcient for our purposes, including the one of guaranteeing
the calculus to be universal as for its expressive power.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

128
Dal Lago: On Probabilistic λ-Calculi
Value Typing Rules
Γ ⊢⋆: Unit S
Γ, x : τ ⊢x : τ V
Γ ⊢r : Num R
Γ, x : τ ⊢M : ρ
Γ ⊢λx.M : τ →ρ λ
Γ, x : τ →ρ ⊢M : τ →ρ
Γ ⊢fix x.M : τ →ρ
X
Term Typing Rules
Γ ⊢V : τ →ρ
Γ ⊢W : τ
Γ ⊢V W : ρ
@
Γ ⊢M : τ
Γ, x : τ ⊢N : ρ
Γ ⊢let M = x in N : ρ
L
Γ ⊢M : τ
Γ ⊢N : τ
Γ ⊢M ⊕N : τ
⊕
Γ ⊢V : Num
Γ ⊢M : τ
Γ ⊢N : τ
Γ ⊢if V then M else N : τ
I
Γ ⊢V1 : Num
· · ·
Γ ⊢Vn : Num
Γ ⊢fn(V1,. . .,Vn) : Num
F
Figure 4.2 Type System Rules
The notions of free and bound occurrences of variables in terms are the usual
ones from ordinary λ-calculus, and allow us to deﬁne the subsets CT and CV (of T
and V, respectively) of closed terms and closed values.
Deﬁnition 4.3 (PCF⊕: Type Judgments and Rules). A type judgment is an expression
in the form Γ ⊢M : τ, where M is a term, τ is a type, and Γ is an environment,
namely a set {x1 : ρ1,· · · , xm : ρm} of assignments of types to variables which is
non-ambiguous: xi = xj implies i = j. As customary, such an environment Γ is
indicated as x1 : ρ1,· · · , xm : ρm, thus omitting parentheses. The typing rules for
values and terms are in Figure 4.2.
The typing rules as we have introduced them are standard. Just some quick comments
are needed about the rule typing binary choices. The way one types M ⊕N is quite
restrictive, but anyway very natural: we require M and N to both have type τ in
order for M ⊕N to have type τ. This constraint might be relaxed by way of a
notion of monadic typing, which, together with aﬃnity and sized types, enforces
termination (Dal Lago and Grellois, 2017).
Example 4.4. As an example of a term, consider the following expression
GEO := (fix f .λx.x ⊕(let succ1(x) = y in f y)) 0
Actually, GEO is nothing more than a PCF⊕term behaving like the hypothetical
term M 0 we were talking about in Section 4.2. Observe how writing it requires
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

4.3 A Typed λ-Calculus with Binary Probabilistic Choice
129
One-Step Reduction
(λx.M)V →δ(M[V/x])
let V = x in M →δ(M[V/x])
if 0 then M else N →δ(M)
if r then M else N →δ(N) if r  0
M ⊕N →
*
M : 1
2, N : 1
2
+
f (r1,· · · ,rn) →δ( f ∗(r1 . . .,rn))
M →{Li : pi}i∈I
let M = x in N →{let Li = x in N : pi}i∈I
Step-Indexed Reduction
M ⇒0 ∅
V ⇒1 δ(V)
V ⇒n+1 ∅
M →D
∀N ∈SUPP(D).N ⇒n EN
M ⇒n+1
	
N ∈SUPP(D) D(N) · EN
Figure 4.3 Small-Step Distribution Semantics
the presence of a term succ1 among the functions in F1. As expected, succ∗
1 is
the successor function. Another key ingredient for writing GEO is of course the
ﬁxed-point operator fix, without which the essentially inﬁnitary behaviour of GEO
could not be captured.
Typing induces a family {CTτ}τ, where CTτ is the set of all closed terms which
can be assigned type τ in the empty environment, i.e. those terms M such that
∅⊢M : τ. Similarly for {CVτ}τ.
4.3.2 Operational Semantics
We are now going to deﬁne the operational semantics of the closed terms of PCF⊕.
We ﬁrst deﬁne a family of step-indexed reduction relations, and then take the
operational semantics of a term as the sum of all its step-indexed approximations. In
turn, the step-indexed reduction relation is obtained by convolution from a one-step
reduction relation. Both these relations rewrite terms into subdistributions of terms,
which need to be deﬁned formally:
Deﬁnition 4.5 (Distributions). Given any set X, a distribution on X is a function
D : X →R[0,1] such that D(x) > 0 only for denumerably many elements of X and
that 	
x∈X D(x) ≤1. The support of a distribution D on X is the subset SUPP(D)
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

130
Dal Lago: On Probabilistic λ-Calculi
of X deﬁned as
SUPP(D) := {x ∈X | D(x) > 0}.
The set of all distributions over X is indicated as D(X). We indicate the distribution
assigning probability 1 to the element x ∈X and 0 to any other element of X,
the so-called Dirac distribution on x, as δ(x). The null distribution ∅∈D(X)
assigns 0 to every element of X. The distribution D on X mapping xi to pi for every
i ∈{1,. . .,n} (and 0 to any other element of X) is indicated as {x1 : p1,· · · , xn : pn},
similarly for the expression {xi : pi}i∈I, where I is any countable index set. Given a
distribution D on X, its sum ∥D∥is simply 	
x∈X D(x).
The one-step reduction relation →is a relation between closed terms and
distributions over closed terms, i.e., a subset of CT × D(CT) The step-indexed
reduction relations are instead a family of relations {⇒n}n∈N, where each ⇒n
is a subset of CT × D(CV). As customary, we write M ⇒n D to indicate that
(M,D) ∈⇒n, and similarly for →. The rules deriving the one-step and step-indexed
reduction relations are given in Figure 4.3, and are to be interpreted inductively.
Observe that the only rule for →allowing for a distribution not in the form δ(M) in
the right-hand side is, expectedly, the one for the binary probabilistic choice M ⊕N.
Remark 4.6. A quick inspection at the rules in Figure 4.3 reveals that →and each
of the ⇒n are partial functions: for every M ∈CT and for every n ∈N, there are at
most one D ∈D(CT) such that M →D and one D ∈D(CV) such that M ⇒n D.
This can be proved formally by easy inductions on the structure of M, and on n.
The following is an easy observation, that will be useful in some of the forthcoming
sections:
Lemma 4.7. If M ⇒n D, then SUPP(D) is a ﬁnite set.
If we consider reduction of typed closed terms rather than mere terms, classic
results in the theory of λ-calculus continue to hold. On the one hand, reduction can
only get stuck at values:
Proposition 4.8 (Progress). For every M ∈CTτ, either M is a value or there is D
with M →D.
Proof
The proof is by induction on the structure of any type derivation for M,
whose conclusion has to be in the form ∅⊢M : τ.
□
On the other hand, reduction preserves typing:
Proposition 4.9 (Subject Reduction). For every M ∈CTτ and for every n ∈N, if
M →D and M ⇒n E, then D ∈D(CTτ) and E ∈D(CVτ).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

4.3 A Typed λ-Calculus with Binary Probabilistic Choice
131
Proof
The proof, as usual, consists in ﬁrst proving a Substitution Lemma, followed
by some case analysis on the rules used to derive that M →D. The generalisation
to ⇒n can be proved by an induction on n.
□
Example 4.10. By applying the rules in Figure 4.3, one easily derives that
GEO ⇒3
*
0 : 1
2
+
;
GEO ⇒8
*
1 : 1
4
+
;
GEO ⇒13
*
2 : 1
8
+
.
More generally, GEO ⇒3+5n
1
n :
1
2n+1
2
for every n, while GEO ⇒m ∅whenever m
cannot be written as 3 + 5n.
An interesting consequence of Progress and Subject Reduction is that ⇒n becomes
a total function on closed typable terms:
Corollary 4.11. For every M ∈CTτ and for every n ∈N, there is exactly one
distribution Dn such that M ⇒n Dn
The distribution Dn from Corollary 4.11 will sometimes be indicated as ⟨M⟩n.
Noticeably, not only ⟨M⟩n but also 	n
m=0⟨M⟩m is a distribution, as can be easily
proved by induction on n.
Deﬁnition 4.12 (Pointwise Order on Distributions). Given two distributions D,E ∈
D(X), we write D ≤E iﬀD(x) ≤E(x) for every x ∈X. This relation endows D(X)
with the structure of a partial order, which is actually an ωCPO: every ω-chain
{Dn}n∈N of distributions has a least upper bound, which is deﬁned pointwise:
sup{Dn}n∈N = x →sup
n∈N
Dn(x).
That this is a good deﬁnition ultimately descends from the fact that R[0,1] is itself
and ωCPO.
We are now ready to give the most important deﬁnition of this section:
Deﬁnition 4.13 (Operational Semantics of Closed Terms.). Given a closed term
M ∈CTτ, the operational semantics of M is deﬁned to be the distribution ⟨M⟩∈
D(CVτ) deﬁned as 	
n∈N⟨M⟩n = supm∈N
	m
n=0⟨M⟩n. That this is a well-posed
deﬁnition is a consequence of 	m
n=0⟨M⟩n being an ω-chain in D(CVτ).
Example 4.14. It is routine to check that
⟨GEO⟩=

n∈N
⟨GEO⟩n =
*
n :
1
2n+1
+
n∈N
.
In other words, the operational semantics of GEO is indeed the geometric distribution
on the natural numbers.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

132
Dal Lago: On Probabilistic λ-Calculi
Term Contexts
CT, DT ::= CV | [·] | CV V | V CV
| let CT = x in N
| let M = x in CT | CT ⊕DT
| if V then CT else DT
Value Contexts
CV, DV ::= λx.CT | fix x.CV
Figure 4.4 Value and Term Contexts
An easy corollary of Subject Reduction is that ⟨M⟩∈D(CVτ) whenever M ∈CTτ.
In other words, the operational semantics respects types.
4.3.3 Contextual Equivalence
Once an operational semantics is given, the next step to be taken towards building a
metatheory for PCF⊕consists in endowing it with a notion of program equivalence:
when is it reasonable to dub two programs to be equivalent, i.e., to have the same
behaviour? A ﬁrst answer to the question above consists in stipulating that equivalent
programs should behave the same when placed in any context.
Deﬁnition 4.15 (PCF⊕: Contexts). Value and term contexts are deﬁned in Figure 4.4.
Given a term context CT and a term M, the expression CT[M] stands for the term
obtained by substituting the (unique) occurrence of [·] in CT with M. Similarly for
CV[M], which is by construction a value. When we speak of a context, what we are
referring to is a term context, a concept more general than the one of a value context.
Metavariables like C or D refer to term contexts.
It is easy to generalise the type system as we presented it in Section 4.3 to a formal
system capable of deriving judgments in the form
Γ ⊢C[Δ ⊢· : τ] : ρ.
The judgment above, when provable, ensures that the ordinary type judgment
Γ ⊢C[M] : ρ is provable whenever Δ ⊢M : τ is itself derivable.
We are now ready to give the most important deﬁnition of this section.
Deﬁnition 4.16 (Contextual Equivalence). Given two terms M, N such that Γ ⊢M :
τ and Γ ⊢N : τ, we say that M and N are (Γ,τ)-equivalent, and we write M ≡τ
Γ N
iﬀwhenever ∅⊢C[Γ ⊢· : τ] : Unit, it holds that ∥⟨C[M]⟩∥= ∥⟨C[N]⟩∥.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

4.3 A Typed λ-Calculus with Binary Probabilistic Choice
133
The way we have deﬁned contextual equivalence turns it into a typed relation,
i.e. a family {Rτ
Γ}Γ,τ of relations such that MRτ
ΓN implies Γ ⊢M : τ and Γ ⊢N : τ.
We say that any typed relation {Rτ
Γ}Γ,τ is:
• A congruence iﬀeach Rτ
Γ is an equivalence and whenever MRτ
ΓN and Δ ⊢C[Γ ⊢
· : τ] : ρ, it holds that C[M]Rρ
ΔC[N].
• Adequate iﬀwhenever MRτ
ΓN and ∅⊢C[Γ ⊢· : τ] : Unit, it holds that
∥⟨C[M]⟩∥= ∥⟨C[N]⟩∥.
In fact contextual equivalence is an adequate congruence, and is the largest such
typed relation, as witnessed by the following result, whose proof is easy, and
whose deterministic counterpart has been known since the inception of contextual
equivalence (Morris, 1969):
Proposition 4.17. Contextual equivalence is the largest adequate congruence.
Contextual equivalence is thus a very satisfactory notion of program equivalence.
This does not mean, however, that proving pairs of terms to be contextually equivalent
is easy: the universal quantiﬁcation over all contexts Deﬁnition 4.16 relies on makes
concrete proofs of equivalence hard. This has stimulated many investigations on
alternative notions of equivalence, not only in presence of probabilistic choice, but
also in the realm of usual, deterministic λ-calculi.
4.3.4 On the Expressive Power of PCFN
⊕
It is well-known that the class of partial functions on the natural numbers Plotkin's
PCF can represent is precisely the class of partial recursive functions (see (Longley
and Normann, 2015) for a proof). But how about PCF⊕? First of all, is there any
analogue to the class of partial recursive functions if the underlying computation
model is probabilistic rather than deterministic?
There are two essentially diﬀerent ways in which one can answer the question
above. The ﬁrst one consists in seeing any probabilistic computational model (e.g.
probabilistic Turing machines (De Leeuw et al., 1956; Santos, 1969) as a device
meant to solve ordinary computational problems seen as functions or languages. If
one proceeds this way, one soon realises that, under mild conditions, any probabilistic
computational model only decides partial recursive functions, capturing all of them
when the underlying deterministic machinery is suﬃciently powerful (Santos, 1969).
Another route consists in looking at probabilistic computational models as devices
computing functions from the natural numbers to distributions of natural numbers,
called a probabilistic function. This is the route followed by the author in his work
with Gabbrielli and Zuppiroli (Dal Lago et al., 2014b), in which a variation on
Kleene's function algebra is proved to capture probabilistic computable functions,
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

134
Dal Lago: On Probabilistic λ-Calculi
namely those probabilistic functions which can be represented by probabilistic
Turing machines. In the rest of this Section, we give an overview of this result, only
taking the deﬁnition of a probabilistic Turing machine for granted.
Let us start by deﬁning probabilistic functions and their computability:
Deﬁnition 4.18 (Computable Probabilistic Functions). Any function f : N →D(N)
is said to be a probabilistic function. Such a probabilistic function f is said to be
Turing-computable (or just computable) iﬀthere is a probabilistic Turing machine
M which, when fed with the encoding of n ∈N terminates producing in output an
encoding of m ∈N with probability f (n)(m).
A quite similar deﬁnition can be obtained by replacing Turing machines with
PCF⊕:
Deﬁnition 4.19. Let M be a PCFN
⊕closed term of type Num →Num. Then M
is said to compute a probabilistic function f : N →D(N) if and only if for every
n ∈N, it holds that ⟨M n⟩= f (n). Such a probabilistic function f is in this case
said to be computable by PCFN
⊕.
One may wonder how endowing either Turing machines or PCF with an operation
for probabilistic choice aﬀects the underlying expressive power. In fact, the obtained
computational models remain equivalent:
Theorem 4.20. The class of computable probabilistic functions coincides with the
class of probabilistic functions computable by PCFN
⊕.
Proof
Proving that probabilistic functions computable by PCFN
⊕are also Turing
computable is straightforward, since the operational semantics of PCFN
⊕is eﬀective,
thus implementable by a Turing machine. The converse implication can be easily
proved via the already mentioned characterisation of probabilistic computable
functions via a slight variation of Kleene partial recursive functions (Dal Lago et al.,
2014b), namely one in which a basic function modelling probabilistic choice is
present.
□
4.3.5 Termination in PCF⊕
As we mentioned in the Introduction, techniques ensuring termination of probabilistic
programs have already been investigated, and at least two distinct notions of
termination for probabilistic programs have been introduced, namely almost sure
termination, and its strengthening positive almost sure termination. Let us ﬁrst of all
see how these notions can be formalised in our setting.
Deﬁnition 4.21 (Almost Sure Termination). Let M be any closed term. We say
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

4.3 A Typed λ-Calculus with Binary Probabilistic Choice
135
that M is almost surely terminating if ∥⟨M⟩∥= 1, namely if its probability of
convergence is 1.
Example 4.22. An example of an almost surely terminating term is certainly GEO
from Example 4.4. Not all PCFN
⊕terms are almost surely terminating, however. As an
example, the term M = (fix f . f ) 0 is clearly not terminating because M →δ(M),
and as a consequence ⟨M⟩n = ∅for every natural number n. There are subtler
examples, like the following variation on GEO:
TWICE := (fix f .λx.x ⊕(let succ1(x) = y in f ( f y))) 0.
Please observe how the only diﬀerence between GEO and TWICE lies in the presence
of two nested recursive calls to f (instead of one) in the right-hand-side of the
probabilistic choice operator. The reader is invited to derive a value for ∥⟨TWICE⟩∥
as an exercise.
There is nothing in the deﬁnition of an almost surely terminating term which
ensures the term's expected number of reduction steps to be ﬁnite. Enforcing it
requires an additional, further, constraint. But before introducing it, let us ﬁrst
deﬁne the expected reduction length of any closed term M. As already mentioned in
Section 4.2, a convenient way to deﬁne it is as
∞

m=0
Pr(T > m),
where T is the random variable counting the number of steps M requires to be
reduced to a value. Now, how can we deﬁne Pr(T > m) in terms of the operational
semantics of M? Actually, an easy way to do it is to observe that Pr(T > m) is
1 −	m
n=0 ∥⟨M⟩n∥: the quantity 	m
n=0 ∥⟨M⟩n∥precisely captures the probability for
M to reduce to a value in at most m reduction steps. As a consequence, the average
number of reduction steps ExLen(M) for M is deﬁned as follows:
ExLen(M) :=
∞

m=0

1 −
m

n=0
∥⟨M⟩n∥

.
Deﬁnition 4.23 (Positive Almost Sure Termination). Let M be any closed term. We
say that M is positively almost surely terminating if ExLen(M) < +∞.
The following is easy to prove, and is a standard result in the theory of Markov
chains and processes:
Lemma 4.24. Every positively almost-surely terminating term is almost-surely
terminating.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

136
Dal Lago: On Probabilistic λ-Calculi
Proof
A necessary condition for ExLen(M) to be ﬁnite is that
lim
m→+∞
m

n=0
∥⟨M⟩n∥=
lim
m→+∞
33333
m

n=0
⟨M⟩n
33333 = 1,
which can hold only if ∥⟨M⟩∥= 1, namely only if M is almost surely terminating.
□
The converse implication does not hold however, as witnessed by the following
example.
Example 4.25. Consider the following PCFN
⊕term:
RW := (fix f .λx.if gt2(x,0) then (N⇑⊕N⇓) else 0)1,
where
N⇑:= let succ1(x) = y in f y
N⇓:= let pred1(x) = y in f y
The recursive function on which the term is based ﬁrst tests whether the argument x
(of type Num) is positive, and in case it is, makes a recursive call with argument
either decreased or increased by 1, each with equal probability 1
2. The term RW,
then, can be seen as modelling an unbounded, fair, random walk. As such it is well
known to be almost surely terminating, but not positively: the average number of
steps which are necessary to reach the base case is inﬁnite.
Is there any reasonable way to restrict, e.g., PCFN
⊕in such a way as to enforce
almost-sure termination? The answer is positive. As an example:
• Removing ﬁxpoints from the class of terms, replacing them with primitive
recursion, namely with a combinator rec having type
(Num →τ →τ) →τ →Num →τ
turns the calculus into a probabilistic variation on Gödel's T, that we call T⊕.
Terms of the calculus are not only positively almost-surely terminating, but satisfy
an even stronger constraint: there is a global, uniform, bound on the length of any
probabilistic branch, i.e., for every M ∈CTτ there is n ∈N such that ⟨M⟩m = ∅
for every m ≥n. By Lemma 4.7, we can conclude that SUPP(⟨M⟩) is ﬁnite, i.e.
that T⊕is an essentially ﬁnitary calculus. Notice that such a uniform bound cannot
be found for terms like GEO which, although being almost surely terminating,
can possibly diverge (of course with null probability).
• T⊕can be made inﬁnitary by endowing it with a primitive geo behaving exactly
as GEO, and having type Num. Remarkably, this apparently innocuous change
has the eﬀect of making the calculus almost surely terminating, but not positively
so.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

4.3 A Typed λ-Calculus with Binary Probabilistic Choice
137
4.3.6 Further Reading
In the previous sections, a brief introduction to randomised λ-calculi has been given.
This Section is meant to be a repository of pointers to the literature about this class
of idioms, without any hope of being comprehensive.
We have speciﬁed the operational semantics of PCF⊕in small-step style, and
by way of an inductively deﬁned set of rules. This is not, however, the only
option. Indeed, one could certainly go big-step, but also interpret reduction rules
coinductively (Dal Lago and Zorzi, 2012). Another choice we have implicitly
made when introducing PCF⊕is to consider call-by-value rather than call-by-name
evaluation. This, again, does not mean that the latter is a route which cannot be
followed (Dal Lago and Zorzi, 2012; Danos and Ehrhard, 2011). What makes
call-by-value more appealing is the possibility of "implicitly memoizing" the result
of probabilistic choices by way of sequencing, something which is not available in
call-by-name. Consider, as an example, a term M in which some probabilistic choice
(λx.N) ⊕(λx.L) occurs. In call-by-value evaluation, this occurrence can be copied
unevaluated, and once one copy of it is indeed evaluated (i.e. when it becomes the
argument of a let), the outcome of the probabilistic choice can itself be copied. In
call-by-name, at least if sequencing is not available, this is simply impossible: once (a
copy of) a subterm is evaluated, the result of its evaluation cannot be spread around
the term by way of copying. This, by the way, is the source of some discrepancies
between the nature of contextual equivalence in call-by-name and call-by-value
evaluation, which shows up when probabilistic choice is available (Crubillé and
Dal Lago, 2014).
Contextual equivalence, as we have introduced it, is a very satisfactory deﬁni-
tion of equivalence for probabilistic programs, being the largest compatible and
adequate (equivalence) relation. Contextual equivalence relying on a universal
quantiﬁcation over all contexts, however, makes concrete proofs of equivalence quite
hard. Alternative methodologies have been introduced for the purpose of making
proofs of equivalence easier in a probabilistic setting, following the extended body
of work about the same problem in the deterministic setting (e.g. (Plotkin, 1973;
Abramsky, 1990; Mitchell, 1996)). For example, step-indexed logical relations have
been adapted to an higher-order probabilistic λ-calculus, and proved not only sound
for contextual equivalence, but also complete (Bizjak and Birkedal, 2015). As an
another example, Abramsky's applicative bisimilarity has been itself generalised
to randomised λ-calculi (Dal Lago et al., 2014a; Crubillé and Dal Lago, 2014)
and proved fully-abstract, the latter holding only when call-by-value evaluation is
considered. Finally, a variation on the notion of Böhm tree (Barendregt, 1984) has
been recently deﬁned for an untyped, randomised λ-calculus (Leventis, 2018); quite
interestingly, the classic separability result continues to hold.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

138
Dal Lago: On Probabilistic λ-Calculi
Another way of proving terms to be equivalent consists in comparing their mean-
ings in any adequate model, along the lines of so-called denotational semantics.
Following this path has proved remarkably hard in randomised λ-calculi. In particu-
lar, coming up with a completely satisfactory notion of probabilistic powerdomain,
this way modelling probabilistic choice in monadic style has proved to be impossi-
ble (Jones and Plotkin, 1989; Jung and Tix, 1998). On the other hand, interpreting
PCF⊕by denotational models in the style of coherence spaces (Danos and Ehrhard,
2011) is indeed possible, and also leads to full abstraction results (Ehrhard et al.,
2014). Very recently, another way of giving semantics to randomised λ-calculi and
based on Boolean-Valued models has been proposed (Bacci et al., 2018).
The two notions of termination for probabilistic programs we introduced and
discussed in this section have been studied in depth in the context of imperative pro-
gramming languages (McIver and Morgan, 2005), and have been proved to be strictly
more diﬃcult than their deterministic counterparts, recursion-theoretically (Kamin-
ski and Katoen, 2015). Various techniques for proving imperative programs to be
terminating have been introduced, based on the notion of ranking martingale or
Lyapunov function, the natural probabilistic analogues of the so-called ranking
function (Bournez and Garnier, 2005). While the same technique has been shown to
be applicable to term rewrite systems recently (Avanzini et al., 2018), not much is
known about its applicability to higher-order functional programs. Up to now, the
only works in this directions are based on type systems, and in particular on variations
on either sized-types (Dal Lago and Grellois, 2017) or intersection types (Breuvart
and Dal Lago, 2018).
4.4 Sampling and Conditioning
In randomised λ-calculi, only one form of probabilistic choice is available, which most
often has a discrete nature. As we argued in the last section, this is perfectly adequate
to model randomised computation. In recent years, starting from the pioneering works
on languages like CHURCH and ANGLICAN, functional programming languages
have also been employed as vehicles for the representation of probabilistic models
rather than algorithms. This amounts to a diﬀerent execution model, in which
inference takes the place of evaluation.
In this Section, we give some hints about how this style of programming can be
modelled in an extension of PCF⊕, that we call PCFsample,score. The latter calculus
can be derived from the former by:
• Replacing binary probabilistic choice with an operator sample which, when
evaluated, samples a real number in [0,1] uniformly at random. This implies,
in particular, that the underlying monoid M needs to include [0,1], and is often
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

4.4 Sampling and Conditioning
139
Terms
M, N ::= sample | score(V).
Typing Rules
Γ ⊢sample : Num A
Γ ⊢V : Num
Γ ⊢score(V) : Unit C
Figure 4.5 Grammar and Typing Rules for sample and score.
taken as the additive monoid of real numbers. The type of the new term sample
is Num.
• Endowing the class of terms with another operator, called score, which takes
a positive real number r as a parameter, and modiﬁes the weight of the current
probabilistic branch by multiplying it byr. This serves as a way to take observations
into account, by conditioning on them. The type of score is Unit, while its
argument must of course have type Num.
Formally, the language of terms and the typing rules are extended as shown in
Figure 4.5. From a purely syntactical point of view, then, formally deﬁning Bayesian
λ-calculi poses absolutely no problem.
What is nontrivial, however, is to give a meaning to those calculi, even in the
form of an operational semantics. As already mentioned, terms are not meant to
model algorithms but probabilistic models, on which inference is supposed to
take place. This can be dealt with by deﬁning a sampling operational semantics,
following (Borgström et al., 2016), or by a distribution semantics which, however,
requires some nontrivial measure theory. We will deal with them in the following
section.
4.4.1 Operational Semantics
How could we give an operational semantics to PCFsample,score? As we already
mentioned, there are at least two answers to this questions, which lead to formal
systems which are related, although having distinct properties.
One may ﬁrst of all wonder whether the distribution semantics we introduced for
PCF⊕could be adapted to PCFsample,score. In fact this can be done, at the price of
making the whole development nontrivial, due to the underlying measure theory. To
understand why this is the case, let us consider how the evaluation rule for sample
would look like. At the right-hand-side of it, what we expect is a distribution D on R.
The latter's support, however, is R[0,1], and is thus not countable. As a consequence,
one needs to switch to measures in the sense of measure theory, and assume the
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

140
Dal Lago: On Probabilistic λ-Calculi
underlying set, namely R to have the structure of a measurable space. Adapting the
rule for let-terms naturally leads to
M →μ
let M = x in N →let μ = x in N
where let μ = x in N should itself be a measure, meaning that not only real
numbers, but also terms should be endowed with the structure of a measurable
space. Finally, the last rule in step-indexed reduction needs to be adapted itself, the
summation in its conclusion to be replaced by an integral:
M →μ
∀N ∈SUPP(μ).N ⇒n σN
M ⇒n+1 A →
∫
σN(A)μ(dN)
For the integral above to be well deﬁned, the underlying function must be measurable.
It turns out that the appropriate invariant is even stronger: each ⇒n+1 can be seen
as ﬁnite kernel, and the operational semantics of M thus becomes an s-ﬁnite
kernel (Staton, 2017).
Measure-theoretic distribution semantics, however, is not the only way a calculus
like PCFsample,score can be given a meaning. An alternative consists of going for the
so-called sampling-based semantics, in which the process of sampling and scoring
are made explicit.
Deﬁnition 4.26 (Trace). A trace is a possibly empty ﬁnite sequence of elements
from R[0,1] and is indicated with metavariables like s,t. The trace whose ﬁrst element
is r ∈R[0,1], and whose other elements form a trace t is indicated as r :: t. The set
of all traces is X.
In sampling-based semantics, one-step reduction and multi-step reduction are
both subsets of (CT × X) × R+ × (CT × X), i.e. ternary rather than binary relations.
They are indicated as ↠and ⇛, respectively. We write ⟨M, s⟩
r↠⟨N,t⟩for
((M, s),r,(N,t)) ∈↠. Similarly for ⟨M, s⟩
r
⇛⟨N,t⟩. Rules for small-step sampling
semantics can be found in Figure 4.6. Observe that if ⟨M, s⟩
r↠⟨N,t⟩and r  1,
then the redex ﬁred in M must be of the form score(r).
The two kinds of semantics can be proved equivalent, in the following sense: for
every measurable set of real numbers A, the total probability of observing A when
evaluating ∅⊢M : Num in sampling-based and distribution-based are the same (see,
e.g., (Borgström et al., 2016) for some more details).
4.4.2 Further Reading
The study of Bayesian λ-calculi is in its infancy , and the underlying metatheory,
despite some breakthrough advances in the last ten years, is still underdeveloped
compared to the one of randomised λ-calculi.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

4.4 Sampling and Conditioning
141
One-Step Reduction
⟨(λx.M)V, s⟩
1↠⟨M[V/x], s⟩
⟨let V = x in M, s⟩
1↠⟨M[V/x], s⟩
⟨if 0 then M else N, s⟩
1↠⟨M, s⟩
⟨if r then M else N, s⟩
1↠⟨N, s⟩if r  0
⟨sample,r :: s⟩
1↠⟨r, s⟩
⟨score(r), s⟩
r↠⟨⋆, s⟩
⟨f (r1,· · · ,rn), s⟩
1↠⟨f ∗(r1 . . .,rn), s⟩
⟨M, s⟩
r↠⟨L,t⟩
⟨let M = x in N, s⟩
r↠⟨let L = x in N, s⟩
Multi-Step Reduction
⟨V, s⟩
1
⇛⟨V, s⟩
⟨M, s⟩
r↠⟨N,t⟩
⟨N,t⟩
s
⇛⟨L,u⟩
⟨M, s⟩
r ·s
⇛⟨L,u⟩
Figure 4.6 Small-Step Sampling Semantics
Calculi in which continuous distributions and sampling from them are available
were introduced by Ramsey and Pfeﬀer (Ramsey and Pfeﬀer, 2002) and Park,
Pfenning, and Thrun (Park et al., 2005). The ﬁrst example of a λ-calculus in
which these two features are both present is due to the author, together with
Börgstrom, Gordon, and Szymczak (Borgström et al., 2016), who introduced trace
and distribution semantics for an untyped bayesian λ-calculus with primitives
for sampling and scoring, together with trace and distribution semantics, both in
small-step and big-step styles.
Contextual equivalence and logical relations for a typed λ-calculus with sampling
and scoring were introduced in Culpepper and Cobb (2017), and adapted to a
calculus with full higher-order recursion in Wand et al. (2018).
Giving a satisfactory denotational semantics for bayesian λ-calculi has been
proved to be quite challenging. Quasi-borel spaces (Heunen et al., 2017) provide
both a closed structure and the machinery necessary to model sampling and
conditioning, something which is provably impossible in the category of measurable
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

142
References
spaces. Subsequently, quasi-borel spaces have also been shown to give rise to a
category of domains, thus accounting for the presence of recursion in the underlying
calculus (Vákár et al., 2019). Generalising probabilistic coherent spaces (Danos and
Ehrhard, 2011) to a calculus allowing sampling from continuous distributions has
proved to be possible, but highly nontrivial (Ehrhard et al., 2018). At the time of
writing, it is not clear whether all this scales to a calculus in which a general form of
conditioning (as embodied by the score operator) is available.
References
Abramsky, Samson. 1990. The lazy lambda calculus. Pages 65-117 of: Turner, D.
(ed), Research Topics in Functional Programming. Addison Wesley.
Avanzini, Martin, Lago, Ugo Dal, and Yamada, Akihisa. 2018. On probabilistic
term rewriting. Pages 132-148 of: Proc. of FLOPS 2018.
Bacci, Giorgio, Furber, Robert, Kozen, Dexter, Mardare, Radu, Panangaden, Prakash,
and Scott, Dana. 2018. Boolean-valued semantics for the stochastic λ-calculus.
Pages 669-678 of: Proc. of LICS 2018.
Barendregt, Henk P. 1984. The Lambda Calculus, Its Syntax and Semantics. Elsevier.
Bizjak, Ales, and Birkedal, Lars. 2015. Step-indexed logical relations for probability.
Pages 279-294 of: Proc. of FoSSaCS 2015.
Borgström, Johannes, Dal Lago, Ugo, Gordon, Andrew D., and Szymczak, Marcin.
2016. A lambda-calculus foundation for universal probabilistic programming.
Pages 33-46 of: Proc. of ICFP 2016.
Bournez, Olivier, and Garnier, Florent. 2005. Proving positive almost-sure termina-
tion. Pages 323-337 of: Proc. of RTA 2005.
Breuvart, Flavien, and Dal Lago, Ugo. 2018. On intersection types and probabilistic
lambda calculi. Pages 8:1-8:13 of: Proc. of PPDP 2018.
Crubillé, Raphaëlle, and Dal Lago, Ugo. 2014.
On Probabilistic applicative
bisimulation and call-by-value λ-calculi. Pages 209-228 of: Proc. of ESOP
2014.
Culpepper, Ryan, and Cobb, Andrew. 2017. Contextual equivalence for probabilistic
programs with continuous random variables and scoring. Pages 368-392 of:
Proc. of ESOP 2017.
Dal Lago, Ugo, and Grellois, Charles. 2017. Probabilistic termination by monadic
aﬃne sized typing. Pages 393-419 of: Proc. of ESOP 2017.
Dal Lago, Ugo, and Zorzi, Margherita. 2012. Probabilistic operational semantics
for the lambda calculus. RAIRO - Theor. Inf. and Applic., 46(3), 413-450.
Dal Lago, Ugo, Sangiorgi, Davide, and Alberti, Michele. 2014a. On coinductive
equivalences for higher-order probabilistic functional programs. Pages 297-308
of: Proc. of POPL 2014.
Dal Lago, Ugo, Zuppiroli, Sara, and Gabbrielli, Maurizio. 2014b. Probabilistic
recursion theory and implicit computational complexity. Sci. Ann. Comp. Sci.,
24(2), 177-216.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
143
Danos, Vincent, and Ehrhard, Thomas. 2011. Probabilistic coherence spaces as
a model of higher-order probabilistic computation. Inf. Comput., 209(6),
966-991.
Danos, Vincent, and Harmer, Russell. 2002. Probabilistic game semantics. ACM
Trans. Comput. Log., 3(3), 359-382.
De Leeuw, Karel, Moore, Edward F, Shannon, Claude E, and Shapiro, Norman. 1956.
Computability by probabilistic machines. Automata Studies, 34, 183-198.
Ehrhard, Thomas, Pagani, Michele, and Tasson, Christine. 2011. The computational
meaning of probabilistic coherence spaces. Pages 87-96 of: Proc. of LICS
2011.
Ehrhard, Thomas, Pagani, Michele, and Tasson, Christine. 2014. Probabilistic
coherence spaces are fully abstract for probabilistic PCF. Pages 309-320 of:
Proc. of POPL 2014.
Ehrhard, Thomas, Pagani, Michele, and Tasson, Christine. 2018. Measurable
cones and stable, measurable functions: a model for probabilistic higher-order
programming. Pages 59:1-59:28 of: Proc. of POPL 2018.
Goodman, Noah D., Mansinghka, Vikash K., Roy, Daniel M., Bonawitz, Keith, and
Tenenbaum, Joshua B. 2008. Church: a language for generative models. Pages
220-229 of: Proc. of UAI 2008.
Heunen, Chris, Kammar, Ohad, Staton, Sam, and Yang, Hongseok. 2017. A
convenient category for higher-order probability theory. Pages 1-12 of: Proc.
of LICS 2017.
Hindley, J. Roger, and Seldin, Jonathan P. 2008. Lambda-Calculus and Combinators:
An Introduction. 2 edn. Cambridge University Press.
Jones, Claire, and Plotkin, Gordon D. 1989. A probabilistic powerdomain of
evaluations. Pages 186-195 of: Proc. of LICS 1989.
Jung, Achim, and Tix, Regina. 1998. The troublesome probabilistic powerdomain.
Electr. Notes Theor. Comput. Sci., 13, 70-91.
Kaminski, Benjamin Lucien, and Katoen, Joost-Pieter. 2015. On the Hardness of
Almost-Sure Termination. Pages 307-318 of: Proc. of MFCS 2015.
Koller, Daphne, and Friedman, Nir. 2009. Probabilistic Graphical Models: Principles
and Techniques - Adaptive Computation and Machine Learning. The MIT
Press.
Kozen, Dexter. 1981. Semantics of Probabilistic Programs. J. Comput. Syst. Sci.,
22(3), 328-350.
Leventis, Thomas. 2018. Probabilistic Böhm Trees and Probabilistic Separation.
Pages 649-658 of: Proc. of LICS 2018.
Longley, John, and Normann, Dag. 2015. Higher-order Computability. Theory and
Applications of Computability. Springer.
Manning, Christopher D, and Schütze, Hinrich. 1999. Foundations of Statistical
Natural Language Processing. Vol. 999. MIT Press.
McIver, Annabelle, and Morgan, Carroll. 2005. Abstraction, Reﬁnement and Proof
for Probabilistic Systems. Monographs in Computer Science. Springer.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

144
References
Mitchell, John C. 1996. Foundations of Programming Languages. Cambridge, MA,
USA: MIT Press.
Morris, James. 1969.
Lambda Calculus Models of Programming Languages.
Ph.D. thesis, Massachusetts Institute of Technology, Alfred P. Sloan School of
Management.
Motwani, Rajeev, and Raghavan, Prabhakar. 1995. Randomized Algorithms. Cam-
bridge University Press.
Park, Sungwoo, Pfenning, Frank, and Thrun, Sebastian. 2005. A probabilistic
language based upon sampling functions. Pages 171-182 of: Proc. of POPL
2005. ACM.
Pearl, Judea. 1988. Probabilistic Reasoning in Intelligent Systems: Networks of
Plausible Inference. Morgan Kaufmann.
Plotkin, Gordon. 1973. Lambda-deﬁnability and logical relations. Tech. rept.
SAI-RM-4. University of Edinburgh.
Prince, Simon J. D. 2012. Computer Vision: Models, Learning, and Inference. New
York, NY, USA: Cambridge University Press.
Ramsey, Norman, and Pfeﬀer, Avi. 2002. Stochastic lambda calculus and monads of
probability distributions. Pages 154-165 of: Proc. of POPL 2002. ACM.
Saheb-Djaromi, N. 1978. Probabilistic LCF. Pages 442-451 of: Proc. of MFCS
1978.
Santos, Eugene S. 1969. Probabilistic Turing machines and computability. Proceed-
ings of the American Mathematical Society, 22(3), 704-710.
Sørensen, Morten Heine, and Urzyczyn, Pawel. 2006. Lectures on the Curry-Howard
Isomorphism,. New York, NY, USA: Elsevier Science Inc.
Statman, Richard. 1979. The typed lambda-calculus is not elementary recursive.
Theor. Comput. Sci., 9, 73-81.
Staton, Sam. 2017. Commutative semantics for probabilistic programming. Pages
855-879 of: Proc. of ESOP 2017.
Tolpin, David, van de Meent, Jan-Willem, and Wood, Frank D. 2015. Probabilistic
programming in Anglican. Pages 308-311 of: Proc. of ECML PKDD 2015,
Part III.
Vákár, Matthijs, Kammar, Ohad, and Staton, Sam. 2019. A domain theory for
statistical probabilistic programming. Pages 36:1-36:29 of: Proc. of POPL
2019.
Wand, Mitchell, Culpepper, Ryan, Giannakopoulos, Theophilos, and Cobb, Andrew.
2018. Contextual equivalence for a probabilistic language with continuous
random variables and recursion, arXiv https://arxiv.org/abs/1807.
02809.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

5
Probabilistic Couplings from Program Logics
Gilles Barthe
MPI For Security and Privacy, Bochum & IMDEA Software Institute, Madrid
Justin Hsu
University of Wisconsin-Madison
Abstract: Proof by coupling is a powerful technique for proving properties about
pairs of probabilistic processes. Originally developed by probability theorists, this
proof technique has recently found surprising applications in formal veriﬁcation,
enabling clean proofs of probabilistic relational properties. We show that the
probabilistic program logic pRHL is a formal logic for proofs by coupling, with
logical proof rules capturing reasoning steps in traditional coupling proofs. This
connection gives a new method to formally verify probabilistic properties.
5.1 Introduction
Formal veriﬁcation of probabilistic programs is an active area of research which aims
to reason about safety and liveness properties of probabilistic computations. Many
important properties for probabilistic programs are naturally expressed in terms of
two program executions; for this reason, such properties are called relational. While
there exist established approaches to verify relational properties of deterministic
programs, reasoning about relational properties of probabilistic programs is more
challenging. In this chapter we explore a powerful method called proof by coupling.
This technique—originally developed in probability theory for analyzing Markov
Chains—is surprisingly useful for establishing a broad range of relational properties,
including:
• probabilistic equivalence (also diﬀerential privacy): two programs produce
distributions that are equivalent or suitably close from an observer's point of view.
For instance, diﬀerential privacy requires that two similar inputs—say, the private
database and a hypothetical version with one individual's data omitted—yield
closely related output distributions;
a From Foundations of Probabilistic Programming, edited by Gilles Barthe, Joost-Pieter Katoen and Alexandra
Silva published 2020 by Cambridge University Press.
145
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

146
Barthe and Hsu: Probabilistic Couplings from Program Logics
• stochastic domination: one probabilistic program is more likely than another to
produce large outputs;
• convergence (also mixing): the output distributions of two probabilistic loops
approach each other as the loops execute more iterations;
• truthfulness (also Nash equilibrium): an agent's average utility is larger when
reporting an honest value instead of deviating to a misleading value.
At ﬁrst glance, relational properties appear to be even harder to establish than
standard, non-relational properties—instead of analyzing a single probabilistic
computation, we now need to deal with two. (Indeed, any property of a single
program can be viewed as a relational property between the target program and the
trivial, do-nothing program.) However, relational properties often relate two highly
similar programs, even comparing the same program on two diﬀerent inputs. In these
cases, we can leverage a powerful abstraction and an associated proof technique
from probability theory—probabilistic coupling and proof by coupling.
The fundamental observation is that probabilistic relational properties compare
computations in two diﬀerent worlds, assuming no particular correlation between
random samples. Accordingly, we may freely assume any correlation we like for
the purposes of the proof—a relational property holds (or does not hold) regardless
of which one we pick. For instance, if two programs generate identical output
distributions, this holds whether they share coin ﬂips or take independent samples;
relational properties do not require that the two programs use separate randomness.
By carefully arranging the correlation, we can reason about two executions as if they
were linked in some convenient way.
To take advantage of this freedom, we need some way to design speciﬁc correlations
between program executions. In principle, this can be a highly challenging task. The
two runs may take samples from diﬀerent distributions, and it is unclear exactly how
they can or should share randomness. When the two programs have similar shapes,
however, we can link two computations in a step-by-step fashion. First, correlations
between intermediate samples can be described by probabilistic couplings, joint
distributions over pairs. For example, a valid coupling of two fair coin ﬂips could
specify that the draws take opposite values; the correlated distribution would produce
"(heads, tails)" and "(tails, heads)" with equal probability. A coupling formalizes
what it means to share randomness: a single source of randomness simulates draws
from two distributions. Since randomness can be shared in diﬀerent ways, two
distributions typically support a variety of distinct couplings.
A proof by coupling, then, describes two correlated executions by piecing together
couplings for corresponding pairs of sampling instructions. In the course of a proof,
we can imagine stepping through the two programs in parallel, selecting couplings
along the way. For instance, if we apply the opposite coupling to link a coin ﬂip in one
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

5.1 Introduction
147
program with a coin ﬂip in the other, we may assume the samples remain opposite
when analyzing the rest of the programs. By ﬂowing these relations forward from
two initial inputs, a proof by coupling can focus on just pairs of similar executions
as it builds up to a coupling between two output distributions. This is the main
product of the proof: features of the ﬁnal coupling imply properties about the output
distributions, and hence relational properties about the original programs.
Working in tandem, couplings and proofs by couplings can signiﬁcantly simplify
probabilistic reasoning in several ways.
• Reduce to one source of randomness. By analyzing two runs as if they shared
a single source of randomness, we can reason about two programs as if they were
one.
• Abstract away probabilities. Proofs by coupling isolate probabilistic reasoning
from the non-probabilistic parts of the proof, which are more straightforward. We
only need to think about probabilistic aspects when we select couplings at the
sampling instructions; throughout the rest of the programs, we can reason purely
in terms of deterministic relations between the two runs.
• Enable compositional, structured reasoning. By focusing on each step of an
algorithm individually and then smoothly combining the results, the coupling
proof technique enables a highly modular style of reasoning guided by the code
of the program.
Proofs by coupling are also surprisingly ﬂexible—many probabilistic relational
properties, including the examples listed above, can be proved in this style. Individual
couplings can also be combined in subtle ways, giving rise to a rich diversity of
coupling proofs.
After reviewing probability theory basics (Section 5.2), we introduce probabilistic
couplings and their key properties (Section 5.3). Then, we present intuition behind
proof by coupling (Section 5.4). To formalize these arguments, we draw a connection
to the program logic pRHL (Barthe et al., 2009). Proofs in the pRHL are formal
proofs by coupling: valid judgments imply the existence of a coupling, and logical
rules describing how to combine couplings to construct new couplings (Section 5.5).
We demonstrate several examples of coupling proofs in the logic (Section 5.6), and
conclude by brieﬂy discussing related lines of work (Section 5.7).
Bibliographic note. This chapter is an updated and expanded version of the ﬁrst
two chapters of the second author's PhD thesis (Hsu, 2017).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

148
Barthe and Hsu: Probabilistic Couplings from Program Logics
5.2 Preliminaries
A discrete probability distribution associates each element of a set with a number
in the unit interval [0,1], representing its probability. In order to model programs
that may not terminate, we work with a slightly more general notion called a
sub-distribution.
Deﬁnition 5.1
A (discrete) sub-distribution over a countable set A is a map
μ : A →[0,1] taking each element of A to a numeric weight such that the weights
sum to at most 1:

a∈A
μ(a) ≤1.
We write SDistr(A) for the set of all sub-distributions over A. When the weights
sum to 1, we call μ a proper distribution; we write Distr(A) for the set of all proper
distributions over A. The empty or null sub-distribution ⊥assigns weight 0 to all
elements.
We work with discrete sub-distributions throughout. While this is certainly a
restriction—excluding, for instance, some well-known distributions over the real
numbers—many interesting coupling proofs can already be expressed in our setting.
Our results should mostly carry over to the continuous setting, as couplings are
frequently used on continuous distributions in probability theory, but the general
case introduces measure-theoretic technicalities (e.g., working with integrals rather
than sums, checking sets are measurable, etc.) that would distract from our primary
focus.
We need several concepts and notations related to discrete distributions. First, the
probability of a set S ⊆A is given by a sum:
μ(S) ≜

a∈S
μ(a).
The support of a sub-distribution is the set of elements with positive probability:
supp(μ) ≜{a ∈A | μ(a) > 0}.
The weight of a sub-distribution is the total probability of all elements:
|μ| ≜

a∈A
μ(a).
Finally, the expected value of a real-valued function f : A →R over a sub-
distribution μ is
E
μ[ f ] ≜E
a∼μ[ f (a)] ≜

a∈A
f (a) · μ(a).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

5.3 Couplings and liftings: deﬁnitions and basic properties
149
Under light assumptions, the expected value is guaranteed to exist (for instance,
when f is a bounded function).
To transform sub-distributions, we can lift a function f : A →B on sets to
a map f ♯: SDistr(A) →SDistr(B) via f ♯(μ)(b) ≜μ( f −1(b)). For example, let
p1 : A1 × A2 →A1 and p2 : A1 × A2 →A2 be the ﬁrst and second projections
from a pair. The corresponding probabilistic projections π1 : SDistr(A1 × A2) →
SDistr(A1) and π2 : SDistr(A1 × A2) →SDistr(A2) are deﬁned by
π1(μ)(a1) ≜p♯
1(μ)(a1) =

a2∈A2
μ(a1,a2)
π2(μ)(a2) ≜p♯
2(μ)(a2) =

a1∈A1
μ(a1,a2).
We call a sub-distribution μ over pairs a joint sub-distribution, and the projected
sub-distributions π1(μ) and π2(μ) the ﬁrst and second marginals, respectively.
5.3 Couplings and liftings: deﬁnitions and basic properties
A probabilistic coupling models two distributions with a single joint distribution.
Deﬁnition 5.2
Given μ1, μ2 sub-distributions over A1 and A2, a sub-distribution
μ over pairs A1 × A2 is a coupling for (μ1, μ2) if π1(μ) = μ1 and π2(μ) = μ2.
Generally, couplings are not unique—diﬀerent witnesses represent diﬀerent ways
to share randomness between two distributions. To give a few examples, we ﬁrst
introduce some standard distributions.
Deﬁnition 5.3
Let A be a ﬁnite, non-empty set. The uniform distribution over A,
written Unif(A), assigns probability 1/|A| to each element. We write Flip for the
uniform distribution over the set {0,1}. This can be viewed as the distribution of a
fair coin ﬂip.
Example 5.4 (Couplings from bijections)
We can give two distinct couplings of
(Flip,Flip):
Identity coupling:
μid(a1,a2) ≜

1/2
: a1 = a2
0
: otherwise.
Negation coupling:
μ¬(a1,a2) ≜

1/2
: a1 = 1 −a2
0
: otherwise.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

150
Barthe and Hsu: Probabilistic Couplings from Program Logics
More generally, any bijection f : A →A yields a coupling of (Unif(A),Unif(A)):
μf (a1,a2) ≜

1/|A|
: f (a1) = a2
0
: otherwise.
This coupling matches samples: each sample a from the ﬁrst distribution is
paired with a corresponding sample f (a) from the second distribution. To take two
correlated samples from this coupling, we can imagine ﬁrst sampling from the ﬁrst
distribution, and then applying f to produce a sample for the second distribution.
When f is a bijection, this gives a valid coupling for two uniform distributions:
viewed separately, both the ﬁrst and second correlated samples are distributed
uniformly.
For more general distributions, if a1 and a2 have diﬀerent probabilities under
μ1 and μ2 then the correlated distribution cannot return (a1,−) and (−,a2) with
equal probabilities; for instance, a bijection with f (a1) = a2 would not give a valid
coupling. However, general distributions can be coupled in other ways.
Example 5.5
Let μ be a sub-distribution over A. The identity coupling of (μ, μ) is
μid(a1,a2) ≜

μ(a)
: a1 = a2 = a
0
: otherwise.
Sampling from this coupling yields a pair of equal values.
Example 5.6
Let μ1, μ2 be sub-distributions over A1 and A2. The independent or
trivial coupling is
μ×(a1,a2) ≜μ1(a1) · μ2(a2).
This coupling models μ1 and μ2 as independent distributions: sampling from this
coupling is equivalent to ﬁrst sampling from μ1 and then pairing with an independent
draw from μ2. The coupled distributions must be proper in order to ensure the
marginal conditions.
Since any two proper distributions can be coupled by the trivial coupling, the mere
existence of a coupling yields little information. Couplings are more useful when
the joint distribution satisﬁes additional conditions, for instance when all elements
in the support satisfy some property.
Deﬁnition 5.7 (Lifting)
Let μ1, μ2 be sub-distributions over A1 and A2, and let
R ⊆A1 × A2 be a relation. A sub-distribution μ over pairs A1 × A2 is a witness
for the R-lifting of (μ1, μ2) if:
(i) μ is a coupling for (μ1, μ2), and
(ii) supp(μ) ⊆R.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

5.3 Couplings and liftings: deﬁnitions and basic properties
151
If there exists μ satisfying these two conditions, we say μ1 and μ2 are related by the
lifting of R and write
μ1 R♯μ2.
We typically express R using set notation, i.e.,
R = {(a1,a2) ∈A1 × A2 | Φ(a1,a2)}
where Φ is some logical formula. When the sets A1 and A2 are clear from the
context, we leave them implicit and just write Φ, sometimes enclosed by parentheses
(Φ) for clarity.
Example 5.8
Many of the couplings we saw before are more precisely described
as liftings.
Bijection coupling. For a bijection f : A →A, the coupling in Theorem 5.4
witnesses the lifting
Unif(A) G♯
f Unif(A).
where the relation Gf ≜{(a1,a2) | f (a1) = a2} models the graph of f .
Identity coupling. The coupling in Theorem 5.5 witnesses the lifting
μ (=)♯μ.
Trivial coupling. The coupling in Theorem 5.6 witnesses the lifting
μ1 ⊤♯μ2,
where ⊤≜A1 × A2 is the trivial relation relating all pairs of elements.
5.3.1 Useful consequences of couplings and liftings
A coupling μ between (μ1, μ2) can be used for proving probabilistic properties about
μ1 and μ2. Surprisingly, many properties already follow from the existence of a
lifting from some relation R—no analysis of the coupling distribution μ is required.
First of all, two coupled distributions have equal weight.
Proposition 5.9 (Equality of weight)
Suppose μ1 and μ2 are sub-distributions
over A such that there exists a coupling μ of μ1 and μ2. Then |μ1| = |μ2|.
This follows because μ1 and μ2 are both projections of μ, and projections preserve
weight. Couplings can also show that two distributions are equal.
Proposition 5.10 (Equality of distributions)
Suppose μ1 and μ2 are two sub-
distributions over A. Then μ1 = μ2 if and only if μ1 (=)♯μ2.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

152
Barthe and Hsu: Probabilistic Couplings from Program Logics
Proof
For the forward direction, deﬁne μ(a,a) ≜μ1(a) = μ2(a) and μ(a1,a2) ≜0
otherwise. Evidently, μ has support in the equality relation (=) and also has the
desired marginals: π1(μ) = μ1 and π2(μ) = μ2. Thus μ is a witness to the desired
lifting.
For the reverse direction, let the witness be μ. By the support condition, π1(μ)(a) =
π2(μ)(a) for every a ∈A. Since the left and right sides are equal to μ1(a) and μ2(a)
respectively by the marginal conditions, μ1(a) = μ2(a) for every a. So, μ1 and μ2
are equal.
□
In some cases we can show results in the converse direction: if a property of two
distributions holds, then there exists a particular lifting. To give some examples, we
ﬁrst introduce a powerful equivalence due to Strassen (1965).
Theorem 5.11
Let μ1, μ2 be sub-distributions over A1 and A2, and let R be a
binary relation over A1 and A2. Then μ1 R♯μ2 implies μ1(S1) ≤μ2(R(S1)) for
every subset S1 ⊆A1, where R(S1) ⊆A2 is the image of S1 under R:
R(S1) ≜{a2 ∈A2 | ∃a1 ∈A1, (a1,a2) ∈R}.
(For instance, if A1 = A2 = N and R is the relation ≤, then R(S) is the set of all
natural numbers larger than min S.) The converse holds if μ1 and μ2 have equal
weight.
Strassen proved Theorem 5.11 for continuous (proper) distributions using deep
results from probability theory. In our discrete setting, there is an elementary proof
by the maximum ﬂow-minimum cut theorem (see, e.g., (Kleinberg and Tardos,
2005)). For now, we use this theorem to illustrate a few more useful consequences of
liftings. First, couplings can bound the probability of an event in the ﬁrst distribution
by the probability of an event in the second distribution.
Proposition 5.12
Suppose μ1, μ2 are sub-distributions over A1 and A2 respec-
tively, and consider two subsets S1 ⊆A1 and S2 ⊆A2. Then,
μ1 {(a1,a2) | a1 ∈S1 →a2 ∈S2}♯μ2
implies μ1(S1) ≤μ2(S2). The converse holds when μ1 and μ2 have equal weight.
Proof
Let R be the relation {(a1,a2) | a1 ∈S1 →a2 ∈S2}. The forward
direction is immediate by Theorem 5.11, taking the subset S1. For the reverse
direction, consider any non-empty subset T1 ⊆A1. If T1 is not contained in S1, then
R(T1) = A2 and μ1(T1) ≤μ2(R(T1)) since μ1 and μ2 have equal weight. Otherwise
R(T1) = S2, so
μ1(T1) ≤μ1(S1) ≤μ2(S2) = μ2(R(T1)).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

5.3 Couplings and liftings: deﬁnitions and basic properties
153
Theorem 5.11 gives the desired lifting:
μ1 {(a1,a2) | a1 ∈S1 →a2 ∈S2}♯μ2.
□
A slightly more subtle consequence is stochastic domination, an order on distri-
butions over an ordered set.
Deﬁnition 5.13
Let (A, ≤A) be a partially ordered set. For every k ∈A, let
k ↑≜{a ∈A | k ≤A a}. Suppose μ1, μ2 are sub-distributions over A. We say μ2
stochastically dominates μ1, denoted μ1 ≤sd μ2, if
μ1(k ↑) ≤μ2(k ↑)
for every k ∈A.
For an example of stochastic domination, take distributions over the natural
numbers N with the usual order and μ1 places weight 1 on 0 while μ2 places weight
1 on 1.
Stochastic domination is precisely the probabilistic lifting of the order relation.
Proposition 5.14
Suppose μ1, μ2 are sub-distributions over a set A with a partial
order ≤A. Then μ1 (≤A)♯μ2 implies μ1 ≤sd μ2. The converse also holds when μ1
and μ2 have equal weight, as long as the upwards closed subsets of A are ∅, A and
k ↑with k ∈A (e.g., A = N or Z with the usual order).
Proof
Let R ≜(≤A). For the forward direction, Theorem 5.11 gives
μ1(k ↑) ≤μ2(R(k ↑)) = μ2(k ↑).
This holds for all k ∈A, establishing μ1 ≤sd μ2.
For the converse, suppose μ1 ≤sd μ2 and μ1 and μ2 have equal weights, and let
S ⊆A be any subset. Note that R(S) is upwards closed so we proceed by case
analysis on R(S). If R(S) = ∅, then S is also empty and μ1(S) ≤μ2(R(S)). If
R(S) = A, then μ1(S) ≤μ2(R(S)) since μ1 and μ2 have equal weights. Finally, if
R(S) is k ↑, and we have
μ1(S) ≤μ1(R(S)) = μ1(k ↑) ≤μ2(k ↑) = μ2(R(S)),
where the middle inequality is by stochastic domination. Theorem 5.11 implies
μ1 (≤A)♯μ2.
□
Finally, a typical application of coupling proofs is showing that two distributions
are close together.
Deﬁnition 5.15
Let μ1, μ2 be sub-distributions over A. The total variation distance
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

154
Barthe and Hsu: Probabilistic Couplings from Program Logics
(also known as TV-distance or statistical distance) between μ1 and μ2 is deﬁned as
dtv (μ1, μ2) ≜1
2

a∈A
|μ1(a) −μ2(a)| = max
S⊆A |μ1(S) −μ2(S)|.
In particular, the total variation distance bounds the diﬀerence in probabilities of
any event.
Couplings are closely related to TV-distance, as captured by the following
theorem. Theorem 5.16 is the fundamental result behind the so-called coupling
method (Aldous, 1983), a technique to show two probabilistic processes converge
by constructing a coupling that causes the processes to become equal with high
probability. Unlike the previous facts, the target property about μ1 and μ2 does not
directly follow from the existence of a lifting—we need more detailed information
about the coupling μ.
Theorem 5.16 (see, e.g., Lindvall (2002); Levin et al. (2009))
Let μ1 and μ2 be
sub-distributions over A and let μ be a coupling. Then
dtv (μ1, μ2) ≤
Pr
(a1,a2)∼μ[a1  a2].
In particular, if S ⊆A × A and μ witnesses
μ1 {(a1,a2) ∈A × A | (a1,a2) ∈S →a1 = a2}♯μ2,
then their TV-distance is bounded by the probability of the complement of S w.r.t. μ:
dtv (μ1, μ2) ≤
Pr
(a1,a2)∼μ[(a1,a2)  S].
Moreover, there exists a coupling μ, called maximal coupling, such that
dtv (μ1, μ2) =
Pr
(a1,a2)∼μ[a1  a2].
Proof
We only prove the inequality. Let μ be a coupling of μ1 and μ2. We have:
dtv (μ1, μ2)
= max
P
 Pr
a1∼μ1[a1 ∈P] −Pr
a2∼μ2[a2 ∈P]

= max
P

Pr
(a1,a2)∼μ[a1 ∈P] −
Pr
(a1,a2)∼μ[a2 ∈P]

= max
P

Pr
(a1,a2)∼μ[a1 ∈P ∧a1 = a2] +
Pr
(a1,a2)∼μ[a1 ∈P ∧a1  a2]
−
Pr
(a1,a2)∼μ[a2 ∈P ∧a1 = a2] −
Pr
(a1,a2)∼μ[a2 ∈P ∧a1  a2]

https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

5.3 Couplings and liftings: deﬁnitions and basic properties
155
= max
P

Pr
(a1,a2)∼μ[a1 ∈P ∧a1  a2] −
Pr
(a1,a2)∼μ[a2 ∈P ∧a1  a2]

≤max
P (max(
Pr
(a1,a2)∼μ[a1 ∈P ∧a1  a2],
Pr
(a1,a2)∼μ[a2 ∈P ∧a1  a2]))
≤
Pr
(a1,a2)∼μ[a1  a2]
The proof is similar when μ witnesses
μ1 {(a1,a2) ∈A × A | (a1,a2) ∈S →a1 = a2}♯μ2
by case analysis on (a1,a2) ∈S rather than a1 = a2.
□
5.3.2 Composition properties
Couplings and liftings are closed under various notions of composition. Most
important for our purposes will be sequential composition.
Theorem 5.17
Let μ ∈Distr(A1 × A2) witness μ1 R♯μ2, where μ1 ∈Distr(A1)
and μ2 ∈Distr(A2) and R ⊆A1 × A2. Let M : A1 × A2 →Distr(B1 × B2)
such that M(a1,a2) witnesses for M1(a1) S♯M2(a2) for every (a1,a2) ∈R. Then
bind(μ, M) witnesses
bind(μ1, M1) S♯bind(μ2, M2).
While this theorem may appear a bit cryptic at this point, it will play a key role
in later developments—informally, this result enables us to build a coupling for a
sequential composition of two processes by constructing a coupling for each piece.
5.3.3 Couplings and liftings for Markov chains
The previous results suggest an approach to proving properties of two distributions:
demonstrate there exists a coupling of a particular form. This approach is indirect,
but surprisingly fruitful, when employed to prove properties about probabilistic
processes modelled as discrete-time Markov chains. Recall that a discrete-time
Markov chain is given by a state space A, which we assume to be discrete, by an
initial distribution μ ∈Distr(A) and by a transition map t : A →Distr(A).
Couplings and R-liftings naturally extend to (discrete-time) Markov chains.
Deﬁnition 5.18
A coupling between two Markov chains given by initial sub-
distributions μ1 and μ2 and transition functions t1 and t2 is a Markov chain given by an
initial sub-distributions μ and a joint transition function t : (A×A) →Distr(A×A)
such that:
• μ is a coupling for μ1 and μ2;
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

156
Barthe and Hsu: Probabilistic Couplings from Program Logics
• for every x1 and x2, t(x1, x2) is a coupling for t1(x1) and t2(x2).
The notion of R-lifting extends similarly.
Deﬁnition 5.19
Let R ⊆A1 × A2 be a relation. A R-lifting between two Markov
chains given by initial sub-distributions μ1 and μ2 and transition functions t1 and
t2 is a Markov chain given by an initial sub-distributions μ and a joint transition
function t : (A × A) →Distr(A × A) such that:
• μ is a R-lifting for μ1 and μ2;
• for every (x1, x2) ∈R, t(x1, x2) is a R-lifting for t1(x1) and t2(x2).
The deﬁnition of R-lifting naturally extends to families of relations (Ri)i∈N.
In this case one requires that the sub-distributions obtained by iterating k times
the transition functions on the initial sub-distributions are related by Rk. Other
deﬁnitions relax these conditions; for instance, in shift couplings the relation needs
not be pointwise, i.e. one can relate the two processes at diﬀerent steps k1 and k2.
5.4 Proof by coupling
Finding appropriate couplings requires ingenuity and is often the main intellectual
challenge when carrying out a proof by coupling. Given a conjecture, how are we
supposed to ﬁnd a witness distribution with the desired properties? To address
this challenge, probability theorists have developed a powerful proof technique
called proof by coupling. We close this section with an informal explanation and an
example of the proof technique in action.
Given two probabilistic processes, a proof by coupling builds a coupling for the
output distributions by coupling intermediate samples. In a bit more detail, we
imagine stepping through the processes in parallel, one step at a time, starting from
two inputs, and decoupling the transition function into a random sampling and
a deterministic computation. For the samplings, we pick a valid coupling for the
sampled distributions. The selected couplings induce a relation on samples, which
we can assume when analyzing the rest of the computation (i.e. the deterministic
part). For instance, by selecting couplings for earlier samples carefully, we may be
able to assume the samplings yield equal values.
Example 5.20
Consider a probabilistic process that tosses a fair coin T times and
returns the number of heads. If μ1, μ2 are the output distributions from running this
process for T = T1,T2 iterations respectively and T1 ≤T2, then μ1 ≤sd μ2.
Proof by coupling
For the ﬁrst T1 iterations, couple the coin ﬂips to be equal—this
ensures that after the ﬁrst T1 iterations, the coupled counts are equal. The remaining
T2 −T1 coin ﬂips in the second run can only increase the second count, while
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

5.5 A formal logic for coupling proofs
157
preserving the ﬁrst count. Therefore under the coupling, the ﬁrst count is no more
than the second count at termination, establishing μ1 ≤sd μ2.
□
For readers unfamiliar with these proofs, this argument may appear bewildering.
The coupling is constructed implicitly, and some of the steps are mysterious. To
clarify such proofs, a natural idea is to design a formal logic describing coupling
proofs. Somewhat surprisingly, the logic we are looking for was already proposed in
the formal veriﬁcation literature, originally for verifying security of cryptographic
constructions.
5.5 A formal logic for coupling proofs
We will work with the logic pRHL (probabilistic Relational Hoare Logic) proposed
by Barthe et al. (2009). Before detailing its connection to coupling proofs, we
provide a brief introduction to program logics.
5.5.1 Program logics: A brief primer
A logic consists of a collection of formulas, also known as judgments, and an
interpretation describing what it means—in typical, standard mathematics—for
judgments to be true (valid). While it is possible to prove judgments valid directly by
using regular mathematical arguments, this is often inconvenient as the interpretation
may be quite complicated. Instead, many logics provide a proof system, a set of
logical rules describing how to combine known judgments (the premises) to prove
a new judgment (the conclusion). Each rule represents a single step in a formal
proof. Starting from judgments given by rules with no premises (axioms), we can
successively apply rules to prove new judgments, building a tree-shaped derivation
culminating in a single judgment. To ensure that this ﬁnal judgment is valid, each
logical rule should be sound: if the premises are valid, then so is the conclusion.
Soundness is a basic property, typically one of the ﬁrst results to be proved about a
logic.
Program logics were ﬁrst introduced by Hoare (1969), building on earlier ideas
by Floyd (1967); they are also called Floyd-Hoare logics. These logics are really
two logics in one: the assertion logic, where formulas describe program states, and
the program logic proper, where judgments describe program behavior. A judgment
in the program logic consists of three parts: a program c and two assertions Φ and Ψ
from the assertion logic. The pre-condition Φ describes the initial conditions before
executing c (for instance, assumptions about the input), while the post-condition Ψ
describes the ﬁnal conditions after executing c (for instance, properties of the output).
Hoare (1969) proposed the original logical rules, which construct a judgment for a
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

158
Barthe and Hsu: Probabilistic Couplings from Program Logics
program by combining judgments for its sub-programs. This compositional style of
reasoning is a hallmark of program logics.
By varying the interpretation of judgments, the assertion logic, and the logical
rules, Floyd-Hoare logics can establish a variety of properties about diﬀerent kinds
of imperative programs. Notable extensions reason about non-determinism (Dijkstra,
1976), pointers and memory allocation (O'Hearn et al., 2001; Reynolds, 2001, 2002),
concurrency (O'Hearn, 2007), and more. (Readers should consult a survey for a
more comprehensive account of Floyd-Hoare logic (Apt, 1981, 1983; Jones, 2003).)
In this tradition, Barthe et al. (2009) introduced the logic pRHL targeting security
properties in cryptography. Compared to standard program logics, there are two
twists: each judgment describes two programs,1 and programs can use random
sampling. In short, pRHL is a probabilistic Relational Hoare Logic. Judgments
encode probabilistic relational properties of two programs, where a post-condition
describes a probabilistic liftings between two output distributions. More importantly,
the proof rules represent diﬀerent ways to combine liftings, formalizing various
steps in coupling proofs. Accordingly, we will interpret pRHL as a formal logic for
proofs by coupling.
To build up to this connection, we ﬁrst provide a brief overview of a core version of
pRHL, reviewing the programming language, the judgments and their interpretation,
and the logical rules.
5.5.2 The logic pRHL: the programming language
Programs in pRHL are deﬁned in terms of expressions E including constants, like
the integers and booleans, as well as combinations of constants and variables with
primitive operations, like addition and subtraction. We suppose E also includes
terms for basic datatypes, like tuples and lists. Concretely, E is inductively deﬁned
by the following grammar:
E

X
|
L
(variables)
|
Z
|
E + E
|
E −E
|
E · E
(numbers)
|
B
|
E ∧E
|
E ∨E
|
¬E
|
E = E
|
E < E
(booleans)
|
(E,. . .,E)
|
πi(E)
|
[]
|
E :: E
|
O(E)
(tuples, lists, operations)
Expressions can mention two classes of variables: a countable set X of program
variables, which can be modiﬁed by the program, and a set L of logical variables,
1 Logics reasoning about two programs are known as relational program logics and were ﬁrst considered by
Benton (2004); see Section 5.7 for a discussion of other prior systems.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

5.5 A formal logic for coupling proofs
159
which model ﬁxed parameters. Expressions are typed as numbers, booleans, tuples,
or lists, and primitive operations O have typed signatures; we consider only well-
typed expressions throughout. The expressions (E,. . .,E) and πi(E) construct and
project from a tuple, respectively; [] is the empty list, and E :: E adds an element
to the head of a list. We typically use the letter e for expressions, x, y, z,. . . for
program variables, and lower-case Greek letters (α, β,. . . ) and capital Roman letters
(N, M,. . . ) for logical variables.
We write V for the countable set of values, including integers, booleans, tuples,
ﬁnite lists, etc. We can interpret expressions given maps from variables and logical
variables to values.
Deﬁnition 5.21
Program states are memories, maps X →V; we usually write m
for a memory and State for the set of memories. Logical contexts are maps L →V;
we usually write ρ for a logical context.
We interpret an expression e as a function [[e]]ρ : State →V in the usual way,
for instance:
[[e1 + e2]]ρm ≜[[e1]]ρm + [[e2]]ρm.
Likewise, we interpret primitive operations o as functions [[o]]ρ : V →V, so that
[[o(e)]]ρm ≜[[o]]ρ([[e]]ρm).
We ﬁx a set DE of distribution expressions to model primitive distributions that our
programs can sample from. For simplicity, we suppose for now that each distribution
expression d is interpreted as a uniform distribution over a ﬁnite set. So, we have
the coin ﬂip and uniform distributions:
DE 
Flip
|
Unif(E)
where E is a list, representing the space of samples. We will introduce other
primitive distributions as needed. To interpret distribution expressions, we deﬁne
[[d]]ρ : State →Distr(V); for instance,
[[Unif(e)]]ρm ≜U([[e]]ρm)
where U(S) is the mathematical uniform distribution over a set S.
Now let's see the programming language. We work with a standard imperative
language with random sampling. The programs, also called commands or statements,
are deﬁned inductively:
C

skip
(no-op)
|
X ←E
(assignment)
|
X
$←DE
(sampling)
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

160
Barthe and Hsu: Probabilistic Couplings from Program Logics
|
C; C
(sequencing)
|
if E then C else C
(conditional)
|
while E do C
(loop)
We assume throughout that programs are well-typed; for instance, the guard expres-
sions in conditionals and loops must be boolean.
We interpret each command as a mathematical function from states to sub-
distributions over output states; this function is known as the semantics of a
command. Since the set of program variables and the set of values are countable,
the set of states is also countable so sub-distributions over states are discrete. To
interpret commands, we use two basic constructions on sub-distributions.
Deﬁnition 5.22
The function unit : A →SDistr(A) maps every element a ∈A
to the sub-distribution that places probability 1 on a. The function bind : SDistr(A)×
(A →SDistr(B)) →SDistr(B) is deﬁned by
bind(μ, f )(b) ≜

a∈A
μ(a) · f (a)(b).
Intuitively, bind applies a randomized function on a distribution over inputs.
We use a discrete version of the semantics considered by Kozen (1981), presented
in Fig. 5.1; we write m[x →v] for the memory m with variable x updated to hold v,
and a →b(a) for the function mapping a to b(a). The most complicated case is for
loops. The sub-distribution μ(i)(m) models executions that exit after entering the
loop body at most i times, starting from initial memory m. For the base case i = 0,
the sub-distribution either returns m with probability 1 when the guard is false and
the loop exits immediately, or returns the null sub-distribution ⊥when the guard is
true. The cases i > 0 are deﬁned recursively, by unrolling the loop.
Note that μ(i) are increasing in i: μ(i)(m) ≤μ(j)(m) for all m ∈State and i ≤j. In
particular, the weights of the sub-distributions are increasing. Since the weights are
at most 1, the approximants converge to a sub-distribution as i tends to inﬁnity by
the monotone convergence theorem (see, e.g., Rudin (1976, Theorem 11.28), taking
the discrete counting measure over State).
5.5.3 The logic pRHL: judgments and validity
The program logic pRHL features judgments of the following form:
c1 ∼c2 : Φ =⇒Ψ
Here, c1 and c2 are commands and Φ and Ψ are predicates on pairs of memories. To
describe the inputs and outputs of c1 and c2, each predicate can mention two copies
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

5.5 A formal logic for coupling proofs
161
[[skip]]ρm ≜unit(m)
[[x ←e]]ρm ≜unit(m[x →[[e]]ρm])
[[x
$←d]]ρm ≜bind([[d]]ρm,v →unit(m[x →v]))
[[c; c′]]ρm ≜bind([[c]]ρm,[[c′]]ρ)
[[if e then c else c′]]ρm ≜
*[[c]]ρm
: [[e]]ρm = true
[[c′]]ρm
: [[e]]ρm = false
[[while e do c]]ρm ≜lim
i→∞μ(i)(m)
μ(i)(m) ≜
⎧⎪⎪⎨
⎪⎪⎩
⊥
: i = 0 ∧[[e]]ρm = true
unit(m)
: i = 0 ∧[[e]]ρm = false
bind([[if e then c]]ρm, μ(i−1))
: i > 0
Figure 5.1 Semantics of programs
x⟨1⟩, x⟨2⟩of each program variable x; these tagged variables refer to the value of x
in the executions of c1 and c2 respectively.
Deﬁnition 5.23
Let X⟨1⟩and X⟨2⟩be the sets of tagged variables, ﬁnite sets of
variable names tagged with ⟨1⟩or ⟨2⟩respectively:
X⟨1⟩≜{x⟨1⟩| x ∈X}
and
X⟨2⟩≜{x⟨2⟩| x ∈X}.
Let State⟨1⟩and State⟨2⟩be the sets of tagged memories, maps from tagged
variables to values:
State⟨1⟩≜X⟨1⟩→V
and
State⟨2⟩≜X⟨2⟩→V.
Let State× be the set of product memories, which combine two tagged memories:
State× ≜X⟨1⟩⊎X⟨2⟩→V.
For notational convenience we identify State× with pairs of memories State⟨1⟩×
State⟨2⟩; for m1 ∈State⟨1⟩and m2 ∈State⟨2⟩, we write (m1,m2) for the product
memory and we use the usual projections on pairs to extract untagged memories
from the product memory:
p1(m1,m2) ≜|m1|
and
p2(m1,m2) ≜|m2|,
where the memory |m| ∈State has all variables in X. For commands c and
expressions e with variables in X, we write c⟨1⟩, c⟨2⟩and e⟨1⟩, e⟨2⟩for the
corresponding tagged commands and tagged expressions with variables in X⟨1⟩and
X⟨2⟩.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

162
Barthe and Hsu: Probabilistic Couplings from Program Logics
We consider a set P of predicates (assertions) from ﬁrst-order logic deﬁned by
the following grammar:
P 
E⟨1/2⟩= E⟨1/2⟩
|
E⟨1/2⟩< E⟨1/2⟩
|
E⟨1/2⟩∈E⟨1/2⟩
|
⊤
|
⊥
|
O(E⟨1/2⟩,. . .,E⟨1/2⟩)
(predicates)
|
P ∧P
|
P ∨P
|
¬P
|
P →P
|
∀L ∈Z, P
|
∃L ∈Z, P
(ﬁrst-order formulas)
We typically use capital Greek letters (Φ,Ψ,Θ,Ξ,. . . ) for predicates. E⟨1/2⟩denotes
an expression where program variables are tagged with ⟨1⟩or ⟨2⟩; tags may be
mixed within an expression. We consider the usual binary predicates {=,<,∈,. . . }
where e ∈e′ means e is a member of the list e′, and we take the always-true and
always-false predicates ⊤and ⊥, and a set O of other predicates. Predicates can be
combined using the usual connectives {∧,∨,¬,→} and can quantify over ﬁrst-order
types (e.g., the integers, tuples, etc.). We will often interpret a boolean expression e
as the predicate e = true.
Predicates are interpreted as sets of product memories.
Deﬁnition 5.24
Let Φ be a predicate. Given a logical context ρ, Φ is interpreted
as a set [[Φ]]ρ ⊆State× in the expected way, e.g.,
[[e1⟨1⟩< e2⟨2⟩]]ρ ≜{(m1,m2) ∈State× | [[e1]]ρm1 < [[e2]]ρm2}.
We can inject a predicate on single memories into a predicate on product memories;
we call the resulting predicate one-sided since it constrains just one of two memories.
Deﬁnition 5.25
Let Φ be a predicate on State. We deﬁne formulas Φ⟨1⟩and Φ⟨2⟩
by replacing all program variables x in Φ with x⟨1⟩and x⟨2⟩, respectively, and we
deﬁne
[[Φ⟨1⟩]]ρ ≜{(m1,m2) | m1 ∈[[Φ]]ρ}
and
[[Φ⟨2⟩]]ρ ≜{(m1,m2) | m2 ∈[[Φ]]ρ}.
Valid judgments in pRHL relate two output distributions by lifting the post-
condition.
Deﬁnition 5.26 (Barthe et al. (2009))
A judgment is valid in logical context ρ,
written ρ |= c1 ∼c2 : Φ =⇒Ψ, if for any two memories (m1,m2) ∈[[Φ]]ρ there
exists a lifting of Ψ relating the output distributions:
[[c1]]ρm1 [[Ψ]]♯
ρ [[c2]]ρm2.
For example, a valid judgment
|= c1 ∼c2 : Φ =⇒(=),
states that for any two input memories (m1,m2) satisfying Φ, the resulting output
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

5.5 A formal logic for coupling proofs
163
distributions from running c1 and c2 are related by lifted equality; by Theorem 5.10,
these output distributions must be equal.
5.5.4 The logic pRHL: the proof rules
Valid judgments in pRHL state that the output distributions of two programs
are related in a speciﬁc way. However, it is generally not possible to directly
prove validity—even simple probabilistic programs with loops can produce highly
complex output distributions, and we typically do not have a description of the
output distribution that is more precise than the probabilistic program itself.
To make reasoning about probabilistic programs more tractable, pRHL includes a
collection of logical rules to inductively build up a proof of a new judgment from
known judgments, combining proofs about sub-programs into proofs about larger
programs. The rules are superﬁcially similar to those from standard Hoare logic.
However, the interpretation of judgments in terms of liftings means some rules in
pRHL are not valid in Hoare logic, and vice versa.
Before describing the rules, we introduce some necessary notation. A system of
logical rules inductively deﬁnes a set of derivable formulas; we use the head symbol
⊢to mark such formulas. As is standard in logic, the premises in each logical rule
are written above the horizontal line, and the single conclusion is written below the
line; for easy reference, the name of each rule is given to the left of the line.
The main premises are judgments in the program logic, but rules may also use
other side-conditions. For instance, many rules require an assertion logic formula to
be valid in all memories. Other side-conditions state that a program is terminating,
or that certain variables are not modiﬁed by the program. We use the head symbol
|= to mark valid side-conditions; while we could give a separate proof system for
these premises, in practice they are simple enough to check directly.
We also use notation for substitution in assertions. We write Φ {e/x} for the
formula Φ with every occurrence of the variable x replaced by e. Similarly,
Φ {v1,v2/x1⟨1⟩, x2⟨2⟩} is the formula Φ where occurrences of the tagged vari-
ables x1⟨1⟩, x2⟨2⟩are replaced by v1,v2 respectively.
Now, we take a tour through the logical rules of pRHL. While most of these rules
were proposed in prior works, we use the coupling interpretation to give a new way
of thinking about what the rules mean. It turns out that certain steps of the informal
coupling proofs we saw in Section 5.4 correspond to speciﬁc logical rules in pRHL,
seen from the right perspective. We summarize this reading in Section 5.5.
One important feature of coupling proofs can already be seen in the form of the
proof rules: though the notion of validity and target properties are probabilisitic—i.e.,
they describe pairs of probability distributions—assertions describe individual mem-
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

164
Barthe and Hsu: Probabilistic Couplings from Program Logics
Skip ⊢skip ∼skip : Φ =⇒Φ
Assn ⊢x1 ←e1 ∼x2 ←e2 : Ψ {e1⟨1⟩,e2⟨2⟩/x1⟨1⟩, x2⟨2⟩} =⇒Ψ
Sample
f : supp(d1) →supp(d2) is a bijection
⊢x1
$←d1 ∼x2
$←d2 : ∀v ∈supp(d1), Ψ {v, f (v)/x1⟨1⟩, x2⟨2⟩} =⇒Ψ
Seq ⊢c1 ∼c2 : Φ =⇒Ψ
⊢c′
1 ∼c′
2 : Ψ =⇒Θ
⊢c1; c′
1 ∼c2; c′
2 : Φ =⇒Θ
Cond
|= Φ →e1⟨1⟩= e2⟨2⟩
⊢c1 ∼c2 : Φ ∧e1⟨1⟩=⇒Ψ
⊢c′
1 ∼c′
2 : Φ ∧¬e1⟨1⟩=⇒Ψ
⊢if e1 then c1 else c′
1 ∼if e2 then c2 else c′
2 : Φ =⇒Ψ
While |= Φ →e1⟨1⟩= e2⟨2⟩
⊢c1 ∼c2 : Φ ∧e1⟨1⟩=⇒Φ
⊢while e1 do c1 ∼while e2 do c2 : Φ =⇒Φ ∧¬e1⟨1⟩
Figure 5.2 Two-sided pRHL rules
ories, rather than distributions over memories. Abstracting away from probabilistic
aspect of the program makes probabilistic reasoning signiﬁcantly easier, and is a
key reason why the coupling proof technique is so powerful.
The rules of pRHL can be divided into three groups: two-sided rules, one-sided
rules, and structural rules. All judgments are parameterized by a logical context
ρ, but since this context is assumed to be a ﬁxed assignment of logical variables—
constant throughout the proof—we omit it from the rules. The two-sided rules in
Fig. 5.2 apply when the two programs in the conclusion judgment have the same
top-level shape.
The rule [Skip] simply states that skip instructions preserve the pre-condition.
The rule [Assn] handles assignment instructions. It is the usual Hoare-style rule: if
Ψ holds initially with e1⟨1⟩and e2⟨2⟩substituted for x1⟨1⟩and x2⟨2⟩, then Ψ holds
after the respective assignment instructions.
The rule [Sample] is more subtle. In some ways it is the key rule in pRHL,
allowing us to select a coupling for a pair of sampling instructions. To gain intuition,
the following rule is a special case:
Sample*
f : supp(d) →supp(d) is a bijection
⊢x
$←d ∼x
$←d : ⊤=⇒f (x⟨1⟩) = x⟨2⟩
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

5.5 A formal logic for coupling proofs
165
In terms of couplings, the conclusion states that there exists a coupling of a distribution
d with itself such that each sample x from d is related to f (x). Soundness of this
rule crucially relies on d being uniform—as we have seen, any bijection f induces a
coupling of uniform distributions (cf. Theorem 5.4). It is possible to support more
general distributions at the cost of a more complicated side-condition,2 but we will
not need this generality. The full rule [Sample] can prove a post-condition of any
shape: a post-condition holds after sampling if it holds before sampling, where x⟨1⟩
and x⟨2⟩are replaced by any two coupled samples (v, f (v)).
More generally, a key feature of coupling proofs can be seen in the rule [Sample]:
reducing two separate sources of randomness into a single source of randomness. A
priori, two sampling instructions in the two programs are completely independent—
we have no reason to think that the results of their random draws are related in any
way. The sampling rule shows that for the purpose of the proof, it is sound to assume
that the results from the two sampling statements are related by a bijection. In this
way, we may analyze the two programs with their separate sources of randomness
as if they shared a single, common source of randomness. When the original
programs have similar shapes—as is the typical case in relational veriﬁcation—this
coordination enables us to limit our attention to pairs of highly similar program
executions.
The rule [Seq] resembles the normal rule for sequential composition in Hoare
logic, but this superﬁcial similarity hides some complexity. In particular, note that
the intermediate assertion Ψ is interpreted diﬀerently in the two premises: in the ﬁrst
judgment it is a post-condition and interpreted as a relation between distributions
over memories via lifting, while in the second judgment it is a pre-condition and
interpreted as a relation between memories, not distributions over memories.
The next two rules deal with branching commands. Rule [Cond] requires that
the guards e1⟨1⟩and e2⟨2⟩are equal assuming the pre-condition Φ. The rule is
otherwise similar to the standard Hoare logic rule: if we can prove the post-condition
Ψ when the guard is initially true and when the guard is initially false, then we can
prove Ψ as a post-condition of the conditional.
Rule [While] uses a similar idea for loops. We again assume that the guards are
initially equal, and we also assume that they are equal in the post-condition of the
loop body. Since the judgments are interpreted in terms of couplings, this second
condition is a bit subtle. For one thing, the rule does not require e1⟨1⟩= e2⟨2⟩in all
possible executions of the two programs—this would be a rather severe restriction,
for instance ruling out programs where e1⟨1⟩and e2⟨2⟩are probabilistic. Rather,
the guards only need to be equal under the coupling of the two programs given by
the premise. The upshot is that by selecting appropriate couplings in the loop body,
2 Roughly speaking, the probability of any set S under d should be equal to the probability of f (S) under d.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

166
Barthe and Hsu: Probabilistic Couplings from Program Logics
Assn-L ⊢x1 ←e1 ∼skip : Ψ {e1⟨1⟩/x1⟨1⟩} =⇒Ψ
Assn-R ⊢skip ∼x2 ←e2 : Ψ {e2⟨2⟩/x2⟨2⟩} =⇒Ψ
Sample-L ⊢x1
$←d1 ∼skip : ∀v ∈supp(d1), Ψ {v/x1⟨1⟩} =⇒Ψ
Sample-R ⊢skip ∼x2
$←d2 : ∀v ∈supp(d2), Ψ {v/x2⟨2⟩} =⇒Ψ
Cond-L ⊢c1 ∼c : Φ ∧e1⟨1⟩=⇒Ψ
⊢c′
1 ∼c : Φ ∧¬e1⟨1⟩=⇒Ψ
⊢if e1 then c1 else c′
1 ∼c : Φ =⇒Ψ
Cond-R ⊢c ∼c2 : Φ ∧e2⟨2⟩=⇒Ψ
⊢c ∼c′
2 : Φ ∧¬e2⟨2⟩=⇒Ψ
⊢c ∼if e2 then c2 else c′
2 : Φ =⇒Ψ
While-L
⊢c1 ∼skip : Φ ∧e1⟨1⟩=⇒Φ
|= Φ →Φ1⟨1⟩
Φ1 |= while e1 do c1 lossless
⊢while e1 do c1 ∼skip : Φ =⇒Φ ∧¬e1⟨1⟩
While-R
⊢skip ∼c2 : Φ ∧e2⟨2⟩=⇒Φ
|= Φ →Φ2⟨2⟩
Φ2 |= while e2 do c2 lossless
⊢skip ∼while e2 do c2 : Φ =⇒Φ ∧¬e2⟨2⟩
Figure 5.3 One-sided pRHL rules
we can assume the guards are equal when analyzing loops with probabilistic guards.
The rule is otherwise similar to the usual Hoare logic rule, where Φ is the loop
invariant.
So far, we have seen rules that relate two programs of the same shape. These are
the most commonly used rules in pRHL, as relational reasoning is most powerful
when comparing two highly similar (or even the same) programs. However, in some
cases we may need to reason about two programs with diﬀerent shapes, even if
the two top-level commands are the same. For instance, if we can't guarantee two
executions of a program follow the same path at a conditional statement under a
coupling, we must relate the two diﬀerent branches. For this kind of reasoning, we
can fall back on the one-sided rules in Fig. 5.3. These rules relate a command of a
particular shape with skip or an arbitrary command. Each rule comes in a left- and
a right-side version.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

5.5 A formal logic for coupling proofs
167
The assignment rules, [Assn-L] and [Assn-R], relate an assignment instruction
to skip using the usual Hoare rule for assignment instructions. The sampling rules,
[Sample-L] and [Sample-R], are similar; they relate a sampling instruction to skip
if the post-condition holds for all possible values of the sample. These rules represent
couplings where fresh randomness is used, i.e., where randomness is not shared
between the two programs.
The conditional rules, [Cond-L] and [Cond-R], are similar to the two-sided
conditional rule except there is no assumption of synchronized guards—the other
command c might not even be a conditional. If we can relate the general command
c to the true branch when the guard is true and relate c to the false branch when the
guard is false, then we can relate c to the whole conditional.
The rules for loops, [While-L] and [While-R], can only relate loops to the skip;
a loop that executes multiple iterations cannot be directly related to an arbitrary
command that executes only once. These rules mimic the usual loop rule from Hoare
logic, with a critical side-condition: losslessness.
Deﬁnition 5.27
A command c is Φ-lossless if for any memory m satisfying Φ and
every logical context ρ, the output [[c]]ρm is a proper distribution (i.e., it has total
probability 1). We write Φ-lossless as the following judgment:
Φ |= c lossless
Losslessness is needed for soundness: skip produces a proper distribution on any
input and liftings can only relate sub-distributions with equal weights (Theorem 5.9),
so the loop must also produce a proper distribution to have any hope of coupling
the output distributions. For the examples we will consider, losslessness is easy to
show since loops execute for a ﬁnite number of iterations; when there is no ﬁnite
bound, proving losslessness may require more sophisticated techniques (e.g., Barthe
et al. (2018a); Ferrer Fioriti and Hermanns (2015); Chatterjee et al. (2016b,a, 2017);
McIver et al. (2018)).
Finally, pRHL includes a handful of structural rules which apply to programs of
any shape. The ﬁrst rule [Conseq] is the usual rule of consequence, allowing us to
strengthen the pre-condition and weaken the post-condition—assuming more about
the input and proving less about the output, respectively.
The rule [Equiv] replaces programs by equivalent programs. This rule is par-
ticularly useful for reasoning about programs of diﬀerent shapes. Instead of using
one-sided rules, which are often less convenient, we can sometimes replace a
program with an equivalent version and then apply two-sided rules. For simplicity,
we use a strong notion of equivalence:
c1 ≡c2 ≜[[c1]]ρ = [[c2]]ρ
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

168
Barthe and Hsu: Probabilistic Couplings from Program Logics
Conseq ⊢c1 ∼c2 : Φ′ =⇒Ψ′
|= Φ →Φ′
|= Ψ′ →Ψ
⊢c1 ∼c2 : Φ =⇒Ψ
Equiv ⊢c′
1 ∼c′
2 : Φ =⇒Ψ
c1 ≡c′
1
c2 ≡c′
2
⊢c1 ∼c2 : Φ =⇒Ψ
Case ⊢c1 ∼c2 : Φ ∧Θ =⇒Ψ
⊢c1 ∼c2 : Φ ∧¬Θ =⇒Ψ
⊢c1 ∼c2 : Φ =⇒Ψ
Trans ⊢c1 ∼c2 : Φ =⇒Ψ
⊢c2 ∼c3 : Φ′ =⇒Ψ′
⊢c1 ∼c3 : Φ′ ◦Φ =⇒Ψ′ ◦Ψ
Frame ⊢c1 ∼c2 : Φ =⇒Ψ
FV(Θ) ∩MV(c1,c2) = ∅
⊢c1 ∼c2 : Φ ∧Θ =⇒Ψ ∧Θ
Figure 5.4 Structural pRHL rules
for every logical context ρ; more reﬁned notions of equivalence are also possible,
but will not be needed for our purposes. For our examples, we just use a handful of
basic program equivalences, e.g., c; skip ≡c and skip; c ≡c.
The rule [Case] performs a case analysis on the input. If we can prove a judgment
when Θ holds initially and a judgment when Θ does not hold initially, then we can
combine the two judgments provided they have the same post-condition.
The rule [Trans] is the transitivity rule: given a judgment relating c1 ∼c2 and a
judgment relating c2 ∼c3, we can glue these judgments together to relate c1 ∼c3.
The pre- and post-conditions of the conclusion are given by composing the pre- and
post-conditions of the premises; for binary relations R and S, relation composition
is deﬁned by
R ◦S ≜{(x1, x3) | ∃x2. (x1, x2) ∈S ∧(x2, x3) ∈R}.
The last rule [Frame] is the frame rule (also called the rule of constancy): it
states that an assertion Θ can be carried from the pre-condition through to the
post-condition as long as the variables MV(c1,c2) that may be modiﬁed by the
programs c1 and c2 don't include any of the variables FV(Θ) appearing free in Θ; as
usual, MV and FV are deﬁned syntactically by collecting the variables that occur in
programs and assertions.
As expected, the proof system of pRHL is sound.
Theorem 5.28 (Barthe et al. (2009))
Let ρ be a logical context. If a judgment is
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

5.6 Constructing couplings, formally
169
derivable
ρ ⊢c1 ∼c2 : Φ =⇒Ψ,
then it is valid:
ρ |= c1 ∼c2 : Φ =⇒Ψ.
5.5.5 The coupling interpretation
Now that we have seen the core logical rules of pRHL, we revisit the connection
with couplings. Not only do valid judgments assert the existence of a coupling
between two output distributions, the proof system itself is a formalization of proofs
by coupling, which we saw in Section 5.4. This perspective gives a better, more
precise understanding of what proofs by coupling are, and how they work.
In more detail, a valid judgment ρ |= c1 ∼c2 : Φ =⇒Ψ implies that for any two
input memories related by Φ, there exists a coupling with support in Ψ between the
two output distributions. By applying the results in Section 5.3, valid judgments
imply relational properties of programs.
Moreover, we can identify common steps in standard coupling proofs in the form
of speciﬁc logical rules. For instance, [Sample] selects a coupling for corresponding
sampling statements; the function f lets us choose among diﬀerent bijection
couplings. The rule [Seq] formalizes the sequential composition principle for
couplings; when two processes produce samples related by Ψ under a particular
coupling, we can continue to assume this relation when analyzing the remainder of
the program. The structural rule [Case] shows we can select between two possible
couplings depending on whether a predicate Θ holds. In short, not only is pRHL a
logic for verifying cryptographic constructions, it is also a formal logic for proofs
by coupling.
5.6 Constructing couplings, formally
The coupling proof technique has been applied to a variety of probabilistic properties,
using the same basic pattern: construct a coupling of a speciﬁc form between the
output distributions of two programs, then use the existence of this coupling
to conclude a relational property using known consequences of couplings (cf.
Section 5.3). Given the close connection between coupling proofs and our logic,
we carry out this proof pattern in pRHL to build formal proofs of three classical
properties: equivalence, stochastic domination, and convergence.
Remark 5.29
There are some inherent challenges in presenting formal proofs on
paper. Fundamentally, our proofs are branching derivation trees. When such a proof
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

170
Barthe and Hsu: Probabilistic Couplings from Program Logics
is linearized, it becomes more diﬃcult to follow which part of the derivation tree
the paper proof corresponds to. To help organize the proof, we generally proceed in
a top-down fashion, giving proofs and judgments for the most deeply nested parts of
the program ﬁrst and then gradually zooming out to consider larger and larger parts
of the whole program.
Applications of sequential composition are also natural places to signpost the
proof. We typically consider the commands in order, unless the second command
is much more complex than the ﬁrst. Finally, for space reasons we will gloss over
applications of the assignment rule [Assn] and minor uses of the rule of consequence
[Conseq]; a completely formal proof would necessarily include these details.
5.6.1 Probabilistic equivalence
To warm up, we prove two programs to be probabilistically equivalent. Our example
models perhaps the most basic encryption scheme: the XOR cipher. Given a boolean
s representing the secret message, the XOR cipher ﬂips a fair coin to draw the secret
key k and then returns k ⊕s as the encrypted message. A receiving party who knows
the secret key can decrypt the message by computing k ⊕(k ⊕s) = s.
To prove secrecy of this scheme, we consider the following two programs:
k
$←Flip;
r ←k ⊕s
k
$←Flip;
r ←k
The ﬁrst program xor1 implements the encryption function, storing the encrypted
message into r. The second program xor2 simply stores a random value into r. If we
can show the distribution of r is the same in both programs, then the XOR cipher is
secure: the distribution on outputs is completely random, leaking no information
about the secret message s. In terms of pRHL, it suﬃces to prove the following
judgment:
⊢xor1 ∼xor2 : ⊤=⇒r⟨1⟩= r⟨2⟩
By validity of the logic, this judgment implies that for any two memories m1,m2,
the output distributions are related by a coupling that always returns outputs with
equal values of r; by reasoning similar to Theorem 5.10, this implies that the output
distributions over r⟨1⟩and r⟨2⟩are equal.3
Before proving this judgment in the logic, we sketch the proof by coupling. If
s⟨1⟩is true, then we couple k to take opposite values in the two runs. If s⟨1⟩is false,
then we couple k to be equal in the two runs. In both cases, we conclude that the
results r⟨1⟩,r⟨2⟩are equal under the coupling.
3 To be completely precise, Theorem 5.10 assumes that we have lifted equality, while here we only have a lifting
where the variables r are equal. An analogous argument shows that the marginal distributions of variable r
must be equal.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

5.6 Constructing couplings, formally
171
To formalize this argument in pRHL, we use the [Case] rule:
Case
⊢xor1 ∼xor2 : s⟨1⟩= true =⇒r⟨1⟩= r⟨2⟩
⊢xor1 ∼xor2 : s⟨1⟩ true =⇒r⟨1⟩= r⟨2⟩
⊢xor1 ∼xor2 : ⊤=⇒r⟨1⟩= r⟨2⟩
.
For the ﬁrst premise we select the negation coupling using the bijection f = ¬ in
[Sample], apply the assignment rule [Assn], and combine with the sequencing rule
[Seq]. Concretely, we have
Sample
f = ¬
⊢k
$←Flip ∼k
$←Flip : s⟨1⟩= true =⇒k⟨1⟩= ¬k⟨2⟩∧s⟨1⟩= true
Assn
⊢r ←k ⊕s ∼r ←k : k⟨1⟩= ¬k⟨2⟩∧s⟨1⟩= true =⇒r⟨1⟩= r⟨2⟩
and we combine the two judgments to give:
Seq
⊢k
$←Flip ∼k
$←Flip : s⟨1⟩= true =⇒k⟨1⟩= ¬k⟨2⟩∧s⟨1⟩= true
⊢r ←k ⊕s ∼r ←k : k⟨1⟩= ¬k⟨2⟩∧s⟨1⟩= true =⇒r⟨1⟩= r⟨2⟩
⊢xor1 ∼xor2 : s⟨1⟩= true =⇒r⟨1⟩= r⟨2⟩
.
For the other case s⟨1⟩ true, we give the same proof except with the identity
coupling in [Sample]:
Sample
f = id
⊢k
$←Flip ∼k
$←Flip : s⟨1⟩ true =⇒k⟨1⟩= k⟨2⟩∧s⟨1⟩ true
and the assignment rule, we have
Assn
⊢r ←k ⊕s ∼r ←k : k⟨1⟩= k⟨2⟩∧s⟨1⟩ true =⇒r⟨1⟩= r⟨2⟩.
Combining the conclusions, we get
Seq
⊢k
$←Flip ∼k
$←Flip : s⟨1⟩ true =⇒k⟨1⟩= ¬k⟨2⟩∧s⟨1⟩ true
⊢r ←k ⊕s ∼r ←k : k⟨1⟩= k⟨2⟩∧s⟨1⟩ true =⇒r⟨1⟩= r⟨2⟩
⊢xor1 ∼xor2 : s⟨1⟩ true =⇒r⟨1⟩= r⟨2⟩
.
By [Case], we conclude the desired post-condition r⟨1⟩= r⟨2⟩.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

172
Barthe and Hsu: Probabilistic Couplings from Program Logics
5.6.2 Stochastic domination
For our second example, we revisit Theorem 5.20 and replicate the proof in pRHL.
The following program sdom ﬂips a coin T times and returns the number of coin
ﬂips that come up true:
i ←0; ct ←0;
while i < T do
i ←i + 1;
s
$←Flip;
ct ←s ? ct + 1 : ct
(The last line uses the ternary conditional operator—s ? ct + 1 : ct is equal to ct + 1
if s is true, otherwise equal to ct.)
We consider two runs of this program executing T1 and T2 iterations, where
T1 ≤T2 are logical variables; call the two programs sdom1 and sdom2. By soundness
of the logic and Theorem 5.14, the distribution of ct in the second run stochastically
dominates the distribution of ct in the ﬁrst run if we can prove the judgment
⊢sdom1 ∼sdom2 : ⊤=⇒ct⟨1⟩≤ct⟨2⟩.
Encoding the argument from Theorem 5.20 in pRHL requires a bit of work. The
main obstacle is that the two-sided loop rule in pRHL can only analyze loops in a
synchronized fashion, but this is not possible here: when T1 < T2 the two loops run
for diﬀerent numbers of iterations, no matter how we couple the samples. To get
around this problem, we use the equivalence rule [Equiv] to transform sdom into a
more convenient form using the following equivalence:
while e do c ≡while e ∧e′ do c; while e do c
This transformation, known in the compilers literature as loop splitting (Callahan
and Kennedy, 1988), separates out the ﬁrst iterations where e′ holds, and then runs
the original loop to completion. We transform sdom2 as follows:
sdom′
2a
≜
⎧⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎩
i ←0; ct ←0;
while i < T2 ∧i < T1 do
i ←i + 1;
s
$←Flip;
ct ←s ? ct + 1 : ct;
i ←0; ct ←0;
while i < T1 do
i ←i + 1;
s
$←Flip;
ct ←s ? ct + 1 : ct;
⎫⎪⎪⎪⎪⎪⎪⎬
⎪⎪⎪⎪⎪⎪⎭
≜sdom1
sdom′
2b
≜
⎧⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩
while i < T2 do
i ←i + 1;
s
$←Flip;
ct ←s ? ct + 1 : ct
We aim to relate sdom′
2a; sdom′
2b to sdom1. First, we apply the two-sided rule
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

5.6 Constructing couplings, formally
173
[While] to relate sdom1 to sdom′
2a. Taking the identity coupling with f = id in
[Sample], we relate the sampling in the loop body via
Sample
f = id
⊢s
$←Flip ∼s
$←Flip : ⊤=⇒s⟨1⟩= s⟨2⟩
and establish the loop invariant
Θ ≜i⟨1⟩= i⟨2⟩∧ct⟨1⟩= ct⟨2⟩,
proving the judgment
⊢sdom1 ∼sdom′
2a : ⊤=⇒Θ.
Then we use the one-sided rule [While-R] for the loop sdom′
2b with loop invariant
ct⟨1⟩≤ct⟨2⟩:
⊢skip ∼sdom′
2b : Θ =⇒ct⟨1⟩≤ct⟨2⟩.
Composing these two judgments with [Seq] and applying [Equiv] gives the desired
judgment:
Equiv
⊢sdom1; skip ∼sdom′
2a; sdom′
2b : ⊤=⇒ct⟨1⟩≤ct⟨2⟩
⊢sdom1 ∼sdom2 : ⊤=⇒ct⟨1⟩≤ct⟨2⟩
using the equivalence sdom1; skip ≡sdom1.
5.6.3 Probabilistic convergence
In our ﬁnal example, we build a coupling witnessing convergence of two random
walks. Each process begins at an integer starting point start, and proceeds for T
steps. At each step it ﬂips a fair coin. If true, it increases the current position by
1; otherwise, it decreases the position by 1. Given two random walks starting at
diﬀerent initial locations, we want to bound the distance between the two resulting
output distributions in terms of T. Intuitively, the position distributions spread out
as the random walks proceed, tending towards the uniform distribution on the even
integers or the uniform distribution over the odd integers depending on the parity of
the initial position and the number of steps. If two walks initially have the same parity
(i.e., their starting positions diﬀer by an even integer), then their distributions after
taking the same number of steps T should approach one another in total variation
distance.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

174
Barthe and Hsu: Probabilistic Couplings from Program Logics
We model a single random walk with the following program rwalk:
pos ←start;i ←0; hist ←[start];
while i < T do
i ←i + 1;
r
$←Flip;
pos ←pos + (r ? 1 : −1);
hist ←pos :: hist
The last command records the history of the walk in hist; this ghost variable does
not aﬀect the ﬁnal output value, but will be useful for our assertions.
By Theorem 5.16, we can bound the TV-distance between the position distributions
by constructing a coupling where the probability of pos⟨1⟩ pos⟨2⟩tends to 0 as
T increases. We don't have the tools yet to reason about this probability (we will
revisit this point in the next chapter), but for now we can build the coupling and
prove the judgment
⊢rwalk ∼rwalk : start⟨2⟩−start⟨1⟩= 2K
=⇒K + start⟨1⟩∈hist⟨1⟩→pos⟨1⟩= pos⟨2⟩
where K is an integer logical variable. The pre-condition states that the initial
positions are an even distance apart. To read the post-condition, the predicate
K + start⟨1⟩∈hist⟨1⟩holds if and only if the ﬁrst walk has moved to position
K + start⟨1⟩at some time in the past; if this has happened, then the two coupled
positions must be equal.
Our coupling mirrors the two walks. Each step, we have the walks make symmetric
moves by arranging opposite samples. Once the walks meet, we have the walks
match each other by coupling the samples to be equal. In this way, if the ﬁrst
walk reaches start⟨1⟩+ K, then the second walk must be at start⟨2⟩−K since
both walks are coupled to move symmetrically. In this case, the initial condition
start⟨2⟩−start⟨1⟩= 2K gives
pos⟨1⟩= start⟨1⟩+ K = start⟨2⟩−K = pos⟨2⟩
so the walks meet and continue to share the same position thereafter. This argument
requires the starting positions to be an even distance apart so the positions in the two
walks always have the same parity; if the two starting positions are an odd distance
apart, then the two distributions after T steps have disjoint support and the coupled
walks can never meet.
To formalize this argument in pRHL, we handle the loop with the two-sided rule
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

5.6 Constructing couplings, formally
175
[While] and invariant
Θ ≜
⎧⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎩
|hist⟨1⟩| > 0 ∧|hist⟨2⟩| > 0
K + start⟨1⟩∈hist⟨1⟩→pos⟨1⟩= pos⟨2⟩
K + start⟨1⟩ hist⟨1⟩→pos⟨2⟩−pos⟨1⟩=
2(K −(hd(hist⟨1⟩) −start⟨1⟩)),
where hd(hist) is the ﬁrst element (the head) of the non-empty list hist. The last two
conditions model the two cases. If the ﬁrst walk has already visited K + start⟨1⟩, the
walks have already met under the coupling and they must have the same position.
Otherwise, the walks have not met. If d ≜hd(hist⟨1⟩) −start⟨1⟩is the (signed)
distance the ﬁrst walk has moved away from its starting location and the two walks
are initially 2K apart, then the current distance between coupled positions must be
2(K −d).
To show the invariant is preserved, we perform a case analysis with [Case]. If
K +start⟨1⟩∈hist⟨1⟩holds then the walks have already met in the past and currently
have the same position (by Θ). So, we select the identity coupling in [Sample]:
Sample
f = id
⊢r
$←Flip ∼r
$←Flip : K + start⟨1⟩∈hist⟨1⟩=⇒r⟨1⟩= r⟨2⟩.
Since K + start⟨1⟩∈hist⟨1⟩→pos⟨1⟩= pos⟨2⟩holds at the start of the loop,
we know pos⟨1⟩= pos⟨2⟩at the end of the loop; since K + start⟨1⟩∈hist⟨1⟩is
preserved by the loop body, the invariant Θ holds.
Otherwise if K + start⟨1⟩ h⟨1⟩, then the walks have not yet met and should be
mirrored. So, we select the negation coupling with f = ¬ in [Sample]:
Sample
f = ¬
⊢r
$←Flip ∼r
$←Flip : K + start⟨1⟩ hist⟨1⟩=⇒¬r⟨1⟩= r⟨2⟩
To show the loop invariant, there are two cases. If K + start⟨1⟩∈h⟨1⟩holds
after the body, the two walks have just met for the ﬁrst time and pos⟨1⟩= pos⟨2⟩
holds. Otherwise, the walks remain mirrored: pos⟨1⟩increased by r⟨1⟩and pos⟨2⟩
decreased by r⟨1⟩, so pos⟨2⟩−pos⟨1⟩= 2(K + (hd(hist⟨1⟩) −start⟨1⟩)) and the
invariant Θ is preserved.
Putting it all together, we have the desired judgment:
⊢rwalk ∼rwalk : start⟨2⟩−start⟨1⟩=2K =⇒K+start⟨1⟩∈h⟨1⟩→pos⟨1⟩=pos⟨2⟩.
While this judgment describes a coupling between the position distributions, we
need to analyze ﬁner properties of the coupling distribution to apply Theorem 5.16 -
namely, we must bound the probability that pos⟨1⟩is not equal to pos⟨2⟩. We will
consider how to extract this information in the next chapter.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

176
Barthe and Hsu: Probabilistic Couplings from Program Logics
5.6.4 Verifying non-relational properties: independence and uniformity
As we have seen, couplings are a natural ﬁt for probabilistic relational properties.
Properties describing a single program can also be viewed relationally in some cases,
enabling cleaner proofs by coupling. Barthe et al. (2017b) develop this idea to prove
uniformity, probabilistic independence, and conditional independence, examples of
probabilistic non-relational properties. We brieﬂy sketch their main reductions.
A uniform distribution places equal probability on every value in some range.
Given a distribution μ over State and an expression e with ﬁnite range S (say, the
booleans), e is uniform in μ if for all a and a′ in S, we have
Pr
m∼μ[[[e]]m = a] = Pr
m∼μ[[[e]]m = a′].
When μ is the output distribution of a program c, uniformity follows from the pRHL
judgment
∀a,a′ ∈S, ⊢c ∼c : (=) =⇒e⟨1⟩= a ↔e⟨2⟩= a′.
This reduction is a direct consequence of Theorem 5.12. Moreover, the resulting
judgment is ideally suited to relational veriﬁcation since it relates two copies of the
same program c.
Handling independence is only a bit more involved. Given a distribution μ
and expressions e,e′ with ranges S and S′, we say e and e′ are probabilistically
independent if for all a ∈S and a′ ∈S′, we have
Pr
m∼μ[[[e]]m = a ∧[[e′]]m = a′] = Pr
m∼μ[[[e]]m = a] · Pr
m∼μ[[[e′]]m = a′].
This useful property roughly implies that properties involving e and e′ can be
analyzed by focusing on e and e′ separately. When e and e′ are uniformly distributed,
independence follows from uniformity of the tuple (e,e′) over the product set S × S′
so the previous reduction applies. In general, we can compare the distributions of
e and e′ in two experiments: when both are drawn from the output distribution
of a single execution, and when they are drawn from two independent executions
composed sequentially. If the expressions are independent, these two experiments
should look the same. Concretely, independence follows from the relational judgment
∀a ∈S,a′ ∈S′, ⊢c ∼c(1); c(2) : Φ =⇒e⟨1⟩= a ∧e′⟨1⟩= a′ ↔
e(1)⟨2⟩= a ∧e′(2)⟨2⟩= a′,
where c(1) and c(2) are copies of c with variables x renamed to x(1) and x(2)
respectively; this construction is also called self-composition since it sequentially
composes c with itself (Barthe et al., 2011). The pre-condition Φ states that the
three copies of each variable are initially equal: x⟨1⟩= x(1)⟨2⟩= x(2)⟨2⟩. Handling
conditional independence requires a slightly more complex encoding, but the general
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

5.7 Related work
177
pattern remains the same: encode products of probabilities by self-composition and
equalities by lifted equivalence (↔)♯.
These reductions give a simple method to prove uniformity and independence.
Other non-relational properties could beneﬁt from a similar approach, especially
in conjunction with more sophisticated program transformations in pRHL to relate
diﬀerent copies of the same sampling instruction. Albarghouthi and Hsu (2018a)
consider how to automatically construct such coupling proofs by program synthesis
and veriﬁcation techniques.
5.7 Related work
Relational Hoare logics and probabilistic couplings have been extensively studied
and (re)discovered in various research communities.
5.7.1 Relational Hoare logics
The logic pRHL is a prime example of a relational program logic, which extend
standard Floyd-Hoare logics to prove properties about two programs. Benton (2004)
ﬁrst designed a relational version of Hoare logic called RHL to prove equivalence
between two (deterministic) programs. Benton used his logic to verify compiler
transformations, showing the original program is equivalent to the transformed
program. Relational versions of other program logics have also been considered,
including an extension of separation logic by Yang (2007) to prove relational
properties of pointer-manipulating programs. There is nothing particularly special
about relating exactly two programs; recently, Sousa and Dillig (2016) give a Hoare
logic for proving properties of k executions of the same program for arbitrary k.
Barthe et al. (2017a) give an extended logic ×pRHL where judgments also include
probabilistic product program simulating two coupled runs of the related programs;
in a sense, coupling proofs are probabilistic product programs.
Barthe et al. (2009) extended Benton's work to prove relational properties of
probabilistic programs, leading to the logic pRHL. As we have seen, the key
technical insight is to interpret the relational post-condition as a probabilistic lifting
between two output distributions. Barthe et al. (2009) used pRHL to verify security
properties for a variety of cryptographic constructions by mimicking the so-called
game-hopping proof technique (Shoup, 2004; Bellare and Rogaway, 2006), where
the original program is transformed step-by-step to an obviously secure version (e.g.,
a program returning a random number). Security follows if each transformation
approximately preserves the program semantics. Our analysis of the XOR cipher is
a very simple example of this technique; more sophisticated proofs chain together
dozens of transformations.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

178
Barthe and Hsu: Probabilistic Couplings from Program Logics
5.7.2 Probabilistic couplings and liftings
Couplings are a well-studied tool in probability theory; readers can consult the
lecture notes by Lindvall (2002) or the textbooks by Thorisson (2000) and Levin
et al. (2009) for entry points into this vast literature.
Probabilistic liftings were also considered in connection with probabilistic
bisimulation, a powerful technique for proving equivalence of probabilistic transition
systems. Larsen and Skou (1991) were the ﬁrst to consider a probabilistic notion of
bisimulation. Roughly speaking, their deﬁnition considers an equivalence relation
E on states and requires that any two states in the same equivalence class have
the same probability of stepping to any other equivalence class. The construction
for arbitrary relations arose soon after, when researchers generalized probabilistic
bisimulation to probabilistic simulation; Jonsson and Larsen (1991, Deﬁnition 4.3)
proposes a satisfaction relation using witness distributions, similar to the deﬁnition
used in pRHL. Desharnais (1999, Deﬁnition 3.6.2) and Segala and Lynch (1995,
Deﬁnition 12) give an alternative characterization without witness distributions,
similar to Strassen's theorem (Strassen, 1965); Desharnais (1999, Theorem 7.3.4)
observed that both deﬁnitions are equivalent in the ﬁnite case via the max ﬂow-min
cut theorem. Probabilistic (bi)simulation can be characterized logically, i.e., two
systems are (bi)similar if and only if they satisfy the same formulas in some modal
logic (Larsen and Skou, 1991; Desharnais et al., 2002, 2003; Fijalkow et al., 2017).
Deng and Du (2011) survey logical, metric, and algorithmic characterizations of
these relations.
While proofs by bisimulation and proofs by coupling are founded on the same
mathematical concept, they have been applied to diﬀerent kinds of target properties.
Veriﬁcation techniques based on bisimulation, for instance, typically focus on
possibly large, but ﬁnite state systems. In this setting, there are many algorithmic
techniques known for constructing these proofs. On the other hand, the main strength
of proofs by coupling is that by describing a binary relation between states using a
logical formula, the proof technique directly extends to inﬁnite state systems and
systems with unknown parameters. At the same time, it appears that the coupling
proof technique requires enough structure on the states in order to express possibly
inﬁnite relations with a compact logical formula. In contrast to the well-established
algorithmic techniques for bisimulation, there has been little research to date on
automating proofs of coupling (Albarghouthi and Hsu, 2018a,b). This direction
deserves further exploration.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

5.7 Related work
179
5.7.3 Approximate couplings and diﬀerential privacy
Diﬀerential privacy is a recent, statistical notion of privacy for database queries,
proposed by Dwork et al. (2006). This property is essentially a form of sensitivity:
pairs of similar input databases should lead to pairs of indistinguishable output
distributions. Inspired by pRHL, Barthe et al. (2013) developed an approximate
version of the program logic called apRHL to verify this property. The logic apRHL
relies on a probabilistic notion of relation lifting but unlike pRHL, this lifting is
approximate in a quantitative sense—it approximately models two given distributions
with a joint distribution.4 Much like for probabilistic couplings, the existence of an
approximate lifting with a particular support relating two distributions can imply
relational properties about the two distributions. For instance, the approximate lifting
of the equality relation relates pairs of indistinguishable distributions.
Approximate liftings can be fruitfully viewed as an approximate generalization of
probabilistic coupling. Moreover, the proof rules in apRHL immediately suggest
a clean method to build approximate couplings. Informally, we can construct
approximate couplings much like regular probabilistic couplings, while keeping
track of two numeric approximation parameters (ϵ,δ) on the side. To reason about
pairs of sampling instructions, we can apply any approximate coupling of the two
primitive distributions if we increment (ϵ,δ) by the parameters of the selected
coupling; in this way, we can think of (ϵ,δ) as kind of a cost that must be paid in
order to apply approximate couplings. This idea enables new proofs of diﬀerential
privacy by coupling, conceptually simpler and more amenable to formal veriﬁcation
than existing arguments (Barthe et al., 2016b,a). The interested reader can consult
the thesis (Hsu, 2017) for more on the theory and applications of approximate
couplings.
5.7.4 Expectation couplings and the Kantorovich metric
Probabilistic couplings and approximate probabilistic couplings apply to distributions
over sets. In some cases, the ground sets may naturally come with a notion of distance.
For instance, programs may generate distributions over the real numbers (or vectors)
with the Euclidean distance. A classical way of comparing such distributions is with
the Kantorovich metric, which lifts a distance on the ground space to a distance on
distributions over the ground space. This metric is closely related to probabilistic
couplings—one way to deﬁne the Kantorovich metric is as the minimum average
distance over all couplings of the two given distributions. By constructing speciﬁc
couplings and reasoning about the expected distance, we can upper-bound the
4 There are several deﬁnitions of approximate relation lifting (Barthe and Olmedo, 2013; Olmedo, 2014; Sato,
2016; Albarghouthi and Hsu, 2018b); many of which can be shown equivalent (Barthe et al., 2017c).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

180
References
Kantorovich metric between two output distributions and derive ﬁner relational
properties of probabilistic programs. Barthe et al. (2018b) develop a program logic
EpRHL extending pRHL to carry out this kind of reasoning, and establish quantitative
relational properties including algorithmic stability of machine learning algorithms
and rapid mixing of Markov chains.
References
Albarghouthi, Aws, and Hsu, Justin. 2018a. Constraint-Based Synthesis of Coupling
Proofs. In: International Conference on Computer Aided Veriﬁcation (CAV),
Oxford, England. To appear.
Albarghouthi, Aws, and Hsu, Justin. 2018b. Synthesizing Coupling Proofs of
Diﬀerential Privacy. Proceedings of the ACM on Programming Languages,
2(POPL). Appeared at ACM SIGPLAN-SIGACT Symposium on Principles
of Programming Languages (POPL), Los Angeles, California.
Aldous, David. 1983. Random Walks on Finite Groups and Rapidly Mixing Markov
Chains. Pages 243-297 of: Séminaire de Probabilités XVII 1981/82. Lecture
Notes in Mathematics, vol. 986. Springer-Verlag.
Apt, Krzysztof R. 1981. Ten Years of Hoare's Logic: A Survey-Part I. ACM
Transactions on Programming Languages and Systems, 3(4), 431-483.
Apt, Krzysztof R. 1983. Ten years of Hoare's logic: A survey-Part II: Nondetermin-
ism. Theoretical Computer Science, 28(1), 83-109.
Barthe, Gilles, and Olmedo, Federico. 2013. Beyond Diﬀerential Privacy: Composi-
tion Theorems and Relational Logic for f -Divergences between Probabilistic
Programs. Pages 49-60 of: International Colloquium on Automata, Languages
and Programming (ICALP), Riga, Latvia. Lecture Notes in Computer Science,
vol. 7966. Springer-Verlag.
Barthe, Gilles, Grégoire, Benjamin, and Zanella-Béguelin, Santiago. 2009. Formal
Certiﬁcation of Code-Based Cryptographic Proofs. Pages 90-101 of: ACM
SIGPLAN-SIGACT Symposium on Principles of Programming Languages
(POPL), Savannah, Georgia.
Barthe, Gilles, D'Argenio, Pedro R., and Rezk, Tamara. 2011. Secure Information
Flow by Self-Composition. Mathematical Structures in Computer Science,
21(06), 1207-1252.
Barthe, Gilles, Köpf, Boris, Olmedo, Federico, and Zanella-Béguelin, Santiago. 2013.
Probabilistic Relational Reasoning for Diﬀerential Privacy. ACM Transactions
on Programming Languages and Systems, 35(3), 9:1-9:49.
Barthe, Gilles, Fong, Noémie, Gaboardi, Marco, Grégoire, Benjamin, Hsu, Justin,
and Strub, Pierre-Yves. 2016a. Advanced Probabilistic Couplings for Diﬀer-
ential Privacy. Pages 55-67 of: ACM SIGSAC Conference on Computer and
Communications Security (CCS), Vienna, Austria. There is an error in the
treatment of advanced composition; please see my thesis for the correction.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
181
Barthe, Gilles, Gaboardi, Marco, Grégoire, Benjamin, Hsu, Justin, and Strub, Pierre-
Yves. 2016b. Proving Diﬀerential Privacy via Probabilistic Couplings. Pages
749-758 of: IEEE Symposium on Logic in Computer Science (LICS), New York,
New York.
Barthe, Gilles, Grégoire, Benjamin, Hsu, Justin, and Strub, Pierre-Yves. 2017a.
Coupling Proofs Are Probabilistic Product Programs. Pages 161-174 of: ACM
SIGPLAN-SIGACT Symposium on Principles of Programming Languages
(POPL), Paris, France.
Barthe, Gilles, Espitau, Thomas, Grégoire, Benjamin, Hsu, Justin, and Strub, Pierre-
Yves. 2017b. Proving Uniformity and Independence by Self-Composition
and Coupling. Pages 385-403 of: International Conference on Logic for
Programming, Artiﬁcial Intelligence and Reasoning (LPAR), Maun, Botswana.
EPiC Series in Computing, vol. 46.
Barthe, Gilles, Espitau, Thomas, Hsu, Justin, Sato, Tetsuya, and Strub, Pierre-Yves.
2017c. ⋆-Liftings for Diﬀerential Privacy. Pages 102:1-102:12 of: International
Colloquium on Automata, Languages and Programming (ICALP), Warsaw,
Poland. Leibniz International Proceedings in Informatics, vol. 80. Schloss
Dagstuhl-Leibniz Center for Informatics.
Barthe, Gilles, Espitau, Thomas, Gaboardi, Marco, Grégoire, Benjamin, Hsu,
Justin, and Strub, Pierre-Yves. 2018a. An Assertion-Based Program Logic for
Probabilistic Programs. In: European Symposium on Programming (ESOP),
Thessaloniki, Greece.
Barthe, Gilles, Espitau, Thomas, Grégoire, Benjamin, Hsu, Justin, and Strub,
Pierre-Yves. 2018b. Proving Expected Sensitivity of Probabilistic Programs.
Proceedings of the ACM on Programming Languages, 2(POPL). Appeared
at ACM SIGPLAN-SIGACT Symposium on Principles of Programming
Languages (POPL), Los Angeles, California.
Bellare, Mihir, and Rogaway, Phillip. 2006. The Security of Triple Encryption
and a Framework for Code-Based Game-Playing Proofs. Pages 409-426 of:
IACR International Conference on the Theory and Applications of Crypto-
graphic Techniques (EUROCRYPT), Saint Petersburg, Russia. Lecture Notes
in Computer Science, vol. 4004. Springer-Verlag.
Benton, Nick. 2004. Simple Relational Correctness Proofs for Static Analyses
and Program Transformations. Pages 14-25 of: ACM SIGPLAN-SIGACT
Symposium on Principles of Programming Languages (POPL), Venice, Italy.
Callahan, David, and Kennedy, Ken. 1988. Compiling Programs for Distributed-
Memory Multiprocessors. The Journal of Supercomputing, 2(2), 151-169.
Chatterjee, Krishnendu, Fu, Hongfei, Novotný, Petr, and Hasheminezhad, Rouzbeh.
2016a. Algorithmic Analysis of Qualitative and Quantitative Termination
Problems for Aﬃne Probabilistic Programs. Pages 327-342 of: ACM SIGPLAN-
SIGACT Symposium on Principles of Programming Languages (POPL), Saint
Petersburg, Florida.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

182
References
Chatterjee, Krishnendu, Fu, Hongfei, and Goharshady, Amir Kafshdar. 2016b.
Termination Analysis of Probabilistic Programs through Positivstellensatz's.
Pages 3-22 of: International Conference on Computer Aided Veriﬁcation
(CAV), Toronto, Ontario. Lecture Notes in Computer Science, vol. 9779.
Springer-Verlag.
Chatterjee, Krishnendu, Novotný, Petr, and Žikelić, D. 2017. Stochastic Invariants
for Probabilistic Termination. Pages 145-160 of: ACM SIGPLAN-SIGACT
Symposium on Principles of Programming Languages (POPL), Paris, France.
Deng, Yuxin, and Du, Wenjie. 2011 (March). Logical, Metric, and Algorithmic
Characterisations of Probabilistic Bisimulation. Tech. rept. CMU-CS-11-110.
Carnegie Mellon University.
Desharnais, Josée. 1999.
Labelled Markov Processes.
Ph.D. thesis, McGill
University.
Desharnais, Josée, Edalat, Abbas, and Panangaden, Prakash. 2002. Bisimulation for
Labelled Markov Processes. Information and Computation, 179(2), 163-193.
Desharnais, Josée, Gupta, Vineet, Jagadeesan, Radha, and Panangaden, Prakash.
2003. Approximating Labelled Markov Processes. Information and Computa-
tion, 184(1), 160-200.
Dijkstra, Edsger W. 1976. A Discipline of Programming. Series in Automatic
Computation. Prentice Hall.
Dwork, Cynthia, McSherry, Frank, Nissim, Kobbi, and Smith, Adam D. 2006.
Calibrating Noise to Sensitivity in Private Data Analysis. Pages 265-284 of:
IACR Theory of Cryptography Conference (TCC), New York, New York. Lecture
Notes in Computer Science, vol. 3876. Springer-Verlag.
Ferrer Fioriti, Luis María, and Hermanns, Holger. 2015. Probabilistic Termination:
Soundness, Completeness, and Compositionality. Pages 489-501 of: ACM
SIGPLAN-SIGACT Symposium on Principles of Programming Languages
(POPL), Mumbai, India.
Fijalkow, Nathanaël, Klin, Bartek, and Panangaden, Prakash. 2017. Expressiveness of
Probabilistic Modal Logics, Revisited. Pages 105:1-105:12 of: Chatzigiannakis,
Ioannis, Indyk, Piotr, Kuhn, Fabian, and Muscholl, Anca (eds), International
Colloquium on Automata, Languages and Programming (ICALP), Warsaw,
Poland. Leibniz International Proceedings in Informatics, vol. 80. Dagstuhl,
Germany: Schloss Dagstuhl-Leibniz Center for Informatics.
Floyd, Robert W. 1967. Assigning Meanings to Programs. In: Symposium on
Applied Mathematics. American Mathematical Society.
Hoare, Charles A. R. 1969. An Axiomatic Basis for Computer Programming.
Communications of the ACM, 12(10), 576-580.
Hsu, Justin. 2017. Probabilistic Couplings for Probabilistic Reasoning. Ph.D. thesis,
University of Pennsylvania.
Jones, CliﬀB. 2003. The Early Search for Tractable Ways of Reasoning about
Programs. Annals of the History of Computing, 25(2), 26-49.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
183
Jonsson, Bengt, and Larsen, Kim Guldstrand. 1991. Speciﬁcation and Reﬁnement
of Probabilistic Processes. Pages 266-277 of: IEEE Symposium on Logic in
Computer Science (LICS), Amsterdam, The Netherlands.
Kleinberg, Jon, and Tardos, Eva. 2005. Algorithm Design. Addison-Wesley.
Kozen, Dexter. 1981. Semantics of Probabilistic Programs. Journal of Computer
and System Sciences, 22(3), 328-350.
Larsen, Kim Guldstrand, and Skou, Arne. 1991. Bisimulation through Probabilistic
Testing. Information and Computation, 94(1), 1-28.
Levin, David A., Peres, Yuval, and Wilmer, Elizabeth L. 2009. Markov Chains and
Mixing Times. American Mathematical Society.
Lindvall, Torgny. 2002. Lectures on the Coupling Method. Courier Corporation.
McIver, Annabelle, Morgan, Carroll, Kaminski, Benjamin Lucien, and Katoen,
Joost-Pieter. 2018. A new proof rule for almost-sure termination. Proceedings
of the ACM on Programming Languages, 2(POPL), 33:1-33:28.
O'Hearn, Peter W. 2007. Resources, Concurrency, and Local Reasoning. Theoretical
Computer Science, 375(1), 271-307. Festschrift for John C. Reynolds's 70th
birthday.
O'Hearn, Peter W., Reynolds, John C., and Yang, Hongseok. 2001. Local Reasoning
about Programs That Alter Data Structures. Pages 1-19 of: International
Workshop on Computer Science Logic (CSL), Paris, France. Lecture Notes in
Computer Science, vol. 2142. Springer-Verlag.
Olmedo, Federico. 2014. Approximate Relational Reasoning for Probabilistic
Programs. Ph.D. thesis, Universidad Politécnica de Madrid.
Reynolds, John C. 2001. Intuitionistic Reasoning about Shared Mutable Data
Structure. Millennial Perspectives in Computer Science, 2(1), 303-321.
Reynolds, John C. 2002. Separation Logic: A Logic for Shared Mutable Data
Structures. Pages 55-74 of: IEEE Symposium on Logic in Computer Science
(LICS), Copenhagen, Denmark.
Rudin, Walter. 1976. Principles of Mathematical Analysis. Third edn. International
Series in Pure and Applied Mathematics. McGraw-Hill.
Sato, Tetsuya. 2016. Approximate Relational Hoare Logic for Continuous Random
Samplings. In: Conference on the Mathematical Foundations of Programming
Semantics (MFPS), Pittsburgh, Pennsylvania.
Segala, Roberto, and Lynch, Nancy A. 1995. Probabilistic Simulations for Proba-
bilistic Processes. Nordic Journal of Computing, 2(2), 250-273.
Shoup, Victor. 2004. Sequences of Games: A Tool for Taming Complexity in Security
Proofs. Cryptology ePrint Archive, Report 2004/332.
Sousa, Marcelo, and Dillig, Isil. 2016. Cartesian Hoare Logic for Verifying k-Safety
Properties. Pages 57-69 of: ACM SIGPLAN Conference on Programming
Language Design and Implementation (PLDI), Santa Barbara, California.
Strassen, Volker. 1965. The Existence of Probability Measures with Given Marginals.
The Annals of Mathematical Statistics, 423-439.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

184
References
Thorisson, Hermann. 2000. Coupling, Stationarity, and Regeneration. Springer-
Verlag.
Yang, Hongseok. 2007. Relational Separation Logic. Theoretical Computer Science,
375(1), 308-334. Festschrift for John C. Reynolds's 70th birthday.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

6
Expected Runtime Analysis
by Program Veriﬁcation
Benjamin Lucien Kaminski, Joost-Pieter Katoen and Christoph Matheja
RWTH Aachen University
Abstract:
This chapter is concerned with analysing the expected runtime of
probabilistic programs by exploiting program veriﬁcation techniques. We intro-
duce a weakest pre-conditioning framework à la Dijkstra that enables to determine
the expected runtime in a compositional manner. Like weakest pre-conditions, it
is a reasoning framework at the syntax level of programs. Applications of the
weakest pre-conditioning framework include determining the expected runtime
of randomised algorithms, as well as determining whether a program is positive
almost-surely terminatiing, i.e., whether the expected number of computation steps
until termination is ﬁnite for every possible input. For Bayesian networks, a re-
stricted class of probabilistic programs, we show that the expected runtime analysis
can be fully automated. In this way, the simulation time under rejection sampling
can be determined. This is in particular useful for ill-conditioned inference queries.
6.1 Introduction
In 1976, Michael Rabin published his paper titled Randomized Algorithms in which
he describes a method for solving the closest-pair problem in computational geom-
etry (Rabin, 1976). This work is today considered the seminal paper on randomized
algorithms (Smid, 2000). While a naïve deterministic brute-force approach takes
quadratic time, Rabin's randomized algorithm solves the closest-pair problem in
expected linear time.
One year later, in 1977, Robert Solovay and Volker Strassen presented a ran-
domized primality test that decides in polynomial time whether a given number
is either composite or probably prime, thus proving that primality testing is in
the complexity class coRP (Solovay and Strassen, 1977). In 1992, Leonard Adle-
man and Ming-Deh Huang further reduced the complexity of primality testing
a From Foundations of Probabilistic Programming, edited by Gilles Barthe, Joost-Pieter Katoen and Alexandra
Silva published 2020 by Cambridge University Press.
185
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

186
Kaminski, Katoen and Matheja: Expected Runtime Analysis
to ZPP, thus proving that primality testing can be solved eﬃciently in expecta-
tion (Adleman and Huang, 1992). Turning an ineﬃcient deterministic algorithm
into a randomized algorithm that is - in expectation - more eﬃcient (possibly at
the cost of incorrect results, though with low probability) is a principal motivation
of introducing randomization into the computation. Prime examples are Freivalds'
matrix multiplication veriﬁcation (Freivalds, 1979) or Hoare's variant of quicksort
with random pivot selection (Hoare, 1962). Some problems even inherently require
randomized solutions such as various self-stabilization algorithms in anonymous
distributed systems.
Probabilistic programs are, however, not limited to randomized algorithms. In
fact, they are a powerful modeling formalism for describing, amongst others, graph-
ical models, such as Bayesian networks or Markov random ﬁelds (Koller and Fried-
man, 2009). This lead to the emergence of probabilistic programming (Gordon et al.,
2014) as a new paradigm for probabilistic modeling. A key feature of probabilistic
programming languages is that they decouple individual models from algorithms
for their analysis, e.g. Bayesian inference techniques. For example, one of the ﬁrst
approaches to perform inference on probabilistic programs ﬁrst compiles a pro-
gram into a Bayesian network and then applies standard techniques for graphical
models (Minka and Winn, 2017). Probabilistic programming also enables to resort
to established program analysis techniques, such as slicing (Hur et al., 2014), to
optimize probabilistic models. In this context, analyzing expected runtimes, i.e. the
expected time required for sampling from a complex probability distribution de-
scribed by a probabilistic program, to speed up inference algorithms is of paramount
importance, too.
Reasoning about expected runtimes of probabilistic programs is surprisingly
subtle and full of nuances as we will discuss in detail in this chapter. Thus, there
is a desire for a formal veriﬁcation technique suited for reasoning about expected
runtimes. The main objective of this chapter is to provide a gentle introduction
to one particular formal method for analyzing expected runtimes of probabilistic
programs: The expected runtime calculus. This approach was originally developed
in Kaminski et al. (2016) and was further studied in Olmedo et al. (2016); Batz
et al. (2018); Kaminski et al. (2018b); Kaminski (2019). The calculus is a weakest-
precondition style calculus à la Dijkstra (see Dijkstra, 1976) to derive runtime
assertions. In a similar vein to Dijkstra's predicate transformers, our calculus uses
runtime transformers. Its core is the expected runtime transformer ert:
ert[c](t)(σ)
captures the expected runtime of program c when started in initial state σ. The
t appearing above is the so-called postruntime: t is a function mapping program
states to non-negative reals and captures the expected runtime of the computation
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

6.1 Introduction
187
following program c. It is hence evaluated in the ﬁnal states reached after termination
of c on σ. In particular, this subsumes the plain expected runtime of program c on
initial state σ if t is the constantly zero runtime. For most control structures, ert is
deﬁned in a straightforward compositional manner. The action of the transformer
on loops is given using ﬁxed-point techniques. To avoid the tedious reasoning about
such ﬁxed points and to enhance the calculus' usability, we provide invariant-based
proof rules that establish bounds on the expected runtime of loops.
A notable feature of the ert-calculus is that it ﬁrmly builds upon standard tech-
niques from formal semantics and program veriﬁcation - in particular denotational
semantics, ﬁxed point theory, and invariants. It provides a useful abstraction from
the semantical intricacies of probabilistic programs and the underlying probability
theory. ert thus enables writing elegant and compositional proofs to bound ex-
pected runtimes (from above and below) on source code level. Furthermore, the
reliance on standard techniques makes ert amenable to a large degree of automa-
tion. The ert-calculus yields comprehensible proofs for the expected runtime of
complex randomized algorithms. For instance, it has been successfully applied
to analyze the Coupon Collector's problem (Kaminski et al., 2016), a Sherwood
binary search (Olmedo et al., 2016), and expected sampling times in Bayesian
networks (Batz et al., 2018). The latter can be derived fully automatically.
Ngo et al. (2018) have developed an automatic approach for deriving polynomial
runtime bounds, using our ert calculus as an underlying theoretical framework for
proving soundness of their approach. The ert calculus has also been mechanized in
the interactive theorem prover Isabelle/HOL by Hölzl (2016). In particular, Hölzl
proved that our calculus is indeed sound and complete and that our proof rules for
deriving runtime bounds are correct.
A second asset is that ert enables determining whether the expected runtime
of a randomized algorithm (for all possible inputs) is ﬁnite or not. To the best
of our knowledge, this is the ﬁrst formal veriﬁcation framework that can handle
both almost-sure termination (does a program terminate with probability one?) and
positive almost-sure termination (does a program terminate within ﬁnite expected
time?). The universal positive almost-sure termination problem is complete for level
Π0
3 of the arithmetical hierarchy (Kaminski and Katoen, 2015) and hence strictly
harder to decide than the universal halting problem for deterministic programs
(which is Π0
2-complete).
Organization of this chapter. We describe a simple probabilistic programming
language in Section 6.2. In Section 6.3, we then present challenges and phenom-
ena encountered when reasoning about expected runtimes. The expected runtime
calculus and our proof rules for loops are presented in Section 6.4. An application
of our calculus to the automated analysis of expected sampling times of Bayesian
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

188
Kaminski, Katoen and Matheja: Expected Runtime Analysis
networks is presented in Section 6.6. Finally, in Section 6.7, we conclude with a
discussion of recent research directions.
6.2 Probabilistic Programs
In this chapter, we consider probabilistic programs written in a simple probabilistic
extension of Dijkstra's Guarded Command Language (GCL) (Dijkstra, 1976). To
that end, we extend GCL with random assignments. Let us brieﬂy go over the
statements in the resulting probabilistic Guarded Command Language (pGCL) by
means of small examples. Furthermore, since we want to reason about (expected)
runtimes of pGCL programs, we also discuss our underlying runtime model, i.e.
the time consumed by each pGCL statement. Our pGCL programs adhere to the
grammar
C
−→
empty | x :≈μ | C; C
| if (ϕ) {C} else {C}
| {c1} □{c2}
| while (ϕ) {C}
where empty is a program that has no eﬀect and consumes no time, x is a program
variable, μ represents a (discrete) probability distribution, and ϕ a Boolean expres-
sion. We now go over the language constructs and the runtime model. For more
details, in particular on an operational semantics capturing our runtime model,
please refer toKaminski et al. (2016).
Random assignments. The key feature of pGCL is the ability to sample values
from a (discrete) probability distribution, say μ, and assign the sampled value to a
program variable, say x. The corresponding pGCL statement is a random assignment
of the form
x :≈μ .
For example, the random assignment
heads :≈1/3 · ⟨true⟩+ 2/3 · ⟨false⟩
simulates a biased coin ﬂip: With probability 1/3 the value true is assigned to
variable heads and with the remaining probability, i.e. 2/3, the value false is assigned,
respectively. The right-hand side of a random assignment may be any (computable)
discrete probability distribution over the set of possible values of a variable. In
particular, we allow probability distributions to depend on the current program state,
i.e. an evaluation of all program variables. For instance, the random assignment
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

6.2 Probabilistic Programs
189
y :≈uniform(0, x) samples from a (discrete) uniform distribution over the range
from 0 to the current value stored in variable x and assigns the thereby obtained
value to variable y. Notice that deterministic assignments, such as x :≈x + 1, are
a special case in which a probability of one is assigned to a single value.
In our runtime model, every random assignment consumes one unit of time. Note
that this is a design choice in order to keep the calculus we are going to present as
clean and simple as possible. It is unproblematic to assume a more nuanced runtime
model for random assignments. The same holds for the runtimes we associate with
the other language constructs below.
Control ﬂow. pGCL is equipped with standard control ﬂow constructs for sequen-
tial composition, conditional choices, and loops:
• The sequential composition c1; c2 ﬁrst executes program c1 and then executes
program c2. The composition operation itself consumes no time.
• The conditional choice if (ϕ) {c1} else {c2} executes c1 if the (deterministic)
guard ϕ evaluates to true and c2 if ϕ evaluates to false, respectively. The guard
evaluation consumes one unit of time.
• The loop while (ϕ) {c} keeps executing the loop body c as long as the guard
ϕ evaluates to true at the loop head. If the guard evaluates to false, the loop
terminates. Every guard evaluation consumes one unit of time.
Let us consider the following probabilistic program inspired by Chakarov and
Sankaranarayanan (2013):
h :≈0; t :≈30;
while (h ≤t) {
c :≈1/2 ·⟨true⟩+ 1/2 ·⟨false⟩;
if (c = true) {
h :≈h + uniform[0 . . . 10]
} else {empty};
t :≈t + 1
} .
Here, empty is a pGCL statement representing the empty program, i.e. the statement
has no eﬀect and consumes no time. The example models a race between a tortoise
and a hare; the variables t and h represent their respective positions. The tortoise
starts with a lead of 30 and advances one step in each round, i.e. each loop iteration.
The hare with probability 1/2 advances a random number of steps between 0 and 10
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

190
Kaminski, Katoen and Matheja: Expected Runtime Analysis
(governed by a uniform distribution) and with the remaining probability remains
still. The race ends when the hare passes the tortoise.
Regarding the runtime, the program requires two units of time for the initial
assignments. In every loop iteration, the program consumes either four or ﬁve units
of time: It always takes one unit of time to evaluate the loop guard, ﬂip a coin,
evaluate the conditional, and to update variable t, respectively. If the conditional
is evaluated to true, an additional unit of time is consumed to update the value of
variable h.
Nondeterminism. Apart from sampling from a known distribution, pGCL also
supports true nondeterminism: The statement {c1} □{c2} represents a nondeter-
ministic choice between programs c1 and c2, i.e. either c1 or c2 is executed, but
there is no probability distribution underlying the choice between the two programs.
Similarly to sequential composition, a nondeterministic choice itself consumes no
additional time in our runtime model.
As an example, consider the program
{x :≈3} □{x :≈5} ;
while (x > 0) {
x :≈x −1
} .
This program has two possible executions: One execution initially assigns 3 to x
and has a runtime of 8 units of time. The other execution initially assigns 5 to x and
has a runtime of 12 units of time. When reasoning about the expected runtime of
a pGCL program, we resolve nondeterminism by a demonic scheduler (cf. McIver
and Morgan, 2004; Dijkstra, 1976). That is, nondeterministic choices are resolved
in a way that maximizes the runtime. In the above example, this means that the
nondeterministic choice is resolved such that 5 is assigned to x. Strictly speaking,
we thus reason about worst-case expected runtimes.
Remark on the runtime model. We stress that the runtime model presented in this
section is one particular design choice for the sake of concreteness. It is straight-
forward to adapt our approach to alternative runtime models, where, for example,
only loop iterations or assignments are considered relevant. The same holds for
alternative resolutions of nondeterminism such as using an angelic scheduler. Fur-
thermore, more ﬁne-grained models that take, for instance, the size of expressions
and distributions that appear in the random assignments into account can easily be
incorporated.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

6.3 Semantic Intricacies
191
6.3 Semantic Intricacies
Reasoning about expected runtimes of probabilistic programs is full of nuances.
Let us illustrate this by discussing a few phenomena. To this end, we consider a
fundamental property of ordinary, i.e. non-probabilistic, programs: An ordinary
program terminates, meaning all of its runs are ﬁnite, if and only if it has a ﬁnite
runtime. What is a probabilistic analog of this property when considering expected
runtimes?
Termination is too strong. A single diverging run of an ordinary program causes
its runtime to be inﬁnite. This is not the case for probabilistic programs. They may
admit arbitrarily long and even inﬁnite runs while still having a ﬁnite expected
runtime. For example, the program
cgeo :
b :≈1;
while(b = 1){
b :≈1/2 ·⟨0⟩+ 1/2 ·⟨1⟩
} .
keeps ﬂipping a fair coin until observing the ﬁrst heads (represented by 0). It admits
arbitrarily long runs, since - for every natural number n - the probability of not
seeing a heads in the ﬁrst n trials is non-zero. It even admits a non-terminating
run, namely the one in which the outcome of all coin ﬂips is tails. The runtime
of program cgeo, however, is geometrically distributed and therefore its expected
runtime is ﬁnite, even constant: On average, it terminates after two loop iterations.
The classical notion of termination for ordinary programs - all program runs
have to be ﬁnite - is thus too strong for probabilistic programs (with respect to the
considered property). In the above example, we observe that the only inﬁnite run of
program cgeo has probability zero. A more sensible notion of termination might thus
require that all inﬁnite runs of a program have probability zero. Conversely: The
probability of termination is one. This is referred to as almost-sure termination (Hart
et al., 1983). Does almost-sure termination - instead of classical termination -
capture ﬁnite expected runtimes?
Almost-sure termination is too weak. For ordinary programs, termination always
implies ﬁnite runtime. For probabilistic programs this is not always true - even if
we consider almost-surely terminating programs only. For example, consider the
program
crw :
x :≈10;
while (x > 0){
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

192
Kaminski, Katoen and Matheja: Expected Runtime Analysis
x :≈1/2 · ⟨x−1⟩+ 1/2 · ⟨x+1⟩
} ,
which models a one-dimensional random walk of a particle: Starting from position
10, in each step the particle moves randomly one step to the left or one step to
the right, until reaching position 0. The particle reaches position 0 with probability
one. The program crw thus terminates almost-surely. However, doing so requires
inﬁnitely many steps on average (cf. Ibe, 2013, Chapter 3.7.3). The expected runtime
of crw is thus inﬁnite.
Since an almost-surely terminating programmightrun- inexpectation-inﬁnitely
long, a better probabilistic analog of classical termination might be to require that
a program's expected runtime is ﬁnite. This is referred to as positive almost-sure
termination (Bournez and Garnier, 2005). In fact, having a ﬁnite expected runtime
implies almost-sure termination (Olmedo et al., 2016, Theorem 5.3). However,
there are subtle diﬀerences between classical termination and positive almost-sure
termination. From a complexity-theoretic view, it is noteworthy that the decision
problem "does a program terminate in ﬁnite expected time (on all inputs)?" is Π0
3-
complete in the arithmetical hierarchy, and thus strictly harder than the universal
halting problem for ordinary programs (Kaminski and Katoen, 2015; Kaminski
et al., 2018a).
Positive almost-sure termination is not compositional. Running two ordinary
terminating programs in sequence yields again a terminating program. Termina-
tion is thus closed under sequential composition. This is not true for probabilistic
programs when considering positive almost-sure termination. Consider the pair of
programs
c1 :
x :≈1; b :≈1;
c2 :
while(x > 0){
while(b = 1){
x :≈x −1
b :≈1/2 ·⟨0⟩+ 1/2 ·⟨1⟩;
}
x :≈2x
}
Both programs terminate positive almost-surely: As the loop in C1 terminates on
average in two iterations, it has a ﬁnite expected runtime. Furthermore, program c2
performs at most ⌈x⌉iterations for any initial value of x, i.e. its expected runtime is
ﬁnite, too. However, the composed program c1; c2 has an inﬁnite expected runtime
- even though it almost-surely terminates. This is intuitively due to the fact that
the expected value of x after termination of c1 is inﬁnite and c2 needs x steps to
terminate.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

6.4 The Expected Runtime Calculus
193
6.4 The Expected Runtime Calculus
We now present a sound and complete calculusthatenablesrigorous reasoningabout
expected runtimes of probabilistic programs. Apart from programs, the two central
objects used within our calculus are program states and runtimes. A program state
σ is an evaluation of program variables, i.e. a mapping from variables - collected in
the set Var - to possible values, such as integers or rationals, which are collected in
the set Val. A runtime is a function mapping every program state σ to a non-negative
real number or inﬁnity. Formally, the sets of program states and runtimes are given
by
Σ = {σ: Var →Val}
and
T = {t : Σ →R∞
≥0} .
Our goal is to associate with every program c a runtime t mapping every program
state σ to the average or expected runtime of executing program c on initial state σ.
To this end, we express the expected runtime of programs in a continuation-passing
style by means of the runtime transformer
ert[ · ]: pGCL →(T →T) .
The number ert[c](t)(σ) is the expected runtime of executing program c on initial
state σ assuming that t captures the runtime of the computation following c. The
ert-transformer thus applies backward reasoning. The runtime t is usually referred
to as the continuation (or postruntime) and we can think of it as being evaluated
in the ﬁnal states that are reached upon termination of c. Thus, the plain expected
runtime of executing c on initial state σ is ert[c](0)(σ), where 0 is a shortcut for
the constant runtime λσ• 0.1 In general, we write k to denote the constant runtime
λσ• k for k ∈R∞
≥0.
The ert-transformer is deﬁned by induction on the structure of pGCL programs
and adheres to our simple runtime model described in Section 6.2. That is, ert[c](0)
captures the expected number of assignments and guard evaluations. A summary
of the ert deﬁnitions is found in Table 6.1. Let us brieﬂy go over the deﬁnitions for
each pGCL statement.
Empty program. Since the empty program empty has no eﬀect on the program
state and consumes no time, the expected runtime of empty with respect to contin-
uation t corresponds to the identity, i.e.
ert[empty](t) = t .
1 We use λ-expressions to denote functions: Function λX• f applied to an argument α evaluates to f in which
every free occurrence of X is replaced by α.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

194
Kaminski, Katoen and Matheja: Expected Runtime Analysis
Table 6.1 Rules for deﬁning the expected runtime transformer ert.
c
ert [c] (t)
empty
t
x :≈μ
1 + λσ• 	
v∈Val Prμ(σ)(v) · t[x/v](σ)
c1; c2
ert[c1](ert[c2](t))
if (ϕ) {c1} else {c2}
1 + [ϕ] · ert[c1](t) + [¬ϕ] · ert[c2](t)
{c1} □{c2}
max {ert[c1](t),ert[c2](t)}
while (ϕ) {c′}
lfp Ft, where
Ft(X) = 1 + [ϕ] · ert[c′](X) + [¬ϕ] · t
Random assignment. For the random assignment x :≈μ, one unit of time is
consumed. Moreover, the remaining expected runtime represented by continuation
t has to be considered after updating t to take the possible new values of variable x
- weighted according to their probabilities - into account. Formally, we deﬁne
ert[x :≈μ](t)(σ) = 1 +

v∈Val
Prμ(σ)(v) · t σ[x/v]! ,
where Prμ(σ)(v) is the probability that - for state σ - distribution expression μ
evaluates to value v. Moreover, σ[x/v] is the program state σ in which the value
assigned to variable x is updated to v. The above deﬁnition does, unfortunately,
depend on the program state σ. If the distribution expression μ is agnostic of
the program state, we can obtain a simpler deﬁnition. To this end, we deﬁne the
"syntactic replacement" of a variable x in a runtime t by value v as t[x/v] =
λσ• t(σ[x/v]). Then, since the probability distribution μ is independent of σ,
we can write the expected runtime of the random assignment without referring
explicitly to a program state:
ert[x :≈μ](t) = 1 +

v∈Val
Prμ(v) · t[x/v]
For example, consider a biased coin ﬂip x :≈
1/3 · ⟨0⟩+ 2/3 · ⟨x + 1⟩. Since the
probability distribution does not depend on the program state, we have
ert

x :≈1/3 · ⟨0⟩+ 2/3 · ⟨x + 1⟩

(t) = 1 + 1/3 · t[x/0] + 2/3 · t[x/x + 1] .
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

6.4 The Expected Runtime Calculus
195
C2
t
ert[C2](t)
postruntime t
evaluated in ﬁnal states
after termination of C2
expected time needed to execute C2
and then let time t pass
C1
ert[C1] 
ert[C2](t)!
expected time needed to execute C1
and then let time ert[C2](t) pass
or in other words:
expected time needed to execute C1; C2
and then let time t pass
Figure 6.1 Continuation-passing style expected runtime transformer.
Sequential composition. For the composition c1; c2 of pGCL programs c1 and
c2, it becomes evident that we reason backwards: We ﬁrst determine the expected
runtime of c2 with respect to continuation t, i.e. ert[c2](t). Afterwards, we determine
the expected runtime of c1 with respect to continuation ert[c2](t). As a diagram,
the intuition behind this is depicted in Figure 6.1. Formally, we deﬁne the ert of
sequential composition as
ert[c1; c2](t) = ert[c1](ert[c2](t)) .
Conditional choice. For the conditional if(ϕ) {c1} else {c2}, one unit of time is
consumed to account for the guard evaluation. Furthermore, the expected runtime of
c1 (with respect to continuation t) is added if guard ϕ evaluates to true. Otherwise,
the expected runtime of c2 is added. The truth value of a Boolean expression ξ is
captured by the indicator function, also called Iverson bracket,
[ξ] : Σ →{0,1} ,
which, for a given state σ, evaluates to 1 if ξ evaluates to true in state σ. Otherwise,
it evaluates to 0. Using Iverson brackets, the ert of the conditional choice statement
is given by
ert

if (ϕ) {c1} else {c2}

(t) = 1 + [ϕ] · ert[c1](t) + [¬ϕ] · ert[c2](t) .
Nondeterminism. For the nondeterministic choice {c1} □{c2}, either c1 or c2
is executed. In particular, no probability distribution guiding which of the two
programs is executed is known. Since the choice itself consumes no time, the
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

196
Kaminski, Katoen and Matheja: Expected Runtime Analysis
expected runtime of {c1} □{c2} is either the expected runtime of c1 or the
expected runtime of c2. Following the "demonic nondeterminism" school of thought
(cf. McIver and Morgan, 2004; Dijkstra, 1976), we assume that the program with
the worst expected runtime will be executed, i.e. we take the maximum of both
expected runtimes. Formally, we deﬁne
ert

{c1} □{c2}

(t) = max

ert[c1](t),ert[c2](t)

.
Loops. For the loop while (ϕ) {c}, we exploit the fact that the expected runtime
of the loop coincides with the expected runtime of its unrolling
if (ϕ)

c; while (ϕ) {c}

else {empty} .
Applying ert to this program then yields (for a ﬁxed continuation t):
ert[while (ϕ) {c}](t)
= ert[if (ϕ) {c; while (ϕ) {c}} else {empty}](t)
= 1 + [ϕ] · ert[c; while (ϕ) {c}](t)
(Deﬁnition of ert)
+ [¬ϕ] · ert[empty](t)
= 1 + [ϕ] · ert[c] 
ert

while (ϕ) {c}

(t)! + [¬ϕ] · t .
(Deﬁnition of ert)
Every solution of this equation is a ﬁxed point of the transformer
Ft :
T →T,
X →1 + [ϕ] · ert[c](X) + [¬ϕ] · t ,
in which we substituted ert[while (ϕ) {c}](t) by X. In fact, as is standard in denota-
tional semantics, we are interested in the least ﬁxed point. The underlying intuition
is that, for every natural number n,
Fn
t (0) = Ft(Ft(. . . (0) . . .))
precisely captures the expected runtime when allowing at most n loop iterations.
Consequently, we approximate the expected runtime of the loop from below and
take the ﬁrst solution capturing the expected runtime for all loop iterations, i.e. the
least ﬁxed point of Ft. The least ﬁxed point of the characteristic functional Ft is
guaranteed to exist for every loop while (ϕ) {c} and every continuation t, because
T (with pointwise ordering of runtimes) is a complete lattice and Ft is continuous
(and hence also monotonic). The Kleene Fixed Point Theorem (Kleene, 1952) then
ensures by continuity that the least ﬁxed point of Ft, which we denote by lfp Ft,
exists and coincides with the limit of Fn
t (0) for n →∞. Hence, we deﬁne the
expected runtime of loop while (ϕ) {c} with respect to continuation t as
ert[while (ϕ) {c}](t) = lfp Ft =
lim
n→∞Fn
t (0) .
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

6.5 Proof Rules for Loops
197
Remark on soundness. Our expected runtime calculus is sound with respect to
a simple operational semantics based on Markov Decision Processes, where each
state corresponds to a program statement and each transition corresponds to one
execution step. The time consumed by a statement is modeled using state rewards.
More precisely, one can show that for every pGCL program c, every continuation
t and every program state σ, the expected runtime ert[c](t)(σ) coincides with
the maximal expected reward (assuming demonic nondeterminism) of the unique
Markov Decision Process corresponding to c, t, and σ as deﬁned by the operational
semantics. We refer the interested reader to Kaminski et al. (2016) for further details.
A loop-free example. Consider the program ctrunc:
c1 :
x :≈1/2 · ⟨true⟩+ 1/2 · ⟨false⟩;
c2 :
if(x = true){
c3 :
x :≈1/2 · ⟨true⟩+ 1/2 · ⟨false⟩
c4 :
if(x = true){
c5 :
x :≈1/2 · ⟨true⟩+ 1/2 · ⟨false⟩
} else {empty}
} else {empty}
It simulates a geometric distribution that is truncated after the third coin ﬂip. To
determine its expected runtime, i.e. ert[ctrunc](0), it suﬃces to apply the rules of the
ert-transformer (see Table 6.1). Throughout this chapter, we will use the notation
 s′
 s
c
 t
to express the fact that s = ert[c](t) and moreover that s′ = s. It is thus more intuitive
to read annotated programs from bottom to top, just like the ert-transformer moves
from the back to the front. Using this notation, we can annotate the program ctrunc
simply by applying the ert rules from Table 6.1 as shown below in Figure 6.2.
Hence, on average, running program ctrunc takes 13/4 units of time.
6.5 Proof Rules for Loops
Reasoning about the runtime of loop-free programs, such as the program ctrunc in
the above example, amounts mostly to syntactic reasoning. The runtime of a loop,
however, is deﬁned as the least ﬁxed point of its characteristic functional Ft. It can
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

198
Kaminski, Katoen and Matheja: Expected Runtime Analysis

13
4
 . . .
 1 +
1
2 · 1 + [x = true] · 5
2
[x/true]
+
1
2 · 1 + [x = true] · 5
2
[x/false]
x :≈1/2 · ⟨true⟩+ 1/2 · ⟨false⟩;
 1 + [x = true] · 5
2
 1 + [x = true] · 5
2 + [x = false] · 0
if(x = true){

5
2
 1 +
1
2 · 1 + 1 +
1
2 · 1 + 0
 1 +
1
2 · 1 + [true = true] +
1
2 · 1 + [false = true]
 1 +
1
2 · 1 + [x = true][x/true]
+
1
2 · 1 + [x = true][x/false]
x :≈1/2 · ⟨true⟩+ 1/2 · ⟨false⟩
 1 + [x = true]
 1 + [x = true] · 1 + [x = false] · 0
if(x = true){
 1
 1 +
1
2 · 0[x/true] +
1
2 · 0[x/false]
x :≈1/2 · ⟨true⟩+ 1/2 · ⟨false⟩
 0
} else {
 0
empty
 0
}
 0
} else {
 0
empty
 0
}
 0
Figure 6.2 Runtime annotations for the program ctrunc. It is more intuitive to read the annotations
from bottom to top. The postruntime after executing the whole program is 0; the a priori expected
runtime of executing the whole program is 13/4.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

6.5 Proof Rules for Loops
199
thus be obtained by ﬁxed point iteration using Kleene's ﬁxed point theorem (Kleene,
1952), i.e.
lfp Ft = sup
n∈N
Fn
t (0) ,
where Fn
t (X) denotes n-fold application of Ft to X. However, the ﬁxed point is
not necessarily reached within a ﬁnite number of iterations. We thus study various
proof rules for approximating the expected runtime of loops.
6.5.1 Proof Rule for Upper Bounds
We ﬁrst present a simple, yet powerful, proof rule for determining upper bounds
on expected runtimes of loops. This rule is based on an alternative characterization
of the least ﬁxed point due to Tarski and Knaster (see Tarski et al., 1955): Any X
that satisﬁes F(X) ≤X is called a pre-ﬁxed point of the function F. The least ﬁxed
point of F can be characterized as its smallest pre-ﬁxed point, i.e. the smallest X
such that F(X) ≤X. Consequently, every pre-ﬁxed point is greater than or equal to
the least ﬁxed point of F.
How does this lead us to a proof rule? Let Ft be the characteristic functional of
some loop while (ϕ) {c} with respect to a continuation t ∈T. In the context of
runtimes, we refer to a pre-ﬁxed point I ∈T of Ft as an upper invariant of loop
while (ϕ) {c} and continuation t. By the above observation, we can then formulate
our ﬁrst proof rule as follows:
Ft(I) ≤I
789:
I is an upper invariant
implies
ert[while (ϕ) {c}](t) = lfp Ft ≤I
789:
I is an upper bound of the expected runtime
.
In particular, since the exact expected runtime of a loop itself is an upper invariant,
completeness of the above proof rule is immediate.
Example: The geometric distribution. Let us consider an application of our proof
rule. The loop cgeo below has a geometrically distributed runtime as it keeps ﬂipping
a fair coin until it hits tails (c = 0).
cgeo :
while (c = 1) {
c :≈1/2 · ⟨0⟩+ 1/2 · ⟨1⟩
}
How can we apply our proof rule to verify an upper bound on the expected run-
time of cgeo? The corresponding characteristic functional with respect to postrun-
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

200
Kaminski, Katoen and Matheja: Expected Runtime Analysis
time t = 0 is:
F0(X) = 1 + [c  1] · 0 + [c = 1] · ert[c :≈1/2 · ⟨0⟩+ 1/2 · ⟨1⟩](X)
= 1 + [c = 1] ·
(
1 + 1
2 ·  X[c/0] + X[c/1]!)
.
By the calculations below we verify that I = 1 + [c = 1] · 4 is an upper invariant of
the loop (with respect to 0):
F0(I) = 1 + [c = 1] ·
(
1 + 1
2 ·  I[c/0] + I[c/1]!)
= 1 + [c = 1] ·
(
1 + 1
2 ·  1 + [0 = 1] · 4
789:
= 1
+ 1 + [1 = 1] · 4
789:
= 5
!)
= 1 + [c = 1] · 4
= I ≤I .
Hence, I is an upper invariant. By our proof rule, we then obtain
ert

cgeo

(0) ≤1 + [c = 1] · 4 .
In words, the expected runtime of cgeo is at most 1 + 4 = 5 from any initial state
where c = 1 and at most 1 + 0 = 1 from any other state. Notice that if the loop
body is itself loop-free, as in the above example, verifying that some runtime I is
an upper invariant is usually fairly easy. Inferring the invariant, in contrast, is one
of the most involved part of the veriﬁcation eﬀort.
6.5.2 Proof Rule for Lower Bounds
It is tempting to use the converse version of our proof rule based on upper in-
variants to reason about lower bounds on the expected runtime. That is, one
would like to check I ≤Ft(I) for some runtime I ∈T in order to verify that
I ≤ert[while (ϕ) {c}](0). Such a rule is unfortunately not sound as is, but we can
add further premises to make it sound.
Metering Functions
We would like ﬁrst to point out that it is not self-evident that the simple lower bound
rule suggested above must necessarily fail: For non-probabilistic programs, Frohn
et al. (2016) have shown that this very lower bound rule is indeed sound. They call
an I, such that I ≤Ft(I), a metering function. Whenever I is a metering function, I
is a lower bound on the runtime of a non-probabilistic loop, just as I being an upper
invariant implies that I is an upper bound on the (expected) runtime of a loop - be
it probabilistic or not.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

6.5 Proof Rules for Loops
201
The intuition behind the soundness of the metering function rule is that for
non-probabilistic programs there exists some n ∈N such that
 
lfp Ft
!(σ) =  Fn
t (0)!(σ) ,
in case that the loop terminates on σ (this is not true if the loop diverges, but then
any lower bound is a lower bound). Existence of n allows for proving soundness
of the metering function rule by induction on n. This is not true for probabilistic
programs: We may well have the situation that we need to take the limit for n, so
that
 
lfp Ft
!(σ) = sup
n∈N
 Fn
t (0)!(σ) ,
but for all n ∈N
 
lfp Ft
!(σ) >  Fn
t (0)!(σ) ,
even for a ﬁxed initial state σ. Indeed, for probabilistic programs, the metering func-
tion approach is unfortunately unsound, as the following counterexample shows:
Consider the loop c, given by
while (y = 1) {
y :≈1/2 · ⟨0⟩+ 1/2 · ⟨1⟩;
x :≈x + 1
} ,
where we assume that x ranges over N for simplicity. Suppose we want to reason
about a lower bound on the expected runtime of c by a metering function. The
characteristic functional of the while loop with respect to postruntime 0 is given by
F0(X) = 1 + [y = 1] ·
(
2 + 1
2
 X[x/x + 1][y/0] + X[x/x + 1][y/1]!)
.
We now propose two ﬁxed points of F0, namely
I1 = 1 + [y = 1] 6
and
I2 = 1 + [y = 1]  6 + 2x+a! ,
for any constant a ≥0, are both a ﬁxed point of F0 and hence also a metering
function. I1 is in fact the least ﬁxed point of F0 and we clearly have I1 ⪇I2. Thus, if
we prove I2 ≤F0(I2), we cannot possibly have proven that I2 is a lower bound on the
least ﬁxed point of F0, since I1 is a ﬁxed point strictly smaller than I2. The intuitive
reason is that the expected runtime of c is completely independent of x but x has an
inﬂuence on the value that I2 assumes. For more details on the connections between
the ert calculus and metering functions, we refer the interested reader Kaminski
(2019, Sections 7.6.3 and 7.6.4).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

202
Kaminski, Katoen and Matheja: Expected Runtime Analysis
Table 6.2 Rules for obtaining upper or lower bounds on the (expected) runtime of
a loop while (ϕ) {c} with respect to postruntime t.
ert[while (ϕ) {c}](t) ≤I
I ≤ert[while (ϕ) {c}](t)
c non-probabilistic
Ft(I) ≤I
I ≤Ft(I)
c probabilistic
Ft(I) ≤I
I ≤Ft(I)
and
λσ• ert[c] |I(σ) −I|!(σ) ≤c
Probabilistic Metering Functions
We call a runtime I that satisﬁes I ≤Ft(I) a lower invariant. We have learned above
that I being a lower invariant is not enough of a premise to ensure that I is a lower
bound on ert[while (ϕ) {c}](t). The additional premise that we have to add is that
the expected change of I after performing one iteration of the loop body is bounded
by a constant, i.e. for every initial state σinit, we have
Exp
(I(σinit) −I(σﬁnal)

)
≤c ,
for some positive constant c (Hark et al., 2020). This property is called conditional
diﬀerence boundedness. It is easy to show that the above expected value is upper
bounded by λσ• ert[c] |I(σ) −I|!(σ) and hence we can add
λσ• ert[c] |I(σ) −I|!(σ) ≤c ,
for some constant c ≥0
as a premise (additionally to I ≤Ft(I)), to ensure that I is a lower bound on
ert[while (ϕ) {c}](t).2 The overall situation is summarized in Table 6.2.
Example: The geometric distribution revisited. Let us consider an application
of the lower bound proof rule by revisiting the loop cgeo:
cgeo :
while (c = 1) {
c :≈1/2 · ⟨0⟩+ 1/2 · ⟨1⟩
}
We have already shown that I = 1 + [c = 1] · 4 is not only a preﬁxed point of the
corresponding characteristic function
F0(X) = 1 + [c = 1] ·
(
1 + 1
2 ·  X[c/0] + X[c/1]!)
,
2 Technically, we have to check a few ﬁniteness conditions too, but those are easy to check.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

6.5 Proof Rules for Loops
203
and thus an upper bound on the expected runtime of the loop, but indeed a true
ﬁxed point. Thus, if we show that there exists a constant c, such that
λσ• ert[body] |I(σ) −I|!(σ) ≤c ,
then I is also a lower bound and hence the exact expected runtime. We can check
the above condition as follows:
λσ• ert[c :≈1/2 · ⟨0⟩+ 1/2 · ⟨1⟩] |I(σ) −I|!(σ)
= λσ•

1 + 1
2 ·
(I(σ) −I[c/0]
 +
I(σ) −I[c/1]

)
(σ)
= 1 + 1
2 ·
(I −I[c/0]
 +
I −I[c/1]

)
= 1 + 1
2 ·
(1 + [c = 1] · 4 −1 −[0 = 1] · 4

+
1 + [c = 1] · 4 −1 −[1 = 1] · 4

)
= 1 + 1
2 ·
([c = 1] · 4
 +
[c = 1] · 4 −4

)
≤1 + 1
2 · (4 + 4)
= 5
Thus we have established that
ert

cgeo

(0) = I = 1 + [c = 1] · 4 .
6.5.3 Another Proof Rule for Lower Bounds
One can show that the lower bound rule we presented in the previous section is
incomplete in the sense that there exist lower bounds which are not conditionally
diﬀerence bounded. Furthermore, that proof rule is incapable of verifying inﬁnite
expected runtimes. We present in this section a third proof rule, which is more
diﬃcult to apply but in turn complete for verifying lower bounds on expected
runtimes, in particular inﬁnite expected runtimes.
Recall that, by Kleene's ﬁxed point theorem (Kleene, 1952), the least ﬁxed point
characterizing the expected runtime of a loop with characteristic functional Ft
is given by
lfp Ft = sup
n∈N
Fn
t (0) .
It can thus be obtained by ﬁxed point iteration: Starting at 0, we iteratively apply
the characteristic functional and take the limit of this iteration process. We now
under-approximate each step of this ﬁxed point iteration. To this end, we use a
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

204
Kaminski, Katoen and Matheja: Expected Runtime Analysis
0
≤
Ft(0)
≤
F2
t (0)
≤
F3
t (0)
≤. . . ≤
sup
n∈N
Fn
t (0) = lfp Ft
≥
≥
≥
≥
I1
Ft(I1)
Ft(I2)
. . .
lim
n→∞Ft(In)
≥
≥
≥
I2
I3
. . .
lim
n→∞In
Figure 6.3 Illustration of approximating each step of a ﬁxed point iteration of Ft on initial value
0 with a lower ω-invariant In. The chain 0 ≤Ft(0) ≤F2
t (0) ≤. . . on top is a consequence of
the monotonicity of Ft which in turn is a consequence of its continuity.
runtime In ∈T that is parameterized in a natural number n. Then, In is called a
lower ω-invariant of while (ϕ) {c} with respect to runtime t if and only if
I1 ≤Ft(0)
and
∀n ≥1:
In+1 ≤Ft(In) .
Intuitively, a lower ω-invariant In under-approximates the n-th step of a ﬁxed point
iteration that determines the exact expected runtime of a loop. It thus represents
a lower bound on the expected runtime of those executions that ﬁnish within n
loop iterations, weighted according to their probabilities. Intuitively, the limit of In
consequently represents a lower bound on the expected runtime for any number of
loop iterations. More formally, we can show by induction that
In+1 ≤Ft(In) ≤Fn+1
t
(0) .
An illustration of a ﬁxed point iteration approximated by In is given in Figure 6.3.
Formally, we obtain the following proof rule based on ω-invariants: If In is a lower
ω-invariant of loop while(ϕ){c} with respect to runtime t and the limit of In exists
then
lim
n→∞In ≤ert[while (ϕ) {c}](t) .
This rule is obviously complete as we can always choose the exact ﬁxed point
iteration sequence In = Fn
t (0) as lower ω-invariant.
It is worthwhile to note that for upper bounds there is no need for ω-invariants,
even though a dual rule exists: In is called an upper ω-invariant of while (ϕ) {c}
with respect to runtime t if and only if
Ft(0) ≤I1
and
∀n ≥1:
Ft(In) ≤In+1 .
If In is an upper ω-invariant of loop while (ϕ) {c} with respect to runtime t and
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

6.5 Proof Rules for Loops
205
the limit of In exists, then indeed
ert[while (ϕ) {c}](t) ≤
lim
n→∞In .
However, one can show that in this case limn→∞In itself is already an upper (global)
invariant, i.e.
Ft
(
lim
n→∞In
)
≤
lim
n→∞In
and thus, there is no need to guess such a sequence and then ﬁnd the limit. Instead,
we can just immediately guess a limit and check whether this limit is an upper
invariant, without having to perform an additional induction on n.
Example: Disproving positive almost-sure termination. The expected runtime
transformer ert enables proving positive almost-sure termination by verifying a
ﬁnite upper bound on the expected runtime of a program. With the help of ω-
invariants, it can also be employed to prove that inﬁnity is a lower bound on the
expected runtime. In other words, we can verify that a given program does not
terminate positively almost-surely. As an example, let us verify that the concatena-
tion of two positively almost-surely terminating programs may itself not terminate
positively almost-surely. We already presented a counterexample, but without proof,
namely the program
ccex :
1: x := 1; b := 1;
2: while (b = 1) {b :≈1/2⟨0⟩+ 1/2⟨1⟩; x := 2x};
3: while (x > 0) {x := x −1} .
Our goal is to formally prove that ccex has an inﬁnite expected runtime, i.e. ∞≤
ert[ccex](0). To this end, let us denote the program in the i-th line of ccex by ci. By
the rule for sequential composition, we then obtain
ert[ccex](0) = ert[c1](ert[c2](ert[c3](0))) .
Let us thus start by analyzing the second loop, i.e. program c3. Its characteristic
functional with respect to continuation 0 is given by
F0(X) = 1 + [x > 0] ·  1 + X[x/x −1]! .
Since the variable x is decremented in each loop iteration and every iteration con-
sumes two units of time (one for the guard evaluation and one for the assignment),
we use the lower ω-invariant
In = 1 + [0 < x < n −1] · 2x + [x ≥n −1] · (2n −3)
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

206
Kaminski, Katoen and Matheja: Expected Runtime Analysis
of the loop c3 to conclude that
ert[c3](0) ≥
lim
n→∞In = 1 + [x > 0] · 2x .
We now have an under-approximation of the expectedruntime of c3.We cancontinue
reasoning about c2 using this under-approximation because the ert-transformer
satisﬁes a fundamental property: it is monotonic. Hence,
ert[c3](0) ≥1 + [x > 0] · 2x
implies
ert[c2 ; c3](0) = ert[c2] 
ert[c3](0)! ≥ert[c2](1 + [x > 0] · 2x) .
Our next step is therefore to analyze the expected runtime of the ﬁrst loop, i.e. c2,
with respect to continuation t = 1 + [x > 0] · 2x. The corresponding characteristic
functional is given by
Gt(X) = 1 + [b  1] · (1 + [x > 0] · 2x)
+ [b = 1] ·  2 + 1
2 · X[x/2x][b/0] + 1
2 · X[x/2x][b/1]! .
As a lower ω-invariant of c2, we propose
Jn = 1 + [b  1] · (1 + [x > 0] · 2x)
+ [b = 1] · (7 −
5
2n−1 + (n −1) · [x > 0] · 2x) .
The calculations establishing that Jn is a lower ω-invariant go as follows:
Gt(0) = 1 + [b  1] ·  1 + [x > 0] · 2x!
+ [b = 1] ·
(
2 + 1
2 · 0[x/2x][b/0] + 1
2 · 0[x/2x][b/1]
)
= 1 + [b  1] ·  1 + [x > 0] · 2x! + [b = 1] · 2
= I1 ≥I1 ✓
Gt(Jn) = 1 + [b  1] ·  1 + [x > 0] · 2x!
+ [b = 1]·
(
2 + 1
2 · Jn[x/2x][b/0] + 1
2 · Jn[x/2x][b/1]
)
= 1 + [b  1] ·  1 + [x > 0] · 2x!
+ [b = 1]·
(
2 + 1
2 · (2 + [2x > 0] · 4x)
+ 1
2 ·
(
8 −
5
2n−1 + (n −1) · [2x > 0]
789:
= [x>0]
·4x
))
= 1 + [b  1] ·  1 + [x > 0] · 2x!
+ [b = 1]·
(
7 −
5
2n+1−1 + (n + 1 −1) · [x > 0] · 2x
)
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

6.5 Proof Rules for Loops
207
= In+1 ≥In+1 ✓
Hence, our proof rule for lower ω-invariants yields
ert[c2](1 + [x > 0] · 2x) ≥
lim
n→∞Jn
= 1 + [b  1] ·  1 + [x > 0] · 2x!
+ [b = 1]·(7 + [x > 0] · ∞) .
Again appealing to monotonicity of the ert-transformer, we can complete the run-
time analysis of program ccex:
ert[ccex](0) = ert[c1](ert[c2](ert[c3](0)))
≥ert[c1](ert[c2](1 + [x > 0] · 2x))
≥ert[c1]
(
1 + [b  1] ·  1 + [x > 0] · 2x!
+ [b = 1]·(7 + [x > 0] · ∞)
)
= ert[x := 1]
(
ert[b := 1]
(
1 + [b  1] ·  1 + [x > 0] · 2x!
+ [b = 1]·(7 + [x > 0] · ∞)
))
= ert[x := 1](1 + 8 + [x > 0] · ∞)
= 1 + 1 + 8 + [1 > 0] · ∞
= ∞
Overall, we obtain that the expected runtime of program ccex is inﬁnite even though
it terminates with probability one. In other words, ccex terminates almost-surely,
but not positively almost-surely. Furthermore, notice that both sub-programs c2 and
c3 for themselves have ﬁnite expected runtimes, since
ert[c2](0) = 1 + [b = 1] · 4
and
ert[c3](0) = 1 + [x > 0] · 2x .
We emphasize that the ert-calculus allows for reasoning about positive almost-sure
termination (PAST) although PAST itself is not compositional.
6.5.4 Independent and Identically Distributed Loops
So far, we have studied two classes of complete proof rules. However, both rules rely
on ﬁnding invariants, which is usually the hardest part of the veriﬁcation process.
We now consider a restricted class of loops whose exact expected runtime can be
analyzed without invariants or other user-supplied artifacts. That class thus oﬀers
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

208
Kaminski, Katoen and Matheja: Expected Runtime Analysis
while
(
(x −5)2 + (y −5)2 ≤25
)
{
x :≈uniform[0 . . . 10];
y :≈uniform[0 . . . 10]
}
5
10
5
10
×
×
×
×
×
×
×
×
×
×
×
×
×
×
×
×
×
×
Figure 6.4 A probabilistic program sampling a point within a circle uniformly at random using
rejection sampling. The picture on the right-hand side visualizes the procedure: In each iteration
a point (×) is sampled. If we obtain a point within the white area inside the square, we terminate.
Otherwise, we resample.
a high degree of automation. Intuitively, the key concept underlying our next proof
rule are loops without data ﬂow across diﬀerent loop iterations. For deterministic
programs, such loops are not very interesting: They either terminate after exactly
one iteration or never. This is not the case for probabilistic programs. Consider, for
example, the probabilistic program depicted in Figure 6.4. It samples a point within
a circle with center (5,5) and radius 5 uniformly at random by means of rejection
sampling: In each loop iteration, we sample a point (x, y) ∈[0,10]2 with some
ﬁxed precision. If the sampled point lies within the circle, we terminate; otherwise,
we resample. Although our program admits arbitrarily long runs, the program
terminates within ﬁnite expected time. Moreover, there is no data ﬂow across loop
iterations. This is an example of an independent and identically distributed (i.i.d.)
loop. In the remainder of this section we develop a proof rule to determine exact
expected runtimes of i.i.d. loops.
Towards a rigorous proof rule, let us ﬁrst formally characterize i.i.d. loops. Let
Var( f ) denote the set of all variables that "occur in" runtime f ∈T, i.e.
x ∈Var( f )
iﬀ
∃σ ∃v,v′:
f
(
σ[x/v]
)
 f
(
σ[x/v′]
)
.
Furthermore, let the set Mod(c) be the collection of all variables that occur on the
left-hand side of an assignment in a program c. We then call a runtime f unaﬀected
by program c, denoted
f ̸⋒c
if and only if Var( f ) ∩Mod(c) = ∅. Moreover, let us denote by
℘c( f )
the expected value of f after executing program c. This value can be computed simi-
larly to expected runtimes with our ert-calculus by assuming that the time consumed
by each statement is zero (this corresponds to the weakest preexpectation calculus
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

6.6 Application: Bayesian networks
209
of McIver and Morgan, 2004). With these notions at hand, a loop while (ϕ) {c} is
f -i.i.d. for some postruntime f ∈T if and only if
(i) the probability of loop guard ϕ being true after one execution of loop body c is
unaﬀected by c, i.e.
℘c [ϕ]! ̸⋒c ,
(ii) the probability of violating the loop guard and continuing with runtime f after
one execution of loop body c is unaﬀected by c, i.e.
℘c [¬ϕ] · f ! ̸⋒c ,
and
(iii) every loop iteration runs in the same expected time, i.e.
ert[c](0) ̸⋒c .
For example, the program in Figure 6.4 that samples a point in a circle is f -
i.i.d. for every postruntime f ∈T. How does the fact that a loop is f -i.i.d. help
us when analyzing the expected runtime of a program? Intuitively, since each loop
iteration has the same expected runtime, we can characterize the expected runtime
of the whole loop as the expected runtime of a single loop iteration divided by
the probability of termination, i.e. 1 minus the probability of satisfying the loop
guard after execution the loop body. Formally, we additionally have to take the
time consumed by guard evaluations and the possibility that the loop guard is never
satisﬁed into account. This leads us to the following proof rule (Batz et al., 2018):
Proof rule for f -i.i.d. loops. Let while (ϕ) {c} be an f -i.i.d. loop such that the
loop body c terminates almost-surely, i.e. ℘c(1) = 1. Then, the expected runtime
of while (ϕ) {c} with respect to postruntime f ∈T is
ert[while (ϕ) {c}]( f ) = 1 + [ϕ] · 1 + ert[c]([¬ϕ] · f )
1 −Pr[c]([ϕ])
+ [¬ϕ] · f ,
where we deﬁne 0/0 = 0 and a/0 = ∞for a  0.
6.6 Application: Bayesian networks
The notion of f -i.i.d. loops prevents data ﬂow across loop iterations. While this
might seem like a severe restriction, it naturally applies to certain classes of prob-
abilistic models. In particular, Bayesian networks (Koller and Friedman, 2009) are
probabilistic graphical models representing joint probability distributions of sets of
random variables with conditional dependencies. Graphical models are popular as
they allow to succinctly represent complex distributions in a human-readable way.
For example, Bayesian networks have applications in machine learning (Heckerman,
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

210
Kaminski, Katoen and Matheja: Expected Runtime Analysis
2008), speech recognition (Zweig and Russell, 1998), sports betting (Constantinou
et al., 2012), gene regulatory networks (Friedman et al., 2000), medicine (Jiang and
Cooper, 2010), and ﬁnance (Neapolitan and Jiang, 2010).
The central problem for Bayesian networks is probabilistic inference, i.e. deter-
mining the probability of an event given observed evidence. This problem is often
approached using sampling-based techniques, such as rejection sampling: Repeat-
edly sample from the joint distribution of the network until the obtained sample
complies with all observed evidence. However, a major problem with rejection
sampling is that for poorly conditioned data, many samples have to be rejected to
obtain a single compliant sample. In fact, Gordon et al. (2014) point out that "the
main challenge in this setting [i.e. sampling based approaches] is that many samples
that are generated during execution are ultimately rejected for not satisfying the ob-
servations." If too many samples are rejected, the expected sampling time grows so
large that sampling becomes infeasible. The expected sampling time of a Bayesian
network is therefore a key ﬁgure for deciding whether sampling based inference is
the method of choice. In other words, we are concerned with the question:
"Given a Bayesian network with observed evidence, how long does it take to obtain
a single sample that satisﬁes the observations?"
In this section, we present how this question can be addressed fully automatically:
We translate a Bayesian network into an equivalent pGCL program such that the
expected runtime of the resulting program corresponds to the expected sampling
time of the network. The expected runtime is then determined using the ert-calculus
and our proof rule for f -i.i.d. loops.
6.6.1 From Bayesian Networks to Probabilistic Programs
Let us brieﬂy introduce Bayesian networks by means of an example. Further details -
including formal deﬁnitions - are found in Batz et al. (2018); Koller and Friedman
(2009). A Bayesian network is a directed acyclic graph in which every node is
a random variable and every edge between two nodes represents a probabilistic
dependency between these nodes. As a running example, consider the network
depicted in Figure 6.5 (inspired by Koller and Friedman, 2009) that models the
mood of students after taking an exam. The network contains four random variables.
They represent the diﬃculty of the exam (D), the level of preparation of a student
(P), the achieved grade (G), and the resulting mood (M). For simplicity, let us
suppose that each random variable assumes either value 0 or 1. The underlying
dependencies express that the mood of a student depends on the achieved grade
which, in turn, depends on the diﬃculty of the exam and the amount of preparation
before taking it. Every node is accompanied by a conditional probability table that
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

6.6 Application: Bayesian networks
211
Diﬃculty
Preparation
Grade
Mood
D = 0
D = 1
0.6
0.4
P = 0
P = 1
0.7
0.3
G = 0
G = 1
D = 0, P = 0
0.95
0.05
D = 1, P = 1
0.05
0.95
D = 0, P = 1
0.5
0.5
D = 1, P = 0
0.6
0.4
M = 0
M = 1
G = 0
0.9
0.1
G = 1
0.3
0.7
Figure 6.5 A Bayesian network
provides the probabilities of a node given the values of all the nodes it depends
upon. We can then use the Bayesian network to answer queries such as "What is the
probability that a student is well-prepared for an exam (P = 1), but ends up with a
bad mood (M = 0)?"
It can be shown that every Bayesian network with observed evidence can be
translated into an equivalent pGCL program, i.e. a program describing the same
conditional probability distribution (Batz et al., 2018). For instance, Figure 6.6
shows the probabilistic program corresponding to the Bayesian network in Fig-
ure 6.5 and observation P = 1. Here, the statement repeat { c } until (ϕ) is a
shortcut for c; while (ϕ) {c}. Essentially, every node in a network corresponds to
a variable. It is then straightforward to encode the (discrete) conditional probability
table of every node using conditional branching and random assignments.
To deal with observations, one could syntactically enrich the programming lan-
guage to allow for observe-statements. This approach is taken in, for exam-
ple,Katoen et al. (2015); Olmedo et al. (2018); Bichsel et al. (2018). However,
taking that approach would not give us an insight on how long it would take to
obtain an execution trace that complies with the observations. Instead, we wrap
around the original program a global loop that implements rejection sampling.
That is, the whole program is re-run until all observations are satisﬁed. Since no
variable inside the loop body of such a program is accessed before it is set by a
probabilistic assignment, there is no data ﬂow across loop iterations. In other words,
all loops that model Bayesian networks are f -i.i.d. for every postruntime f ∈T.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

212
Kaminski, Katoen and Matheja: Expected Runtime Analysis
1
repeat {
2
xD :≈0.6 · ⟨0⟩+ 0.4 · ⟨1⟩;
3
xP :≈0.7 · ⟨0⟩+ 0.3 · ⟨1⟩
4
if (xD = 0 ∧xP = 0) {
5
xG :≈0.95 · ⟨0⟩+ 0.05 · ⟨1⟩
6
} else if (xD = 1 ∧xP = 1) {
7
xG :≈0.05 · ⟨0⟩+ 0.95 · ⟨1⟩
8
} else if (xD = 0 ∧xP = 1) {
9
xG :≈0.5 · ⟨0⟩+ 0.5 · ⟨1⟩
10
} else {
11
xG :≈0.6 · ⟨0⟩+ 0.4 · ⟨1⟩
12
};
13
if (xG = 0) {
14
xM :≈0.9 · ⟨0⟩+ 0.1 · ⟨1⟩
15
} else {
16
xM :≈0.3 · ⟨0⟩+ 0.7 · ⟨1⟩
17
}
18
} until (xP = 1)
Figure 6.6 The probabilistic program obtained from the network in Figure 6.5.
Consequently, the expected runtime of programs obtained from Bayesian networks
can be analyzed fully automatically by applying the rules of the ert-calculus.
6.6.2 Implementation
We implemented a prototype to analyze expected sampling times of Bayesian
networks (cf. Batz et al., 2018). More concretely, our tool takes as input a Bayesian
network together with observations in the popular Bayesian Network Interchange
Format.3 The network is ﬁrst translated into a probabilistic program. The expected
runtime of the resulting program is then determined fully automatically by applying
our ert-calculus together with our proof rule for f -i.i.d. loops.
The size of the resulting program is linear in the total number of rows of all
conditional probability tables in the network. The program size is thus not the bot-
tleneck of our analysis. As we are dealing with an NP-hard problem (Cooper, 1990;
Dagum and Luby, 1993), it is not surprising that our algorithm has a worst-case
exponential time complexity. However, also the space complexity of our algorithm
is exponential in the worst case: As an expectation is propagated backwards through
an if-clause of the program, the size of the expectation is potentially multiplied.
This is also the reason that our analysis runs out of memory on some benchmarks.
We evaluated our implementation on the largest Bayesian networks in the
Bayesian Network Repository (Scutari, 2017) that consists - to a large extent - of
real-world Bayesian networks including expert systems for, e.g., electromyography
(munin) (Andreassen et al., 1989), hematopathology diagnosis (hepar2) (Onisko
et al., 1998), weather forecasting (hailfinder) (Abramson et al., 1996), and
printer troubleshooting in the Windows 95 operating system (win95pts) (Ramanna
et al., 2013, Section 5.6.2). All experiments were performed on an HP BL685C G7.
3 http://www.cs.cmu.edu/ fgcozman/Research/InterchangeFormat/
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

6.7 Conclusion and Future Directions
213
Although up to 48 cores with 2.0GHz were available, only one core was used apart
from Java's garbage collection. The Java virtual machine was limited to 8GB of
RAM.
Our experimental results are shown in Table 6.3. The number of nodes of the
considered networks ranges from 56 to 1041. For each Bayesian network, we
computed the expected sampling time (EST) for diﬀerent collections of observed
nodes (#obs). EST = ∞means that our implementation automatically infers that
the expected sampling time is in fact inﬁnite, which is the case if and only if
the probability of complying with all observed evidence is precisely 0. #obs = 0
means that no evidence is observed; the repeat-until loop would thus be executed
exactly once. For #obs > 0, observations were picked at random. Note that the time
required by our prototype varies depending on both the number of observed nodes
and the actual observations. Thus, there are cases in which we run out of memory
although the total number of observations is small. Furthermore, Table 6.3 provides
the average Markov Blanket size, i.e. the average number of parents, children and
children's parents of nodes in the Bayesian network (Pearl, 1985), as an indicator
measuring how independent nodes in the network are.
In order to obtain an understanding of what the EST corresponds to in actual ex-
ecution times on a real machine, we also performed simulations for the win95pts
network. More precisely, we generated Java programs from this network analo-
gously to the translation from Bayesian networks into pGCL programs. This allowed
us to approximate that our Java setup can execute 9.714 · 106 steps (in terms of
EST) per second. For the win95pts with 17 observations, an EST of 1.11 · 1015
then corresponds to an expected time of approximately 3.6 years in order to obtain
a single valid sample. We were additionally able to ﬁnd a case with 13 observed
nodes where our tool discovered within 0.32 seconds an EST that corresponds to
approximately 4.3 million years. In contrast, exact inference using variable elimina-
tion was almost instantaneous. This demonstrates that knowing expected sampling
times upfront can indeed be beneﬁcial when selecting an inference method.
6.7 Conclusion and Future Directions
We presented a weakest-precondition-style calculus for reasoning about the ex-
pected runtime of probabilistic programs. Our calculus demonstrates how standard
techniques from program veriﬁcation - in particular denotational semantics and
invariants - enable elegant proofs of (non)positive-almost sure termination. Fur-
thermore, both lower and upper bounds on the expected runtime can be determined.
We studied the restricted class of independently and identically distributed loops,
which enable a fully automated runtime analysis. In particular, Bayesian networks
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

214
Kaminski, Katoen and Matheja: Expected Runtime Analysis
Table 6.3 Experimental results. Time is in seconds. MO denotes out of memory.
#obs refers to the number of observed nodes.
Network
#obs
Time
EST
#obs
Time
EST
#obs
Time
EST
earthquake
#nodes: 5, #edges: 4, avg. Markov Blanket: 2.00
0
0.09
8.000 · 100
2
0.23
9.276 · 101
4
0.24
1.857 · 102
cancer
#nodes: 5, #edges: 4, avg. Markov Blanket: 2.00
0
0.09
8.000 · 100
2
0.22
1.839 · 101
5
0.20
5.639 · 102
survey
#nodes: 6, #edges: 6, avg. Markov Blanket: 2.67
0
0.09
1.000 · 101
2
0.21
2.846 · 102
5
0.22
9.113 · 103
asia
#nodes: 8, #edges: 8, avg. Markov Blanket: 2.50
0
0.26
1.400 · 101
2
0.25
3.368 · 102
6
0.25
8.419 · 104
sachs
#nodes: 11, #edges: 17, avg. Markov Blanket: 3.09
0
0.13
2.000 · 101
3
0.24
7.428 · 102
6
2.72
5.533 · 107
insurance
#nodes: 27, #edges: 52, avg. Markov Blanket: 5.19
0
0.17
5.200 · 101
3
0.31
5.096 · 103
5
0.91
1.373 · 105
alarm
#nodes: 37, #edges: 46, avg. Markov Blanket: 3.51
0
0.14
6.200 · 101
2
MO
—
6
40.47
3.799 · 105
barley
#nodes: 48, #edges: 84, avg. Markov Blanket: 5.25
0
0.46
8.600 · 101
2
0.53
5.246 · 104
5
MO
—
hailfinder
#nodes: 56, #edges: 66, avg. Markov Blanket: 3.54
0
0.23
9.500 · 101
5
0.63
5.016 · 105
9
0.46
9.048 · 106
hepar2
#nodes: 70, #edges: 123, avg. Markov Blanket: 4.51
0
0.22
1.310 · 102
1
1.84
1.579 · 102
2
MO
—
win95pts
#nodes: 76, #edges: 112, avg. Markov Blanket: 5.92
0
0.20
1.180 · 102
1
0.36
2.284 · 103
3
0.36
4.296 · 105
7
0.91
1.876 · 106
12
0.42
3.973 · 107
17
61.73
1.110 · 1015
pathfinder
#nodes: 135, #edges: 200, avg. Markov Blanket: 3.04
0
0.37
217
1
0.53
1.050 · 104
3
31.31
2.872 · 104
5
MO
—
7
5.44
∞
7
480.83
∞
andes
#nodes: 223, #edges: 338, avg. Markov Blanket: 5.61
0
0.46
3.570 · 102
1
MO
—
3
1.66
5.251 · 103
5
1.41
9.862 · 103
7
0.99
8.904 · 104
9
0.90
6.637 · 105
pigs
#nodes: 441, #edges: 592, avg. Markov Blanket: 3.66
0
0.57
7.370 · 102
1
0.74
2.952 · 103
3
0.88
2.362 · 103
5
0.85
1.260 · 105
7
1.02
1.511 · 106
8
MO
—
munin
#nodes: 1041, #edges: 1397, avg. Markov Blanket: 3.54
0
1.29
1.823 · 103
1
1.47
3.648 · 104
3
1.37
1.824 · 107
5
1.43
∞
9
1.79
1.824 · 1016
10
65.64
1.153 · 1018
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

6.7 Conclusion and Future Directions
215
- if interpreted as probabilistic programs - are covered by this class. Hence, exact
expected sampling times of Bayesian networks can be determined automatically.
Since the original development of the expected runtime calculus (Kaminski et al.,
2016), there has been ongoing research into several further directions. We conclude
with a brief discussion of recent developments.
Applications. The main application of our calculus is the analysis of randomized
algorithms. However, many randomized algorithms rely on advanced programming
features that are not supported by the simplistic language considered in this chap-
ter. There have been various extensions of weakest-precondition-style calculi for
probabilistic programs that attempt to support additional features while maintaining
elegant and applicable proof rules. In particular, recursion (Olmedo et al., 2016)
and dynamic data structures (Batz et al., 2019) have been incorporated into our
probabilistic guarded command language. An important feature that is still missing
is support for concurrent randomized algorithms.
Automation. While ﬁnding invariants is a challenging task, we were usually able
to ﬁnd correct invariants by considering a few loop unrollings. Hence, there is hope
that the proof rules presented in this chapter provide a foundation for automated
reasoning about expected runtimes. As a ﬁrst step, our calculus has been mecha-
nized in the theorem prover Isabelle (Hölzl, 2016). Furthermore, the class of i.i.d.
loops is a further step towards automation for a restricted class of programs. More
recently, Ngo et al. (2018) extended work on automated amortized resource analysis
to automatically reason about bounds on the expected runtime of a larger class of
probabilistic programs. They reduce inference of upper bounds to a linear program-
ming problem. In fact, their work can be considered an extension of our ert-calculus
by specialized rules. In particular, soundness of their approach explicitly relies on
the soundness of the expected runtime transformer presented here.
Almost-sure termination. Our calculus allows for proving positive almost-sure
termination, i.e. ﬁnite expected runtimes. A weaker notion is plain almost-sure ter-
mination, i.e. termination with probability 1. Powerful rules for proving almost-sure
termination of a large class of programs have been developed (McIver et al., 2018),
and for certain subclasses of probabilistic programs even automated approaches for
proving almost-sure termination exist (Esparza et al., 2012; Chatterjee et al., 2016,
2017; Agrawal et al., 2017).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

216
References
Acknowledgements
Kaminski and Katoen have been supported by the ERC Advanced Grant FRAP-
PANT (project number 787914) and the DFG-funded Research Training Group
2236 UnRAVeL. Matheja was supported by the DFG Project ATTESTOR. The
authors thank Kevin Batz and Federico Olmedo; joint work with them provided the
basis for this chapter.
References
Abramson, Bruce, Brown, John, Edwards, Ward, Murphy, Allan, and Winkler,
Robert L. 1996. Hailﬁnder: A Bayesian system for forecasting severe weather.
International Journal of Forecasting, 12(1), 57-71.
Adleman, Leonard Max, and Huang, Ming-Deh. 1992.
Primality Testing and
Abelian Varieties over Finite Fields. Lecture Notes in Mathematics, 1512.
Agrawal, Sheshansh, Chatterjee, Krishnendu, and Novotn`y, Petr. 2017. Lexico-
graphic ranking supermartingales: an eﬃcient approach to termination of
probabilistic programs. Proceedings of the ACM on Programming Languages,
2(POPL), 1-32.
Andreassen, Steen, Jensen, Finn V, Andersen, Stig Kjær, Falck, B, Kjærulﬀ, U,
Woldbye, M, Sørensen, AR, Rosenfalck, A, and Jensen, F. 1989. MUNIN: an
expert EMG assistant. Pages 255-277 of: Computer-aided Electromyography
and Expert Systems. Pergamon Press.
Batz, Kevin, Kaminski, Benjamin Lucien, Katoen, Joost-Pieter, and Matheja,
Christoph. 2018. How long, O Bayesian network, will I sample thee? - A
program analysis perspective on expected sampling times. Pages 186-213 of:
European Symposium on Programming (ESOP). Lecture Notes in Computer
Science, vol. 10801. Springer.
Batz, Kevin, Kaminski, Benjamin Lucien, Katoen, Joost-Pieter, Matheja, Christoph,
and Noll, Thomas. 2019. Quantitative separation logic: a logic for reasoning
about probabilistic pointer programs. Proceedings of the ACM on Program-
ming Languages, 3 (POPL), 1-29.
Bichsel, Benjamin, Gehr, Timon, and Vechev, Martin T. 2018. Fine-grained se-
mantics for probabilistic programs. Pages 145-185 of: European Symposium
on Programming (ESOP). Lecture Notes in Computer Science, vol. 10801.
Springer.
Bournez, Olivier, and Garnier, Florent. 2005. Proving positive almost-sure termina-
tion. Pages 323-337 of: International Conference on Rewriting Techniques and
Applications (RTA). Lecture Notes in Computer Science, vol. 3467. Springer.
Chakarov, Aleksandar, and Sankaranarayanan, Sriram. 2013. Probabilistic program
analysis with martingales. Pages 511-526 of: Computer Aided Veriﬁcation
(CAV). Lecture Notes in Computer Science, vol. 8044. Springer.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
217
Chatterjee, Krishnendu, Fu, Hongfei, Novotný, Petr, and Hasheminezhad, Rouzbeh.
2016. Algorithmic analysis of qualitative and quantitative termination prob-
lems for aﬃne probabilistic programs. Pages 327-342 of: Principles of Pro-
gramming Languages (POPL). ACM.
Chatterjee, Krishnendu, Novotný, Petr, and Zikelic, Dorde. 2017. Stochastic invari-
ants for probabilistic termination. Pages 145-160 of: Principles of Program-
ming Languages (POPL). ACM.
Constantinou, Anthony C., Fenton, Norman E., and Neil, Martin. 2012. pi-football: a
Bayesian network model for forecasting Association Football match outcomes.
Knowledge-Based Systems, 36, 322-339.
Cooper, Gregory F. 1990. The computational complexity of probabilistic inference
using Bayesian Belief Networks. Artiﬁcial intelligence, 42(2-3), 393-405.
Dagum, Paul, and Luby, Michael. 1993. Approximating probabilistic inference in
Bayesian Belief Networks is NP-hard. Artiﬁcial intelligence, 60(1), 141-153.
Dijkstra, Edgser W. 1976. A Discipline of Programming. Prentice Hall.
Esparza, Javier, Gaiser, Andreas, and Kiefer, Stefan. 2012. Proving termination
of probabilistic programs using patterns. Pages 123-138 of: Computer Aided
Veriﬁcation (CAV). Lecture Notes in Computer Science, vol. 7358. Springer.
Freivalds, R¯usin, š M¯artin, š. 1979. Fast probabilistic algorithms. Pages 57-69 of:
Mathematical Foundations of Computer Science (MFCS). Lecture Notes in
Computer Science, vol. 74. Springer.
Friedman, Nir, Linial, Michal, Nachman, Iftach, and Pe'er, Dana. 2000. Using
Bayesian networks to analyze expression data. Pages 127-135 of: Computa-
tional Molecular Biology (RECOMB). ACM.
Frohn, Florian, Naaf, Matthias, Hensel, Jera, Brockschmidt, Marc, and Giesl, Jür-
gen. 2016. Lower runtime bounds for integer programs. Pages 550-567 of:
International Joint Conference on Automated Reasoning (IJCAR). Lecture
Notes in Computer Science, vol. 9706. Springer.
Gordon, Andrew D., Henzinger, Thomas A., Nori, Aditya V., and Rajamani, Sri-
ram K. 2014. Probabilistic programming. Pages 167-181 of: Future of Soft-
ware Engineering (FOSE). ACM.
Hark, Marcel, Kaminski, Benjamin Lucien, Giesl, Jürgen, and Katoen, Joost-Pieter.
2020. Aiming low Is harder - inductive proof rules for lower bounds on weakest
pre-expectations in probabilistic program veriﬁcation. Proceedings of the ACM
on Programming Languages, 4(POPL), 37:1-37:28.
Hart, Sergiu, Sharir, Micha, and Pnueli, Amir. 1983. Termination of probabilistic
concurrent programs. ACM Transactions on Programming Languages and
Systems, 5(3), 356-380.
Heckerman, David. 2008. A tutorial on learning with Bayesian networks. Pages
33-82 of: Innovations in Bayesian Networks. Studies in Computational Intel-
ligence, vol. 156. Springer.
Hoare, Charles Antony Richard. 1962. Quicksort. The Computer Journal, 5(1),
10-15.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

218
References
Hölzl, Johannes. 2016. Formalising semantics for expected running time of prob-
abilistic programs. Pages 475-482 of: Interactive Theorem Proving (ITP).
Lecture Notes in Computer Science, vol. 9807. Springer.
Hur, Chung-Kil, Nori, Aditya V, Rajamani, Sriram K, and Samuel, Selva. 2014.
Slicing probabilistic programs. Pages 133-144 of: ACM SIGPLAN Notices,
vol. 49. ACM.
Ibe, Oliver C. 2013. Elements of Random Walk and Diﬀusion Processes. John
Wiley & Sons.
Jiang, Xia, and Cooper, Gregory F. 2010. A Bayesian spatio-temporal method
for disease outbreak detection. Journal of the American Medical Informatics
Association, 17(4), 462-471.
Kaminski, Benjamin Lucien. 2019. Advanced Weakest Precondition Calculi for
Probabilistic Programs. Ph.D. thesis, RWTH Aachen University, Germany.
Kaminski, Benjamin Lucien, and Katoen, Joost-Pieter. 2015. On the hardness of
almost-sure termination. Pages 307-318 of: Mathematical Foundations of
Computer Science (MFCS), Part I. Lecture Notes in Computer Science, vol.
9234. Springer.
Kaminski, Benjamin Lucien, Katoen, Joost-Pieter, Matheja, Christoph, and
Olmedo, Federico. 2016. Weakest precondition reasoning for expected run-
times of probabilistic programs. Pages 364-389 of: European Symposium
on Programming (ESOP). Lecture Notes in Computer Science, vol. 9632.
Springer.
Kaminski, Benjamin Lucien, Katoen, Joost-Pieter, and Matheja, Christoph. 2018a.
On the hardness of analyzing probabilistic programs. Acta Informatica, 1-31.
Kaminski, Benjamin Lucien, Katoen, Joost-Pieter, Matheja, Christoph, and
Olmedo, Federico. 2018b. Weakest precondition reasoning for expected run-
times of randomized Algorithms. Journal of the ACM, 65(5), 30:1-30:68.
Katoen, Joost-Pieter, Gretz, Friedrich, Jansen, Nils, Kaminski, Benjamin Lucien,
and Olmedo, Federico. 2015. Understanding probabilistic programs. Pages
15-32 of: Correct System Design - Symposium in Honor of Ernst-Rüdiger
Olderog on the Occasion of His 60th Birthday. Lecture Notes in Computer
Science, vol. 9360. Springer.
Kleene, Stephen Cole. 1952. Introduction to Metamathematics. North-Holland.
Koller, Daphne, and Friedman, Nir. 2009. Probabilistic Graphical Models - Prin-
ciples and Techniques. MIT Press.
McIver, Annabelle, and Morgan, Carroll. 2004. Abstraction, Reﬁnement and Proof
for Probabilistic Systems. Springer.
McIver, Annabelle, Morgan, Carroll, Kaminski, Benjamin Lucien, and Katoen,
Joost-Pieter. 2018. A new proof rule for almost-sure termination. Proceedings
of the ACM on Programming Languages, 2(POPL), 33:1-33:28.
Minka, Tom, and Winn, John. 2017.
Infer.NET.
Accessed online at
http://infernet.azurewebsites.net July 30, 2018.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
219
Neapolitan, Richard E, and Jiang, Xia. 2010. Probabilistic Methods for Financial
and Marketing Informatics. Morgan Kaufmann.
Ngo, Van Chan, Carbonneaux, Quentin, and Hoﬀmann, Jan. 2018. Bounded ex-
pectations: resource analysis for probabilistic programs. Pages 496-512 of:
Proceedings of the Conference on Programming Language Design and Imple-
mentation (PLDI). ACM.
Olmedo, Federico, Kaminski, Benjamin Lucien, Katoen, Joost-Pieter, and Matheja,
Christoph. 2016. Reasoning about recursive probabilistic programs. Pages
672-681 of: Logic in Computer Science (LICS). ACM.
Olmedo, Federico, Gretz, Friedrich, Jansen, Nils, Kaminski, Benjamin Lucien, Ka-
toen, Joost-Pieter, and McIver, Annabelle. 2018. Conditioning in probabilistic
programming. ACM Transactions on Programming Languages and Systems,
40(1), 4:1-4:50.
Onisko, Agnieszka, Druzdzel, Marek J, and Wasyluk, Hanna. 1998. A probabilistic
causal model for diagnosis of liver disorders. Pages 379-387 of: Intelligent
Information Systems (IIS).
Pearl, Judea. 1985.
Bayesian networks: a model of self-activated memory for
evidential reasoning. Pages 329-334 of: Conference of the Cognitive Science
Society.
Rabin, Michael Oser. 1976.
Probabilistic algorithms.
Pages 21-39 of: Traub,
Joseph Frederick (ed), Algorithms and Complexity: New Directions and Recent
Results. Academic Press.
Ramanna, Sheela, Jain, Lakhmi C, and Howlett, Robert J. 2013.
Emerging
Paradigms in Machine Learning. Springer.
Scutari, Marco. 2017.
Bayesian Network Repository.
Accessed online at
http://www.bnlearn.com July 30, 2018.
Smid, Michiel. 2000. Closest-point problems in computational geometry. Pages
877-935 of: Sack, Jörg-Rüdiger, and Urrutia, Jorge (eds), Handbook of Com-
putational Geometry. North-Holland.
Solovay, Robert, and Strassen, Volker. 1977. A fast Monte-Carlo test for primality.
SIAM Journal on Computing, 6(1), 84-85.
Tarski, Alfred, et al. 1955. A lattice-theoretical ﬁxpoint theorem and its applications.
Paciﬁc Journal of Mathematics, 5(2), 285-309.
Zweig, Geoﬀrey, and Russell, Stuart J. 1998. Speech recognition with dynamic
Bayesian networks. Pages 173-180 of: AAAI/IAAI. AAAI Press / The MIT
Press.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

7
Termination Analysis of Probabilistic Programs with
Martingales
Krishnendu Chatterjee
IST Austria
Hongfei Fu
Shanghai Jiao Tong University
Petr Novotný
Masaryk University
Abstract:
Probabilistic programs extend classical imperative programs with
random-value generators. For classical non-probabilistic programs, termination is
a key question in static analysis of programs, that given a program and an initial
condition asks whether it terminates. In the presence of probabilistic behavior there
are two fundamental extensions of the termination question, namely, (a) the almost-
sure termination question that asks whether the termination probability is 1; and (b)
the bounded-time termination question that asks whether the expected termination
time is bounded. While there are many active research directions to address the
above problems, one important research direction is the use of martingale theory for
termination analysis. We will survey the main techniques related to martingale-based
approach for termination analysis of probabilistic programs.
7.1 Introduction
Stochastic models and probabilistic programs. The analysis of stochastic models
is a fundamental problem, and randomness plays a crucial role in several disci-
plines across computer science. Some prominent examples are (a) randomized
algorithms (Motwani and Raghavan, 1995); (b) stochastic network protocols (Baier
and Katoen, 2008; Kwiatkowska et al., 2011); (c) systems that interact with uncer-
tainty in artiﬁcial intelligence (Kaelbling et al., 1996, 1998; Ghahramani, 2015).
Programming language support for analysis of such models requires extending the
classical non-probabilistic programming models, and the extension of classical
imperative programs with random value generators that produce random values
according to some desired probability distribution gives rise to the class of proba-
bilistic programs (Gordon et al., 2014). The formal analysis of probabilistic systems
and probabilistic programs is an active research topic across diﬀerent disciplines,
a From Foundations of Probabilistic Programming, edited by Gilles Barthe, Joost-Pieter Katoen and Alexandra
Silva published 2020 by Cambridge University Press.
221
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

222
Chatterjee, Fu and Novotný: Termination Analysis with Martingales
such as probability theory and statistics (Durrett, 1996; Howard, 1960; Kemeny
et al., 1966; Rabin, 1963; Paz, 1971), formal methods (Baier and Katoen, 2008;
Kwiatkowska et al., 2011), artiﬁcial intelligence (Kaelbling et al., 1996, 1998),
and programming languages (Chakarov and Sankaranarayanan, 2013; Fioriti and
Hermanns, 2015; Sankaranarayanan et al., 2013; Esparza et al., 2012; Chatterjee
et al., 2016a).
Termination questions. One of the most basic, yet fundamental, question in analysis
of reactive systems or programs is the termination problem. For non-probabilistic
program the termination problem asks whether a given program always terminates.
The termination problem represents the fundamental notion of liveness for programs,
and corresponds to the classical halting problem of Turing machines. While for
general programs the termination problem is undecidable, static analysis methods
for program analysis aim to develop techniques that can answer the question for
subclasses of programs. For non-probabilistic programs, the proof of termination
coincides with the construction of ranking functions (Floyd, 1967), and many diﬀerent
approaches exist for such construction (Bradley et al., 2005a; Colón and Sipma,
2001; Podelski and Rybalchenko, 2004; Sohn and Gelder, 1991). For probabilistic
programs, the presence of randomness requires that the termination questions are
extended to handle stochastic aspects. The most natural and basic extensions of the
termination problem are as follows: First, the almost-sure termination question asks
whether the program terminates with probability 1. Second, the bounded termination
question asks whether the expected termination time is bounded. While the bounded
termination implies almost-sure termination, the converse is not true in general.
Section 7.2.4 illustrates the concepts on several examples.
Non-determinism. Besides stochastic aspects, another fundamental modeling con-
cept is the notion of non-determinism. A classic example of non-determinism
in program analysis is abstraction: for eﬃcient static analysis of large programs,
it is infeasible to track all variables of the program. Abstraction ignores certain
variables and replaces them with worst-case behavior modeled as non-determinism.
Moreover, non-determinism can be used to replace large portions of a program by
overapproximating their eﬀect on variables.
Martingales for probabilistic programs. While there are various diﬀerent ap-
proaches for analyzing probabilistic programs (see Section 7.6 for further discussion),
the focus of this chapter is to consider martingale-based approaches. This approach
considers martingales (a special type of stochastic processes) and how they can
be used to develop algorithmic analysis techniques for analysis of probabilistic
programs. The approach brings together various diﬀerent disciplines, namely, prob-
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

7.1 Introduction
223
ability theory, algorithmic aspects, and program analysis techniques. Below we
present a glimpse of the main results, and then the organization of the chapter.
Glimpse of main results. We present a brief description of main results related to
the martingale-based approach.
• Finite probabilistic choices. First, for probabilistic programs with non-determinism,
but restricted to ﬁnite probabilistic choices, quantitative invariants were used to
establish termination in McIver and Morgan (2004, 2005).
• Inﬁnite probabilistic choices without non-determinism. The approach presented
in McIver and Morgan (2004, 2005) was extended in Chakarov and Sankara-
narayanan (2013) to ranking supermartingales to obtain a sound (but not complete,
see Chakarov and Sankaranarayanan (2013, page 10) for a counterexample) ap-
proach for almost-sure termination for inﬁnite-state probabilistic programs without
non-determinism, but with inﬁnite-domain random variables. The connection
between termination of probabilistic programs without non-determinism and
Lyapunov ranking functions was considered in Bournez and Garnier (2005). For
probabilistic programs with countable state space and without non-determinism,
Lyapunov ranking functions provide a sound and complete method to prove
bounded termination (Bournez and Garnier, 2005; Foster, 1953).
• Inﬁnite probabilistic choices with non-determinism. The interaction of non-
determinism and inﬁnite probabilistic choice is quite tricky as illustrated in Fioriti
and Hermanns (2015). For bounded termination, the ranking supermartingale
based approach is sound and complete (Chatterjee and Fu, 2017; Fu and Chatter-
jee, 2019). As mentioned above, a key goal is to obtain algorithmic methods for
automated analysis. Automated approaches for synthesis of linear and polyno-
mial ranking supermartingales have been studied in Chatterjee et al. (2016a,b).
Moreover, recently parametric supermartingales, rather than ranking supermartin-
gales, (McIver et al., 2018; Chatterjee and Fu, 2017; Huang et al., 2018) and lexi-
cographic ranking supermartingales (Agrawal et al., 2018) have been considered
for proving almost-sure termination of probabilistic programs. The martingale-
based approach has also been studied to prove high-probability termination and
non-termination of probabilistic programs (Chatterjee et al., 2017).
• Undecidability characterization. The problem of deciding termination (almost-
sure termination and bounded termination) of probabilistic programs is undecid-
able, and its precise undecidability characterization has been studied in Kaminski
and Katoen (2015).
Organization. The chapter is organized as follows: In Section 7.2 we present the
preliminaries (syntax, semantics, and the formal deﬁnition of termination problems).
In Section 7.3 we present the results related to the theoretical foundations of ranking
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

224
Chatterjee, Fu and Novotný: Termination Analysis with Martingales
supermartingales and bounded termination. In Section 7.4 we discuss algorithmic
approaches for synthesis of linear and polynomial ranking supermaritngales. In
Section 7.5 we consider the martingale-based approach beyond bounded termination:
we ﬁrst consider almost-sure termination and discuss the parametric supermartingale
and lexicographic ranking supermartingale based approach, then discuss the approach
for high-probability termination. Finally, we discuss related works (Section 7.6),
and conclude with future perspective (Section 7.7).
7.2 Preliminaries
7.2.1 Syntax of Probabilistic Programs
We consider a mathematically clean formulation of a simple imperative probabilistic
programming language with real-valued numerical variables. An abstract grammar
of our probabilistic language is presented in Figure 7.1. There, ⟨pvar⟩stands for
program variables, while ⟨expr⟩and ⟨boolexpr⟩represent arithmetic expressions
and boolean predicates, respectively.
Expressions and Predicates. We assume that the expressions used in each program
satisfy the following: (1) for each expression E over variables {x1,. . ., xn} and each
n-dimensional vector x the value E(x) is well deﬁned; and (2) the function deﬁned
by each expression E is Borel-measurable (for deﬁnition of Borel-measurability, see,
e.g. Billingsley (1995)). This holds in particular for expressions built using standard
arithmetic operators (+,−,∗,/), provided that expressions evaluating to zero are not
allowed as divisors. A predicate is a boolean combination of atomic predicates of
the form E ≤E ′, where E, E ′ are expressions. We denote by x |= ψ the fact that
the predicate ψ is satisﬁed by substituting values from of x for the corresponding
variables in ψ.
Probability and Non-Determinism. Apart from the classical programming con-
structs, our probabilistic programs also have constructs introducing probabilistic
and non-deterministic behaviour. The former include probabilistic branching (e.g.
'if prob(1
3) then...') and sampling of a variable value from a probability distribution
(e.g. x := sample(Uniform[−2,1])). We allow both discrete and continuous distribu-
tions and we also permit sampling instructions to appear in place of variables within
expressions. For the purpose of our analysis, we require that for each distribution
d appearing in the program we know the following characteristics: the expected
value E[d] and a set SPd containing the support of d (the support of d is the
smallest closed set of real numbers whose complement has probability zero under
d). We also allow (demonic) non-deterministic branching represented by ⋆in the
conditional guard. The techniques presented in this chapter can be extended also to
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

7.2 Preliminaries
225
⟨stmt⟩::= ⟨assgn⟩| skip | ⟨stmt⟩; ⟨stmt⟩
| if ⟨ndboolexpr⟩then ⟨stmt⟩else ⟨stmt⟩ﬁ
| while ⟨boolexpr⟩do ⟨stmt⟩od
⟨assgn⟩::= ⟨pvar⟩:= ⟨expr⟩| ⟨pvar⟩:= sample(⟨dist⟩)
⟨ndboolexpr⟩::= ⋆| prob(p) | ⟨boolexpr⟩
Figure 7.1 Abstract grammar of imperative probabilistic programs.
programs with non-deterministic assignments, but we omit this feature for the sake
of simplicity.
Aﬃne Probabilistic Programs. The mathematical techniques presented in this
chapter are applicable to a rather general class of probabilistic programs. When
considering automation of these methods, we restrict our attention to aﬃne programs.
A probabilistic program P is aﬃne if each arithmetic expression occurring in P
(i.e. in its loop guards, conditionals, and right-hand sides of assignments) is an
aﬃne expression, i.e. an expression of the form b + 	n
i=1 aixi, where b,a1,. . .,an
are real-valued constants.
7.2.2 Semantics of Probabilistic Programs
We now sketch our deﬁnition of semantics of PPs with non-determinism. We use the
standard operational semantics presented in more detail in (Agrawal et al., 2018).
Basics of Probability Theory. We assume some familiarity with basic concepts of
probability theory. A probability space is a triple (Ω, F,P), where Ω is a non-empty
set (so called sample space), F is a sigma-algebra of measurable sets over Ω,
i.e. a collection of subsets of Ω that contains the empty set ∅, and that is closed
under complementation and countable unions, and P is a probability measure on
F , i.e., a function P: F →[0,1] such that: (1) P(∅) = 0, (2) for all A ∈F it holds
P(Ω ∖A) = 1 −P(A), and (3) for all pairwise disjoint countable set sequences
A1, A2,· · · ∈F (i.e., Ai ∩Aj = ∅for all i  j) we have 	∞
i=1 P(Ai) = P(∞
i=1 Ai).
A random variable in a probability space (Ω, F,P) is an F -measurable function
R: Ω →R ∪{∞}, i.e., a function such that for every a ∈R ∪{∞} the set
{ω ∈Ω | R(ω) ≤a} belongs to F . We denote by E[R] the expected value of a
random variable R (see (Billingsley, 1995, Chapter 5) for a formal deﬁnition). A
random vector in (Ω, F,P) is a vector whose every component is a random variable
in this probability space. We denote by X[j] the j-component of a vector X. A
stochastic process in a probability space (Ω, F,P) is an inﬁnite sequence of random
vectors in this space. A ﬁltration in the probability space is an inﬁnite non-decreasing
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

226
Chatterjee, Fu and Novotný: Termination Analysis with Martingales
sequence of sigma-algebras F0 ⊆F1 ⊆F2 ⊆· · · F characterizing an increase
of available information over time (see (Williams, 1991, Chapter 10)). A process
{Xn}n∈N0 is adapted to the ﬁltration {Fn}n∈N0, if Xn is Fn-measurable for each
n ∈N0. We will also use random variables of the form R: Ω →S for some ﬁnite
set S, which easily translates to the variables above.
Conﬁgurations and Runs. For a program P we denote by VP the set of programs
variables used in P (we routinely drop the subscript when P is known from the
context). A conﬁguration of a PP P is a tuple (ℓ,x), where ℓis a program location
(a line of the source code carrying a command) and x is valuation, i.e. a |VP|-
dimensional vector s.t. x[t] is the current value of variable t ∈VP. A run is a ﬁnite
or inﬁnite sequence of conﬁgurations corresponding to a possible execution of the
program. A ﬁnite run which does not end in the program's terminal location is also
called an execution fragment.
Schedulers. Non-determinism in a program is resolved via a scheduler. Formally,
a scheduler is a function σ assigning to every execution fragment that ends in a
location containing a command if ⋆then... else... a probability distribution over
the if- and else branches. We impose an additional measurability condition on
schedulers, so as to ensure that the semantics of probabilistic non-deterministic
programs is deﬁned in a mathematically sound way. The deﬁnition of a measurable
scheduler that we use is the standard one used when dealing with systems that
exhibit both probabilistic and non-deterministic behaviour over a continuous state
space (Neuhäußer et al., 2009; Neuhäußer and Katoen, 2007). In the rest of this
work, we refer to measurable schedulers simply as "schedulers."
From a Program to a Stochastic process. A program P together with a scheduler
σ and initial variable valuation x0 deﬁne a stochastic process which produces a
random run (ℓ0,x0)(ℓ1,x1)(ℓ2,x2) · · · . The evolution of this process can be informally
described as follows: we start in the initial conﬁguration, i.e. (ℓ0,x0), where ℓ0
corresponds to the ﬁrst command of P and ℓ0 is the initial valuation of variables
(from now on, we assume that each program is accompanied by some initial variable
valuation denoted xinit). Now assume that i steps have elapsed and the program has
not yet terminated, and let πi = (ℓ0,x0)(ℓ1,x1) · · · (ℓi,xi) be the execution fragment
produced so far. Then the next conﬁguration (ℓi+1,xi+1) is chosen as follows:
• If ℓi corresponds to a deterministic assignment, the assignment is performed
and the program location advances to the next command, which yields the new
conﬁguration.
• If ℓi corresponds to a probabilistic assignment, the value to assign is ﬁrst sampled
from a given distribution, after which the assignment of the sampled value is
performed as above.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

7.2 Preliminaries
227
• If ℓi corresponds to a command if ⋆then..., then a branch to execute is sampled
according to scheduler σ, i.e. from the distribution σ(πi). The valuation remains
unchanged, but ℓi+1 advances to the ﬁrst command of the sampled branch.
• If ℓi corresponds to a command if prob(p) then..., then we select the if branch
with probability p and the else branch with probability 1 −p. The selected branch
is then executed as above.
• Otherwise, ℓi contains a standard deterministic conditional (branching or loop
guard). We evaluate the truth value of the conditional under the current valuation
xi to select the correct branch, which is then executed as above.
The above intuition can be formalized by showing that each probabilistic program
P together with a scheduler σ and initial valuation x0 uniquely determine a certain
probability space (ΩRun,R,Pσ
x0) in which ΩRun is a set of all runs in P, and a
stochastic process Cσ = {Cσ
i }∞
i=0 in this space such that for each run ϱ ∈ΩRun we
have that Cσ
i (ϱ) is the i-th conﬁguration on ϱ. The formal construction of R and
Pσ
x0 proceeds via the standard cylinder construction (Ash and Doléans-Dade, 2000,
Theorem 2.7.2). We denote by Eσ
x0 the expectation operator in the probability space
(ΩRun,R,Pσ
x0).
7.2.3 Termination
Each program P has a special location ℓout corresponding to the value of the program
counter after ﬁnishing the execution of P. We say that a run terminates if it reaches a
conﬁguration whose ﬁrst component is ℓout; such conﬁgurations are called terminal.
Analysing program termination is one of the fundamental questions already in
non-probabilistic program analysis. The question whether (every execution of) a
program terminates is really just a re-statement of the classical Halting problem
for Turing machines, which is, per one of the ﬁrst fundamental results in computer
science, undecidable (Turing, 1937). While we cannot decide whether a given
program terminates, we can still aim to prove program termination via automated
means, i.e. construct an algorithm which proves termination of as many terminating
programs as possible, and reports a failure when it is unable to ﬁnd such a proof
(note that failure to ﬁnd a termination proof does not, per se, prove the program's
non-termination).
A classical technique for proving termination of non-probabilistic programs is
the synthesis of an appropriate ranking function (Floyd, 1967). A ranking function
maps program conﬁgurations to rational numbers, satisfying the following two
properties: (1) each step of the program's execution strictly decreases the value
of the ranking function by a value bounded away from zero, say at least by one;
and (2) non-terminal conﬁgurations are mapped to positive numbers. Due to this
strict decrease, the value of the function cannot stay positive ad inﬁnitum; hence, the
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

228
Chatterjee, Fu and Novotný: Termination Analysis with Martingales
existence of a ranking function shows that the program terminates. Conversely, if
we restrict to non-probabilistic programs with bounded non-determinism (where the
number of non-deterministic choices in every step is bounded by some constant, such
as in our syntax), then each such terminating program possesses a ranking function
which maps a conﬁguration (ℓ,x) to the maximal number of steps the program needs
to reach a terminal conﬁguration from (ℓ,x). Since termination is undecidable, we
cannot have a sound and complete algorithm for synthesis of such ranking functions.
We can however employ techniques that are sound and conditionally complete in
the sense that they search for ranking functions of a restricted form (such as linear
ranking functions) and are guaranteed to ﬁnd such a restricted ranking function
whenever it exists (Bradley et al., 2005a; Colón and Sipma, 2001; Podelski and
Rybalchenko, 2004).
7.2.4 Termination Questions for Probabilistic Programs
Termination and Termination Time. Recall that ℓout is a location to a terminated
program execution. We deﬁne a random variable Term such that for each run ϱ the
value Term(ϱ) represents the ﬁrst point in time when the current location is ℓout. If a
run ϱ does not terminate, then Term(ϱ) = ∞. We call Term the termination time of
P.
We consider the following fundamental computational problems regarding termi-
nation:
• Almost-sure termination: A probabilistic program P is almost-surely (a.s.) termi-
nating if under each scheduler σ it holds that Pσ
xinit({ϱ ∈ΩRun | ϱ terminates}) = 1,
or equivalently, if for each σ it holds Pσ
xinit(Term < ∞) = 1.
• Finite and bounded termination: A probabilistic program P is said to be ﬁnitely
(aka positive almost-surely (Fioriti and Hermanns, 2015)) terminating if under
each σ it holds that Eσ
xinit[Term] < ∞. Furthermore, the program P is boundedly
terminating if we have supσ Eσ
xinit[Term] < ∞.
• Probabilistic termination: In this generalization of the a.s. termination problem,
we aim to compute a non-trivial lower bound p ∈[0,1] on termination probability,
i.e. p s.t. for each σ we have Pσ
xinit({ϱ ∈ΩRun | ϱ terminates}) ≥p. In particular,
here we also aim to analyse programs that are not necessarily a.s. terminating.
Remark 7.1
We present some remarks about the above deﬁnitions.
• First, ﬁnite termination implies almost-sure termination as Eσ
xinit[Term] < ∞
implies Pσ
xinit(Term) = 1; however, the converse does not hold (see Example 7.2
below).
• Second, there is subtle but important conceptual diﬀerence between ﬁnite and
bounded termination. While the ﬁrst asks for the expected termination time to be
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

7.2 Preliminaries
229
ﬁnite for all schedulers, the expected termination time can still grow unbounded
with diﬀerent schedulers. In contrast, the bounded termination asks for the
expected termination time to be bounded for all schedulers (but can depend on
initial conﬁguration). For probabilistic programs without non-determinism they
coincide, since there is no quantiﬁcation over schedulers. In general bounded
termination implies ﬁnite termination; however, the converse does not hold (see
Example 7.3 below).
It follows that bounded termination provides the strongest termination guarantee
among the above questions, and we will focus on bounded termination.
Example 7.2
We present an example program that is almost-sure terminating, but
not ﬁnite terminating. Consider the probabilistic program depicted in Figure 7.2.
The loop models the classical symmetric random walk that hits zero almost-surely,
but in inﬁnite expected termination time (see Williams, 1991, Chapter 10). Hence,
the loop is a.s. terminating but not ﬁnitely terminating.
Example 7.3
We present, in Figure 7.3, an example program that is ﬁnitely
terminating, but not boundedly terminating. A scheduler for the program can be
characterized by how many times the scheduler chooses the program counter 6 from
the non-deterministic branch at the program counter 5 (ﬁnitely or inﬁnitely), as once
the scheduler chooses the program counter 10, the program then jumps out of the
while loop at the program counter 4 and terminates after the execution of the while
loop at the program counter 12. Under each such scheduler, the expected termination
time is ﬁnite, so we have that the program is ﬁnitely terminating. However, since
we have 3n at the right-hand-side of the program counter 10 and the probability to
jump out of the while loop at the non-deterministic branch 4 is 0.5 by the Bernoulli
distribution, the expected termination time under a scheduler can be arbitrarily large
when the number of times to choose the program counter 6 at the program counter 5
increases. Hence, there is no upper bound on the expected termination time for all
schedulers, i.e., the probabilistic program is not boundedly terminating. See Fioriti
and Hermanns (2015, Page 2) for details.
We now argue that termination analysis for probabilistic programs is more complex
than for non-probabilistic programs.
First, note that the classical ranking functions do not suﬃce to prove even
almost-sure termination. Since ranking functions are designed for non-probabilistic
programs, applying them to probabilistic programs would necessitate replacing
probabilistic choices and assignments with non-determinism. But Figure 7.2 shows
a program which terminates almost-surely in the probabilistic setting, but does not
necessarily terminate when the choice on line 3 is replaced by non-determinism (the
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

230
Chatterjee, Fu and Novotný: Termination Analysis with Martingales
non-deterministic choice might e.g. alternate between the if- and the else-branch,
preventing x from decreasing to 0).
Second, there are deeper theoretical reasons for the hardness of probabilistic
termination. The termination of classical programs, i.e. the halting problem, is
undecidable but recursively enumerable. As shown by (Kaminski and Katoen, 2015),
the problems of deciding almost sure and positive termination in probabilistic
programs are complete for the 2nd level of the arithmetic hierarchy.
Hence, the classical analysis is not applicable and new approaches to probabilistic
termination are needed.
7.3 Theoretical Foundations for Bounded Termination
In this section, we establish theoretical foundations for proving bounded termina-
tion of probabilistic programs. First, we consider probabilistic programs without
non-determinism and demonstrate mathematical approaches for proving bounded
termination over such programs. Second, we extend the approach to probabilis-
tic programs with non-determinism. Third, we show that our approach is sound
and complete for proving bounded termination of non-deterministic probabilistic
programs. Finally, we describe algorithms for proving bounded termination.
7.3.1 Probabilistic Programs without Non-determinism
For probabilistic programs without non-determinism, Chakarov and Sankara-
narayanan (2013) ﬁrst proposed a sound approach for proving bounded termination.
(Recall that in the absence of non-determinism, ﬁnite and bounded termination
coincide.) The approach can be described as follows.
• First, a general result on bounded termination of a special class of stochastic
processes called ranking supermartingales (RSMs) is established.
• Second, program executions are translated into stochastic processes through a
notion of RSM-maps.
• Third, the existence of RSM-maps that ensure bounded termination of probabilistic
programs without non-determinism is established. The central idea of the proof is
a construction of RSMs from RSM-maps.
We begin with the notion of ranking supermartingales which is the key to the
approach. We take the original deﬁnition in Chakarov and Sankaranarayanan (2013).
Deﬁnition 7.4 (Ranking Supermartingales)
A discrete-time stochastic process
Γ = {Xn}n∈N0 adapted to a ﬁltration {Fn}n∈N0 is a ranking supermartingale (RSM)
if there exist real numbers ϵ > 0 and K ≤0 such that for all n ∈N0, the following
conditions hold:
• (integrability) E[|Xn|] < ∞;
• (lower-bound) it holds a.s. that Xn ≥K;
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

7.3 Bounded Termination: Theory
231
1: x := 100 ;
2:
while x ≥0 do
3:
i f prob(0.5) then
4:
x := x + 1
e l s e
5:
x := x −1
f i ;
od
6:
Figure 7.2 An a.s. (but not ﬁnitely) terminating example
1 : n := 0 ; 2 : i := 0 ; 3 : c := 0 ;
4 :
while c = 0 do
5 :
i f ⋆then
6 :
c := sample(Bernoulli (0.5) ) ;
7 :
i f
c = 0 then
8 :
n := n + 1
e l s e
9 :
i := n
f i
e l s e
10 :
i := 3n ;
11 :
c := 1
f i
od ;
12 :
while i > 0 do
13 :
i := i −1
od
14 :
Figure 7.3 A ﬁnitely (but not boundedly) terminating example
• (ranking) it holds a.s. that E[Xn+1|Fn] ≤Xn−ϵ ·1Xn ≥0, where the random variable
E[Xn+1|Fn] is the conditional expectation of Xn+1 given the sigma-algebra Fn
(see Williams, 1991, Chapter 9 for details), and the random variable 1Xn ≥0 takes
value 1 if the event Xn ≥0 holds and 0 otherwise.
Informally, an RSM is a stochastic process whose values have a lower bound and
decrease in expectation when the step increases.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

232
Chatterjee, Fu and Novotný: Termination Analysis with Martingales
The random variable ZΓ.
Given an RSM Γ = {Xn}n∈N0 adapted to a ﬁltration
{Fn}n∈N0, we deﬁne the random variable ZΓ by ZΓ(ω) := min{n | Xn(ω) < 0}
where min ∅:= ∞. By deﬁnition, the random variable ZΓ measures the amount of
steps before the value of the stochastic process Γ drops below zero for the ﬁrst time.
The following theorem from illustrates the relationship between an RSM Γ and
its termination time ZΓ. There are several versions for the theorem. The original
version is Chakarov and Sankaranarayanan (2013) which only asserts almost-sure
termination. (Recall that bounded termination implies almost-sure termination, but
not vice versa.) Then in Fioriti and Hermanns (2015, Lemma 5.5), the theorem
was extended to bounded termination with an explicit upper bound on expected
termination time. The version in Fioriti and Hermanns (2015, Lemma 5.5) restricts
K to be zero. Here we follow the version in Chatterjee et al. (2018a) that relaxes
K to be a non-positive number while deriving an upper bound on the expected
termination time.
Proposition 7.5
Let Γ = {Xn}n∈N0 be an RSM adapted to a ﬁltration {Fn}n∈N0
with ϵ,K given as in Deﬁnition 7.4. Then P(ZΓ < ∞) = 1 and E[ZΓ] ≤E(X0)−K
ϵ
.
Proof Sketch
Using the ranking condition in Deﬁnition 7.4, we ﬁrst prove by
induction on n ≥0 that E[Xn] ≤E[X0] −ϵ · 	n−1
k=0 P(Xk ≥0). Moreover, we have
from the lower-bound condition in Deﬁnition 7.4 that E[Xn] ≥K, for all n. Then we
obtain that for all n, it holds that
	n
k=0 P(Xk ≥0) ≤E[X0]−E[Xn+1]
ϵ
≤E[X0]−K
ϵ
.
Hence, the series 	∞
k=0 P(Xk ≥0) converges and is no greater than E[X0]−K
ϵ
. It
follows from ZΓ(ω) > k ⇒Xk(ω) ≥0 (for all k,ω) that
• P(ZΓ = ∞) = limk→∞P(ZΓ > k) = 0, and
• E[ZΓ] = 	∞
k=0 P(k < ZΓ < ∞) ≤	∞
k=0 P(Xk ≥0) ≤E[X0]−K
ϵ
.
Then the desired result follows. See Fioriti and Hermanns (2015, Lemma 5.5) and
Chatterjee et al. (2018a, Proposition 3.2) for details.
□
Theorem 7.5 established the ﬁrst step of the approach. In the next step, we need
to relate RSMs with probabilistic programs. To accomplish this, the notion of
RSM-maps plays a key role. We ﬁrst introduce the notion of pre-expectation, then
that of RSM-maps.
Below we ﬁx a non-deterministic probabilistic program P with the set L of
locations (values of the program counter), the set V of program variables and the set
D of probability distributions appearing in P. Then the set of variable valuations is
R|V | and the set of conﬁgurations is L × R|V |. Moreover, we say that a sampling
valuation is a real vector in R|D | that represents a vector of sampled values from
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

7.3 Bounded Termination: Theory
233
all probability distributions. Then for each assignment statement in P at a location
ℓ, regardless of whether the assignment statement is deterministic or a sampling,
we have a function Fℓwhich maps each current variable valuation x and current
sampling valuation r to the next variable valuation Fℓ(x,r) after the execution of the
assignment statement.
The following deﬁnition introduces the notion of pre-expectation (Chatterjee
et al., 2018a; Chakarov and Sankaranarayanan, 2013; McIver and Morgan, 2005).
Deﬁnition 7.6 (Pre-expectation)
Let η : L × R|V | →R be a function which maps
every conﬁguration to a real number. We deﬁne the pre-expectation of η as the
function preη : L × R|V | →R by:
• preη(ℓ,x) := 	
ℓ′∈L pℓ,ℓ′ · η (ℓ′,x) if ℓcorresponds to a probabilistic branch and
pℓ,ℓ′ is the probability that the next location is ℓ′;
• preη(ℓ,x) := η (ℓ′,x) if ℓcorresponds to either an if-branch or a while-loop and ℓ′
is the next location determined by the current variable valuation x and the boolean
predicate associated with ℓ;
• preη(ℓ,x) := η(ℓ′,Er (Fℓ(x,r))) if ℓcorresponds to an assignment statement,
where ℓ′ is the location after the assignment statement and the expectation Er(−)
is considered when x is ﬁxed and r observes the corresponding probability
distributions in D.
Intuitively, preη(ℓ,x) is the expected value of η after the execution of the statement
at ℓwith the current conﬁguration (ℓ,x).
Remark 7.7
The pre-expectation here is taken from Chatterjee et al. (2018a), and
is a small-step version that only considers the execution of one individual statement.
A big-step version is given in Chakarov and Sankaranarayanan (2013) and McIver
and Morgan (2005) that consider the execution of a block of statements. The big-step
version can be obtained by iterating the small-step version statement by statement in
the block.
Invariants. To introduce the notion of ranking-supermartingale maps, we further
need the notion of invariants. Formally, given an initial conﬁguration (ℓ0,x0), an
invariant I is a function that assigns to each location ℓa subset of variable valuations
I(ℓ) such that in any program execution from the initial conﬁguration and for all
conﬁgurations (ℓ,x) visited in the execution, we have that x ∈I(ℓ). Intuitively, an
invariant is an over-approximation of the reachable conﬁgurations from a speciﬁed
initial conﬁguration. A trivial invariant is the one that assigns to all locations the set
R|V | of all variable valuations. Usually, we can obtain more precise invariants that
tightly approximate the reachable conﬁgurations through well-established techniques
such as abstract interpretation (Cousot and Cousot, 1977).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

234
Chatterjee, Fu and Novotný: Termination Analysis with Martingales
Now we introduce the notion of ranking-supermartingale maps.
Deﬁnition 7.8 (Ranking-supermartingale Maps)
A ranking-supermartingale map
(RSM-map) wrt an invariant I is a function η : L × R|V | →R such that there exist
real numbers ϵ > 0 and K,K′ < 0 such that for all conﬁgurations (ℓ,x), the following
conditions hold:
(C1) if ℓ ℓout and x ∈I(ℓ), then η(ℓ,x) ≥0;
(C2) if ℓ= ℓout and x ∈I(ℓ), then K ≤η(ℓ,x) ≤K′;
(C3) if ℓ ℓout and x ∈I(ℓ), then preη(ℓ,x) ≤η(ℓ,x) −ϵ.
Intuitively, the condition (C1) speciﬁes that when the program does not terminate
then the value of the RSM-map should be non-negative. The condition (C2) speciﬁes
that when the program terminates, then the value should be negative and bounded
from below. Note that (C1) and (C2) together guarantees that the program terminates
iﬀthe value of the RSM-map is negative. Finally, the condition (C3) speciﬁes that
the pre-expectation at non-terminal locations should decrease at least by some ﬁxed
positive amount, which is related to the ranking condition in the RSM deﬁnition (cf.
Deﬁnition 7.4).
The key role played by RSM-maps is that if we have an RSM-map, then we can
assert the bounded termination of the program and an explicit upper bound. In
other words, RSM-maps are sound for proving bounded termination of probabilistic
programs. This is demonstrated by the following proposition from (Chatterjee et al.,
2018a, Theorem 3.8).
Proposition 7.9 (Soundness)
If there exists an RSM-map η wrt some invariant I,
then we have that supσ Eσ
xinit[Term] ≤η(ℓ0,xinit)−K
ϵ
.
Proof Sketch
Suppose that there is an RSM-map η. Let the stochastic process
Γ = {Xn}n∈N0 be given by: Xn := η(Cn). (Recall that Cn is the vector of random
variables that represents the conﬁguration at the n-th step in a program execution.)
Then from (C2) and (C3), we have that Γ is an RSM with the same ϵ,K. Thus we
obtain from Proposition 7.5 that E[ZΓ] ≤E[X0]−K
ϵ
. Furthermore, from (C1) and
(C2), we have that Term = ZΓ. It follows that Eσ
xinit[ZΓ] ≤E[X0]−K
ϵ
for all schedulers
σ. See Chatterjee et al. (2018a, Theorem 3.8) for details.
□
Below we illustrate the approach of RSM-maps for proving bounded termination
of probabilistic programs through a simple example. The example is taken from
Chakarov and Sankaranarayanan (2013, Example 2).
Example 7.10 (A Tortoise-Hare Race)
Consider a scenario where a tortoise and a
hare race against each other. The program representation for such a race is depicted
in the left part of Figure 7.4. At the beginning, the hare starts at the position 0
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

7.3 Bounded Termination: Theory
235
1: h := 0 ;
2: t := 30 ;
3:
while h ≤t do
4:
i f prob(0.5) then
5:
r := sample(Uniform(0,10)) ;
6:
h := h + r
e l s e
7:
skip
f i ;
8:
t := t + 1
od
9:
ℓ
Invariant I
RSM-map η
1
true
119
2
h = 0
118
3
h ≤t + 9
3 · (t −h) + 27
4
h ≤t
3 · (t −h) + 26
5
h ≤t
3 · (t −h) + 18
6
h ≤t
∧
0 ≤r ≤10
3 · (t −h −r) + 32
7
h ≤t
3 · (t −h) + 32
8
h ≤t + 10
3 · (t −h) + 31
9
t ≤h
−1
Figure 7.4 Left: The Probabilistic Program for a Tortoise-Hare Race Right: An RSM-map for
the Program
(location 1), while the tortoise starts at the position 30 (location 2). Then in each
round (an iteration of the loop body from the location 4 to location 8), the hare either
stops (location 7) or proceeds with a random distance that observes the uniform
distribution over [0,10] (location 6), both with probability 1
2, while the tortoise
always proceeds with a unit distance (location 8). It is intuitively clear that the hare
will eventually catch the tortoise and the program will enter the terminal location
ℓout = 9 in ﬁnite expected time.
The right part of Figure 7.4 illustrates an RSM-map η w.r.t an invariant I for
the program, where "ℓ" stands for "location", the invariant I is speciﬁed through
conditions on program variables for each location (e.g., I(3) is the set of all variable
valuations x where x[h] ≤x[t] + 9), and the RSM-map η is also speciﬁed for each
location (e.g., η(3,x) = 3 · (x[t] −x[h]) + 27).
The function η is an RSM-map with ϵ = 1,K = K′ = −1 since it satisﬁes (C1)-
(C3). For example, the condition (C1) is satisﬁed at the location 3 since x[h] ≤x[t]+9
implies that 3·(x[t]−x[h])+27 ≥0; the condition (C2) is straightforwardly satisﬁed
at the location 9; ﬁnally, the condition (C3) at the location 5 is satisﬁed as we
have E[uniform(0,10)] = 5 and 3 · (t −h −E(r)) + 32 ≤3 · (t −h) + 18 −1. As a
consequence, we obtain that Exinit[Term] ≤η(1,xinit)−K
ϵ
= 120.
□
7.3.2 Probabilistic Programs with Non-determinism
The approach of ranking supermartingales can be directly extended to non-determinism.
However, before we illustrate the extension, an important issue to resolve is the
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

236
Chatterjee, Fu and Novotný: Termination Analysis with Martingales
operational semantics with non-determinism. There is a diversity in the operational
semantics for probabilistic programs with non-determinism. The semantics can
be either directly based on random samplings (Fioriti and Hermanns, 2015) or
Markov decision processes (MDPs). Below we ﬁrst describe the result with random-
sampling semantics (Fioriti and Hermanns, 2015), then the results with the MDP
semantics (Chatterjee et al., 2018a).
Sampling-Based Semantics.
In Fioriti and Hermanns (2015), a semantics directly
based on samplings is proposed. Under this semantics, a sample point (in the sample
space) is an inﬁnite sequence of sampled values from corresponding probability
distributions in the program. Then for each scheduler σ, there is a termination-
time random variable Termσ. The advantage of this semantics is that there is only
one probability space (i.e., the set of all inﬁnite sequences of sampled values).
However, the cost is that there are many random variables Termσ, and one needs
to deﬁne a "supremum" random variable Term∗:= supσ Termσ where σ ranges
over all schedulers. As a result, a relative completeness result under such semantics
is established in Fioriti and Hermanns (2015, Theorem 5.8) which states that if
E(Term∗) < ∞then there exists a ranking supermartingale. As the semantics takes
the supremum over all termination-time random variables, it is infeasible to explore
the internal eﬀect of an individual scheduler. As a consequence, it is diﬃcult to
develop algorithmic approaches based on this semantics.
MDP-Based Semantics.
In Chatterjee et al. (2018a), the MDP-semantics is
adopted. MDPs are a standard operational model for probabilistic systems with non-
determinism. Under the MDP-semantics, a state is a conﬁguration of the program,
while the probabilistic transitions between conﬁgurations are determined by the
imperative semantics of each individual statement. Compared with the sampling-
based semantics, there is only one termination-time random variable Term and each
scheduler determines a probabilistic space. Since the behaviour of an individual
scheduler can be manipulated under this semantics, algorithmic approaches can be
developed (which will be further illustrated in Section 7.4).
We follow the MDP-based semantics and demonstrate the extension of ranking
supermartingales to non-determinism. To introduce the notion of RSM-maps in the
context of non-determinism, we ﬁrst extend the notion of pre-expectation.
Below we ﬁx a non-deterministic probabilistic program P with the set L of
locations, the set V of program variables and the set D of probability distributions
appearing in P.
Deﬁnition 7.11 (Pre-expectation)
Let η : L × R|V | →R be a function which maps
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

7.3 Bounded Termination: Theory
237
every conﬁguration to a real number. We deﬁne the pre-expectation of η as the
function preη : L × R|V | →R by:
• preη(ℓ,x) := 	
ℓ′∈L pℓ,ℓ′ · η (ℓ′,x) if ℓcorresponds to a probabilistic branch and
pℓ,ℓ′ is the probability that the next location is ℓ′;
• preη(ℓ,x) := η (ℓ′,x) if ℓcorresponds to either an if-branch or a while-loop and
ℓ′ is the next location given the current variable valuation x;
• preη(ℓ,x) := η(ℓ′,Er [Fℓ(x,r)]) if the location ℓcorresponds to an assignment
statement, where ℓ′ is the location after the assignment statement and the
expectation Er(−) is considered when x is ﬁxed and r observes the corresponding
probability distributions in D;
• preη(ℓ,x) := max{η(ℓth,x),η(ℓel,x)} if ℓcorresponds to a non-deterministic branch
where ℓth and ℓel are the locations for respectively the then- and else-branch.
Compared with Deﬁnition 7.6, the current deﬁnition is extended with non-
determinism. In the last item of Deﬁnition 7.11, the pre-expectation at a non-
deterministic branch are deﬁned as the maximum over its then- and else-branches.
The reason to have maximum is that the non-deterministic branch in our programming
language can be resolved arbitrarily by any scheduler, so we need to consider the
worst case at non-deterministic branches regardless of the choice of the scheduler.
Soundness Result.
Once we extend pre-expectation with non-determinism, we can
keep the deﬁnition for RSM-maps the same as in Deﬁnition 7.8. Then with similar
proofs, the statement of Proposition 7.9 still holds with non-determinism. Thus,
RSM-maps are sound for proving bounded termination of probabilistic programs
with non-determinism.
Proposition 7.12 (Soundness)
RSM-maps are sound for proving bounded termi-
nation of probabilistic programs with non-determinism.
Completeness Result.
In Fu and Chatterjee (2019, Theorem 2), a completeness
result is established for RSM-maps and probabilistic programs with integer-valued
variables. The result states that if the expected termination time of the probabilistic
program is bounded for all schedulers, then there exists an RSM-map. The formal
statement is as follows.
Proposition 7.13 (Completeness)
If all program variables in a probabilistic
program P are integer-valued and supσ Eσ
xinit[Term] < ∞, then there exists an
RSM-map w.r.t some invariant I for P.
From Proposition 7.12 and Proposition 7.13, we obtain that the approach of RSMs
is sound and complete (through RSM-maps).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

238
Chatterjee, Fu and Novotný: Termination Analysis with Martingales
Theorem 7.14
RSM-maps are sound and complete for proving bounded termination
of probabilistic programs.
Remark 7.15
Note that the termination problems for probabilistic programs gen-
eralize the termination problems for non-probabilistic programs (i.e., the halting
problem of Turing machines) and is undecidable (for detailed complexity characteri-
zation see Kaminski and Katoen (2015)). The above soundness and completeness
result does not imply that program termination is decidable, as it only ensures the
existence of an RSM-map in general form which is not always computable. Thus
the completeness result is orthogonal to the decidability results, however, special
classes of RSM-maps can be obtained algorithmically which we consider in the
following section.
7.4 Algorithms for Proving Bounded Termination
In the previous sections, we have illustrated that the existence of an RSM-map leads
to bounded termination of probabilistic programs. Thus, in order to develop an
algorithmic approach to prove bounded termination of probabilistic programs, it
suﬃces to synthesize an RSM-map. Furthermore, since it is infeasible to synthesize
an RSM-map in general form, in an algorithmic approach one needs to restrict the
form of an RSM-map so as to make the approach feasible. In this section, we illustrate
algorithmic approaches that can synthesize linear and polynomial RSM-maps given
an input invariant (also in special form). Since the class of linear/polynomial RSM-
maps is quite general, the corresponding algorithmic approaches can be applied
to typical probabilistic programs such as gambler's ruin, random walks, robot
navigation, etc. (see the experimental results in Chakarov and Sankaranarayanan
(2013), Chatterjee et al. (2018a) and Chatterjee et al. (2016b) for details).
We ﬁrst describe the algorithmic approach for synthesizing linear RSM-maps
over aﬃne probabilistic programs where the right-hand-side of each assignment
statement is aﬃne in program variables. A linear RSM-map is an RSM-map η such
that for each location ℓ, the function η(ℓ,−) is aﬃne in the program variables of P.
For example, the RSM-map at the right part of Figure 7.4 is linear.
To illustrate the algorithm, we need the well-known Farkas' Lemma that charac-
terizes the inclusion of a polyhedron in a halfspace.
Theorem 7.16 (Farkas' Lemma (Farkas, 1894; Schrijver, 2003))
Let A ∈Rm×n,
b ∈Rm, c ∈Rn and d ∈R. Assume that {x ∈Rn | Ax ≤b}  ∅. Then we have that
{x ∈Rn | Ax ≤b} ⊆{x ∈Rn | cTx ≤d}
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

7.4 Bounded Termination: Algorithms
239
iﬀthere exists y ∈Rm such that y ≥0, ATy = c and bTy ≤d, where y ≥0 means
that every coordinate of y is non-negative.
The Farkas' Linear Assertions Φ.
Farkas' Lemma transforms the inclusion testing
of systems of linear inequalities into an emptiness problem. Given a polyhedron
H = {x ∈Rn | Ax ≤b} as in the statement of Farkas' Lemma (Theorem 7.16),
we deﬁne the predicate Φ[H,c, d](ξ) (which is called a Farkas' linear assertion) for
Farkas' Lemma by
Φ[H,c, d](ξ) := (ξ ≥0) ∧
(
ATξ = c
)
∧
(
bTξ ≤d
)
where ξ is a variable representing a column vector of dimension m. Then by Farkas'
Lemma, we have that H ⊆{x | cTx ≤d} iﬀthere exists a column vector y such that
Φ[H,c, d](y) holds.
Linear Invariants.
We also need the notion of linear invariants. Informally, A
linear invariant is an invariant I such that for all locations ℓwe have that I(ℓ) is a
ﬁnite union of polyhedra.
Now we illustrate the algorithm for synthesizing linear RSM-maps w.r.t a given
linear invariant. The description of the algorithm is as follows.
(i) First, the algorithm establishes a linear template for an RSM map. The linear
template speciﬁes that at each location, the function is aﬃne in program variables
with unknown coeﬃcients. Besides, the algorithm also sets up three unknown
parameters ϵ,K,K′ which correspond to the counterparts in the deﬁnition of
RSM-maps (cf Deﬁnition 7.8).
(ii) Second, the algorithm transforms the conditions (C1)-(C3) equivalently into
Farkas' linear assertions through Farkas' Lemma.
(iii) Third, since the Farkas' linear assertions refer to the emptiness problem
over polyhedra, we can use linear programming to solve those assertions. If a
linear programming solver eventually ﬁnds the concrete values for the unknown
coeﬃcients in the template, then the algorithm ﬁnds a linear RSM-map that
witnesses the bounded termination of the input program. Otherwise, the algorithm
outputs "fail", meaning that the algorithm does not know whether the input
program is boundedly terminating or not.
Since linear programming can be solved in polynomial time, our algorithm also
runs in polynomial time, as is illustrated by the following theorem.
Theorem 7.17 (Chatterjee et al., 2018a, Theorem 4.1)
The problem to synthesize
a linear RSM-map over non-deterministic aﬃne probabilistic programs where all
loop guards are in disjunctive normal form can be solved in polynomial time.
Below we illustrate the details on how the algorithm works on Example 7.10.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

240
Chatterjee, Fu and Novotný: Termination Analysis with Martingales
Example 7.18
We illustrate our algorithm on Example 7.10, where the input
invariant is the same as given by the right part of Figure 7.4.
(i) First, the algorithm establishes a template η for a linear RSM-map so that
η(i,−) = ai · h + bi · t + ci · r + di for 1 ≤i ≤9, where ai, bi,ci, di are unknown
coeﬃcients. The algorithm also sets up the three unknown parameters ϵ,K,K′.
(ii) Second, the algorithm transforms the conditions (C1)-(C3) at all locations into
Farkas' linear assertions. We present two examples for such transformation.
• The condition (C1) at location 6 says that η(6,−) should be non-negative over
the polyhedron H′ := {x | x[h] ≤x[t] ∧0 ≤x[r] ≤10}. Then from Farkas'
Lemma, we construct the Farkas' linear assertion Φ[H′,(−a6,−b6,−c6)T, d6](ξ)
where ξ is a column vector of fresh variables.
• The condition (C3) at location 4 says that 0.5·η(5,−)+0.5·η(7,−)+ϵ ≤η(4,−)
holds over the polyhedron H′′ := {x | x[h] ≤x[t]}. Note that 0.5 · η(5,−) +
0.5 · η(7,−) + ϵ −η(4,−) = (c′) · (h,t,r)T −d′ where c′ = (0.5 · (a5 + a7) −
a4,0.5 · (b5 + b7) −b4,0.5 · (c5 + c7) −c4) and d′ = −0.5 · (d5 + d7) + d4 −ϵ. So
we construct the Farkas' linear assertion Φ[H′′,c′, d′](ξ′) with fresh variables
in ξ′. Note that this assertion is linear in both the unknown coeﬃcients (i.e.,
ai, bi,ci, di's), the unknown parameters ϵ,K,K′ and the variables in ξ′.
(iii) Third, the algorithm collects all the Farkas' linear assertions constructed from
the second step in the conjunctive fashion. Then, together with the constraint
ϵ ≥1 and K,K ≤−1 (which is equivalent to ϵ > 0 and K,K < 0 as we can
always multiply them with a large enough factor), the algorithm calls a linear
programming solver (e.g. Cplex, 2010, Lpsolve, 2016) to get the solution to the
unknown coeﬃcients in the template.
Remark 7.19 (Synthesis of Polynomial RSM-maps)
In several situations, linear
RSM-maps do not suﬃce to prove bounded termination of probabilistic programs.
To extend the applicability of RSM-maps, Chatterjee et al. (2016b) proposed an
eﬃcient sound approach to synthesize polynomial RSM-maps. The approach is
through Positivstellensatz's (Scheiderer, 2008), an extension of Farkas' Lemma to
polynomial case, and linear/semideﬁnite programming. This sound approach gives
polynomial-time algorithms. Moreover, it is shown in Chatterjee et al. (2016b) that
the existence of polynomial RSM-maps is decidable through the ﬁrst-order theory
of reals.
Remark 7.20 (Angelic Non-determinism)
In this chapter, all non-deterministic
branches are demonic in the sense that they cannot be controlled and we need
to consider the worst-case. In contrast to demonic non-deterministic branches,
angelic non-deterministic branches are branches that can be controlled in order to
fulﬁll a prescribed aim. Similar to the demonic case, theoretical and algorithmic
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

7.5 Beyond Bounded Termination
241
approaches for angelic branches have been considered. The diﬀerences for angelic
non-determinism as compared to demonic non-determinism are follows: (i) Motzkin's
Transposition Theorem is used instead of Farkas' Lemma in the algorithm, and
(ii) the problem to decide the existence of a linear RSM-map over aﬃne probabilistic
programs with angelic non-determinism is NP-hard and in PSPACE (see Chatterjee
et al. (2018a) for details).
Remark 7.21 (Concentration Bound)
A key advantage of martingales is that with
additional conditions sharp concentration results can be obtained. For example,
in Chatterjee et al. (2018a), it is shown that the existence of a diﬀerence-bounded
RSM can derive a concentration bound beyond which the probability of non-
termination within a given number of steps decreases exponentially. Informally, an
RSM is diﬀerence-bounded if its change of value is bounded from the current step
to the next step. The key techniques for such concentration bounds are Azuma's or
Hoeﬀding's inequality; for a detailed discussion see Chapter 8 of this book.
7.5 Beyond Bounded Termination
As shown above, ranking supermartingales provide a sound and complete method
of proving bounded termination. In this section, we present several martingale
techniques capable of proving a.s. termination of programs that do not necessarily
terminate in bounded or even ﬁnite expected time. Moreover, already for programs
that do terminate boundedly, some of the techniques we present here provide a
computationally more eﬃcient approach to termination proving. For succinctness,
we will from now on omit displaying the terminal location when presenting program
examples.
7.5.1 Zero Trend and Zeno Behaviour
Consider a program modelling a symmetric random walk (Figure 7.5, here in a dis-
crete variant where the change in each step is either −1 or +1, with equal probability).
It is well-known that such a program is a.s. terminating. At the same time it does
not admit any ranking supermartingale. This is because ranking supermartingales
require that the "distance" to termination strictly decreases (in expectation) in every
step, while the expected one-step change of the symmetric random walk is zero.
Another scenario in which the standard ranking supermartingales are not applicable
is when there is a progress towards termination, but the magnitude of this progress
decreases over the runtime of the program, as is the case in Figure 7.6.
McIver et al. (2018) give a martingale-based proof rule which can handle the
above issues. Here we present a re-formulation of the rule within the scope of our
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

242
Chatterjee, Fu and Novotný: Termination Analysis with Martingales
1:
while x ≥1 do
2:
x := x + sample(Uniform{−1,1})
od
Figure 7.5 Symmetric random walk.
1:
while x ≥1 do
2:
p := 1/(x + 1)
3:
t := sample(Uniform[0,1])
4:
i f t ≤p then
5:
x := 0
e l s e
6:
x := x + 1
f i
od
Figure 7.6 Escaping spline program from (McIver et al., 2018).
syntax and semantics of PPs. In the following, we say that a real function f is
antitone (or, alternatively, non-increasing) if f (x) ≤f (y) ⇔y ≤x.
Deﬁnition 7.22
A non-negative discrete-time stochastic process Γ = {Xn}n∈N0
adapted to a ﬁltration {Fn}n∈N0 is a parametric ranking supermartingale (PRSM) if
there exist functions d (for "decrease") of type d : R →R≥0, and p (for "probability")
of type R →[0,1], both of them antitone and strictly positive on positive reals, such
that the following conditions hold:
(i) for each n ∈N0, E[Xn+1 | Fn] ≤Xn; and
(ii) for each n ∈N0, P(Xn+1 ≤Xn −d(Xn) | Fn) ≥p(Xn).
In PRSMs, the constraint on expected change is relaxed so that we prohibit an
expected increase of the value (i.e., Γ has to be a supermartingale). On the other hand,
in each step, there is a positive probability of a strict decrease, and this probability as
well as the magnitude of the decrease can only get larger as the value of the process
approaches zero (this is to avoid a possible "Zeno behaviour", when the process
would approach zero but never reach it).
Theorem 7.23
Let Γ = {Xn}n∈N0 be a PRSM adapted to some ﬁltration. Then
P(ZΓ < ∞) = 1, i.e. with probability 1 the process reaches a zero value.
Proof (sketch).
Let H ∈N be arbitrary, and and let TH be a random variable
returning the ﬁrst point in time in which Γ jumps out of the interval (0, H]. Then
has P(TH < ∞) = 1. This is because within the interval (0, H] both the probability
and magnitude of decrease of Γ are bounded away from zero (as p and d are
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

7.5 Beyond Bounded Termination
243
antitone on positive reals), so Γ cannot stay within this interval forever with positive
probability. Hence, we can apply the optional stopping theorem for non-negative
supermartingales Williams (1991, Section 10.10 d)), which says that the expected
value E[XTH ] of Γ at time TH satisﬁes E[XTH ] ≤E[X0]. But at the same time
E[XTH ] ≥H · P(XTH ≥H), so P(XTH ≥H) ≤E[X0]/H. Hence, the probability
that Γ "escapes" through the upper boundary of (0, H] decreases as H increases. It
follows that, denoting ℓH the probability that Γ escapes through the lower boundary,
we have ℓH →1 as H →∞. But each ℓH is a lower bound on P(ZΓ < ∞), from
which the result follows.
□
One way to apply this theorem to a concrete program P equipped with an
invariant I is to ﬁnd positive antitone functions pℓ, dℓ(one per each location)
along with a function η mapping P's conﬁgurations to non-negative real numbers,
such that the following holds whenever x ∈I(ℓ): η(ℓ,x) > 0 if ℓis not the
terminal conﬁguration; preη(ℓ,x) ≤η(ℓ,x); and, denoting Pη,x,ℓthe function
mapping (ℓ′,y) to 0 if η(ℓ′,y) ≤η(ℓ,x) −dℓ(η(ℓ,x)), and to 1 otherwise, we have
prePη,x,ℓ(ℓ,x) ≤1 −pℓ(η(ℓ,x)). We call such a function η a PRSM map. Existence
of such a PRSM map guarantees that the program terminates almost-surely. (Note
that allowing separate d and p functions for each location is acceptable, since there
are only ﬁnitely many locations and a minimum of ﬁnitely many positive antitone
functions is again positive and antitone.) However, ﬁnding PRSM maps might be an
intricate process. To illustrate this, consider the symmetric ransom walk in Figure 7.5.
Looking at a deﬁnition of a PRSM, it would seem natural to choose x itself as the
required function, since its expected change is non-positive and with probability 1
2
the value of x decreases by 1 in every loop iteration. However, a mapping η assigning
x to each of the two program locations is not a PRSM map, since at the beginning of
each loop iteration, when transitioning from location 1 to location 2, there is not a
positive probability of decrease of x. Indeed, a simple computation shows that there
is no linear PRSM map for the program. Nevertheless, a PRSM map exists, as the
following example shows.
Example 7.24
Take η such that η(1, x) =
√
x + 1 and η(2, x) = 1
2 · √x + 1
2 ·
√
x + 2.
Indeed, such η only takes positive values for x ≥0 and furthermore, preη(2,x) =
η(2,x) (by deﬁnition) and preη(1,x) = 1
2 ·√x+ 1
2 ·
√
x + 2 ≤
√
x + 1 the last inequality
following by a straightforward application of calculus. As for the decrease function,
when making a step from 2 to 1, there is a p2 = 1
2 probability of the value decreasing
by d2(η(2, x)) = 1
2
√
x + 2 −1
2
√x; while a step from 1 to 2 entails decrease by
d1(η(1, x)) =
√
x + 1 −1
2
√
x + 2 −1
2
√x with probability p1 = 1. A straightforward
analysis reveals that both d1 and d2 are positive and antitone on positive reals.
An alternative "loop-based" approach to usage of PRSMs was proposed in (McIver
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

244
Chatterjee, Fu and Novotný: Termination Analysis with Martingales
et al., 2018). Imagine that our aim is to prove almost-sure termination of a probabilistic
loop 1 : while ψ do P od, and that we are provided with an invariant I(1) for the
head of the loop. Assume that for each conﬁguration x such that x ∈I(1) and x |= ψ,
the body P of the loop terminates when started with variables set according to x.
(Such a guarantee might be obtained by recursively analysing P. If P is loopless,
the guarantee holds trivially.) Let f be a non-negative function mapping variable
valuations to real numbers. Since P is guaranteed to terminate a.s., we can deﬁne
a stochastic process {X f
i }i∈N0 such that for a run ϱ, X f
i (ϱ) returns the value f (˜xi),
where ˜xi is the valuation of variables immediately after the i-th iteration of the loop
along ϱ (if ϱ traverses the loop less than i times, we put X f
i (ϱ) = 0). If the process
{X f
i }i∈N0 is a PRSM, then with the help of Theorem 7.23 it can be easily shown
that the loop indeed terminates almost surely.
Example 7.25
Returning to the symmetric random walk (Figure 7.5), let f (x) = x.
In each iteration of the loop, the value of x has zero expected change, and with
probability p = 1
2 it decreases by d = 1. Hence, {X f
i }i∈N0 is a PRSM and the walk
terminates a.s.
Example 7.26
Consider the escaping spline in Figure 7.6 and set f (x, p) = x. Fix
any point in which the program's execution passes through the loop head and let a
be the value of x at this moment. Then the expected value of x after performing one
loop iteration is 0 ·
1
a+1 + (a + 1) ·
a
a+1 = a, so the expected change of x in each loop
iteration is zero. Moreover, in each iteration the value of x decreases by at least 1
with probability p =
1
x+1. Since p is antitone, it follows that {X f
i }i∈N0 is a PRSM,
and hence the program terminates a.s.
This loop-based use of PRSMs is non-local: we have to analyse the behaviour
of f along one whole loop iteration, as opposed to single computational steps. For
complex loops, ﬁnding the right f and checking its properties might be an intricate
process. In McIver et al. (2018), the authors propose proving required properties of
f in the weakest pre-expectation logic, a formal calculus which extends the classical
weakest-precondition reasoning to probabilistic programs. While falling short of
automated termination analysis, formalizing the proofs in the formal logic makes use
of interactive proof assistants possible, with a potential to achieve provably correct
results with signiﬁcantly decreased human workload.
Remark 7.27
A similar martingale-based approach for proving almost-sure termi-
nation of probabilistic while loops is proposed in Huang et al. (2018). Compared
with McIver et al. (2018), the martingale-based approach in Huang et al. (2018)
can derive asymptotically optimal bounds on tail probabilities of program non-
termination within a given number of steps, while McIver et al. (2018) cannot
derive such probabilities. On the other hand, the approach in McIver et al. (2018)
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

7.5 Beyond Bounded Termination
245
1:
while x ≥1 and y ≥1 do
2:
i f ⋆then
3:
x := x + sample(Uniform{−3,1})
e l s e
4:
y := y −1
5:
x := 2x + sample(Uniform{−1,1})
f i
Figure 7.7 A program without a linear RSM but admitting a LexRSM.
reﬁnes that in Huang et al. and can prove the almost-sure termination of probabilistic
programs that Huang et al. cannot. Another related approach in Huang et al. (2018)
uses Central Limit Theorem to prove almost-sure termination.
7.5.2 Lexicographic Ranking Supermartingales
For some programs (even for those that do terminate in ﬁnite expected time), it
might be diﬃcult to ﬁnd an RSM because of a complex control ﬂow structure, which
makes the computation go through several phases, each with a diﬀerent program
behaviour.
Example 7.28
Consider the program in Figure 7.7 with an invariant I s.t. I(1) =
{(x, y) | x ≥−2 ∧y ≥0}, I(2) = I(3) = I(4) = {(x, y) | x ≥1 ∧y ≥1} and
I(5) = {(x, y) | x ≥1 ∧y ≥0}. The program terminates in bounded expected
time, as shown by the existence of the following (non-linear) RSM map η: η(i) =
(x + 2) · 2y · y −(i−1)
2
for i ∈{1,. . .,4} and η(5) = (x + 2) · 2y+1 · y + 1. Next, it is
easy to verify, that there is no linear RSM map for the program. Intuitively, in the
else branch, executing the decrement of y can decrease the value of a linear function
only by some constant, and this cannot compensate for the possibly unbounded
increase of x caused by doubling.
The absence of a termination certiﬁcate within the scope of linear arithmetic
is somewhat bothersome, as non-linear reasoning can become computationally
hard. In non-probabilistic setting, similar issues were addressed by considering
multi-dimensional termination certiﬁcates. The crucial idea is to consider functions
that map the program conﬁgurations to real-valued vectors instead of just numbers,
such that the value of the vector-valued function strictly decreases in every step
w.r.t. some well-founded ordering of the vectors. This in essence entails a certain
"decomposition" of the termination certiﬁcate: it might happen that a program
admits a multi-dimensional certiﬁcate where each component is linear, even when
no one-dimensional linear certiﬁcates exist. Such certiﬁcates can often be found
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

246
Chatterjee, Fu and Novotný: Termination Analysis with Martingales
via fully automated linear-arithmetic reasoning. A prime example of this concept
are lexicographic ranking functions (Cook et al., 2013), where the well-founded
ordering used is typically the lexicographic ordering on non-negative real vectors.
In the context of probabilistic programs, the lexicographic extension of ranking
supermartingales was introduced in Agrawal et al. (2018). We again start with a
general mathematical deﬁnition and a correctness theorem. In the following, an
n-dimensional stochastic process is a sequence {Xi}∞
i=0 of n-dimensional random
vectors, i.e. each Xi is a vector whose component is a random variable. We denote
by Xi[j] the j-component of Xi.
Deﬁnition 7.29
An n-dimensional real-valued stochastic process {Xi}∞
i=0 is a
lexicographic ϵ-ranking supermartingale (ϵ-LexRSM) adapted to a ﬁltration {Fi}∞
i=0
if the following conditions hold:
(i) For each 1 ≤j ≤n the 1-dimensional stochastic process {Xi[j]}∞
i=0 is adapted
to {Fi}∞
i=0.
(ii) For each i ∈N0 and 1 ≤j ≤n it holds Xi[j] ≥0, i.e. the process takes values
in non-negative real vectors.
(iii) For each i ∈N0 there exists a partition of the set {ω ∈Ω | ∀1 ≤j ≤
n,Xi[j](ω) > 0} into n subsets Li
1,. . ., Li
n, all of them Fi-measurable, such that
for each 1 ≤j ≤n:
• E[Xi+1[j] | Fi](ω) ≤Xi[j](ω) −ϵ for each ω ∈Li
j;
• for all 1 ≤j′ < j we have E[Xi+1[j′] | Fi](ω) ≤Xi[j′](ω) for each ω ∈Li
j.
Note that we dropped the integrability condition from Deﬁnition 7.4. This is
because integrability is only needed to ensure that the conditional expectations in
the deﬁniton of a (Lex)RSM exist and are well-deﬁned. However, the existence of
conditional expectations is also guaranteed for random variables that are real-valued
and non-negative, see Agrawal et al. (2018) for details. This is exactly the case
in LexRSMs. Waiving the integrability condition might simplify application of
LexRSMs to programs with non-linear arithmetic, where, as already shown in Fioriti
and Hermanns (2015), integrability of program variables is not guaranteed.
The full proof of the following theorem is provided in Agrawal et al. (2018).
Theorem 7.30
Let {Xi}∞
i=0 be a LexRSM adapted to some ﬁltration. Then with
probability 1 at least one component of the process eventually attains a zero value.
To apply LexRSMs to a.s. termination proving, let P be a program and I be an
invariant for P.
Deﬁnition 7.31 (Lexicographic Ranking Supermartingale Map)
Let ϵ > 0. An
n-dimensional lexicographic ϵ-ranking supermartingale map (ϵ-LexRSM map) for
a program P with an invariant I is a vector function −→η = (η1,. . .,ηn), where each
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

7.5 Beyond Bounded Termination
247
ηi maps conﬁgurations of P to real numbers, such that for each conﬁguration (ℓ,x)
where x ∈I(ℓ) the following conditions are satisﬁed:
• for all 1 ≤j ≤n: ηj(ℓ,x) ≥0, and if ℓ ℓout, then ηj(ℓ,x) > 0; and
• if ℓ ℓout and ℓdoes not contain a non-deterministic choice, then there exists
1 ≤j ≤n such that
- preηj(ℓ,x) ≤ηj(ℓ,x) −ϵ, and
- for all 1 ≤j′ < j we have preηj′(ℓ,x) ≤ηj′(ℓ,x);
• ℓ ℓout and ℓcontains a non-deterministic choice, then for each ˜ℓ∈{ℓth,ℓel}
(where ℓth,ℓel are the successor locations in the corresponding branches) there is
1 ≤j ≤n such that
- ηj( ˜ℓ,x) ≤ηj(ℓ,x) −ϵ, and
- for all 1 ≤j′ < j we have ηj′( ˜ℓ,x) ≤ηj′(ℓ,x).
If additionally each ηi is a linear expression map, then we call −→η a linear ϵ-LexRSM
map (ϵ-LinLexRSM).
Using Theorem 7.30, we get the following.
Theorem 7.32
Let P be a probabilistic program and I its invariant. Assume that
there exists an ϵ > 0 and an n-dimensional ϵ-LexRSM map for P and I. Then P
terminates almost surely.
Example 7.33
Consider again the program in Figure 7.7, together with the invariant
I from Example 7.28. Then the following 3-dimensional 1-LexRSM map −→η proves
that the program terminates a.s.: −→η (1,x) = (y +1, x +3,4), −→η (2,x) = (y +1, x +3,3),
−→η (3,x) = −→η (4,x) = (y + 1, x + 3,2), −→η (5,x) = (y + 2, x + 3,1), and −→η (ℓout,x) =
(0,0,0).
(Agrawal et al., 2018) presented an algorithm for synthesis of linear LexRSM
maps in aﬃne probabilistic programs with pre-computed invariants. The algorithm is
based on a method for ﬁnding lexicographic ranking functions presented in Alias et al.
(2010). The method attempts to ﬁnd a LinLexRSM map by computing one component
at a time, iteratively employing the algorithm for synthesis of 1-dimensional RSMs
(Section 7.4) as a sub-procedure. The method is complete in the sense that if there
exists a LinLexRSM map for a program P with a given invariant I, then the algorithm
ﬁnds such a map. If guards of all conditional statements and loops in the program
are linear assertions (i.e. conjunctions of linear inequalities), then the algorithm runs
in time polynomial in the size of P and I.
We now show that LexRSMs are indeed capable of proving a.s. termination of
programs that terminate in inﬁnite expected number of steps.
Example 7.34
Consider the program in Figure 7.8, together with an invariant I such
that I(1) = {(x,c) | x ≥1 ∧c ≥0}, I(2) = I(3) = I(4) = {(x,c) | x ≥1 ∧c ≥1},
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

248
Chatterjee, Fu and Novotný: Termination Analysis with Martingales
1:
while c ≥1 and x ≥1 do
2:
i f
prob ( 0 . 5 )
then
3:
x := 2 · x
e l s e
4:
c := 0
f i
od ;
5:
while x ≥1 do
6:
x := x −1
od
Figure 7.8 An example program that is a.s. terminating but with inﬁnite expected termination
time.
I(5) = {(x,c) | x ≥0}, and I(6) = {(x,c) | x ≥1}. The a.s. termination of the
program is witnessed by a linear 1-LexRSM map −→η such that −→η (1,x) = (6c+5,2x+2),
−→η (2,x) = (6c + 4,2x + 2), −→η (3,x) = (6c + 6,2x + 2), −→η (4,x) = (6c,2x + 2),
−→η (5,x) = (1,2x + 2), and −→η (5,x) = (1,2x + 1). However, the program terminates in
an inﬁnite expected number of steps: to see this, note that that the expected value
of variable x upon reaching the second loop is 1
2 · 1 + 1
4 · 2 + 1
8 · 4 + · · · = ∞, and
that the time needed to get out of the second loop is equal to the value of x upon
entering the loop.
Finally, we remark that (Agrawal et al., 2018) introduced further uses of LexRSMs,
such as compositional termination proving (where we prove a.s. termination one
loop at a time, proceeding from the innermost ones) and the use of special type of
linear LexRSMs for obtaining polynomial bounds on expected termination time.
7.5.3 Quantitative Termination and Safety
Consider the program in Figure 7.9. Due to lines 5-6, the program does not terminate
a.s., because there is a positive probability that x hits zero before y falls below 1.
However, a closer look shows that such an event, while possible, is unlikely, since
x tends to increase and y tends to decrease on average. (Chatterjee et al., 2017)
studied martingale-based techniques that can provide lower bounds on termination
probabilities of such programs.
First, the paper introduced the concept of stochastic invariants.
Deﬁnition 7.35
Let (PI, p) be a tuple such that PI is a function mapping each
program location to a set of variable valuations and p ∈[0,1] is a probability. The
tuple (PI, p) is a stochastic invariant for a program P if the following holds: if we
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

7.5 Beyond Bounded Termination
249
1: x := 150, y := 100
2:
while y ≥1 do
3:
x := x + sample(Uniform[−1
4,1])
4:
y := y + sample(Uniform[−1, 1
4])
5:
while x ≤0 do
6:
skip od
od
Figure 7.9 A program with inﬁnitely many reachable conﬁgurations which terminates with high
probability, but not almost surely, together with a sketch of its pCFG.
denote by Fail(PI) the set of all runs that reach a conﬁguration of the form (ℓ,x)
with x  PI(ℓ), then for all schedulers σ it holds Pσ(Fail(PI)) ≤1 −p.
Example 7.36
Consider the example in Figure 7.9 and a tuple (PI, p) for the
program such that PI(5) = {(x, y) | x ≥1
9}, PI(ℓ) = R2 for all the other locations,
and p = 10−5. Using techniques for analysis of random walks, one can prove that
(PI, p) is a stochastic invariant for the program. Below, we will sketch a martingale-
based technique that can be used to prove this formally (and automatically).
Intuitively, unlike their classical counterparts, stochastic invariants are not over-
approximations of the set of reachable conﬁgurations. However, for small p, they
can be viewed as good probabilistic approximations of this set, in the sense that
the probability of reaching a conﬁguration not belonging to this approximation is
small (smaller than p). The following theorem illustrates a possible use of stochastic
invariants in probabilistic termination analysis.
Theorem 7.37
Let P be a probabilistic program, I a (classical) invariant, and
(PI, p) a stochastic invariant for P. Further, let η: L × R|V | →R be a mapping
such that there exists ϵ > 0 for which the following holds in each conﬁguration (ℓ,x)
of P:
• if x ∈I(ℓ), then η(ℓ,x) ≥0, and
• if ℓ ℓout and x ∈I(ℓ) ∩PI(ℓ), then preη(ℓ,x) ≤η(ℓ,x) −ϵ.
Then, under each scheduler σ, the program P terminates with probability at least
1 −p.
Proof (Sketch).
The map η can be viewed as an RSM map for a modiﬁed version of
P which immediately terminates whenever PI is violated. Such a modiﬁed program
therefore terminates with probability 1. Since (PI, p) is a stochastic invariant,
violations of PI can occur with probability at most p, so with probability at least
1 −p the modiﬁed (and thus also the original) program terminates in an orderly
way.
□
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

250
Chatterjee, Fu and Novotný: Termination Analysis with Martingales
Example 7.38
Let (PI,10−5) be the stochastic invariant from Example 7.36
(concerning Figure 7.9). For the corresponding program we have a classical invariant
I such that I(1) = {(30,20)}, I(2) = {(x, y) | x ≥0 ∧y ≥0}, I(3) = {(x, y) | x ≥
0 ∧y ≥1}, I(4) = {(x, y) | x ≥−1
4 ∧y ≥1}, I(5) = {(x, y) | x ≥−1
4 ∧y ≥0},
and I(6) = {(x, y) | 0 ≥x ≥−1
4 ∧y ≥0}. Consider a map η deﬁned as follows:
η(1) = η(5) = 16y+3, η(2) = 16y+2, η(3) = 16y+1, η(4) = 16y, and η(6) = 16y+4.
Then η satisﬁes the conditions of Theorem 7.37, from which it follows that the
program terminates with probability at least 0.99999.
Given an aﬃne probabilistic program and its classical and stochastic invariants, I
and (PI, p) (both I and PI being linear), we can check whether there exists a linear
RSM map satisfying Theorem 7.37 using virtually the same linear system as in
Section 7.4. We just need to take the location-wise intersection I′ of I and PI as the
input invariant used to construct the linear constraints. Although I′ is not a classical
invariant, the linear RSM map obtained from solving the constraints satisﬁes the
requirements of Theorem 7.37.
The question, then, is how to prove that a tuple (PI,p) is a stochastic invariant.
In (Chatterjee et al., 2017), a concept of repulsing supermartingales (RepSMs)
was introduced, which can be used to compute upper bounds on the probability of
violating PI. RepSMs are inspired by use of martingale techniques in the analysis
of one-counter probabilistic systems (Brázdil et al., 2013), and they are in some
sense dual to RSMs: they show that a computation is probabilistically repulsed away
from (rather than attracted to) some set of conﬁgurations. As was the case in the
preceding martingale-based concepts, RepSMs are deﬁned abstractly as a certain
class of stochastic processes, and then applied to program analysis via the notion of
RepSM maps. For the sake of succinctness, we present here only the latter concept.
Deﬁnition 7.39 (Linear repulsing supermartingales)
Let P be a PP with an initial
conﬁguration (ℓinit,xinit), I its invariant, and C ⊆L ×R|V | some set of conﬁgurations
of P. An ϵ-repulsing supermartingale (ϵ-RepSM) map for C supported by I is a
mapping η: L × R|V | →V such that for all conﬁgurations (ℓ,x) of P the following
holds:
• if (ℓ,x) ∈C and x ∈I(ℓ), then η(ℓ,x) ≥0
• if (ℓ,x)  C and x ∈I(ℓ), then preη(ℓ,x) ≤η(ℓ,x) −ϵ,
• η(ℓinit,xinit) < 0.
An ϵ-RepSM map supported by I has c-bounded diﬀerences if for each pair of
locations ℓ,ℓ′ and each pair of conﬁgurations (ℓ,x), (ℓ′,x′) such that x ∈I(ℓ) and
(ℓ′,x′) can be produced by performing a step of computation from (ℓ,x) it holds
|η(ℓ,x) −η(ℓ′,x′)| ≤c.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

7.5 Beyond Bounded Termination
251
The following theorem is proved using Azuma's inequality, a concentration bound
from martingale theory.
Theorem 7.40
Let C be a set of conﬁgurations of a PP P. Suppose that there exist
ϵ > 0, c > 0, and a linear ϵ-RepSM map η for C supported by some invariant I such
that η has c-bounded diﬀerences. Then under each scheduler σ, the probability pC
that the program reaches a conﬁguration from C satisﬁes
pC ≤α · γ ⌈|η(ℓinit,xinit)|/c⌉
1 −γ
,
(7.1)
where γ = exp
(
−
ϵ2
2(c+ϵ)2
)
and α = exp
(
ϵ ·|η(ℓinit,xinit)|
(c+ϵ)2
)
.
Example 7.41
Consider again the program in Figure 7.9, with the same invariant
I as in Example 7.36. Let C = {(ℓ,(x, y)) | ℓ= 5 ∧x ≤1
8}. Then the following map
η is a 13-bounded 1-RepSM map for C: η(1) = η(5) = −16x + 2, η(2) = 16x + 1,
η(3) = −16x, and η(4) = η(6) = −16x + 3. Applying Theorem 7.40 yields that C is
reached with probbaility at most exp
(
−116154
392
−
1
392 · ⌈116154
14
⌉
)
/(1−exp(−1/392)) ≈
1.2 · 10−6 ≤10−5. Now for the map PI in Example 7.36 it holds that violating PI
entails reaching C, which shows that (PI,10−5) is indeed a stochastic invariant.
Checking whether there is a linear RepSM map (supported by a given linear
invariant) for a set of conﬁgurations deﬁned by a given system of linear constraints
can be again performed by linear constraint solving, using techniques analogous to
Section 7.4.
Finally, we mention that RepSM maps can be used to refute almost-sure and ﬁnite
termination.
Theorem 7.42
Let C be a set of terminal conﬁgurations of a program P, i.e. of
those conﬁgurations where the corresponding location is terminal. Suppose that
there exist ϵ ≥0, c > 0, and a linear ϵ-RepSM map η for C supported by some
invariant I such that η has c-bounded diﬀerences. Then, no matter which scheduler
is used, P does not terminate in ﬁnite expected time. Moreover, if ϵ > 0, then P
terminates with probability less than 1 under every scheduler.
Example 7.43
Consider the symmetric random walk (Figure 7.5) together with
an invariant x ≥0 in every location. Assuming that initially x > 1, the mapping
which to each non-terminal conﬁguration (ℓ, x) assigns the number −x + 1, while
each terminal conﬁguration is assigned zero, is a 0-RepSM for the set of terminal
conﬁgurations, with 1-bounded diﬀerences. Hence, the symmetric random walk
indeed does not terminate in ﬁnite expected time.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

252
Chatterjee, Fu and Novotný: Termination Analysis with Martingales
7.6 Related Works
Termination approaches. In Sharir et al. (1984) the termination of concurrent
probabilistic programs with ﬁnite-state space was considered as a fairness problem,
and the precise probabilities did not play a role in termination. A sound and complete
method for proving termination of ﬁnite state programs was given in Esparza et al.
(2012). The above approaches do not apply to programs with countable state space
in general. For countable state space and almost-sure termination a characterization
through ﬁxed-point theory was presented in Hart and Sharir (1985). The analysis of
non-probabilistic program and the termination problem has also been extensively
studied (Bradley et al., 2005a; Colón and Sipma, 2001; Podelski and Rybalchenko,
2004; Sohn and Gelder, 1991; Bradley et al., 2005b; Cook et al., 2013; Lee et al.,
2001). The focus of this chapter was to present the key aspects of martingale-based
approaches for termination of inﬁnite-state probabilistic programs.
Proof-rule based approach. In this work we consider the supermartingale based
approach for probabilistic programs, and an alternative approach is based on the
notion of proof rules (Kaminski et al., 2016; Hesselink, 1993; Olmedo et al., 2016).
These two approaches complement each other, and have their own advantages. The
proof-rule based approach itself does not depend on classical invariants (see for
exampleColón et al., 2003; Cousot, 2005) and is capable of establishing quanti-
tative invariants, whereas the supermartingale approach usually requires classical
invariants to achieve automation (Chakarov and Sankaranarayanan, 2013; Chatterjee
et al., 2016b,a). In contrast, the advantages of the supermartingale-based approach
are: (a) the supermartingale based approach leads to automated and algorithmic
approaches; (b) tail bounds can be obtained through supermartingales using the
mathematical results such as Azuma's inequality or Hoeﬀding's inequality (Chatter-
jee et al., 2016a), and (c) in presence of conditioning, proof-rules cannot be applied
to non-deterministic programs as the schedulers are not necessarily local, whereas
ranking supermartingales can consider non-determinism as the semantics is through
general MDPs and general schedulers.
Other results. Martingales can also be used for analysis of properties other than
termination over probabilistic programs (e.g., probabilistic invariants (Barthe et al.,
2016b) or proving recurrence/persistence/reactivity properties (Chakarov et al.,
2016; Dimitrova et al., 2016; Chatterjee et al., 2017)). Other prominent approaches
for analyzing probabilistic programs include: (a) techniques based on coupling proofs
and their applications in analysis of diﬀerential privacy and probabilistic sensitiv-
ity (Barthe et al., 2017, 2018, 2016a); (b) static-analysis based approaches (Sankara-
narayanan et al., 2013; Cusumano-Towner et al., 2018; Wang et al., 2018); (c)
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

7.7 Conclusion and Future Directions
253
potential-function based approaches for cost analysis (Chatterjee et al., 2018b; Ngo
et al., 2018). Moreover, the semantics of probabilistic programs is studied in Bichsel
et al. (2018) and Staton et al. (2016).
7.7 Conclusion and Future Directions
In this chapter we present the main results related to martingale-based approach
for termination analysis of probabilistic programs. There are several interesting
directions of future work. First, for analysis of probabilistic programs with angelic
non-determinism there is a complexity gap for linear RSMs and an interesting
theoretical question is to close the complexity gap. Second, while the martingale-
based approach and other approaches such as proof-rule based approach each has its
own advantages, techniques for combining them is another interesting direction of
future work. Finally, practical directions of building scalable tools using algorithmic
results for martingales in conjunction with other methods such as compositional
analysis are also largely unexplored.
Acknowledgements
Krishnendu Chatterjee is supported by the Austrian Science Fund (FWF) NFN
Grant No. S11407-N23 (RiSE/SHiNE), and COST Action GAMENET. Hongfei Fu
is supported by the National Natural Science Foundation of China (NSFC) Grant
No. 61802254. Petr Novotný is supported by the Czech Science Foundation grant
No. GJ19-15134Y.
References
Agrawal, S., Chatterjee, K., and Novotný, P. 2018. Lexicographic ranking super-
martingales: an eﬃcient approach to termination of probabilistic programs.
PACMPL, 2(POPL), 34:1-34:32.
Alias, Christophe, Darte, Alain, Feautrier, Paul, and Gonnord, Laure. 2010. Multi-
dimensional Rankings, Program Termination, and Complexity Bounds of
Flowchart Programs. Pages 117-133 of: Proceedings of the 17th International
Conference on Static Analysis. SAS'10. Berlin, Heidelberg: Springer-Verlag.
Ash, R.B., and Doléans-Dade, C. 2000. Probability and Measure Theory. Har-
court/Academic Press.
Baier, C., and Katoen, J.-P. 2008. Principles of Model Checking. MIT Press.
Barthe, Gilles, Gaboardi, Marco, Grégoire, Benjamin, Hsu, Justin, and Strub, Pierre-
Yves. 2016a. Proving Diﬀerential Privacy via Probabilistic Couplings. In:
Grohe et al. (2016).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

254
References
Barthe, Gilles, Espitau, Thomas, Fioriti, Luis María Ferrer, and Hsu, Justin. 2016b.
Synthesizing Probabilistic Invariants via Doob's Decomposition. Pages 43-61
of: Chaudhuri, Swarat, and Farzan, Azadeh (eds), Computer Aided Veriﬁcation
- 28th International Conference, CAV 2016, Toronto, ON, Canada, July 17-23,
2016, Proceedings, Part I. Lecture Notes in Computer Science, vol. 9779.
Springer.
Barthe, Gilles, Grégoire, Benjamin, Hsu, Justin, and Strub, Pierre-Yves. 2017.
Coupling proofs are probabilistic product programs.
Pages 161-174 of:
Castagna, Giuseppe, and Gordon, Andrew D. (eds), Proceedings of the 44th
ACM SIGPLAN Symposium on Principles of Programming Languages, POPL
2017, Paris, France, January 18-20, 2017. ACM.
Barthe, Gilles, Espitau, Thomas, Grégoire, Benjamin, Hsu, Justin, and Strub, Pierre-
Yves. 2018. Proving expected sensitivity of probabilistic programs. PACMPL,
2(POPL), 57:1-57:29.
Bichsel, Benjamin, Gehr, Timon, and Vechev, Martin T. 2018.
Fine-Grained
Semantics for Probabilistic Programs. Pages 145-185 of: Ahmed, Amal
(ed), Programming Languages and Systems - 27th European Symposium on
Programming, ESOP 2018, Held as Part of the European Joint Conferences on
Theory and Practice of Software, ETAPS 2018, Thessaloniki, Greece, April
14-20, 2018, Proceedings. Lecture Notes in Computer Science, vol. 10801.
Springer.
Billingsley, P. 1995. Probability and Measure. 3rd edn. Wiley.
Bournez, O., and Garnier, F. 2005. Proving Positive Almost-Sure Termination.
Pages 323-337 of: International Conference on Rewriting Techniques and
Applications, RTA'05. Springer.
Bradley, A. R., Manna, Z., and Sipma, H. B. 2005a. Linear Ranking with Reachability.
Pages 491-504 of: International Conference on Computer Aided Veriﬁcation,
CAV'05. Springer.
Bradley, A. R., Manna, Z., and Sipma, H. B. 2005b. The Polyranking Principle.
Pages 1349-1361 of: International Colloquium on Automata, Languages, and
Programming, ICALP'05. Springer.
Brázdil, Tomáš, Brožek, Václav, Etessami, Kousha, and Kučera, Antonín. 2013.
Approximating the termination value of one-counter MDPs and stochastic
games. Information and Computation, 222, 121-138.
Chakarov, A., and Sankaranarayanan, S. 2013. Probabilistic Program Analysis with
Martingales. Pages 511-526 of: CAV.
Chakarov, Aleksandar, Voronin, Yuen-Lam, and Sankaranarayanan, Sriram. 2016.
Deductive proofs of almost sure persistence and recurrence properties. Pages
260-279 of: International Conference on Tools and Algorithms for the Con-
struction and Analysis of Systems, TACAS'16. Springer.
Chatterjee, K., Fu, H., Novotný, P., and Hasheminezhad, R. 2016a. Algorithmic anal-
ysis of qualitative and quantitative termination problems for aﬃne probabilistic
programs. Pages 327-342 of: POPL.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
255
Chatterjee, K., Fu, H., and Goharshady, A. K. 2016b. Termination Analysis of
Probabilistic Programs Through Positivstellensatz's. Pages 3-22 of: CAV.
Chatterjee, K., Novotný, P., and Žikelić, Ð. 2017. Stochastic Invariants for Proba-
bilistic Termination. Pages 145-160 of: POPL.
Chatterjee, Krishnendu, and Fu, Hongfei. 2017. Termination of Nondeterministic
Recursive Probabilistic Programs. CoRR, abs/1701.02944.
Chatterjee, Krishnendu, Fu, Hongfei, Novotný, Petr, and Hasheminezhad, Rouzbeh.
2018a. Algorithmic Analysis of Qualitative and Quantitative Termination
Problems for Aﬃne Probabilistic Programs. ACM Trans. Program. Lang. Syst.,
40(2), 7:1-7:45.
Chatterjee, Krishnendu, Fu, Hongfei, Goharshady, Amir Kafshdar, and Okati,
Nastaran. 2018b. Computational Approaches for Stochastic Shortest Path on
Succinct MDPs. Pages 4700-4707 of: Lang, Jérôme (ed), Proceedings of the
Twenty-Seventh International Joint Conference on Artiﬁcial Intelligence, IJCAI
2018, July 13-19, 2018, Stockholm, Sweden. ijcai.org.
Colón, M., and Sipma, H. 2001. Synthesis of Linear Ranking Functions. Pages
67-81 of: TACAS.
Colón, M., Sankaranarayanan, S., and Sipma, H. 2003. Linear Invariant Generation
Using Non-linear Constraint Solving. Pages 420-432 of: CAV.
Cook, B., See, A., and Zuleger, F. 2013. Ramsey vs. Lexicographic Termination
Proving. Pages 47-61 of: TACAS.
Cousot, P. 2005. Proving Program Invariance and Termination by Parametric
Abstraction, Lagrangian Relaxation and Semideﬁnite Programming. Pages
1-24 of: VMCAI.
Cousot, Patrick, and Cousot, Radhia. 1977. Abstract Interpretation: A Uniﬁed Lattice
Model for Static Analysis of Programs by Construction or Approximation of
Fixpoints. Pages 238-252 of: Graham, Robert M., Harrison, Michael A., and
Sethi, Ravi (eds), POPL. ACM.
Cplex. 2010. IBM ILOG CPLEX Optimizer Interactive Optimizer Community Edi-
tion 12.6.3.0. http://www-01.ibm.com/software/integration/optimization/cplex-
optimizer/.
Cusumano-Towner, Marco, Bichsel, Benjamin, Gehr, Timon, Vechev, Martin T., and
Mansinghka, Vikash K. 2018. Incremental inference for probabilistic programs.
In: Foster and Grossman (2018).
Dimitrova, Rayna, Fioriti, Luis María Ferrer, Hermanns, Holger, and Majumdar,
Rupak. 2016. Probabilistic CTL*: The Deductive Way. Pages 280-296 of:
International Conference on Tools and Algorithms for the Construction and
Analysis of Systems, TACAS'16. Springer.
Durrett, R. 1996. Probability: Theory and Examples (Second Edition). Duxbury
Press.
Esparza, J., Gaiser, A., and Kiefer, S. 2012. Proving Termination of Probabilistic
Programs Using Patterns. Pages 123-138 of: CAV.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

256
References
Farkas, J. 1894. A Fourier-féle mechanikai elv alkalmazásai (Hungarian). Mathe-
matikaiés Természettudományi Értesitö, 12, 457-472.
Fioriti, L. M. F., and Hermanns, H. 2015. Probabilistic Termination: Soundness,
Completeness, and Compositionality. Pages 489-501 of: POPL.
Floyd, R. W. 1967. Assigning meanings to programs. Mathematical Aspects of
Computer Science, 19, 19-33.
Foster, F. G. 1953. On the Stochastic Matrices Associated with Certain Queuing
Processes. The Annals of Mathematical Statistics, 24(3), 355-360.
Foster, Jeﬀrey S., and Grossman, Dan (eds). 2018. Proceedings of the 39th ACM
SIGPLAN Conference on Programming Language Design and Implementation,
PLDI 2018, Philadelphia, PA, USA, June 18-22, 2018. ACM.
Fu, Hongfei, and Chatterjee, Krishnendu. 2019. Termination of Nondeterministic
Probabilistic Programs. Pages 468-490 of: Enea, Constantin, and Piskac,
Ruzica (eds), Veriﬁcation, Model Checking, and Abstract Interpretation - 20th
International Conference, VMCAI 2019, Cascais, Portugal, January 13-15,
2019, Proceedings. Lecture Notes in Computer Science, vol. 11388. Springer.
Ghahramani, Z. 2015. Probabilistic machine learning and artiﬁcial intelligence.
Nature, 521(7553), 452-459.
Gordon, A. D., Henzinger, T. A., Nori, A. V., and Rajamani, S. K. 2014. Probabilistic
programming. Pages 167-181 of: FOSE.
Grohe, Martin, Koskinen, Eric, and Shankar, Natarajan (eds). 2016. Proceedings of
the 31st Annual ACM/IEEE Symposium on Logic in Computer Science, LICS
'16, New York, NY, USA, July 5-8, 2016. ACM.
Hart, S., and Sharir, M. 1985. Concurrent Probabilistic Programs, Or: How to
Schedule if You Must. SIAM J. Comput., 14(4), 991-1012.
Hesselink, W. H. 1993. Proof Rules for Recursive Procedures. Formal Asp. Comput.,
5(6), 554-570.
Howard, H. 1960. Dynamic Programming and Markov Processes. MIT Press.
Huang, Mingzhang, Fu, Hongfei, and Chatterjee, Krishnendu. 2018. New Approaches
for Almost-Sure Termination of Probabilistic Programs. Pages 181-201 of: Ryu,
Sukyoung (ed), Programming Languages and Systems - 16th Asian Symposium,
APLAS 2018, Wellington, New Zealand, December 2-6, 2018, Proceedings.
Lecture Notes in Computer Science, vol. 11275. Springer.
Kaelbling, L. P., Littman, M. L., and Moore, A. W. 1996. Reinforcement learning:
A survey. JAIR, 4, 237-285.
Kaelbling, L. P., Littman, M. L., and Cassandra, A. R. 1998. Planning and acting in
partially observable stochastic domains. Artiﬁcial intelligence, 101(1), 99-134.
Kaminski, B. L., and Katoen, J.-P. 2015. On the Hardness of Almost-Sure Termina-
tion. Pages 307-318 of: MFCS.
Kaminski, B. L., Katoen, J.-P., Matheja, C., and Olmedo, F. 2016.
Weakest
Precondition Reasoning for Expected Run-Times of Probabilistic Programs.
Pages 364-389 of: ESOP.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
257
Kemeny, J.G., Snell, J.L., and Knapp, A.W. 1966. Denumerable Markov Chains. D.
Van Nostrand Company.
Kwiatkowska, M. Z., Norman, G., and Parker, D. 2011. PRISM 4.0: Veriﬁcation of
Probabilistic Real-Time Systems. Pages 585-591 of: CAV. LNCS 6806.
Lee, C. S., Jones, N. D., and Ben-Amram, A. M. 2001. The size-change principle
for program termination. Pages 81-92 of: POPL.
Lpsolve. 2016. lp_solve 5.5.2.3. http://lpsolve.sourceforge.net/5.5/.
McIver, A., and Morgan, C. 2004. Developing and Reasoning About Probabilistic
Programs in pGCL. Pages 123-155 of: PSSE.
McIver, A., and Morgan, C. 2005. Abstraction, Reﬁnement and Proof for Probabilistic
Systems. Monographs in Computer Science. Springer.
McIver, A., Morgan, C., Kaminski, B. L., and Katoen, J.-P. 2018. A new proof rule
for almost-sure termination. PACMPL, 2(POPL), 33:1-33:28.
Motwani, Rajeev, and Raghavan, Prabhakar. 1995. Randomized Algorithms. New
York, NY, USA: Cambridge University Press.
Neuhäußer, M., Stoelinga, M., and Katoen, J.-P.. 2009. Delayed Nondeterminism in
Continuous-Time Markov Decision Processes. Pages 364-379 of: Foundations
of Software Science and Computational Structures (FOSSACS 2009). Lecture
Notes in Computer Science, vol. 5504. Springer.
Neuhäußer, Martin R, and Katoen, Joost-Pieter. 2007. Bisimulation and logical
preservation for continuous-time Markov decision processes. Pages 412-427 of:
International Conference on Concurrency Theory (CONCUR 2007). Springer.
Ngo, Van Chan, Carbonneaux, Quentin, and Hoﬀmann, Jan. 2018.
Bounded
expectations: resource analysis for probabilistic programs. In: Foster and
Grossman (2018).
Olmedo, F., Kaminski, B. L., Katoen, J.-P., and Matheja, C. 2016. Reasoning about
Recursive Probabilistic Programs. Pages 672-681 of: LICS.
Paz, A. 1971. Introduction to probabilistic automata (Computer science and applied
mathematics). Academic Press.
Podelski, A., and Rybalchenko, A. 2004. A Complete Method for the Synthesis of
Linear Ranking Functions. Pages 239-251 of: VMCAI.
Rabin, M.O. 1963. Probabilistic automata. Inf. & Control, 6, 230-245.
Sankaranarayanan, S., Chakarov, A., and Gulwani, S. 2013. Static analysis for
probabilistic programs: inferring whole program properties from ﬁnitely many
paths. Pages 447-458 of: PLDI.
Scheiderer, Claus. 2008. Positivity and Sums of Squares: A Guide to Recent Results.
The IMA Volumes in Mathematics and its Applications, 149, 271-324.
Schrijver, Alexander. 2003. Combinatorial Optimization - Polyhedra and Eﬃciency.
Springer.
Sharir, M., Pnueli, A., and Hart, S. 1984. Veriﬁcation of Probabilistic Programs.
SIAM J. Comput., 13(2), 292-314.
Sohn, K., and Gelder, A. V. 1991. Termination Detection in Logic Programs using
Argument Sizes. Pages 216-226 of: PODS.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

258
References
Staton, Sam, Yang, Hongseok, Wood, Frank D., Heunen, Chris, and Kammar,
Ohad. 2016. Semantics for probabilistic programming: higher-order functions,
continuous distributions, and soft constraints. In: Grohe et al. (2016).
Turing, Alan Mathison. 1937. On computable numbers, with an application to the
Entscheidungsproblem. Proceedings of the London mathematical society, 2(1),
230-265.
Wang, Di, Hoﬀmann, Jan, and Reps, Thomas W. 2018. PMAF: an algebraic
framework for static analysis of probabilistic programs. In: Foster and Grossman
(2018).
Williams, D. 1991. Probability with Martingales. Cambridge University Press.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

8
Quantitative Analysis of Programs with Probabilities
and Concentration of Measure Inequalities
Sriram Sankaranarayanan
University of Colorado, Boulder
Abstract:
The quantitative analysis of probabilistic programs answers queries
involving the expected values of program variables and expressions involving them,
as well as bounds on the probabilities of assertions. In this chapter, we will present the
use of concentration of measure inequalities to reason about such bounds. First, we
will brieﬂy present and motivate standard concentration of measure inequalities. Next,
we survey approaches to reason about quantitative properties using concentration of
measure inequalities, illustrating these on numerous motivating examples. Finally,
we discuss currently open challenges in this area for future work.
8.1 Introduction
In this chapter, we present the use of concentration of measure inequalities for the
quantitative analysis of probabilistic programs. A variety of approaches have focused
on qualitative properties that involve the almost-sure satisfaction of temporal formulas
involving the behaviors of programs with special attention towards the analysis of
almost sure termination, recurrence and persistence (McIver and Morgan, 2004;
Esparza et al., 2012; Bournez and Garnier, 2005; Chakarov and Sankaranarayanan,
2013; Fioriti and Hermanns, 2015; Kaminski et al., 2016; Chakarov et al., 2016;
Dimitrova et al., 2016; Chatterjee et al., 2017, 2018; McIver et al., 2018). On
the other hand, quantitative properties include reasoning about probabilities of
assertions involving conditions over the program state, expectations involving the
program variables, and expected time to program termination (Kaminski et al., 2016;
Chatterjee et al., 2018).
A critical diﬃculty of quantitative analysis is the need to integrate over a potentially
large number of random variables generated in a typical run of a probabilistic program
in order to calculate the quantity of interest. Often, these variables are manipulated
a From Foundations of Probabilistic Programming, edited by Gilles Barthe, Joost-Pieter Katoen and Alexandra
Silva published 2020 by Cambridge University Press.
259
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

260
Sankaranarayanan: Quantitative Analysis of Programs
using nonlinear functions over the course of long running loops that calculate the
result of the program. Thus, the result is quite often a nonlinear function involving a
large number of random variables. To make matters worse, the function is represented
only indirectly as the computer program itself. Reasoning about such functions
can be quite challenging and is normally performed in a case-by-case fashion, one
program at a time, to ease the understanding of the behavior. Mechanizing this
process to yield a more automated analysis approach can be quite challenging.
There are many approaches to tackle the challenge of quantitative reasoning over
programs with probabilistic statements. One approach pioneered by McIver and
Morgan annotates the program with assertions and expectations that serve the same
role as loop invariants (see McIver and Morgan, 2004). This approach eﬀectively
represents the distributions over the intermediate states encountered during the
execution at a suﬃcient level of abstraction to establish the property of interest for
the program as a whole. The approach has also been mechanized using ideas from
loop invariant synthesis (see Katoen et al., 2010), and extended to programs with
distributions over continuous state variables (see Chakarov and Sankaranarayanan,
2013; Fioriti and Hermanns, 2015; Chatterjee et al., 2018).
In this chapter, we survey a related approach that uses concentration of measure
inequalities - a set of elegant mathematical ideas that characterize how functions
of random variables deviate from their expected value. More importantly, these
inequalities place upper bounds on the probabilities of deviations of a particular
magnitude. Paradoxically, they avoid the need for expensive integration and thus,
become quite eﬀective when deviations over a large number of random variables are
considered. Most well known inequalities such as the Chernoﬀ-Hoeﬀding bounds,
however, suﬀer a number of limitations that prevent them from being directly
applicable to the analysis of probabilistic programs. They require independence of
the random variables involved, work only for random variables over bounded sets
of support, and ﬁnally, prove concentrations over sums rather than more general
functions of random variables. We show in this chapter how these limitations can be
partly overcome through a series of increasingly more sophisticated inequalities and
the tricks involved in applying them to speciﬁc situations.
The survey is based on previously published papers involving the author:
see Chakarov and Sankaranarayanan (2013) and Bouissou et al. (2016). We present
concentration of measure inequalities motivated by a set of interesting numerical
examples. We show applications to probabilistic programs starting with control
deterministic computations that are handled through approximations known as
probabilistic aﬃne forms, whereas, more general loops are handled through the
use of super-martingale approaches. Our presentation is inspired by the excellent
monograph on this topic by Dubhashi and Panconesi (2009). We recommend this
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

8.1 Introduction
261
1
angles = [10, 60, 110, 160, 140, ...
2
100, 60, 20, 10, 0]
3
x := TruncGaussian(0,0.05,-0.5,0.5)
4
y := TruncGaussian(0, 0.1,-0.5,0.5)
5
# run for 100 repetitions
6
for reps in range(0,100):
7
#iterate through angles
8
for theta in angles:
9
# Distance travelled variation
10
d = Uniform(0.98,1.02)
11
# Steering angle variation
12
t = deg2rad(theta) * (1 + ...
13
TruncGaussian(0,0.01,-0.05,0.05))
14
# Move distance d with angle t
15
x = x + d * cos(t)
16
y = y + d * sin(t)
17
#Probability that we went too far?
18
assert(x >= 277)
Figure 8.1 Left: A probabilistic program capturing the ﬁnal position of 2D robotic end eﬀector.
Right: Scatter plot showing the ﬁnal (x, y) values. Note that TruncGaussian(m, s, l, u)
generates a truncated Gaussian random variable with mean m, standard deviation s, lower bound
l and upper bound u.
book as a starting point towards more mathematically detailed presentations that
include Williams (1991) and Boucheron et al. (2016).
8.1.1 Motivating Examples
In this section, we present motivating examples involving a robotic end eﬀector, an
anesthesia infusion process and a linear aircraft model under wind disturbances.
Example 8.1 (2D robotic end eﬀector). Consider the repetitive motion of a 2D end
eﬀector used for tasks such as soldering printed circuit boards for manufacturing
applications. The end eﬀector makes a series of cyclic repetitive movements for
each widget, ending each cycle at the starting position for soldering the subsequent
widget. At each step, small calibration errors can be introduced in its movement and
these errors accumulate throughout the operation of the unit.
Figure 8.1 (left) shows the program that models the position of the end eﬀector.
Let (x, y) denote the position of the end eﬀector. The initial position is deﬁned by
random variables (x0, y0) which are distributed as zero mean truncated Gaussian
random variables over the set of support [−0.5,0.5] (see Figure 8.1, lines 3, 4). The
program itself runs a for loop in line 6 for N = 100 iterations that represent 100
diﬀerent repetitions of the same sequence of actions by the robot. Each iteration j
consists of a k = 10 diﬀerent geometric transformations of the robot's position that
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

262
Sankaranarayanan: Quantitative Analysis of Programs
result in a sequence of coordinates (x0,j, y0,j) . . .,(xk+1,j, yk+1,j)), wherein,
(xi+1,j, yi+1,j) = (xi,j + di,j cos(θi,j), yi,j + di,j sin(θi,j)),
for i = 1,. . ., k. Here di,j is deﬁned as a uniform random variable over [0.98,1.02].
The mean values of θi,j are deﬁned in degrees using the array angles in Figure 8.1
(line 2), with the uncertainties modeled in line 13. The starting position for iteration
j + 1 is the end position at iteration j.
(x0,j+1, y0,j+1) = (xk+1,j, yk+1,j) .
We are interested in the probability that the value of xN,k+1 ≥277 (line 18),
for N = 100 and k = 10. The value of xN,k+1 is shown for 105 diﬀerent runs of
the program in the scatter plot in Figure 8.1(right) and none of these simulations
violate the assertion of interest. Thus, we seek an upper bound on the probability of
violating this assertion of the form:
P(x ≥277) ≤? .
The challenge lies in obtaining nontrivial bounds for this program given that (a)
it involves nonlinear transformations of random variables and (b) roughly 2000
independent random variables are involved in N = 100 iterations.
Example 8.2 (Anesthesia Infusion Model). The anesthesia model consists of a
four-chamber pharmacokinetic model of the anesthetic Fentanyl that is administered
to a surgical patient using an infusion pump (see McClain and Hug, 1980). This
model has been used as part of automated anesthesia delivery systems (see Shafer
et al., 1988; Youseﬁet al., 2017). We model an erroneous infusion that results in
varying amounts of anesthesia infused over time as a truncated Gaussian random
noise. The state of the model at time t is a vector of concentrations of anesthesia in
various "chambers" of the body:
x(t) : (x1(t), x2(t), x3(t), x4(t))
The target state variable x4(t) measures the concentration of anesthesia in the blood
plasma. Variable u(t) denotes the rate of anesthesia infusion at time t, and is an input
to the model.
At each step, the model evolves as
x(t + 1) = Ax(t) + Bu(t)(1 + w(t))
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

8.1 Introduction
263
The matrices A, B are speciﬁed as follows:
A :
⎡⎢⎢⎢⎢⎢⎢⎣
0.9012
0.0304
0.0031
0
0.0139
0.9857
0
0
0.0015
0
0.9985
0
0.0838
0.0014
0.0001
0.9117
⎤⎥⎥⎥⎥⎥⎥⎦
B :
"###
$
0.2676
0.002
0.0002
0.0012
%&&&
'
The disturbance w(t) is a truncated Gaussian variable over the range [−0.4,0.4]
with mean 0 and standard deviation σ = 0.08. These model the error in the infused
anesthesia rate as a percentage of the commanded rate u(t). This rate u(t) is speciﬁed
as the following ﬁxed set of infusion rates and times:
t(100 seconds)
[0,8]
[8,14]
[14,20]
[20,26]
[26,32]
[32,38]
[38,56]
u(t)(μmol/s)
60
64
66
68
64
62
60
The control inputs in this example are chosen for illustrative purposes, and do not
carry medical signiﬁcance. The goal is to check the probability that the infusion errors
result either in too much anesthesia x4(5600) ≥300ng/mL potentially causing loss
of breathing or too little anesthesia x4(5600) ≤150ng/mL causing consciousness
during surgery.
Example 8.3 (Fixed-Wing UAV Collision). Fixed wing small UAVs are quite prone
to wind disturbances. Thus, it is important to predict if a collision is imminent using
short term forecast models based on a series of positions and velocities of the system.
Auto-regressive moving average state-space (ARMAX) models are an important
class of data-driven time series models that enable such forecasts to be obtained over
short time periods (Brockwell and Davis, 2009). Figure 8.2 shows such a forecast
model for a small ﬁxed wing UAV inferred using ridge regression from data collected
during test ﬂights. The data reports GPS positions (x, y, z) and velocities (vn,ve,vd),
respectively, in the north, east and downward directions every h = 0.18 seconds for a
period of 3 hours. Once the model is inferred, the residual errors between the model
prediction and actual results are histogrammed. Often these residuals are modeled
using Gaussian distributions with some statistical analysis. Here, we simply model
them as unknown distributions whose means and standard deviations are given.
Using the model in Figure 8.2, we seek to build a predictive monitor that given
the current history of positions, velocities and deviations
(x(t), x(t −h), y(t), y(t −h),· · · ,ez(t),ez(t −h)) ,
estimates a bound on the probability:
P((x(t + Nh), y(t + Nh), z(t + Nh)) ∈U) ≤?
where U represents unsafe regions in the airspace denoted by proximity to buildings,
grounds and designated no ﬂy zones.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

264
Sankaranarayanan: Quantitative Analysis of Programs
x(t + h)
= x(t) + hve(t) + ex(t + h)
y(t + h)
= y(t) + hvn(t) + ey(t + h)
z(t + h)
= z(t) + hvd(t) + ez(t + h)
vn(t + h)
= 2.035vn(t) −1.11vn(t −h) + 0.075vn(t −2h) + w1
←σ1 : 0.055
ve(t + h)
= 1.923ve(t) −0.923ve(t −h) + w2
←σ2 : 0.057
vd(t + h)
= 1.626vd(t) −0.778vd(t −h) + 0.109vd(t −2h) + w3
←σ3 : 0.16
ex(t + h)
= 0.567ex(t) + 0.388ex(t −h) + w4
←σ4 : 0.13
ey(t + h)
= 0.491ey(t) + 0.27ey(t −h) + 0.201ey(t −2h) + w5
←σ5 : 0.14
ez(t + h)
= 1.35ez(t) −0.39ez(t −h) + w6
←σ6 : 0.053
Figure 8.2 Data-driven ARMAX model for predicting the future position of a UAV from its
past positions and velocities. The time step h is 0.18 seconds in our model, x, y, z represent
the position of the UAV, vn, ve, vd represent the velocities in the north, east and downward
directions, respectively, ex(t) : x(t)−x(t −h)−hve(t −h) is the deviation along the x direction,
and similarly ey, ez denote deviations from y, z directions. w1, . . . , w6 are residual errors that
have been modeled using distributions with 0 mean and empirically estimated standard deviations
σi shown alongside.
8.2 Quantitative Analysis: Problem and Approaches
In this section, we formally deﬁne the overall problem of quantitative analysis of
probabilistic programs, focusing on (a) the type of systems that can be addressed,
(b) the type of properties, and (c) sets of approaches that have been developed to
reason about quantitative properties of probabilistic programs.
8.2.1 Programs and Properties
Given a "purely" probabilistic program P that computes a function y := FP(X) over
some random variables X, quantitative questions can be of two types: (a) bounds on
the probability of an assertion ϕ involving y: P(ϕ(y)) ▷◁c? and (b) bounds on the
expectation of some function g(y): E(g(y)) ▷◁c? wherein ▷◁∈{≥, ≤,=} and c is a
constant? Some of these questions are illustrated by our motivating examples from
Section 8.1.1. As mentioned earlier, quantitative reasoning about the running time
of programs is addressed elsewhere (see also Chapter 6 in this volume), although
the approaches mentioned in the present chapter remain generally applicable.
Beyond purely probabilistic programs, we may consider programs P that involve a
combination of random variables X, demonic variables w controlled by the adversary,
and angelic variables u controlled by a cooperative player. In such a situation, the
program itself can be viewed as computing a joint function y := FP(X,w,u), wherein
y denotes the outputs of the program. Interpreting ϕ(y) as a failure condition, we
wish to know if
(∃u) (∀w) PX(ϕ(y)) ≤c,
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

8.2 Quantitative Analysis: Problem and Approaches
265
wherein c denotes a constant that is a desired failure threshold. We will focus our
initial discussions on the case of purely probabilistic programs.
Furthermore, the probabilistic program will be assumed to be free of conditioning
operation through observe or assume statements. Conditioning remains an open
challenge for quantitative analysis and somewhat orthogonal to the purposes of
quantitative reasoning considered in this chapter. Conditioning can simply be
eliminated in restricted cases by computing the posterior distributions explicitly in
the case of conjugate prior/posterior, or wherever symbolic integration approaches
can tell us about the form of the posterior distribution (Narayanan et al., 2016;
McElreath, 2015). Another approach involves the use of variational inference that
can substitute prior probabilities by approximate posteriors from a predeﬁned family
of posterior distributions (Wingate and Weber, 2013).
Approaches to quantitative reasoning in probabilistic programs can be broadly
classiﬁed into two: (a) simulation-based approaches and (b) symbolic approaches.
8.2.2 Simulation-Based Quantitative Reasoning
Simulation-based approaches execute the given program by sampling from the
probability distributions generated in order to evaluate the property at hand. These
approaches have been tied to statistical reasoning through hypothesis testing, starting
with the work of Younes and Simmons (2006), leading to so-called statistical model
checking approaches (Clarke et al., 2009; Agha and Palmskog, 2018; Jha et al.,
2009).
Consider a probabilistic program P whose output variables are denoted as y and
a quantitative property P(ϕ(y)) ≤c. A simulation based approach consists of two
components: (a) generate samples y1,. . .,yN and (b) perform a statistical hypothesis
test between two competing hypotheses:
H0 := P(ϕ(y) ≤c) versus H1 := P(ϕ(y) > c) .
In particular, the hypothesis test works in a sequential fashion by examining how
each added sample contributes towards the goal of accepting one hypothesis and
rejecting another, with a new batch of samples generated on-demand.
To this end, the two most frequently used hypothesis tests include the sequential
probability ratio test (SPRT) ﬁrst proposed by Wald (1945) and the Bayes factor
test proposed by Jeﬀries (Kass and Raftery, 1995). Details of these statistical tests
are available from standard references, including the recent survey by Agha and
Palmskog (2018). For instance, the Bayes factor test computes the so-called Bayes
factor which is given by
BayesFactor := P(Observations y1,. . .,yN | H1)P(H1)
P(Observations y1,. . .,yN | H0)P(H0)
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

266
Sankaranarayanan: Quantitative Analysis of Programs
as a measure of the evidence in favor of hypothesis H1 against that in favor of H0.
Here, P(Hj) refers to the prior probability of the hypothesis Hj for j = 0,1. If the
resulting BayesFactor exceeds a given upper bound threshold (see Kass and Raftery,
1995 for an interpretation of the Bayes factor), the hypothesis H1 is accepted. On the
other hand, if the BayesFactor falls below a lower bound, H0 is accepted in favor of
H1. If the BayesFactor remains between these two bounds more evidence is sought
since the data has insuﬃcient evidence.
Besides the use of statistical tests, the generation of samples is another key
problem. Often, in veriﬁcation problems, the event of interest is a "rare" failure
whose probability needs to be bounded by a small number c ∼10−6. To this end,
the number of simulations needed can be prohibitively expensive, in practice. Thus,
approaches such as importance sampling are used to artiﬁcially inﬂate the probability
of obtaining a failure (see Srinivasan, 2002; Bucklew, 2004; Rubinstein and Kroese,
2008). Importance sampling approach ﬁrst modiﬁes the probabilistic program by
replacing the distribution of random variables using sampling distributions designed
to increase the probability and hence the number of samples that satisfy the assertion
ϕ(y) (assuming that ϕ is a rare event). The new samples are weighted by the ratio of
the likelihood score under the original distribution and the new sampling distribution.
A key challenge lies in designing a sampling distribution that can increase the
number of rare event observations. This requires a lot of insight on the part of
the analyzer. Approaches such as the cross-entropy method can be employed to
systematically optimize the parameters of a family of sampling distributions to make
failures more likely (Jégourel et al., 2012; Sankaranarayanan and Fainekos, 2012).
8.2.3 Symbolic Approaches
In contrast to simulation-based approaches, symbolic techniques focus on reasoning
about probabilities of assertions and expectations through a process of abstraction.
Often this abstraction takes one of two forms (see Cousot and Monerau (2012) for a
more reﬁned classiﬁcation): (a) abstractions of intermediate probability distributions
over program states or (b) abstractions of intermediate states as functions over the
random variables generated by the program. Both approaches rely on symbolic
integration to compute bounds on the probabilities and expectations.
Abstractions of Probability Distributions: The probability distributions over
program variables can be precisely represented for ﬁnite state programs. This is
the basis for the tool PRISM, that handles probabilistic programs over ﬁnite state
variables by compiling them into Markov chains or Markov decision processes,
depending on whether demonic/angelic nondeterminism is present (Kwiatkowska
et al., 2011). These approaches can be extended to inﬁnite state systems using the
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

8.2 Quantitative Analysis: Problem and Approaches
267
idea of a game-based abstraction that allows us to treat some of the probabilistic
choices as non-deterministic but controlled by a diﬀerent player (see Parker et al.,
2006).
Abstractions for inﬁnite state probabilistic systems are more complicated since
the intermediate joint probability distributions between the program variables can be
arbitrarily complicated (Kozen, 1981). A variety of approaches have been employed
to abstract the intermediate distributions through probabilistic abstract domains that
associate upper/lower bounds on measures associated with sets of states (Monniaux,
2000, 2005; Cousot and Monerau, 2012). Whereas initial approaches focused
on intervals and polyhedral sets annotated with bounds, it became clear that the
probability bounds can often become too large to be useful or alternatively, the
number of subdivisions of the state-space needed becomes too high to maintain
a desired level of precision. An alternative approach by Bouissou et al. (2012)
uses ideas from imprecise probabilities such as Dempster-Shafer structures (see
Dempster, 1967; Shafer, 1976) and P-boxes(Ferson et al., 2003) to represent
probabilities more precisely. This approach has the added advantage of representing
correlations between program variables in a more precise manner. However, the
process of computing probabilities or expectations involves integration, and therefore
a summation over a large number of cells that tile the region of interest.
Probabilistic Symbolic Execution: A related and complementary approach uses
symbolic execution to represent program states as functions over the input variables
that involve random variables generated by the program (Geldenhuys et al., 2012;
Mardziel et al., 2011; Sankaranarayanan et al., 2013) followed by the use of symbolic
integration to calculate the probability of an assertion exactly or approximately as
needed. Algorithms for computing volume of polyhedra (De Loera et al., 2011)
or interval-based branch-and-bound schemes for approximating these volumes
(Sankaranarayanan et al., 2013) can be employed to perform quantitative analysis. A
key drawback remains the high complexity of volume computation in terms of the
number of dimensions of the region. Here, the dimensionality equals the number
of random variables involved in the computation, which can be prohibitively large,
as seen in our motivating examples. Thus, the applications are limited to programs
that use fewer random variables and carry out complex computations over these.
Furthermore, the exact volume computation is often not needed since for many
applications of interest an upper bound over the probabilities of failure suﬃces.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

268
Sankaranarayanan: Quantitative Analysis of Programs
8.3 Concentration of Measure Inequalities: a Primer
In this section, we present basic facts about concentration of measure inequalities.
An accessible and complete exposition of them, and their application to randomized
algorithms, is Dubhashi and Panconesi (2009).
Concentration of measure inequalities allow us to reason about the behavior
of certain functions of independent random variables. The most basic inequality
remains the widely applied Chernoﬀ-Hoeﬀding inequality. Let X1,. . ., Xn be
independent random variables taking on values in the set {0,1}. Consider the sum
Sn = X1 + · · · + Xn. Clearly, E(Sn) = 	n
j=1 E(Xj). The key question is how likely is
it for the sum to satisfy Sn ≥E(Sn) + t for some positive deviation t ≥0?
There are many ways of answering such a question. For the special case of
{0,1}-valued random variables that are identically distributed so that E(Xi) = p for
all i ∈{1,. . .,n}, the answer can be obtained from an application of combinatorics,
as shown below:
P (Sn ≥E(Sn) + t) =
n

j=⌈np+t⌉
n
j

pj(1 −p)n−j .
The RHS expression provides an exact answer but is often cumbersome to compute.
The expression can be approximated in many ways. For instance, the Poisson
approximation is possible when n is large and p is small so that np is "small
enough". However, such attempts produce a numerical approximation which cannot
be used to establish guaranteed bounds, in general. Furthermore, we cannot deal
with other common situations that involve: (a) the sum of random variables that
are not necessarily identically distributed; (b) the sum of random variables whose
distributions can be continuous; and ﬁnally (c) the sum of random variables that are
not all independent.
Concentration of measure inequalities attempt to answer these questions by
providing upper bounds on deviations of certain functions of random variables from
their expected values. Let f (X1,. . ., Xn) be a function of random variables having
some ﬁxed arity n (the arity of f does not need to be ﬁxed, however). As an example:
f (X1,. . ., Xn) = X1 + · · · + Xn. Let E( f ) denote the expectation E( f (X1,. . ., Xn))
computed over random choices of X1,. . ., Xn. A concentration of measure inequality
typically has the form:
P ( f (X1,. . ., Xn) ≥E( f ) + t) ≤g(n,t),
wherein t ≥0, and g is a function that decreases sharply as t increases. Inequalities
are often "symmetric" providing similar bounds for lower tails as well:
P( f (X1,. . ., Xn) ≤E( f ) −t) ≤g(n,t),
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

8.3 Concentration of Measure Inequalities: a Primer
269
The inequality is sub-gaussian if the bound g(n,t) is of the form g(n,t)
:=
C exp
(
−ct2
n
)
for known constants C,c that depend on the moments and set of
support of the random variables X1,. . ., Xn. Most of the bounds we will explore will
be sub-gaussian in nature. The simplest and most fundamental of these bounds is
the well-known Chernoﬀ-Hoeﬀding inequality.
Theorem 8.4 (Chernoﬀ-Hoeﬀding). Let Xi be independent random variables that
lies in the range [ai, bi] almost surely, for i = 1,. . .,n, and let Sn = 	n
j=1 Xj. For all
t ≥0,
P(Sn ≥E(Sn) + t) ≤exp

−
2t2
	n
j=1(bj −aj)2

.
Using Chernoﬀ-Hoeﬀding inequality, we may bound the upper tail of the sum of
Bernoulli random variables as:
P(Sn ≥E(Sn) + t) ≤exp

−2t2
n

.
However, there are two important limitations of Chernoﬀ-Hoeﬀding inequality: (a)
the random variables X1,. . ., Xn must be independent and (b) Xi must lie within a
bounded range [ai, bi], almost surely.
Example 8.5. We will now illustrate the direct use of Chernoﬀ-Hoeﬀding bounds
to prove upper bounds on the probability of failure for the model described in
Example 8.2. Note that our main object of concern in this example is the value of
the state variable x4 at time t = 5600s. Since at each step, the new state x(t + 1) is
related to the previous state: x(t +1) = Ax(t)+ Bu(t)(1+w(t)), the value of x4(5600)
is, in fact, written as a summation of the following form:
x4(5600) = a0 +
4

i=1
aixi(0) +
5600

j=1
bjw(j),
(8.1)
wherein the coeﬃcients ai, bj are obtained by computing the matrices for AiB
for i = 0,. . .,5600 and An for n = 5600. Furthermore, w(j) for j = 1,. . .,5600,
represent mutually independent random variables over the range [−0.4,0.4] with
mean 0 and standard deviation σ = 0.08.
We may, therefore, apply Chernoﬀ-Hoeﬀding bounds to compute bounds of the
form:
P(x4(5600) ≥E(x4(5600)) + t) ≤exp

−2t2
	5600
i=1 bi(0.8)2

,
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

270
Sankaranarayanan: Quantitative Analysis of Programs
and likewise,
P(x4(5600) ≤E(x4(5600)) −t) ≤exp

−2t2
	5600
i=1 bi(0.8)2

.
Note that in applying these bounds, we consider the summation of random variables
that include a0, aixi(0) and w(j) from Eq. (8.1). The value of E(x4(5600)) is
calculated using linearity of expectation to be 246.7985 up to 4 signiﬁcant digits.
The denominator of the exponent term for the Chernoﬀ-Hoeﬀding is calculated as
follows:
5600

i=1
bi(0.8)2 = 234.3159 .
Thus, we may bound the probability of the Fentanyl concentration in the eﬀect
chamber exceeding 300ng/ml as follows:
P(x4(5600) ≥300) ≤3.05 × 10−5 .
Likewise, we may bound the probability of Fentanyl concentration falling below
150ng/ml as follows:
P(x4(5600) ≤150) ≤2.4 × 10−15 .
Chernoﬀ-Hoeﬀding inequalities are widely used in numerous applications to
the analysis of randomized algorithms for bounding away the probability of an
undesirable behavior of the algorithm at hand. However, their use is constrained by
many important factors:
(i) The inequality applies to random variables Xi whose set of support is bounded
by a ﬁnite interval. Random variables with an unbounded set of support such as
Gaussian random variables are not handled.
(ii) The inequality uses only the range and ﬁrst moment of each Xi. Further
information such as the second or higher moments E(X2
i ) could be more useful in
obtaining sharper bounds.
(iii) The inequality applies to sums of random variables. Programs often compute
more complex functions of random variables than just sums.
(iv) The inequality applies to mutually independent random variables. Even if the
random variables sampled by a program are mutually independent, the state
variables become correlated as they depend on the same set of independent
random variables.
We will now discuss how each of the limitations may be handled using other,
more sophisticated concentration of measure inequalities and/or simply by adapting
how the inequality is applied in the ﬁrst place.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

8.3 Concentration of Measure Inequalities: a Primer
271
8.3.1 Inequalities Using Higher Moments
Numerous inequalities for the concentration of the sum 	n
i=1 Xi of independent
random variables have been proposed that use higher moments such as the second
moment E(X2
i ) of each random variable Xi in addition to E(Xi). Bernstein (1924)
proposed a series of such inequalities.
Theorem 8.6 (Bernstein Inequality). Let X1,. . ., Xn be independent random vari-
ables such that (a) there exists a constant M > 0 such that |Xi −E(Xi)| ≤M for
each i ∈[1,n], and (b) the variance of each Xi is σ2
i . For any t ≥0:
P(X −E(X) ≥t) ≤exp

−t2
2
3 Mt + 2 	n
i=1 σ2
i

(8.2)
For the left tail probability, we may derive an identical bound.
Note that if each random variable Xi ranges over a bounded interval, then condition
(a) for Bernstein inequality is easily satisﬁed. Furthermore, if we let μi denote E(Xi),
it is easy to show that if the interval [μi −σi, μi + σi] for each random variable is
small in comparison to the set of support [ai, bi], this inequality will provide much
tighter bounds when compared to Chernoﬀ-Hoeﬀding bounds.
Example 8.7. Returning back to the analysis of the anesthesia model from Ex-
ample 8.5, we will now apply Bernstein inequality to bound the probability that
x4(5600) ≥300ng/ml. We can compute the sum of the variances 	5600
i=1 σ2
i as 4.687.
Similarly the value of M for Bernstein's inequality in (8.2) is calculated to be 2.362.
These calculations are mechanized using the approach described in Section 8.4.
Applying the inequality yields the bound:
P(x4(5600) ≥300) ≤7.1 × 10−13 .
This is much more useful than the bound of 3.05 × 10−5 obtained using Chernoﬀ-
Hoeﬀding bounds. Similarly, the probability that the anesthesia level falls below
the lower limit of 150ng/ml using Bernstein's inequality is obtained as 2.1 × 10−26,
once again a drastic improvement when compared to Chernoﬀ-Hoeﬀding bounds.
Inequalities that use information from higher order moments beyond just the
mean and the variance are also possible. In fact, these inequalities may be derived by
using an expansion of the moment generating function E(etX) for a random variable
X whose set of support is bounded by [a, b]. The key lies in discovering useful
bounds that can utilize as much information available about the random variables
Xi as possible, while remaining computationally tractable. We see the use of such
designer inequalities derived using computer algebra manipulations rather than
using hand calculations as an important future step in mechanizing the application
of concentration of measure inequalities.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

272
Sankaranarayanan: Quantitative Analysis of Programs
8.3.2 Random Variables with Unbounded Support
All concentration of measure inequalities studied thus far, such as Chernoﬀ-
Hoeﬀding or Bernstein inequalities, rely on the random variables Xi having bounded
set of support. However, this need not be the case for many commonly encountered
distributions such as Gaussian or exponential random variables.
Let X1,. . ., Xn be independent random variables whose support is unbounded
(either [−∞,∞], [a,∞) or (−∞,a], for some constant a). We say that a family of
distributions is Lévy stable iﬀthe linear combination of ﬁnitely many random
variables belonging to the family, is also a random variable that belongs to the family.
For instance, commonly occurring distributions such as Gaussian, exponential,
gamma, and Poisson are Lévy stable. If the variables Xi are identically distributed
and their distributions are Lévy stable, then it is possible to calculate the parameters
for the distribution of the sum from the parameters of the original random variables.
Likewise, questions such as P(X ≥E(X) + t) can be handled by knowing the
cumulative density functions of these variables.
However, appealing to stability property of the random variables will fail if the
distributions are not stable or, more commonly, the variables X1,. . ., Xn are not
identically distributed. In this situation, a simple trick can enable us to successfully
apply concentration of measure inequality as follows:
(i) For each Xi choose an interval Ji := [ai, bi] and compute the probability pi
that P(Xi  Ji) (or compute an interval bounding pi). Also deﬁne a random
variable Yi obtained by restricting the variable Xi to the interval Ji. Let E(Yi) be
its expectation.
(ii) To bound the probability that P(	 Xi ≥t), we can consider two mutually
exclusive events. A := A Xi ∈Ji and B := B Xi  Ji. We have that
P(	 Xi ≥t)
=
P(A)P(	 Xi ≥t | A) + P(B)P(	 Xi ≥t | B)
=
P(A)P(	Yi ≥t) + P(B)P(	 Xi ≥t | B)
≤
P(A)P(	Yi ≥t) + P(B)
≤
(/n
i=1(1 −pi))P(	Yi ≥t) + (1 −/n
i=1(1 −pi))
Note that we obtain P(A) = /n
i=1(1 −pi) through the independence of the random
variables X1,. . ., Xn, and P(B) = 1 −P(A). If independence of X1,. . ., Xn is
dropped (as we will see subsequently), we may instead use Fréchet bounds to
conclude that P(A) ≤min(1 −p1,. . .,1 −pn). Likewise, we may use a weaker
bound P(B) ≤p1 + · · · + pn through Boole's inequality (union bound) if the
independence assumption is dropped. We may now estimate the probability
P(	Yi ≥t) using the Chernoﬀ-Hoeﬀding bounds or Bernstein inequality (if the
variance of Yi is known).
The approach also presents an interesting trade-oﬀbetween the size of the interval
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

8.3 Concentration of Measure Inequalities: a Primer
273
Ji chosen for each random variable. A larger interval makes the probability P(B)
vanishingly small. However, at the same time, the quality of the bounds depend on the
width of the intervals Ji. For instance, the problem can be setup as an optimization
to ﬁnd the best bound that can be obtained by varying the width of Ji against the
probability of event B.
Example 8.8. Returning to the anesthesia example (Ex. 8.2), we will consider
the distribution of the noise to be a Gaussian random variable with mean 0 and
variance 0.08. As a result, the concentration of measure inequalities are no longer
applicable. However, if we consider Ji := [−0.4,0.4], we can estimate the probability
P(wi  Ji) ≤5.73 × 10−7. The latter is obtained knowing the probability that the
value of a normally distributed random variables lies ±5σ away from the mean. As a
result, the result from the Chernoﬀ-Hoeﬀding bounds in Example 8.5 can be reused
here to assert that
P(x4(5600) ≥300) ≤(1 −5.73 × 10−7)3.05 × 10−5 + 5600 × 5.73 × 10−7
789:
=3.293×10−3
On the other hand, We could use a larger interval Ji := [−0.593,0.593] that yields
the probability P(wi  Ji) ≤10−13. However, using this interval to truncate the
random variable yields poorer results overall.
P(x4(5600) ≥300) ≤0.0012 + 5600 × 10−13 ≤0.0013 .
The approach can also be used alongside Bernstein bounds provided the variance
can be estimated for the truncated distribution. Here, we may use a formula for the
variance of a truncated Gaussian distribution. In doing so with the larger interval
Ji := [−0.593,0.593] we obtain a tighter bound:
P(x4(5600) ≥300) ≤3.241 × 10−8 + 5600 × 10−13 ≤3.25 × 10−8 .
8.3.3 Inequalities for Nonlinear Functions
Thus far, we have applied Chernoﬀ-Hoeﬀding and Bernstein bounds for sums of
independent random variables. However, more often, probabilistic programs yield
nonlinear functions of random variables f (X1,. . ., Xn). We are interested in tail
bounds of the form
P( f −E( f ) ≥t) ≤exp(−ct2) .
First, it is clear that not all functions will yield such a bound. It is important to
understand properties of functions that are amenable to such a bound and check if
the function computed by the program falls within such a class.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

274
Sankaranarayanan: Quantitative Analysis of Programs
Example 8.9. Revisiting the 2D robotic end eﬀector from Example 8.1, we note
that the value of x at the end of the program in line 18 of Figure 8.1, is obtained as
x := x0 +
99

i=0
9

j=0
di,j cos(θi,j) .
(8.3)
wherein x0 is a truncated Gaussian random variable with mean 0 and standard
deviation 0.05 over the range [−0.5,0.5] (see line 3), di,j is a uniform random
variable over the range [0.98,1.02] and θi,j is given by
θi,j = αj(1 + wi,j)
wherein αj is speciﬁed in the array angles in line 2 of the program shown in
Figure 8.1 and wi,j is distributed as a truncated Gaussian random variable with
mean 0, standard deviation σ = 0.01 and over the range [−0.05,0.05] (see line 13).
Deﬁnition 8.10 (Diﬀerence Bounded Functions). Let f (x1,. . ., xn) be a function
from S1 × · · · × Sn →R for sets Si ⊆R. We say that f is diﬀerence-bounded iﬀ
there exists constants c1,. . .,cn such that
(∀i ∈{1,2,· · · ,n})
(∀x1 ∈S1,. . ., xi−1 ∈Si−1, xi+1 ∈Si+1,. . ., xn ∈Sn)
(∀xi ∈Si, x′
i ∈Si)
| f (x1,. . .,xi,. . ., xn) −f (x1,. . .,x′
i,. . ., xn)| ≤ci.
In other words, varying just the ith argument while keeping the other arguments
the same yields a bounded change in the value of the function. Dubhashi and
Panconesi (2009) and many other authors sometimes use the terminology Lipschitz
functions to refer to diﬀerence-bounded functions, above. Note that the notion of
diﬀerence bounded is not the same as the standard notion of Lipschitz continuity
that one encounters in calculus, wherein the right hand side of the inequality is
L|xi −x′
i | rather than a ﬁxed constant ci. It is easy to see that a Lipschitz continuous
function is diﬀerence-bounded provided the sets S1,. . .,Sn are compact. On the
other hand, the step function (a discontinuous function) is diﬀerence-bounded over
[−1,1] but not Lipschitz continuous.
A well-known result known as McDiarmid's inequality (see McDiarmid, 1989)
shows that a diﬀerence-bounded function of independent random variables concen-
trates around its mean.
Theorem 8.11 (McDiarmid's Inequality). Let X1,. . ., Xn be independent random
variables and f be a diﬀerence-bounded function over the Cartesian product of the
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

8.3 Concentration of Measure Inequalities: a Primer
275
set of support of the random variables. We conclude that
P( f (X1,. . ., Xn) ≤E( f ) + t) ≤exp

−2t2
	n
j=1 c2
j

.
A similar inequality holds for the lower tail, as well.
Example 8.12. Continuing with the calculation for Example 8.9, we will ﬁrst
show that the function in Equation (8.3) is diﬀerence-bounded and derive the
corresponding constants bounding the diﬀerences by hand:
Random Variable
Diﬀerence-Bound Constant
x0
1
di,j
0.04uj
wi,j
1.02(uj −lj)
Here
uj := max(| cos(0.95αj)|, | cos(1.05αj)|)
and
lj := min(| cos(0.95αj)|, | cos(1.05αj)|) .
Carrying out this calculation, the sum of the squares of the diﬀerence-bound
constants is obtained as 13.68. Next we need to estimate E( f ), which is challenging
as it involves integrating a multivariate nonlinear function over the random variables.
A systematic approach to doing so using a combination of aﬃne forms, interval
arithmetic and Taylor series expansions is described in our previous work (Bouissou
et al., 2016). Using an implementation of our approach, we estimate an interval that
bounds the value of E(x) as
E(x) ∈[268.6170484,270.6914916] .
Such a range is nevertheless useful in estimating tail probabilities. For instance, to
bound upper tail probabilities P( f −E( f ) ≥t), we use the upper limit of the given
range for E( f ). Likewise, we use the the lower limit for the lower tail probabilities
in order to obtain conservative bounds. Therefore, we conclude that
P(x ≥277) = P(x −270.69 ≥6.31) ≤exp
−2 ∗6.312
13.68

= 2.96 × 10−3 .
This bound is much improved using the systematic approach that incorporates
variance information originally described in Bouissou et al. (2016), as will be
discussed in the subsequent section.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

276
Sankaranarayanan: Quantitative Analysis of Programs
8.3.4 Inequalities for Correlated Random Variables
We will now examine how concentration inequalities can be derived for dependent
random variables X1,. . ., Xn. If the variables are correlated in some manner, it is hard
to provide useful concentration bounds for the general case. However, in some cases,
the "structure" of the correlation can be exploited to directly derive inequalities by
adapting existing approaches such as Chernoﬀ-Hoeﬀding or Bernstein inequalities.
Numerous cases have been studied such as negatively dependent random variables
(Dubhashi and Panconesi, 2009; Dubhashi and Ranjan, 1998). We will focus our
approach on sums of random variables with a given correlation graph. Let X1,. . ., Xn
be a set of random variables with an undirected graph G := ({X1,. . ., Xn}, E) whose
vertices correspond to the random variables X1,. . ., Xn. An edge between two
random variables (Xi, Xj) signiﬁes a dependency between the variables.
Example 8.13. Let X1, X2 and X3 be three independent random variables and X4
denote a function f (X1, X2, X3). The dependency graph has edges connecting X4
with X1, X2 and X3.
Naturally, existing approaches discussed thus far require the random variables to
be independent. As a result, it is not possible to apply them in this context. We will
describe an elegant "trick" due to Janson (2004), and in turn following ideas from
Hoeﬀding's seminal paper (Hoeﬀding, 1963)) introducing the Chernoﬀ-Hoeﬀding
inequality.
First, we will introduce the notion of a weighted independent-set cover. Let A be
the set of random variables {X1,. . ., Xn}. A subset Aj ⊆A is an independent set if
any two variables in Aj are mutually independent, i.e, there are no edges between
them in the graph G.
An independent set cover is a family of independent sets A1,. . ., Ak such that
A1 ∪· · · ∪Ak = A. A weighted cover is a family of independent sets with positive
real-valued weights
(A1,w1),. . .,(Ak,wk),
such that (a) A1,. . ., Ak form an independent set cover and (b) for each Xi,
	
Aj | Xi ∈Aj wj ≥1. In other words, for each element Xi, the sum of weights
for all independent sets that contain Xi is greater than or equal to 1. Note that every
independent set cover that partitions the set A is also a weighted cover by assigning
the weights 1 to each set. The total weight of a cover is given by w1 + · · · + wk.
Given a graph G its chromatic number ξ(G) = k, for some k ∈N, is the smallest
number of sets that form an independent set cover of A. Likewise, its fractional
chromatic number ξ∗(G) is the minimum weight 	k
j=1 wj of some A1,. . ., Ak such
that (A1,w1),. . .,(Ak,wk) forms a weighed cover.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

8.3 Concentration of Measure Inequalities: a Primer
277
Let (A1,w1),. . .,(Ak,wk) be a weighted cover of the set of random variables A. Let
[ai, bi] represent the set of support for random variable Xi. Let cj := 	
Xi ∈Aj(bi−ai)2.
Theorem 8.14 (Janson, 2004). Given a set of random variables A := {X1,. . ., Xn}
with correlations speciﬁed by graph G. Let (A1,w1),. . .,(Aj,wj) be a weighted
independent set cover of G. The following bound holds:
P(

Xj −E(

Xj) ≥t) ≤exp
−2t2
T2

,
(8.4)
wherein T2 =
(	k
j=1 wj√cj
)2
and cj = 	
Xi ∈Aj(bi −ai)2.
With ξ∗(G) as the fractional chromatic number of G, we obtain the bound
P(

Xj −E(

Xj) ≥t) ≤exp

−2t2
ξ∗(G) 	n
j=1(bj −aj)2

.
(8.5)
First we note that if all the variables are mutually independent, then the optimal
weighted cover is simply (A,1) yielding ξ∗(G) = 1. Both Equations (8.4) and (8.5)
yield the same answer as Chernoﬀ-Hoeﬀding bounds. Applying the bound in (8.4)
requires us to compute a weighted independent set cover of the graph G. A simple
approach lies in using a greedy algorithm to partition the set A into subsets of
independent sets, and using weights 1 to convert the cover into a weighted cover.
Example 8.15. Continuing with Example 8.13, an independent set cover is given
by {X1, X2, X3} and {X4} which yields a weighted cover by assigning a weight 1 to
each independent set.
Therefore, let S := X1 + X2 + X3 + X4 and [ai, bi] denote the range of each random
variable Xi. Applying Janson's inequality for any t ≥0, we get:
P(S ≥E(S) + t) ≤exp
"##
$
−2t2
(
(b1 −a1)2 + (b2 −a2)2 + (b3 −a3)2 + (b4 −a4)
)2
%&&
'
.
Beyond Chernoﬀ-Hoeﬀding bounds, Janson presents extensions of other inequal-
ities such as Bernstein's inequality to the case of correlated random variables with
known correlation structure.
Thus far, we have studied various concentration of measure inequalities and
how they can be applied to reason about the probability of assertions for some
speciﬁc programs. The bigger question, however, is to what extent can the process of
choosing and applying the right inequality be mechanized for a given probabilistic
program. To answer it, we examine the case of control deterministic programs and
use the idea of aﬃne forms to symbolically reason about the distribution of program
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

278
Sankaranarayanan: Quantitative Analysis of Programs
variables during and after the program execution. This provides us a means to apply
the inequalities we have discussed thus far in this section without requiring extensive
manual calculations.
8.4 Control Deterministic Computations
In this section, we brieﬂy touch upon how the concentration of measure inequalities
presented in the previous sections can be systematically applied to reasoning about
programs. We begin our discussion with a simple class of control deterministic
computations. The material in this section is based upon joint work with Olivier
Bouissou, Eric Goubault and Sylvie Putot (see Bouissou et al., 2016). Control deter-
minism is an important property that is satisﬁed by many probabilistic programs that
occur naturally in application domains such as cyber-physical systems (CPS), control
theory, and motion planning, to name a few. In this section, we brieﬂy summarize
the notion of control determinism and examine how probability distributions of
variables can be abstracted in a symbolic fashion, to enable reasoning using various
concentration of measure inequalities.
8.4.1 Control Deterministic Programs
Put simply, a program is control deterministic if and only if the control ﬂow of
the program is unaﬀected by the stochastic or nondeterministic choices made
during the program execution. In eﬀect, the program does not have any if-then-else
branches, and all loops in the program terminate after a pre-determined number
of iterations. Furthermore, the "primitive" assignment statements of the program
involve a continuous function as their RHS.
Formally, a control deterministic program over real-valued program variables x is
constructed using the grammar shown below:
program
→
statement∗
statement
→
assignment
|
repeat < n > (statement∗)
assignment
→
xi ←f (xi1,. . ., xik)
|
xj ∼D
x1,. . ., xn
∈
Identiﬁers
n
∈
N
f
∈
Continuous
D
∈
Distributions
The program consists of a set Identiﬁers of real-valued state variables x1,. . ., xn
that are manipulated using a sequence of assignment statements and deterministic
loops that repeat a set of statements a ﬁxed number n of times. Further, each
assignment involves a continuous function f applied to a subset of variables. The
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

8.4 Control Deterministic Computations
279
Physical Process
x′ = F(x, u, w)
Control
u = G(x)
Disturbance
w
x ∼X0
n ←0
repeat < T >
u ←G(x)
w ∼D
x ←F(x, u, w)
P(x |= ϕ) ≤?
Figure 8.3 Discrete-time control of a physical process under uncertainties caused by external
disturbances and a control deterministic probabilistic program that simulates it.
statement x ∼D denotes drawing a sample from a distribution D and assigning the
value to variable x. The semantics of such a program can be deﬁned in the usual
manner (see Kozen, 1981), and are omitted for this discussion.
Despite the limitations on expressivity due to the absence of control branches,
control deterministic computations form an important class of probabilistic programs.
They arise naturally in the domain of cyber-physical systems, wherein it is important
to reason about uncertainty in the physical state of the system due to external
disturbances. For instance, all the motivating examples from Section 8.1.1 are all
control deterministic.
Figure 8.3 shows a schematic diagram of a physical process whose internal state
x is updated at each time step using the law x′ = F(x,u,w) wherein u is the control
applied externally by a controller and w ∼D is a stochastic disturbance. We assume
that F is a continuous, but possibly nonlinear function. Similarly, the feedback law
G is a continuous and possibly nonlinear function u = G(x). Given the uncertainty
in the initial state x ∼X0, our goal is to evaluate bounds on the probability that
x(T) |= ϕ for some assertion ϕ specifying the unsafe set of states.
8.4.2 Symbolic Execution Using Aﬃne Forms
In this section, we brieﬂy describe an approach that symbolically executes a control
deterministic program based on aﬃne forms deﬁned in previous work by Bouissou
et al. (2012) and subsequently by Bouissou et al. (2016). Aﬃne forms abstract how
the variables in a computation depend as an aﬃne function of the distributions that
aﬀect the program execution. However, many programs of interest are not aﬃne.
To handle these, aﬃne forms are abstracted in two ways: (a) aﬃne forms involve
abstract noise symbols that represent a set of possible distributions; (b) the symbols
in the aﬃne form can be correlated.
Let us deﬁne a set of noise symbols Y = {y1, y2,. . .}, wherein each symbol yi
has an associated set of support in the form of an interval [ℓi,ui], intervals for
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

280
Sankaranarayanan: Quantitative Analysis of Programs
expectation E(yi) ∈[ai, bi], and possibly, a list of intervals for its higher moments
E(y2
i ),E(y3
i ),· · · ,E(yk
i ).
Deﬁnition 8.16 (Environment). An environment E := ⟨Y,support,E(·),G⟩is given
by a ﬁnite set of noise symbols Y = {y1,. . ., yn}, a map support from each symbol
yj to an interval Ij indicating its set of support, a map that associates some select
monomial terms m := yk1
1 · · · ykn
n to intervals that bound their expectations E(m),
and ﬁnally, a directed graph G whose vertices are the symbols in Y and edges (yi, yj)
denote that the variable yj is derived as a function of yi (and possibly other variables
in Y).
An environment E represents a set of distributions D over the noise symbols in
Y such that the sets of support and expectations all lie in the intervals deﬁned by
the environment. The graph G deﬁnes the functional dependence or independence
within pairs of random variables using the following deﬁnition.
Deﬁnition 8.17 (Probabilistic Dependence). Noise symbols yi and yj are proba-
bilistically dependent random variables if there exists yk such that there are paths
from yk to yi and yj to yk in the graph G. Otherwise, yi, yj represent mutually
independent random variables.
An environment E with noise symbols y := (y1,. . ., yn) corresponds to a set of
possible random vectors Y := (Y1,. . .,Yn) that conform to the following constraints:
(a) (Y1,. . .,Yn) must range over the set of support support(y1) × · · · × support(yn);
(b) the moment vectors lie in the appropriate ranges deﬁned by the environment;
and, (c) if noise symbols yi, yj are probabilistically independent according to
the dependence graph G, the corresponding random variables Yi,Yj are mutually
independent. Otherwise, they are "arbitrarily" correlated while still respecting the
range and moment constraints above.
Given an environment E, aﬃne forms are aﬃne expressions over its noise symbols.
Deﬁnition 8.18 (Aﬃne Forms). An aﬃne form over an environment E is an
expression of the form
a0 + a1y1 + · · · + anyn
where a0,a1,. . .,an are interval coeﬃcients, and y1,. . ., yn are the corresponding
noise symbols.
We assume that support(yj) is bounded for all yj ∈Y. We, however, handle
variables with unbounded set of support through the truncation procedure described
in section 8.3.2. Another important aspect is that of missing moment information. We
may use interval arithmetic to estimate missing information given the information
on the set of support and available moments.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

8.4 Control Deterministic Computations
281
Lemma 8.19. Let X be a (univariate) random variable whose set of support is the
interval I ⊆R. It follows that E(X) ∈I.
Let X1, X2 be two random variables. The following inequality holds:
−
,
E(X2
1)E(X2
2) ≤E(X1X2) ≤
,
E(X2
1)E(X2
2) .
The inequality above follows from the Cauchy-Schwarz inequality. Further details
on how missing moment information is inferred are explained in Bouissou et al.
(2016).
Example 8.20. First we will provide an illustrative example of an environment
E. Let Y = {y1, y2, y3} be a set of noise symbols such that support(y1) = [−1,1],
support(y2) = [0,2] and support(y3) = [−2,3]. The corresponding expectations are
E(y1) = [−0.1,0.1], E(y2) = [1.1,1.3], E(y3) = [−0.5,−0.3].
Furthermore, assume we are provided the higher order moment information
E(y2
1) = [0.2,0.5], E(y1y2) = [−0.4,0.6], E(y2
3) = [0.4,0.6].
The dependency graph has the edges (y1, y3) indicating that y3 is functionally
dependent on y1, which in turn are both pairwise independent of y2.
An example aﬃne form in this environment E is
η1 := [0.5,1.5] + [2.0,2.01]y1 −[2.8,3.2]y3 .
Semantically, an aﬃne form f (y) := a0 + 	n
i=1 aiyi represents a set of linear
expressions  f (y) over y:
 f (y) :=

r0 +
n

i=1
riYi | ri ∈ai,(Y1,. . .,Yn) ∈E

.
Given aﬃne forms, we can deﬁne a calculus that describes how basic operations
such as sums, diﬀerences, products and application of continuous (and k-times
diﬀerentiable) functions are carried out over these aﬃne forms.
Sums, Diﬀerences and Products: Let f1, f2 be aﬃne forms in an environment E
given by f1 := aty + a0 and f2 := bty + b0. We deﬁne the sum f1 ⊕f2 to be the
aﬃne form (a + b)ty + (a0 + b0). Likewise, let λ be a real number. The aﬃne form
λ f1 is given by (λa)ty + λa0.
We now deﬁne the product of two forms f1 ⊗f2.
f1 ⊗f2 = a0b0 + a0 f2 + b0 f1 + approx
(
n

i=1
n

j=1
aiajyiyj
)
.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

282
Sankaranarayanan: Quantitative Analysis of Programs
Note that a0b0,a0 f2, b0 f1 and aiaj denote the result of multiplying two intervals.
The product of two intervals [li,ui][lj,uj] is deﬁned as the interval
[min(lilj,uilj,liuj,uilj),max(lilj,uilj,liuj,uilj)]
(see Moore et al., 2009).
The product of two aﬃne forms f1 ⊗f2 separates the aﬃne and linear parts of this
summation from the nonlinear part that must be approximated to preserve the aﬃne
form. To this end, we deﬁne a function approx that replaces the nonlinear terms by a
collection of fresh random variables. In particular, we add a fresh random variable
yij to approximate the product term yiyj.
Dependencies:
We add the dependency edges (yij, yi) and (yij, yj) to the graph G
to denote the newly deﬁned functional dependences.
Set of Support:
The set of support for yij is the interval product of the set of
supports for yi, yj, respectively. In particular if i = j, we compute the set of support
for y2
i . Interval Iij will represent the set of support for yij.
Moments:
The moments of yij are derived from those of yi and yj, as follows.
Case-1
(i = j). If i = j, we have that the E(yp
ij) = E(y2p
i ). Therefore, the even
moments of yi are taken to provide the moments for yij. However, since we assume
that only the ﬁrst k moments of yi are available, we have that the ﬁrst k
2 moments
of yij are available, in general. To ﬁll in the remaining moments, we approximate
using intervals as follows: E(yr
ij) ∈Ir
ij. While this approximation is often crude, this
is a tradeoﬀinduced by our inability to store inﬁnitely many moments for the noise
symbols.
Case-2
(i  j). If i  j, we have that E(yp
ij) = E(yp
i yp
j ). If yi, yj form an
independent pair, this reduces back to E(yp
i )E(yp
j ). Thus, in this instance, we can
ﬁll in all k moments directly as entry-wise products of the moments of yi and
yj. Otherwise, they are dependent, so we use the Cauchy-Schwarz inequality (see
Lemma 8.19): −
,
E(y2p
i )E(y2p
j ) ≤E(yp
ij)
≤
,
E(y2p
i )E(y2p
j ), and the interval
approximation E(yp
ij) ∈I p
ij.
Continuous Functions: Let g(y) be a continuous and (m + 1)-times diﬀerentiable
function of y, where y belongs to a compact interval J. The Taylor expansion of g
around a point y0 ∈interior(J) allows us to approximate g as a polynomial:
g(y) = g(y0) + Dg(y0)(y −y0) +

2≤|α|1 ≤m
Dαg(y0)(y −y0)α
α!
+ Rm+1
g
,
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

8.4 Control Deterministic Computations
283
wherein Dg denotes the vector of partial derivatives ( ∂g
∂yj )j=1,...,n; α := (d1,. . ., dn)
ranges over all vector of indices, where di ∈N is a natural number; |α|1 := 	n
i=1 di;
α! = d1!d2! · · · dn!; Dαg denotes the partial derivative ∂d1g···∂dn g
∂yd1
1
···∂ydn
n
; and (y −y0)α :=
/n
j=1(yj −y0,j)dj. Finally, Rm+1
g
is an interval-valued Lagrange remainder:
Rm+1
g
∈
⎧⎪⎪⎨
⎪⎪⎩

|α|1=m+1
Dαg(z)
α!
(z −y0)m+1 | z ∈J
⎫⎪⎪⎬
⎪⎪⎭
.
This computation is automated in our implementation through a combination of
standard ideas from automatic diﬀerentiation and interval arithmetic (see Moore
et al., 2009).
Since we have discussed sums and products of aﬃne forms, the Taylor approxi-
mation may be evaluated entirely using aﬃne forms.
The remainder is handled using a fresh noise symbol y(m+1)
g
. Its set of support
is Rm+1
g
and moments are estimated based on this interval. The newly added noise
symbol is functionally dependent on all variables y that appear in g(y). These
dependencies are added to the graph G.
The Taylor expansion allows us to approximate continuous functions including
rational and trigonometric functions of these random variables.
Example 8.21. We illustrate this by computing the sine of an aﬃne form. Let y1 be
a noise symbol over the interval [−0.2,0.2] with the moments
(E(y1) = 0,
E(y2
1) ∈[0.004,0.006],
E(y3
1) = 0,
E(y4
1) ∈[6 × 10−5,8 × 10−5],
E(y5
1) = 0) .
We consider the form sin(y1). Using a Taylor series expansion around y1 = 0, we
obtain
sin(y1) = y1 −1
3! y3
1 + [−1.3 × 10−5,1.4 × 10−5] .
We introduce a fresh variable y2 to replace y3
1 and a fresh variable y3 for the
remainder interval I3 := [−1.3 × 10−5,1.4 × 10−5].
Dependencies:
We add the edges (y2, y1) and (y3, y1) to G.
Sets of Support:
I2 := [−0.008,0.008] and I3 := [−1.3 × 10−5,1.4 × 10−5].
Moments:
E(y2) = E(y3
1) = 0. Further moments are computed using interval
arithmetic. The moment vector I(m2) is (0,[0,64 × 10−6],[−512 × 10−9,512 ×
10−9],. . .). For y3, the moment vector
I(m3) := (I3,square(I3),cube(I3),. . .) .
The resulting aﬃne form for sin(y1) is [1,1]y1 −[0.16,0.17]y2 + [1,1]y3.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

284
Sankaranarayanan: Quantitative Analysis of Programs
8.4.3 Approximating Computations using Aﬃne Forms
Having developed a calculus of aﬃne forms, we may directly apply it to propagate
uncertainties across control deterministic computations. Let X = {x1,. . ., xp} be a set
of program variables collectively written as x with an initial value x0. Our semantics
consist of a tuple (E,η) wherein E is an environment and η := X →AﬃneForms(E)
maps each variable xi ∈X to an aﬃne form over E. The initial environment E0 has
no noise symbols and an empty dependence graph. The initial mapping η0 associates
each xi with the constant xi,0. The basic operations are of two types: (a) assignment
to a fresh random variable, and (b) assignment to a function over existing variables.
Random Number Generation: This operation is of the form xi := rand(I,m),
wherein I denotes the set of support interval for the new random variable, and m
denotes a vector of moments for the generated random variable. The operational
rule is (E,η)
xi:=rand(I,m)
−−−−−−−−−−→(E′,η′), wherein the environment E′ extends E by a
fresh random variable y whose set of support is given by I and moments by m. The
dependence graph is extended by adding a new node corresponding to y but without
any new edges since freshly generated random numbers are assumed independent.
However, if the newly generated random variable is dependent on some previous
symbols, such a dependency is also easily captured in our framework.
Assignment: The assignment operation is of the form xi ←g(x), assigning xi to
a continuous and (j + 1)-times diﬀerentiable function g(x). The operational rule
has the form (E,η)
xi←g(x)
−−−−−−→(E′,η′). First, we compute an aﬃne form fg that
approximates the function g(η(x1),. . .,η(xn)). Let Yg denote a set of fresh symbols
generated by this approximation with new dependence edges Eg. The environment
E′ extends E with the addition of the new symbols Yg and and new dependence
edges Eg. The new map is η′ := η[xi →fg].
Let C be a computation deﬁned by a sequence of random number generation and
assignment operations. Starting from the initial environment (E0,η0) and applying
the rules above, we obtain a ﬁnal environment (E,η). However, our main goal is to
answer queries such as P(xj ∈Ij) that seek the probability that a particular variable
xj belongs to an interval Ij. This directly translates to a query involving the aﬃne
form η(xj) which may involve a prohibitively large number of noise symbols that
may be correlated according to the dependence graph G.
Example 8.22 (2D robotic end eﬀector). Consider a simpliﬁed version of the 2D
robotic end eﬀector model presented in Example 8.1, yielding an aﬃne form with
6900 noise symbols for the variable x that we care about. The computation required
15 seconds of computational time on a laptop with Intel 3.1 core i7 processor and
16GB RAM.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

8.4 Control Deterministic Computations
285
x =
⎧⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩
[8.06365, 8.06441] + [1, 1] ∗y0 + [0.984807, 0.984808] ∗y2+
[0.0303060, 0.0303069] ∗y3 + [−1, −1] ∗y4+
[0.0303060, 0.0303069] ∗y5 + [−1, −1] ∗y6+
[0.499997, 0.500026] ∗y9+
[0.90686, 0.906894] ∗y10+
· · ·
[0.119382, 0.119386] ∗y6885 + [−1, −1] ∗y6886 + [0.984807, 0.984808] ∗y6889
+ [0.0303060, 0.0303069] ∗y6890 + [−1, −1] ∗y6891 + [0.0303060, 0.0303069] ∗y6892+
[−1, −1] ∗y6893 + [1, 1] ∗y6896 + [−1, −1] ∗y6898 + [−1, −1] ∗y6899
Based on the aﬃne form, we can bound the support for x ∈[213.19,326.12] and
its expectation as E(x) ∈[268.61,270.7], and the second central moment (variance)
in the range [0.12,0.28].
8.4.4 Applying Concentration of Measure Inequalities
We will now apply the results from section 8.3 to analyzing the aﬃne forms generated
from control deterministic programs. First, we note that each aﬃne form is a sum of
possibly dependent random variables with information about sets of support, ﬁrst
and possibly higher order moments available. Thus, many strategies for applying
the results in the previous section are available. These are summarized in detail in
Bouissou et al. (2016). In what follows, we will illustrate the application of these
results directly to some of the motivating examples from Section 8.1 using a prototype
implementation of the ideas mentioned thus far. The prototype implementation in
the C++ language interprets a given program using a library of aﬃne forms. Next, it
mechanizes the process of answering queries by analyzing the dependency graph.
The automatic analysis uses a series of approaches that include:
(i) The application of Chernoﬀ-Hoeﬀding bounds by using a compaction procedure
that combines multiple noise symbols into a single one, so that the aﬃne forms
are all summations over independent random variables. Similarly, Bernstein
inequalities are used whenever second moments are consistently available.
(ii) The application of the chromatic number bound Janson (2004), using 1 + Δ as
an approximation for the fractional chromatic number, wherein Δ is the maximum
degree of any node in the dependence graph.
Example 8.23 (2D end eﬀector). Resuming the analysis in Ex. 8.22, we can
automate the application of various approaches discussed thus far, starting with the
Chernoﬀ-Hoeﬀding bounds.
The original aﬃne form has 6900 variables which are not all mutually independent.
To obtain mutual independence, we analyze the strongly connected components of the
undirected dependence graph yielding 3100 diﬀerent components such that variables
in distinct components are pairwise independent. Using this, we compact the aﬃne
form into one involving 3100 random variables and apply Chernoﬀ-Hoeﬀding
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

286
Sankaranarayanan: Quantitative Analysis of Programs
(a)
(b)
Figure 8.4 (a) Simulated (x, y) positions of UAV over the time horizon [0, 3.6] seconds and (b)
Histogram of ﬁnal position x(3.6) + y(3.6).
bounds. This is performed by computing the strongly connected components (SCC)
of the dependency graph G, and taking the set of support and mean of the sum of
random variables belonging to each SCC. Note that Chernoﬀ-Hoeﬀding bounds
can be applied since noise symbols belonging to diﬀerent SCCs are mutually
independent.
This yields
P(x ≥277) ≤exp
−(268.6170484 −277)2
7.486493141

≤8.38 × 10−5 .
Applying Bernstein's inequality yields:
P(X ≤t) ≤exp

−(268.6170484 −t)2
0.4868099186 + 0.3333 ∗(t −286.6170484)

≤5.18 × 10−10 .
The chromatic number bound of Janson (2004) computes a weaker bound given by
0.106.
Now, we will consider the example of a ﬁxed-wing UAV collision probability
estimation from Ex. 8.3.
Example 8.24. Consider a prediction horizon of t = 20 × 0.18 = 3.6 seconds.
Our goal is to run the model twenty times, starting from a given initial state and
query the probability that x + y ≥165. We obtain an aﬃne form for x + y with
88 noise symbols. The mean value E(x + y) ∈[65.85,65.86] matches very well
with the empirical estimate of 65.84 from 10,000 simulations. Furthermore, the
variance is estimated in the range [78.95,78.96] which also matches quite well with
the empirical variance of 78.76 obtained from 10,000 simulations. Some of the
trajectories of the system and the scatter plot with 10000 end points are shown in
Figure 8.4.
Using the Bernstein inequality, we obtain the estimate
P(x + y ≥165) ≤9.6 × 10−4 .
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

8.5 Super-martingales and Concentration of Measure
287
and more generally,
P(x + y ≥65.859 + t) ≤exp

−t2
157.8869 + 12.57t

.
8.5 Super-martingales and Concentration of Measure
In the ﬁnal section, we look at concentration of measure inequalities using super-
martingales. A previous chapter in the same volume by Chatterjee et al adapts the
concept of a super-martingales to prove termination. We will recall the deﬁnition and
show that super-martingales are also useful for proving concentration. First let us
recall conditional expectations. Let X,Y be two random variables. The conditional
expectation E(X|Y) is deﬁned as a function f (y) deﬁned over the support of the
distribution Y such that
f (y) =
∫
X
xdP(x|y)
In other words, for each value of y, the expectation integrates x over the conditional
distribution of x given y.
Deﬁnition 8.25 (Martingales, Super- and Sub-Martingales). A sequence of random
variables X0, X1,. . ., Xn is a martingale if and only if for each i ≥0,
E(Xi+1 | Xi,. . ., X0) = Xi .
A super-martingale satisﬁes the condition
E(Xi+1 | Xi,. . ., X0) ≤Xi .
A sub-martingale satisﬁes the inequality:
E(Xi+1 | Xi,. . ., X0) ≥Xi .
A martingale is, therefore, both a super-martingale and a sub-martingale. Typically,
the stochastic processes that are studied arise from Markovian models such as
probabilistic programs wherein the next state distribution depends on just the current
state. Thus, the conditional expectation E(Xi+1 | Xi,. . ., X0) is written as E(Xi+1 | Xi).
Example 8.26. Consider a random walk involving x(t) ∈Z that is updated as
x(t + 1) =

x(t) + 1
with probability 1
2
x(t) −1
with probability 1
2
It is easy to see that x(t) is a martingale since
E(x(t + 1) | x(t)) = 1
2(x(t) + 1) + 1
2(x(t) −1) = x(t) .
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

288
Sankaranarayanan: Quantitative Analysis of Programs
It is easy to see that a martingale is always a super-martingale, but not necessarily
vice-versa. Another important observation is that often a stochastic process is not a
(super-) martingale itself. However, another process built, for instance, by computing
a function of the original process forms a (super-) martingale.
Example 8.27. Consider a diﬀerent scenario wherein x(t) ∈R:
x(t + 1) =

0.8x(t)
with probability 1
2
1.1x(t)
with probability 1
2
Here, x(t) is neither a martingale or a super-martingale. Note though that y(t) = x(t)2
is a super-martingale:
E(y(t + 1) | x(t)) = 1
20.82y(t) + 1
21.12y(t) = 0.925y(t) ≤y(t) .
Some of the constructions that have been previously encountered such as the
McDiarmid's Inequality (Theorem 8.11) involve a martingale under the hood.
Example 8.28 (Doob Martingale). Let f (x1,. . ., xn) be a function with n inputs
which are drawn from independent random variables X1,. . ., Xn.
Consider the stochastic process
Yi = EXi+1,...,Xn( f (X1,. . ., Xi, Xi+1,. . ., Xn)),
for i = 0,. . .,n. Note that eachYi is a function of X1,. . ., Xi while taking expectations
over the remaining arguments. As a result Y0 is the expected value of f under all its
inputs, Yi for i > 0 ﬁxes random samples for the arguments indexed from 1 to i, and
Yn is the function f computed over some random sample of all the arguments.
Note that for every i < n, it is easy to show that
E(Yi+1 | Xi,. . ., X1) = Yi .
This construction can be achieved for any function f and is called Doob martin-
gale. However, also note the independence requirements for the random variables
X1,. . ., Xn.
Super-martingales from programs: As previously noted in chapter on termination,
we seek expressions involving variables of the programs that form super-martingales.
Consider the program shown in Figure 8.5 (taken from our previous work (Chakarov
and Sankaranarayanan, 2013)), wherein the position of an underwater vehicle (x, y)
is updated at each step through a command that can be randomly chosen direction
or just staying in one position. Based on this command, the actual position changes
through a noisy execution of the command. However, at the same time, the estimation
of the current position is updated. The question is how far the estimate deviates from
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

8.5 Super-martingales and Concentration of Measure
289
1
x, y, estX, estY = 0, 0, 0, 0
2
dx, dy, dxc, dyc = 0, 0, 0, 0
3
N = 500
4
for i in range(N):
5
cmd = choice {N:0.1, S:0.1, E:0.1, W:0.1, NE:0.1, SE:0.1, NW: 0.1,
6
SW: 0.1, Stay: 0.2}
7
if (cmd == 'N'):
8
dxc, dyc = 0, Uniform(1,2)
9
elif (cmd == 'S'):
10
dxc, dyc = 0, Uniform(-2, -1)
11
elif (cmd == 'E'):
12
dxc, dyc = Uniform(1,2), 0
13
...
14
else // cmd == 'Stay'
15
dxc, dyc = 0,0
16
dx = dxc + Uniform(-0.05, 0.05)
17
dy = dyc + Uniform(-0.05, 0.05)
18
x = x + dx
19
y = y + dy
20
estX = estX + dxc
21
estY = estY + dyc
22
assert( |x - estX| >= 3)
Figure 8.5 Program simulating a sequence of moves by a submarine, where (x, y) model the
true position, dxc, dyc model the commanded change in position at any step, and (estX, estY)
model the estimates through dead-reckoning.
the true position after N = 500 steps? Note that for this program it is straightforward
to establish that x −estX and y −estY are super-martingales.
Azuma-Hoeﬀding's Inequality: Let {Xn}N
n=0 be a super-martingale that satisﬁes
a bounded diﬀerence condition that |Xi+1 −Xi| ≤ci for each i ∈{0,. . ., N −1}. It
follows that for any j ∈{0,. . ., N},
P(Xj −X0 ≥t) ≤exp

−t2
2 	j−1
i=0 c2
i

.
Furthermore, if Xn is a sub-martingale, we can conclude that
P(Xj −X0 ≤−t) ≤exp

−t2
2 	j−1
i=0 c2
i

.
Thus, for a martingale which is a super-martingale as well as a sub-martingale, both
inequalities hold.
The Azuma-Hoeﬀding bound is a concentration of measure inequality much along
the lines of previously encountered inequalities in this chapter. For a martingale, it
bounds the probability of a large deviation on either side of its starting value. For a
super-martingale, the inequality bounds the probability of a large deviation above the
starting value. The martingale condition generalizes from the need for independent
random variables that was seen for the case of Chernoﬀ-Hoeﬀding inequalities.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

290
Sankaranarayanan: Quantitative Analysis of Programs
Just as the latter inequalities are applied to random variables with bounded sets of
support, we note the condition of bounded change on the (super-) martingale.
Example 8.29. Returning to the dead-reckoning example, we can use the martingale
x −estX to estimate the failure probability of the assertion at the end of the program.
We note that every loop iteration, the absolute change in this expression is bounded
by 0.05. Therefore, we obtain
P(|x −estX| ≥3) ≤1.5 × 10−3 .
Identical bounds are obtained for the deviation of y from estY, as well.
Super-martingales form very powerful approaches for quantitative reasoning.
However, two major obstacles block their wider application:
(i) Automatically discovering super-martingale expressions remains a hard problem,
especially for nonlinear expressions. However, a variety of approaches summarized
in the termination chapter can be used in this regard. At the same time, the
applications have been limited thus far.
(ii) The resulting bounds remain conservative since independent random variables
are often treated as possibly dependent in the analysis for super-martingales. For
instance, treating x −estX as the sum of independent random variables for the
dead-reckoning example above yields much more precise bounds.
However, super-martingales remain a promising approach for quantitative rea-
soning for more complex models that involve programs with branch conditions
that cannot be treated with the approaches for control deterministic computations
reviewed in the previous sections.
8.6 Conclusion
Thus far, we have examined situations where concentration of measure inequalities
can be applied to analyze probabilistic programs. As the reader may have noticed,
the key issue lies in mechanizing the process of inference, since even small programs
can lead to cumbersome calculations that are hard to carry out by hand. However,
there are numerous challenges that must be tackled before the full power of these
approaches can be realized. First, most approaches are restricted to reasoning about
programs that manipulate real values, whereas programs can exhibit a rich variety
of structures ranging from Booleans, strings, lists, trees and graphs. Extending the
concentration of measure approach to reason about a richer set of programs is an
important area of future work.
Also, one notes that concentration of measure inequalities are often derived to
uniformly exploit available moment information such as ﬁrst moments, second
moments and so on. It is easy to envision a process of customization that can derive
inequalities based on the available moment information on a "per-problem" basis.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
291
This approach of "designing" new inequalities on demand is yet another promising
area of future investigation.
Finally, the broader area of analyzing probabilistic programs has been seemingly
disconnected from the problem of Bayesian inference, which is an important concern
for probabilistic programming. We note that the problem of model inference and
analysis are important steps in the overall "analytics" pipeline. It is therefore natural,
as a ﬁrst step to study these problems separately. The problem of integrating Bayesian
inference and subsequent analysis of the "posterior" model/program remains an im-
portant unsolved problem. Current approaches that combine Monte-Carlo techniques
with their approximate convergence guarantees are not directly compatible with the
use of concentration of measure or other symbolic approaches presented here. In this
regard, the study of imprecise models of probability distributions, representing sets
of distributions, along with concentration of measure inequalities on functions of
samples drawn from such models is another promising area of future investigation.
Acknowledgments
The author gratefully acknowledges collaboration with Aleksandar Chakarov, Olivier
Bouissou, Eric Goubault and Sylvie Putot that formed the basis for the ideas presented
in this chapter. We acknowledge support from the US National Science Foundation
(NSF) under awards 1320069, 1527075 and 1815983. All opinions expressed are
those of the authors and not necessarily of the NSF.
References
Agha, Gul, and Palmskog, Karl. 2018. A Survey of Statistical Model Checking.
ACM Trans. Model. Comput. Simul., 28(1), 6:1-6:39.
Bernstein, Sergei N. 1924. On a modiﬁcation of Chebyshev's inequality and of the
error formula of Laplace. Ann. Sci. Inst. Sav. Ukraine, Sect. Math, 1.
Boucheron, Stephane, Lugosi, Gabor, and Massart, Pascal. 2016. Concentration of
Measure: An Asymptotic Theory of Independence. Oxford University Press.
Bouissou, Olivier, Goubault, Eric, Goubault-Larrecq, Jean, and Putot, Sylvie. 2012.
A generalization of P-Boxes to aﬃne arithmetic. Computing.
Bouissou, Olivier, Goubault, Eric, Putot, Sylvie, Chakarov, Aleksandar, and Sankara-
narayanan, Sriram. 2016. Uncertainty Propagation Using Probabilistic Aﬃne
Forms and Concentration of Measure Inequalities. Pages 225-243 of: Chechik,
Marsha, and Raskin, Jean-François (eds), Tools and Algorithms for the Con-
struction and Analysis of Systems. Springer.
Bournez, Olivier, and Garnier, Florent. 2005. Proving Positive Almost-Sure Termi-
nation. Pages 323-337 of: RTA. LNCS, vol. 3467. Springer.
Brockwell, P. J., and Davis, R. A. 2009. Time Series: Theory and Methods. Springer.
Bucklew, James Antonio. 2004. Introduction to Rare-Event Simulations. Springer.
Chakarov, Aleksandar, and Sankaranarayanan, Sriram. 2013. Probabilistic Program
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

292
References
Analysis using Martingales. Pages 511-526 of: Computer-Aided Veriﬁcation
(CAV). LNCS, vol. 8044. Springer.
Chakarov, Aleksandar, Voronin, Yuen-Lam (Vris), and Sankaranarayanan, Sriram.
2016. Deductive Proofs of Almost Sure Persistence and Recurrence Properties.
Pages 260-279 of: Tools and Algorithms for Construction and Analysis of
Systems (TACAS). LNCS, vol. 9636. Springer.
Chatterjee, Krishnendu, Novotný, Petr, and Zikelic, Dorde. 2017.
Stochastic
invariants for probabilistic termination. Pages 145-160 of: ACM Principles of
Programming Languages (POPL). ACM Press.
Chatterjee, Krishnendu, Fu, Hongfei, Novotný, Petr, and Hasheminezhad, Rouzbeh.
2018. Algorithmic Analysis of Qualitative and Quantitative Termination
Problems for Aﬃne Probabilistic Programs. ACM Trans. Program. Lang. Syst.,
40(2), 7:1-7:45.
Clarke, Edmund, Donze, Alexandre, and Legay, Axel. 2009. Statistical Model
Checking of Analog Mixed-Signal Circuits With An application to a third order
Δ −Σ modulator. Pages 149-163 of: Hardware and Software: Veriﬁcation and
Testing. LNCS, vol. 5394/2009.
Cousot, Patrick, and Monerau, Michael. 2012. Probabilistic Abstract Interpretation.
Pages 169-193 of: ESOP. LNCS, vol. 7211. Springer.
De Loera, J., Dutra, B., Koeppe, M., Moreinis, S., Pinto, G., and Wu, J. 2011.
Software for Exact Integration of Polynomials over Polyhedra. ArXiv e-prints,
July.
Dempster, A.P. 1967. Upper and Lower Probabilities Induced by a Multivalued
Mapping. The Annals of Mathematical Statistics, 38(2), 325-339.
Dimitrova, Rayna, Fioriti, Luis María Ferrer, Hermanns, Holger, and Majumdar,
Rupak. 2016. Probabilistic CTL*: The Deductive Way. Pages 280-296 of:
Proc. TACAS.
Dubhashi, Devdatt, and Ranjan, Desh. 1998. Balls and Bins: A Study in Negative
Dependence. Random Structures and Algorithms, 13(2), 99-124.
Dubhashi, Devdutt, and Panconesi, Alessandro. 2009. Concentration of Measure
for the Analysis of Randomized Algorithms. Cambridge University Press.
Esparza, Javier, Gaiser, Andreas, and Kiefer, Stefan. 2012. Proving Termination of
Probabilistic Programs Using Patterns. Pages 123-138 of: CAV. LNCS, vol.
7358. Springer.
Ferson, Scott, Kreinovich, Vladik, Ginzburg, Lev, Myers, David S., and Sentz,
Kari. 2003 (January). Constructing probability boxes and Dempster-Shafer
structures. Tech. rept. SAND2002-4015. Sandia Laboratories.
Fioriti, Luis María Ferrer, and Hermanns, Holger. 2015. Probabilistic Termination:
Soundness, Completeness, and Compositionality. Pages 489-501 of: Proc.
Principles of Programming Languages, POPL. ACM Press.
Geldenhuys, Jaco, Dwyer, Matthew B., and Visser, Willem. 2012. Probabilistic
symbolic execution. Pages 166-176 of: ISSTA. ACM.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
293
Hoeﬀding, Wassily. 1963. Probability Inequalities for Sums of Bounded Random
Variables. Journal of the American Statistical Association, 58(301), 13-30.
Janson, Svante. 2004. Large deviations for sums of partly dependent random
variables. Random Structures Algorithms, 24(3), 234-248.
Jégourel, Cyrille, Legay, Axel, and Sedwards, Sean. 2012. Cross-Entropy Optimisa-
tion of Importance Sampling Parameters for Statistical Model Checking. Pages
327-342 of: CAV. LNCS, vol. 7358. Springer.
Jha, Sumit Kumar, Clarke, Edmund M., Langmead, Christopher James, Legay, Axel,
Platzer, André, and Zuliani, Paolo. 2009. A Bayesian Approach to Model
Checking Biological Systems. Pages 218-234 of: CMSB. LNCS, vol. 5688.
Springer.
Kaminski, Benjamin Lucien, Katoen, Joost-Pieter, Matheja, Christoph, and Olmedo,
Federico. 2016. Weakest Precondition Reasoning for Expected Run-Times
of Probabilistic Programs.
Pages 364-389 of: European Symposium on
Programming (ESOP).
Kass, Robert E., and Raftery, Adrian E. 1995. Bayes Factors. J. Amer. Stat. Assoc.,
90(430), 774-795.
Katoen, Joost-Pieter, McIver, Annabelle, Meinicke, Larissa, and Morgan, Carroll.
2010. Linear-Invariant Generation for Probabilistic Programs. Page 390-406
of: Static Analysis Symposium (SAS). LNCS, vol. 6337. Springer.
Kozen, Dexter. 1981. Semantics of Probabilistic Programs. J. Computer and System
Sciences, 22, 328-350.
Kwiatkowska, M., Norman, G., and Parker, D. 2011. PRISM 4.0: Veriﬁcation of
Probabilistic Real-time Systems. Pages 585-591 of: CAV. LNCS, vol. 6806.
Springer.
Mardziel, Piotr, Magill, Stephen, Hicks, Michael, and Srivatsa, Mudhakar. 2011.
Dynamic Enforcement of Knowledge-based Security Policies. Pages 114-128
of: Computer Security Foundations Symposium (CSF).
McClain, Deborah A., and Hug, Carl C. 1980. Intravenous Fentanyl Kinetics.
Clinical Pharmacology & Therapeutics, 28(1), 106-114.
McDiarmid, Colin. 1989. On the method of bounded diﬀerences. Surveys in
Combinatorics, 141(1), 148-188.
McElreath, Richard. 2015. Statistical Rethinking: A Bayesian Course with Examples
in R and Stan. CRC Press.
McIver, Annabelle, and Morgan, Carroll. 2004. Abstraction, Reﬁnement and Proof
for Probabilistic Systems. Monographs in Computer Science. Springer.
McIver, Annabelle, Morgan, Carroll, Kaminski, Benjamin Lucien, and Katoen,
Joost-Pieter. 2018. A new proof rule for almost-sure termination. PACMPL,
2(POPL), 33:1-33:28.
Monniaux, David. 2000. Abstract Interpretation of Probabilistic Semantics. Pages
322-339 of: Static Analysis Symposium (SAS). LNCS, vol. 1824. Springer.
Monniaux, David. 2005. Abstract interpretation of programs as Markov decision
processes. Sci. Comput. Program., 58(1-2), 179-205.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

294
References
Moore, R. E., Kearfott, R. B., and Cloud, M. J. 2009. Introduction to Interval
Analysis. SIAM.
Narayanan, Praveen, Carette, Jacques, Romano, Wren, Shan, Chung-chieh, and
Zinkov, Robert. 2016. Probabilistic inference by program transformation in
Hakaru (system description). Pages 62-79 of: FLOPS 2016. Springer.
Parker, David, Norman, Gethin, and Kwiatkowska, Marta. 2006. Game-based
Abstraction for Markov Decision Processes. Pages 157-166 of: QEST'06.
IEEE Press.
Rubinstein, Reuven Y., and Kroese, Dirk P. 2008. Simulation and the Monte Carlo
Method. Wiley Series in Probability and Mathematical Statistics.
Sankaranarayanan, Sriram, and Fainekos, Georgios E. 2012. Falsiﬁcation of temporal
properties of hybrid systems using the cross-entropy method. Pages 125-134
of: HSCC. ACM.
Sankaranarayanan, Sriram, Chakarov, Aleksandar, and Gulwani, Sumit. 2013. Static
analysis for probabilistic programs: inferring whole program properties from
ﬁnitely many paths. Pages 447-458 of: PLDI. ACM.
Shafer, Glenn. 1976. A Mathematical Theory of Evidence. Princeton University
Press.
Shafer, Steven L., Siegel, Lawrence C., Cooke, James E., and Scott, James C. 1988.
Testing Computer-controlled Infusion Pumps by Simulation. Anesthesiology,
68, 261-266.
Srinivasan, Rajan. 2002. Importance Sampling: Applications in Communications
and Detection. Springer.
Wald, A. 1945. Sequential Tests of Statistical Hypotheses. The Annals of Mathemat-
ical Statistics, 16(2), 117-186.
Williams, David. 1991. Probability with Martingales. Cambridge University Press.
Wingate, David, and Weber, Theophane. 2013. Automated Variational Inference in
Probabilistic Programming. CoRR, abs/1301.1299.
Younes, Håkan L. S., and Simmons, Reid G. 2006. Statistical Probabilistic Model
Checking with a Focus on Time-Bounded Properties. Information & Computa-
tion, 204(9), 1368-1409.
Youseﬁ, Mahdi, van Heusden, Klaske, M. Mitchell, Ian, Ansermino, Mark, and
Dumont, Guy. 2017. A Formally-Veriﬁed Safety System for Closed-Loop
Anesthesia. IFAC-PapersOnLine, 50(1), 4424-4429.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

9
The Logical Essentials of Bayesian Reasoning
Bart Jacobs
Radboud Universiteit, Nijmegen
Fabio Zanasi
University College London
Abstract:
This chapter oﬀers an accessible introduction to the channel-based
approach to Bayesian probability theory. This framework rests on algebraic and
logical foundations, inspired by the methodologies of programming language
semantics. It oﬀers a uniform, structured and expressive language for describing
Bayesian phenomena in terms of familiar programming concepts, like channel,
predicate transformation and state transformation. The introduction also covers
inference in Bayesian networks, which will be modelled by a suitable calculus of
string diagrams.
9.1 Introduction
In traditional imperative programming one interprets a program as a function that
changes states. Intuitively, the notion of 'state' captures the state of aﬀairs in a
computer, as given for instance by the contents of the relevant parts of the computer's
memory. More abstractly, a program is interpreted as a state transformer. An
alternative, logical perspective is to interpret a program as a predicate transformer.
In that case the program turns one predicate into a new predicate. This works in
opposite direction: the program turns a predicate on the 'post-state' into a predicate on
the 'pre-state', for instance via the weakest precondition computation. As discovered
in the early days of programming semantics, basic relations exists between state
transformation and predicate transformation, see for instance Dijkstra and Scholten
(1990), Dijkstra (1997), and Proposition 9.11 below.
A similar theory of state and predicate transformation has been developed
for probabilistic programming, see Kozen (1981, 1985). This approach has been
generalised and re-formulated in recent years in categorical terms, typically using
so-called Kleisli categories, in Jacobs (2017), and more generally via the notion of
a From Foundations of Probabilistic Programming, edited by Gilles Barthe, Joost-Pieter Katoen and Alexandra
Silva published 2020 by Cambridge University Press.
295
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

296
Jacobs and Zanasi: Logical Essentials of Bayesian Reasoning
eﬀectus, in Cho et al. (2015). Category theory provides a fundamental language
for the semantics of programming languages. This is clear in approaches based on
domain theory. For instance, many constructions for types in programming languages
have categorical counterparts, like (co)products, exponentials, and initial algebras
(and ﬁnal coalgebras) - where these (co)algebras are used for ﬁxed points. These
categorical notions come with universal properties that guide the design (syntax)
and rules of programming languages.
This use of category theory is well-established in functional programming lan-
guages. However, it is less established in probabilistic programming. The description
of some of the basic notions of probability theory in categorical terms goes back to
the early 1980s (see Giry, 1982) and has seen a steady stream of activities since -
see e.g. Jones and Plotkin (1989), Jung and Tix (1998), de Vink and Rutten (1999),
Bartels et al. (2004), Tix et al. (2005), Varacca and Winskel (2006), Keimel (2008),
Keimel and Plotkin (2009), Panangaden (2009), Sokolova (2011), Mislove (2012),
Fong (2012), Culbertson and Sturtz (2014), Ścibior et al. (2015), Staton et al. (2016),
Ścibior et al. (2018). This categorical perspective is not a goal in itself, but it does
oﬀer a structural, implementation-independent way of thinking which is natural for
systematic programmers.
This chapter oﬀers an introduction to this principled perspective on probability
theory, especially for Bayesian probabilistic programming, based on earlier work of
the authors' in this direction, see e.g. Jacobs (2011, 2013, 2018b), Jacobs and Zanasi
(2016, 2017,?). Even though it is categorically-driven, our exposition does not
require any categorical prerequisite. The reader interested in an explicitly categorical
description of the framework may consult Jacobs and Zanasi (2016) or Cho and
Jacobs (2019).
The fundamental concept will be called channel: all the basics of Bayesian
probability theory (event, belief revision, Bayesian network, disintegration, . . . ) will
be derived from this single primitive. In analogy with approaches in programming
language semantics, channels are formally deﬁnable as arrows of a certain Kleisli
category: depending on the category of choice, the derived notions instantiate to
discrete or to continuous probability theory - and even to quantum probability
too, although the quantum world is out of scope here (but see Jacobs and Zanasi,
2016 and Jacobs, 2018b). This setting does not only provide a completely uniform
mathematical description for a variety of phenomena, but also introduces in Bayesian
reasoning fundamental principles of programming theory, such as compositionality:
channels are composable in a variety of ways, resulting in a structured and modular
theory. Furthermore, we argue that the channel-based perspective improves traditional
approaches. We will study scenarios in which the established language for describing
probabilistic phenomena lacks in ﬂexibility, expressiveness and rigour, while the
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

9.2 Perspectives
297
new foundations disclose the underlying logical structure of phenomena, leading to
new insights.
• Section 9.2 gives an informal overview of the channel-based view on probability
theory in terms of a number of perspectives. These perspectives are stated
explicitly, in imperative form, imposing how things are - or should be - seen
from a channel-based perspective, in contrast to traditional approaches. These
perspectives will already informally use the notions of 'state', 'predicate' and
'channel'.
• Section 9.3 commences the formal presentation of the ingredients of the channel-
based framework, illustrating the concepts of state and predicate, as special forms
of channels.
• Section 9.4 is devoted to conditioning, a key concept of Bayesian probability.
• Sections 9.5 and 9.6 are devoted to channel-based Bayesian inference. First,
Section 9.5 explains the use of channels as predicate and state transformers. Then,
Section 9.6 illustrates this setup to model inference in a Bayesian network, for
the standard 'student' example from Koller and Friedman (2009). This section
concludes with a clash of interpretations in an example taken from Barber (2012).
• Section 9.7 introduces a graphical calculus for channels - formally justiﬁed by
their deﬁnition as arrows of a monoidal category. The calculus encompasses and
enhances the diagrammatic language of Bayesian networks. It oﬀers an intuitive,
yet mathematically rigorous, description of basic phenomena of probability,
including conditional independency.
• Section 9.8 uses the tools developed in the previous sections to study the
relationship between joint distributions and their representation as Bayesian
networks. First, we use the graphical calculus to give a channel-based account
of disintegration. Second, we prove the equivalence of inference as performed
on joint distributions and as performed in Bayesian networks (Theorem 9.16).
The channel perspective explains the diﬀerent dynamics at work in the two forms
of inference, justifying our terminology of crossover inference and transformer
inference respectively.
9.2 Perspectives
This section gives a ﬁrst, informal view of the channel-based approach, through
a series of perspectives. Each of them contains a prescription on how Bayesian
phenomena appear in the channel-based perspective, and motivates how the channel
language improves more traditional descriptions. These perspectives will informally
use the notions of 'state', 'predicate' and 'channel'. To begin, we brieﬂy explain
what they are. A more systematic description is given later on.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

298
Jacobs and Zanasi: Logical Essentials of Bayesian Reasoning
• What is usually called a discrete probability distribution, we call a state. This
terminology emphasises the role that distributions play in our programming-
oriented framework: they express knowledge of a certain conﬁguration (a state of
aﬀairs) that may be transformed by program execution (channels).
A state/distribution is represented by a convex combination of elements from a
set. For instance, on a set A = {a, b, c} one can have a state 1
3|a⟩+ 1
2|b⟩+ 1
6|c⟩.
The 'ket' notation | · ⟩is syntactic sugar: it has no mathematical meaning, but
echoes how states are represented in quantum theory, where our theory may be
also instantiated, see Jacobs and Zanasi (2016).
• A 'predicate' on a set A is a function p: A →0, 1. It assigns a probability
pa ∈0, 1 to each element a ∈A. Such predicates are often called 'fuzzy'. When
pa ∈{0, 1}, so that either pa = 0 or pa = 1, for each a ∈A the predicate is
called sharp. A sharp predicate is traditionally called an event, and corresponds
to a subset of A. For such a subset E ⊆A we write 1E : A →0, 1 for the
corresponding characteristic function (or sharp predicate), given by 1Ea = 1 if
a ∈E and 1Ea = 0 if a  E. For the special case of a singleton set/event we
write 1a instead of 1{a}.
Similarly to the case of states, our terminology draws an analogy with program-
ming language semantics. There is a duality between states and predicates, which
goes beyond the scope of this introduction - so the interested reader is referred
to Jacobs (2017).
• A 'channel' A →B from a set A to another set B is an A-indexed collection
ωa

a∈A of states ωa on the set B. Alternatively, it is a function a →ωa that
sends each element a ∈A to a distribution on B. For A and B ﬁnite, yet another
equivalent description is as a stochastic matrix with |A| columns and |B| rows.
Channels are the pivot of our theory: states, predicates, and - as we shall see in
Section 9.6 - also Bayesian networks can be seen as particular cases of a channel.
More speciﬁcally, a state ω on B can be seen as a channel f : {⋆} →B with
source the one-element set {⋆}, deﬁned by f⋆= ω. A predicate p: A →0, 1 can
be seen as a channel A →{0, 1} that assigns to a ∈A the state pa|1⟩+1−pa|0⟩.
9.2.1 The state is made explicit
Our ﬁrst perspective elaborates on the observation that, in traditional probability, it
is custom to leave the probability distribution implicit, for instance in describing
the probability PrE of an event E = {a, c} ⊆A. This is justiﬁed because this
distribution, say ω = 1
3|a⟩+ 1
2|b⟩+ 1
6|c⟩, is typically ﬁxed, so that carrying it
around explicitly, as in PrωE, burdens the notation. In contrast, in probabilistic
programming, programs act on distributions (states) and change them with every
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

9.2 Perspectives
299
step. Hence in our framework it makes sense to use a richer notation, where
states/distributions have a more prominent role.
First, pursuing a more abstract, logical viewpoint, we introduce notation |= in
place of Pr. For an arbitrary state ω on a set A and a predicate p: A →0, 1 on the
same set A, the validity ω |= p of p in ω is the number in 0, 1 given by:
ω |= p 
a∈A ωa · pa.
(9.1)
When we identify an event (sharp predicate) E ⊆A with its characteristic function
1E : A →0, 1, we have ω |= 1E = PrωE = 1
2. The enhanced notation allows to
distinguish this from the probability of E wrt. an alternative state ψ = 1
4|b⟩+ 3
4|c⟩,
written ψ |= 1E = 3
4.
Once we start treating states as explicit entities, we can give proper attention to
basic operations on states, like parallel composition ⊗, marginalisation, and convex
combination. These operations will be elaborated below in Section 9.3.
9.2.2 Conditional probability is state update with a predicate
Traditionally, conditional probability is described as PrB | A, capturing the
probability of event B given event A. This notation is unfortunate, certainly in
combination with the notation PrB for the probability of event B. It suggests that
conditioning | is an operation on events, and that the probability Pr· of the resulting
event B | A is computed. This perspective is sometimes called 'measure-free
conditioning', see Dubois and Prade (1990). The fact that states are left implicit, see
the previous point 9.2.1, further contributes to the confusion.
In the view advocated here, conditioning is an operation that updates a state ω
in the light of evidence in the form of a predicate p. This is well-deﬁned when ω
and p have the same underlying set A, and when the validity ω |= p is non-zero. We
shall then write ω|p for the state "ω given p", see Section 9.4 for more details. We
emphasise that the validity PrB | A in state ω can now be expressed as ω|1A |= 1B.
It is the validity of B in the state where the evidence A is incorporated.
9.2.3 State/predicate transformation are basic operations
The following notation PrX = a often occurs in traditional probability theory. What
does it mean, and what is assumed? On close reading we ﬁnd that the following data
are involved.
• A set, often called sample space, Ω with a state/distribution ω on it; please note
that ω is not an element of Ω but a probability distribution over elements of Ω;
• A stochastic (or random) variable, X : Ω →A, for some set A of outcomes;
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

300
Jacobs and Zanasi: Logical Essentials of Bayesian Reasoning
• An element a ∈A with associated event X−1a = {z ∈Ω | Xz = a} ⊆Ω;
• The probability PrX = a is then the validity of the latter event in the state ω, that
is, it is ω |= 1X−1a.
A stochast is a special kind of channel (namely a deterministic one). The operation
X−1a will be described more systematically as 'predicate transformation' X ≪1a
along the channel X. It turns the (singleton, sharp) predicate 1a on A into a predicate
on Ω. In fact, X ≪1a can be seen as just function composition Ω →A →0, 1.
Since X ≪1a is now a predicate on Ω, the probability PrX = a can be described
more explicitly as validity: ω |= X ≪1a. More generally, for an event E on A we
would then determine the probability PrX ∈E as ω |= X ≪E.
One can use the channel X also for 'state transformation'. In this way one
transforms the state ω on Ω into a state X ≫ω on A. This operation ≫is
sometimes (aptly) called pushforward, and X ≫ω is the pushforward distribution.
The probability PrX = a can equivalently be described as validity X ≫ω |= 1a.
In Section 9.5 we elaborate on channels. One of our ﬁndings will be that the
probabilities ω |= c ≪p and c ≫ω |= p are always the same - for a channel c from
A to B, a state ω on A, and a predicate p on B.
Moreover, we can proﬁtably combine predicate transformation ≪and state
transformation ≫with conditioning of states from point 9.2.2. As will be elaborated
later on, we can distinguish the following two basic combinations of conditioning
and transformation, with the associated terminology.
notation
action
terminology
ω|c≪q
ﬁrst do predicate
transformation ≪,
then update the state
evidential reasoning, or
explanation, or
backward inference
c ≫
ω|p

ﬁrst update the state,
then do state
transformation ≫,
causal reasoning, or
prediction, or
forward inference
9.2.4 Channels are used as probabilistic functions
We have already mentioned the notation c: A →B to describe a channel c from A
to B. Recall that such a channel produces a state ca on B for each element a ∈A.
It turns out that there is a special way to compose channels: for c: A →B and
d: B →C we can form a composite channel d
c: A →C, understood as "d after
c". We can deﬁne it via state transformation as d
ca = d ≫ca. It is not hard to
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

9.2 Perspectives
301
check that
is associative, and that there are identity maps id : A →A, given by
ida = 1|a⟩. They form unit elements for channel composition .
Abstractly, channels form morphisms in a 'category'. The concept of a category
generalises the idea of sets and functions between them, to objects and morphisms
between them. These morphisms in a category need not be actual functions, but
they must be composable (and have units). Such morphisms can be used to capture
diﬀerent forms of computation, like non-deterministic, or probabilistic (via channels).
Here we shall not use categorical machinery, but use the relevant properties in more
concrete form. For instance, composition
of channels interacts appropriately with
state transformation and with predicate transformation, as in:
d
c ≫ω = d ≫c ≫ω
and
d
c ≪p = c ≪d ≪p.
In addition to sequential composition
we shall also use parallel composition ⊗of
channels, with an associated calculus for combinining
and ⊗.
9.2.5 Predicates are generally fuzzy
In the points above we have used fuzzy predicates, with outcomes in the unit interval
0, 1, instead of the more usual sharp predicates, with outcomes in the two-element
set {0, 1} of Booleans. Why?
• The main technical reason is that fuzzy predicates are closed under probabilistic
predicate transformation ≪, whereas sharp predicates are not. Thus, if we wish
to do evidential (backward) reasoning ω|c≪q, as described in point 9.2.3, we are
forced to use fuzzy predicates.
• Fuzzy predicates are also closed under another operation, namely scaling: for each
p: A →0, 1 and s ∈0, 1 we have a new, scaled predicate s · p: A →0, 1, given
by s · pa = s · pa. This scaling is less important than predicate transformation,
but still it is a useful operation.
• Fuzzy predicates naturally ﬁt in a probabilistic setting, where uncertainty is a
leading concept. It thus makes sense to use this uncertainty also for evidence.
• Fuzzy predicates are simply more general than sharp predicates. Sharp predicates p
can be recognised logically among all fuzzy predicates via the property p & p = p,
where conjunction & is pointwise multiplication.
The traditional approach in probability theory focuses on sharp predicates, in the
form of events. This is part of the notation, for instance in expressions like PrX ∈E,
as used earlier in point 9.2.2. It does not make much sense to replace this sharp
E with a fuzzy p when writing PrX ∈E. That is one more reason why we write
validity via |= and not via Pr. Fuzzy predicates have actually surfaced in more recent
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

302
Jacobs and Zanasi: Logical Essentials of Bayesian Reasoning
research in Bayesian probability, see e.g. the concepts of 'soft' evidence in Valtorta
et al. (2002) and 'uncertain' evidence in Mrad et al. (2015), see also Barber (2012).
Fuzzy predicates have a diﬀerent algebraic structure than sharp predicates. The
latter form Boolean algebras. Fuzzy predicates however form eﬀect modules (see
e.g. Jacobs, 2013). However, these algebraic/logical structures will not play a role in
the current setting.
We shall later sketch how a fuzzy predicate can be replaced by an additional node
in a Bayesian network, see Remark 9.4.
9.2.6 Marginalisation and weakening are operations
Marginalisation is the operation of turning a joint distribution ω on a product
domain X × Y into a distribution on one of the components, say on X. Traditionally
marginalisation is indicated by omitting one of the variables: if ωx, y is written for
the joint distribution on X × Y , then ωx is its (ﬁrst) marginal, as a distribution on
X. It is deﬁned as ωx = y ωx, y.
We prefer to write marginalisation as an explicit operation, so that M1ω is the
ﬁrst marginal (on X), and M2ω is the second marginal (on Y ). More generally,
marginalisation can be performed on a state σ on a domain X1 × · · · × Xn in 2n
many ways.
A seemingly diﬀerent but closely related operation is weakening of predicates. If
p ∈0, 1X is a predicate on a domain X, we may want to use it on a larger domain
X × Y where we ignore the Y -part. In logic this called weakening; it involves
moving a predicate to a larger context. One could also indicate this via variables,
writing px for the predicate on X, and px, y for its extension to X × Y , where y
in px, y is a spurious variable. Instead we write
M
1p ∈0, 1X×Y for this weakened
predicate. It maps x, y to px.
Marginalisation M and weakening
M
are each other's 'cousins'. As we shall see,
they can both be expressed via projection maps π1 : X × Y →X, namely as state
transformation M1ω = π1 ≫ω and as predicate transformation
M
1p = π1 ≪p. As
a result, the symbols M and
M
can be moved accross validity |=, as in (9.6) below.
In what we call crossover inference later on, the combination of marginalisation and
weakening plays a crucial role.
9.2.7 States and predicates are clearly distinguished
As just argued, marginalisation is an operation on states, whereas weakening acts on
predicates (evidence). In general, certain operations only make sense on states (like
convex sum) and others on predicates. This reﬂects the fact that states and predicates
form very diﬀerent algebraic structures: states on a given domain form a convex set
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

9.3 States and predicates
303
(see e.g. Jacobs, 2013), whereas, as already mentioned in Section 9.2.5, predicates
on a given domain form an eﬀect module.
Despite the important conceptual diﬀerences, states and predicates are easily
confused, also in the literature (see e.g. Example 9.14 below). The general rule of
thumb is that states involve ﬁnitely many probabilities that add up to one - unlike
for predicates. We elaborate formally on this distinction in Remark 9.3 below.
On a more conceptual level, one could spell out the diﬀerence by saying that
states have an ontological ﬂavour, whereas predicates play an epistemological role.
That means, states describe factual reality, although in probabilistic form, via convex
combinations of combined facts. In contrast, predicates capture just the likelihoods
of individual facts as perceived by an agent. Thus probabilities in predicates do not
need to add up to one, because our perception of reality (contrary to reality itself) is
possibly inconsistent or incomplete.1 We shall elaborate more on this perspective at
the end of Example 9.14 below.
9.3 States and predicates
Section 9.2.1 claimed that states (ﬁnite probability distributions) and fuzzy predicates
- and their diﬀerent roles - should be given more prominence in probability theory.
We now elaborate this point in greater detail. We thus retell the same story as in the
beginning, but this time with more mathematical details, and with more examples.
States
A state (probability distribution) over a 'sample' set A is a formal weighted
combination r1|a1⟩+ · · · + rn|an⟩, where the ai are elements of A and the ri are
elements of 0, 1 with i ri = 1. We shall write DA for the set of states/distributions
on a set A. We will sometimes treat ω ∈DA equivalently as a 'probability mass'
function ω: A →0, 1 with ﬁnite support suppω = {a ∈A | ωa  0} and with
a∈A ωa = 1. More explicitly, the formal convex combination i ri|ai⟩corresponds
to the function ω: A →0, 1 with ωai = ri and ωa = 0 if a  {a1, . . . , an}. Then
suppω = {a1, . . . , an}, by construction.
For two states σ1 ∈DA1 and σ2 ∈DA2, we can form the joint 'product' state
σ1 ⊗σ2 ∈DA1 × A2 on the cartesian product A1 × A2 of the underlying sets,
namely as:
σ1 ⊗σ2a1, a2  σ1a1 · σ2a2.
(9.2)
1 Within this perspective, it is intriguing to read conditioning of a state by a predicate as adapting the facts
according to the agent's beliefs. In Philosophy one would say that our notion of conditioning forces an "idealistic"
view of reality; in more mundane terms, it yields the possibility of "alternative facts".
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

304
Jacobs and Zanasi: Logical Essentials of Bayesian Reasoning
For instance, if σ1 = 1
3|a⟩+ 2
3|b⟩and σ2 = 1
8|1⟩+ 5
8|2⟩+ 1
4|3⟩, then their product
is written with ket-notation as:
σ1 ⊗σ2 =
1
24|a, 1⟩+ 5
24|a, 2⟩+ 1
12|a, 3⟩+ 1
12|b, 1⟩+ 5
12|b, 2⟩+ 1
6|b, 3⟩.
Marginalisation works in the opposite direction: it moves a 'joint' state on a product
set to one of the components: for a state ω ∈DA1 × A2 we have ﬁrst and second
marginalisation Miω ∈DAi determined as:
M1ωa1 =
a2∈A2 ωa1, a2
M2ωa2 =
aa∈A1 ωa1, a2.
(9.3)
Here we use explicit operations M1 and M2 for taking the ﬁrst and second marginal.
The traditional way to write a marginal is to drop a variable: a joint distribution
is written as Prx, y, and its marginals as Prx and Pry, where Prx = y Prx, y and
Pry = x Prx, y.
The two original states σ1 and σ2 in a product state σ1 ⊗σ2 can be recovered as
marginals of this product state: M1σ1 ⊗σ2 = σ1 and M2σ1 ⊗σ2 = σ2.
In general a joint state ω ∈DA1 × A2 does not equal the product M1ω ⊗M2ω
of its marginals, making the whole more than the sum of its parts. When we do have
ω = M1ω ⊗M2ω, we call ω non-entwined. Otherwise it is called entwined.
Example 9.1
Given sets X = {x, y} and A = {a, b}, one can prove that a state
ω = r1|x, a⟩+r2|x, b⟩+r3|y, a⟩+r4|y, b⟩∈DX ×A, where r1 +r2 +r3 +r4 = 1,
is non-entwined if and only if r1 · r4 = r2 · r3. This fact also holds in the quantum
case, see e.g. Mermin (2007, §1.5).
For instance, the following joint state is entwined:
ω = 1
8|x, a⟩+ 1
4|x, b⟩+ 3
8|y, a⟩+ 1
4|y, b⟩.
Indeed, ω has marginals M1ω ∈DX and M2ω ∈DA, namely:
M1ω = 3
8|x⟩+ 5
8|y⟩
and
M2ω = 1
2|a⟩+ 1
2|b⟩.
The original state ω diﬀers from the product of its marginals:
M1ω ⊗M2ω =
3
16|x, a⟩+ 3
16|x, b⟩+ 5
16|y, a⟩+ 5
16|y, b⟩.
There is one more operation on states that occurs frequently, namely convex sum:
if we have n states ωi ∈DA on the same sets and n probabilities ri ∈0, 1 with
ri = 1, then riωi is a state again.
Predicates
A predicate on a sample space (set) A is a function p: A →0, 1, taking values
in the unit interval 0, 1. We shall use the exponent notation 0, 1A for the set of
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

9.3 States and predicates
305
predicates on A. What in probability theory are usually called events (subsets of
A) can be identiﬁed with sharp predicates, taking values in the subset of booleans
{0, 1} ⊆0, 1. We write 1E ∈0, 1A for the sharp predicate associated with the event
E ⊆A, deﬁned by 1Ea = 1 if a ∈E and 1Ea = 0 if a  E, where we recall that
we simply write 1a for 1{a}. Thus predicates are a more general, 'fuzzy' notion
of event, which we prefer to work with for the reasons explained in Section 9.2.5.
We write 1 = 1A, 0 = 1∅for the truth and falsity predicates. They are the top and
bottom elements in the set of predicates 0, 1A, with pointwise order. As special case,
for an element a ∈A we write 1a for the 'singleton' or 'point' predicate on A that
is 1 only on input a ∈A.
For predicates p, q ∈0, 1A and scalar r ∈0, 1 we deﬁne p & q ∈0, 1A as
a →pa · qa and r · p ∈0, 1A as a →r · pa. Moreover, there is an orthosupplement
predicate p⊥∈0, 1A given by p⊥a = 1 −pa. Then p⊥⊥= p. Notice that 1E &
1D = 1E∩D and 1E⊥= 1¬E, where ¬E ⊆A is the set-theoretic complement of E.
Deﬁnition 9.2
Let ω ∈DA be a state and p ∈0, 1A be a predicate, both on the
same set A. We write ω |= p for the validity or expected value of p in state ω. This
validity is a number in the unit interval 0, 1. We recall its deﬁnition from (9.1):
ω |= p 
a∈A ωa · pa.
(9.4)
For an event (sharp predicate) E, the probability PrE wrt. a state ω is deﬁned
as a∈E ωa. Using the above validity notation (9.4) we write ω |= 1E instead. As
special case we have ω |= 1x = ωx.
Notice that the validity ω |= 1 of the truth predicate 1 is 1 in any state ω. Similarly,
ω |= 0 = 0. Additionally, ω |= p⊥= 1 −ω |= p and ω |= r · p = r · ω |= p.
There is also a parallel product ⊗of predicates, like for states. Given two predicates
p1 ∈0, 1A1 and p2 ∈0, 1A2 on sets A1, A2 we form the product predicate p1 ⊗p2
on A1 × A2 via: p1 ⊗p2a1, a2 = p1a1 · p2a2. It is not hard to see that:
ω1 ⊗ω2 |= p1 ⊗p2 =
ω1 |= p1
 ·
ω2 |= p2
.
A product p ⊗1 or 1 ⊗p with the truth predicate 1 corresponds to weakening, that
is to moving a predicate p to a bigger set (or context). We also write:
M
1p  p ⊗1
and
M
2p  1 ⊗p
(9.5)
for these ﬁrst and second weakening operations, like in Section 9.2.6. We deliberately
use 'dual' notation for marginalisation M and weakening
M
because these operations
are closely related, as expressed by the following equations.
M1ω |= p = ω |=
M
1p
and
M2ω |= q = ω |=
M
2q.
(9.6)
As a result, σ1 ⊗σ2 |=
M
1p = σ1 |= p and similarly σ1 ⊗σ2 |=
M
2q = σ2 |= q.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

306
Jacobs and Zanasi: Logical Essentials of Bayesian Reasoning
Remark 9.3
As already mentioned in Section 9.2.7, conceptually, it is important
to keep states and predicates apart. They play diﬀerent roles, but mathematically it
is easy to confuse them. States describe a state of aﬀairs, whereas predicates capture
evidence. We explicitly emphasise the diﬀerences between a state ω ∈DA and a
predicate p: A →0, 1 in several points.
(i) A state has ﬁnite support. Considered as function ω: A →0, 1, there are only
ﬁnitely many elements a ∈A with ωa  0. In contrast, there may be inﬁnitely
many elements a ∈A with pa  0. This diﬀerence only makes sense when the
underlying set A has inﬁnitely many elements.
(ii) The ﬁnite sum a∈A ωa equals 1, since states involve a convex sum. In contrast
there are no requirements about the sum of the probabilities pa ∈0, 1 for a
predicate p. In fact, such a sum may not exist when A is an inﬁnite set. We thus see
that each state ω on A forms a predicate, when considered as a function A →0, 1.
But a predicate in general does not form a state.
(iii) States and predicates are closed under completely diﬀerent operations. As we
have seen, for states we have parallel products ⊗, marginalisation Mi, and convex
sum. In contrast, predicates are closed under orthosupplement −⊥, conjunction
&, scalar multiplication s · −and parallel product ⊗(with weakening as special
case). The algebraic structures of states and of predicates is completely diﬀerent:
each set of states DA forms a convex set whereas each set of predicates 0, 1A is
an eﬀect module, see e.g. Jacobs (2018b) for more details.
(iv) State transformation (along a channel) happens in a forward direction, whereas
predicate transformation (along a channel) works in a backward direction. These
directions are described with respect the direction of the channel. This will be
elaborated in Section 9.5.
Remark 9.4
One possible reason why fuzzy predicates are not so common in
(Bayesian) probability theory is that they can be mimicked via an extra node in
a Bayesian network, together with a sharp predicate. We sketch how this works.
Assume we have a set X = {a, b, c} and we wish to consider a fuzzy predicate
p: X →0, 1 on X, say with pa = 2
3, pb = 1
2 and pc = 1
4. Then we can introduce an
extra node 2 = {t, f} with a channel h: X →2 given by:
ha = 2
3|t⟩+ 1
3|f ⟩
hb = 1
2|t⟩+ 1
2|f ⟩
hc = 1
4|t⟩+ 3
4|f ⟩.
The original predicate p on X = {a, b, c} can now be reconstructed via predicate
transformation along h as h ≪1t, where, recall, 1t is the sharp predicate on 2
which is 1 at t and 0 at f.
As an aside: we have spelled out the general isomorphism between predicates
on a set A and channels A →2. Conceptually this is pleasant, but in practice we
do not wish to extend our Bayesian network every time a fuzzy predicate pops up.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

9.4 Conditioning
307
What this example also illustrates is that sharpness of predicates is not closed under
predicate transformation.
9.4 Conditioning
Conditioning is one of the most fundamental operations in probability theory. It
is the operation that updates a state in the light of certain evidence. This evidence
is thus incorporated in a new, updated state, that reﬂects the new insight. For this
reason conditioning is sometime called belief update or belief revision. It forms the
basis of learning, training and inference, see also Section 9.6.
A conditional probability is usually written as PrE | D. It describes the probability
of event E, given event D. In the current context we follow a more general path,
using fuzzy predicates instead of events. Also, we explicitly carry the state around.
From this perspective, the update of a state ω with a predicate p, leading to an
updated state ω|p, is the fundamental operation. It allows us to retrieve probabilities
PrE | D as special case, as will be shown at the end of this section.
Deﬁnition 9.5
Let ω ∈DA be a state and p ∈0, 1A be a predicate, both on the
same set A. If the validity ω |= p is non-zero, we write ω|p for the conditional state
"ω given p", deﬁned as formal convex sum:
ω|p :=
a∈A
ωa · pa
ω |= p |a⟩.
(9.7)
Example 9.6
Let's take the numbers of a dice as sample space: pips = {1, 2, 3, 4, 5, 6},
with a fair/uniform dice distribution dice ∈Dpips.
dice = 1
6|1⟩+ 1
6|2⟩+ 1
6|3⟩+ 1
6|4⟩+ 1
6|5⟩+ 1
6|6⟩.
We consider the predicate evenish ∈0, 1pips expressing that we are fairly certain of
pips being even:
evenish1 = 1
5
evenish3 =
1
10
evenish5 =
1
10
evenish2 =
9
10
evenish4 =
9
10
evenish6 = 4
5
We ﬁrst compute the validity of evenish for our fair dice:
dice |= evenish = x dicex · evenishx
= 1
6 · 1
5 + 1
6 · 9
10 + 1
6 · 1
10 + 1
6 · 9
10 + 1
6 · 1
10 + 1
6 · 4
5
= 2+9+1+9+1+8
60
=
1
2.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

308
Jacobs and Zanasi: Logical Essentials of Bayesian Reasoning
If we take evenish as evidence, we can update our state and get:
dice|evenish
= x
dicex · evenishx
dice |= evenish |x⟩
=
16·15
12 |1⟩+
16·910
12 |2⟩+
16·110
12 |3⟩+
16·910
12 |4⟩+
16·110
12 |5⟩+
16·45
12 |6⟩
=
1
15|1⟩+ 3
10|2⟩+ 1
30|3⟩+ 3
10|4⟩+ 1
30|5⟩+ 4
15|6⟩.
As expected, the probability of the even pips is now higher than the odd ones. The
evidence has been factored into the state.
We collect some basic properties of conditioning.
Lemma 9.7
Let ω ∈DA and p, q ∈0, 1A be a state with predicates on the same
set A.
(i) Conditioning with truth does nothing: ω|1 = ω.
(ii) Conditioning with a conjunction amounts to separate conditionings, that is:
ω|p&q =
ω|p
|q.
(iii) Conditioning with scalar product has no eﬀect, when the scalar is non-zero:
ω|r·p = ω|p when r  0.
(iv) Conditioning with a point predicate yields a point state: ω|1x = 1|x⟩, when
ωx  0.
Now let σi ∈DAi and pi ∈0, 1Ai.
(v) σ1 ⊗σ2|p1⊗p2 = σ1|p1 ⊗σ2|p2.
(vi) M1
σ ⊗τ|
M
1p1
 = σ|p1 and M2
σ ⊗τ|
M
2p2
 = τ|p2.
Proof All these properties follow via straightforward computation. We shall do (ii)
and (v).
For (ii) we use:
ω|p|q
a = ω|pa · qa
ω|p |= q
=
ωa·pa
ω|=p · qa
b ω|pb · qb
=
ωa·pa
ω|=p · qa
b
ωb·pb
ω|=p · qb
= ωa · pa · qa
b ωb · pb · qb
= ωa · p & qa
ω |= p & q
=
ω|p&q
a.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

9.4 Conditioning
309
Similarly, for (v) we use:
σ1 ⊗σ2|p1⊗p2a1, a2 = σ1 ⊗σ2a1, a2 · p1 ⊗p2a1, a2
σ1 ⊗σ2 |= p1 ⊗p2
= σ1a1 · σ2a2 · p1a1 · p2a
σ1 |= p1 · σ2 |= p2
= σ1a1 · p1a1
σ1 |= p1
· σ2a2 · p2a
σ2 |= p2
= σ1|p1 ⊗σ2|p2.
□
The following result gives the generalisation of Bayes' rule to the current setting
with states and predicates.
Theorem 9.8
Let ω ∈DA and p, q ∈0, 1A be a state and two predicates on the
set A.
(i) The product rule holds:
ω|p |= q =
ω |= p & q
ω |= p
(9.8)
(ii) Bayes' rule holds:
ω|p |= q =
ω|q |= p · ω |= q
ω |= p
(9.9)
Proof Point (ii) follows directly from (i) by using that p & q = q & p, so we
concentrate on (i).
ω|p |= q = a ω|pa · qa = a
ωa · pa
ω |= p · qa
= a ωa · p & qa
ω |= p
= ω |= p & q
ω |= p
.
□
We now relate our state-and-predicate based approach to conditioning to the
traditional one. Recall that for events E, D ⊆A one has, by deﬁnition:
PrE | D = PrE ∩D
PrD
.
If these probabilities Pr· are computed wrt. a distribution ω ∈DA, we can continue
as follows.
PrE | D = PrE ∩D
PrD
= ω |= 1E∩D
ω |= 1D
= ω |= 1E & 1D
ω |= 1D
(9.8)
=
ω|1D |= 1E.
Thus the probability PrE | D can be expressed in our framework as the validity
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

310
Jacobs and Zanasi: Logical Essentials of Bayesian Reasoning
of the sharp predicate E in the state updated with the sharp predicate D. This is
precisely the intended meaning.
9.5 Bayesian inference via state/predicate transformation
As mentioned in Section 9.2.4, a channel c: A →B between two sets A, B is a
probabilistic function from A to B. It maps an an element a ∈A to a state ca ∈DB
of B. Hence it is an actual function of the form A →DB. Such functions are often
described as conditional probabilities a →Prb | a, or as stochastic matrices. We
repeat that channels are fundamental - more so than states and predicates - since
a state ω ∈DA can be identiﬁed with a channel ω: 1 →A for the singleton set
1 = {0}. Similarly, a predicate p ∈0, 1A can be identiﬁed with a channel p: A →2,
where 2 = {0, 1}; this uses that D2  0, 1.
Channels are used for probabilistic state transformation ≫and predicate transfor-
mation ≪, in the following manner.
Deﬁnition 9.9
Let c: A →B be a channel, with a state ω ∈DA on its domain A
and a predicate q ∈0, 1B on its codomain B.
(i) State transformation yields a state c ≫ω on B deﬁned by:
c ≫ω
b 
a∈A ωa · cab.
(9.10)
(ii) Predicate transformation gives a predicate c ≪q on A deﬁned by:
c ≪q
a 
b∈B cab · qb.
(9.11)
The next example illustrates how state and predicate transformation can be used
systematically to reason about probabilistic questions.
Example 9.10
In a medical context we distinguish patients with low (L), medium
(M), and high (H) blood pressure. We thus use as 'blood' sample space B =
{L, M, H}, say with initial ('prior' or 'base rate') distribution β ∈DB:
β = 1
8|L⟩+ 1
2|M ⟩+ 3
8|H ⟩.
We consider a particular disease, whose a priori occurrence in the population depends
on the blood pressure, as given by the following table.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

9.5 Bayesian inference via state/predicate transformation
311
blood pressure
disease likelihood
Low
5%
Medium
10%
High
15%
We choose as sample space for the disease D = {d, d⊥} where the element d
represents presence of the disease and d⊥represents absence. The above table is
now naturally described as a 'sickness' channel s: B →D, given by:
sL = 0.05|d⟩+ 0.95|d⊥⟩
sM = 0.1|d⟩+ 0.9|d⊥⟩
sH = 0.15|d⟩+ 0.85|d⊥⟩.
We ask ourselves two basic questions.
(i) What is the a priori probability of the disease? The answer to this question
is obtained by state transformation, namely by transforming the blood pressure
distribution β on B to a disease distribution s ≫β on D along the sickness
channel s. Concretely:
s ≫βd
(9.10)
=
x∈B βx · sxd
=
βL · sLd + βM · sMd + βH · sHd
=
1
8 · 1
20 + 1
2 · 1
10 + 3
8 · 3
20
=
9
80
s ≫βd⊥(9.10)
=
x∈B βx · sxd⊥
=
βL · sLd⊥+ βM · sMd⊥+ βH · sHd⊥
=
1
8 · 19
20 + 1
2 · 9
10 + 3
8 · 17
20
=
71
80.
Thus we obtain as a priori disease distribution c ≫β =
9
80|d⟩+ 71
80|d⊥⟩=
0.1125|d⟩+ 0.8875|d⊥⟩. A bit more than 11% of the population has the disease
at hand.
(ii) What is the likely blood pressure for people without the disease? Before
we calculate the updated ('a posteriori') blood pressure distribution, we reason
intuitively. Since non-occurrence of the disease is most likely for people with
low blood pressure, we expect that the updated blood pressure - after taking the
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

312
Jacobs and Zanasi: Logical Essentials of Bayesian Reasoning
evidence 'absence of disease' into account - will have a higher probability of low
blood pressure than the orignal (a priori) value of 1
8 in β.
The evidence that we have is the point predicate 1d⊥on D, representing absence
of the disease. In order to update β ∈DB we ﬁrst apply predicate transformation
s ≪1d⊥to obtain a predicate on B. This transformed predicate in 0, 1B is
computed as follows.
s ≪1d⊥L
(9.11)
=
y∈D sLy · 1d⊥y = sLd⊥= 0.95
s ≪1d⊥M
(9.11)
=
y∈D sMy · 1d⊥y = sMd⊥= 0.9
s ≪1d⊥H
(9.11)
=
y∈D sHy · 1d⊥y = sHd⊥= 0.85.
Notice that although 1d⊥is a sharp predicate, the transformed predicate s ≪1d⊥
is not sharp. This shows that sharp predicates are not closed under predicate
transformation - as mentioned earlier in Section 9.2.5.
We can now update the original blood pressure distribution β with the trans-
formed evicence s ≪1d⊥. We ﬁrst compute validity, and then perform condition-
ing:
β |= s ≪1d⊥
(9.4)
=
x∈B βx · s ≪1d⊥x
=
βL · s ≪1d⊥L
+ βM · s ≪1d⊥M
+ βH · s ≪1d⊥H
=
1
8 · 19
20 + 1
2 · 9
10 + 3
8 · 17
20
=
71
80
β|s≪1d⊥
(9.7)
=
x∈B
βx · s ≪1d⊥x
β |= s ≪1d⊥|x⟩
=
18 · 1920
7180 |L⟩+
12 · 910
7180 |M ⟩+
38 · 1720
7180 |H ⟩
=
19
142|L⟩+ 36
71|M ⟩+ 51
142|H ⟩
∼0.134|L⟩+ 0.507|M ⟩+ 0.359|H ⟩.
As intuitively expected, a posteriori the probability of low blood pressure is higher
than in the a priori distribution β - and the probability of high blood pressure is
lower too.
These calculations with probabilities are relatively easy but may grow out of hand
quickly. Therefore a library has been developed, called EfProb see Cho and Jacobs
(2017), that provides the relevant functions, for validity, state update, state and
predicate transformation, etc.
It is natural to see a state β and a channel s, as used above, as stochastic matrices
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

9.5 Bayesian inference via state/predicate transformation
313
Mβ and Ms, of the form:
Mβ =
⎛
⎜
⎜
⎜
⎝
38
12
38
⎞
⎟
⎟
⎟
⎠
Ms =
⎛
⎝0.05 0.1 0.15
0.95 0.9 0.85
⎞
⎠
These matrices are called stochastic because the columns add up to 1. The matrix
of the state s ≫β is then obtained by matrix multiplication MsMβ. For predicate
transformation s ≪1d⊥with M1d⊥=

0 1

one uses matrix multiplication in a
diﬀerent order:
M1d⊥Ms =

0 1

⎛
⎝0.05 0.1 0.15
0.95 0.9 0.85
⎞
⎠=

0.95 0.9 0.85

.
The diligent reader may have noticed in this example that the probability s ≫
βd⊥= s ≫β |= 1d⊥=
71
80 in Example 9.10 coincides with the probability
β |= s ≪1d⊥= 71
80. This in fact in an instance of the following general result,
relating validity and transformations.
Proposition 9.11
Let c: A →B be a channel, ω ∈DA be a state on its domain,
and q ∈0, 1B a predicate on its codomain. Then:
c ≫ω |= q = ω |= c ≪q.
(9.12)
Proof The result follows from a simple calculation:
c ≫ω |= q
(9.4)
=
b∈Bc ≫ωb · qb
(9.10)
=
b∈B

a∈A ωa · cab

· qb
=
a∈A,b∈B ωa · cab · qb
=
a∈A ωa ·

b∈B cab · qb

(9.11)
=
a∈A ωa · c ≪qa
(9.4)
=
ω |= c ≪q.
□
There are two more operations on channels that we need to consider, namely
sequential composition
and parallel composition ⊗.
Deﬁnition 9.12
Consider channels f : A →B, g: C →D and h: X →Y . These
channels can be composed sequentially and in parallel, yielding new channels:
g
f : A →C
and
f ⊗h: A × X →B × Y,
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

314
Jacobs and Zanasi: Logical Essentials of Bayesian Reasoning
via the following deﬁnitions.
g
fa  g ≫fa
so that
g
fac =
b∈B fab · gbc.
The latter formula shows that channel composition is essentially matrix multiplica-
tion.
Next,
f ⊗ha, x  fa ⊗hx
so that
f ⊗ha, xb, y = fab · hxy.
The product ⊗on the right of  is the product of states, as described in (9.2).
In terms of matrices, parallel composition of channels is given by the Kronecker
product.
It is not hard to see that
and ⊗are well-behaved operations, satisfying for
instance:
g ⊗k

f ⊗h
 =
g
f
 ⊗
k
h
.
They interact nicely with state and predicate transformation:
g
f ≫ω = g ≫
f ≫ω
g
f ≪q = f ≪
g ≪q
f ⊗h ≫σ ⊗τ =
f ≫σ
 ⊗
h ≫τ

f ⊗h ≪p ⊗q =
f ≪p
 ⊗
g ≪q
.
Moreover, for the identity channel id given by idx = 1|x⟩we have:
id
f = f = f
id
id ⊗id = id.
We will see examples of parallel composition of channels in Section 9.7 when we
discuss (the semantics of) Bayesian networks.
Remark 9.13
An ordinary function f : A →B can be turned into a 'deterministic'
channel f: A →B via:
fa  1|fa⟩.
(9.13)
This operation · sends function composition to channel composition: g ◦f =
g f. The random variable X : Ω →A that we used in Section 9.2.3 is an example
of such a deterministic channel. Formally, we should now write X−1a = X ≪1a
for the event X−1a on Ω.
There are some further special cases of deterministic channels that we mention
explicitly.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

9.6 Inference in Bayesian networks
315
(i) For two sets A1, A2 we can form the cartesian product A1 × A2 with its two
projection functions π1 : A1 × A2 →A1 and π2 : A1 × A2 →A2. They can
be turned into (deterministic) channels πi: A1 × A2 →Ai. One can then
see that marginalisation and weakening are state transformation and predicate
transformation along these projection channels:
π1 ≫ω = M1ω
π1 ≪p =
M
1p = p ⊗1
π2 ≫ω = M2ω
π2 ≪q =
M
2q = 1 ⊗q
As a result, equation (9.6) is a special case of (9.12).
Moreover, these projection channels commute with parallel composition ⊗of
channels, in the sense that:
π1
f ⊗h
 = f
π1
π2
f ⊗h
 = h
π2
(ii) For each set A there is a diagonal (or 'copy') function Δ: A →A × A with
Δa = a, a. It can be turned into a channel too, as Δ: A →A × A. However,
this copy channel does not interact well with parallel composition of channels, in
the sense that in general:
Δ
f 
f ⊗f

Δ.
This equation does hold when the channel f is deterministic. Via diagonals we
can relate parallel products ⊗and conjunctions & of predicates:
Δ ≪
p ⊗q
 = p & q.
In what follows we often omit the braces · around projections and diagonals, and
simply write projection and copy channels as πi : A1×A2 →Ai and Δ: A →A×A.
9.6 Inference in Bayesian networks
In this section we illustrate how channels can be used both to model Bayesian
networks and to reason about them. We shall use a standard example from the
literature, namely the 'student' network from Koller and Friedman (2009). The
graph of the student network is described in original form in Figure 9.1. We see how
a student's grade depends on the diﬃculty of a test and the student's intelligence.
The SAT score only depends on intelligence; whether or not the student gets a strong
(l1) or weak (l0) recommendation letter depends on the grade.
With each of the ﬁve nodes in the network a sample space is associated, namely:
D = {d0, d1},
I = {i0, i1},
G = {g1, g2, g3},
S = {s0, s1},
L = {l0, l1}.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

316
Jacobs and Zanasi: Logical Essentials of Bayesian Reasoning
Figure 9.1 Picture of the student Bayesian network, copied from Koller and Friedman (2009),
with conditional probability tables.
For the two inital nodes Diﬃculty (D) and Intelligence (I) we obtain two distribu-
tions/states ωD and ωI, whose probabilities are given in the two upper tables in
Figure 9.1:
ωD = 0.6|d0⟩+ 0.4|d1⟩
ωI = 0.7|i0⟩+ 0.3|i1⟩.
They capture the a priori state of aﬀairs, with a 0.4 likelihood of a diﬃcult test (d1),
and a 0.3 likelihood of an intelligent student (i1).
The remaining three nodes Grade (G), Letter (L) and SAT (S) have incoming
arrows from parent nodes, and are thus not initial. They correspond to three channels:
cG : D × I →G,
cS : I →S,
cL : G →L.
The deﬁnitions of these channels can be read directly from the tables. The SAT
channel cS : I →S and the Letter channel cL : G →L are thus of the form:
cSi0 = 0.95|s0⟩+ 0.05|s1⟩
cSi1 = 0.2|s0⟩+ 0.8|s1⟩
cLg1 = 0.1|l0⟩+ 0.9|l1⟩
cLg2 = 0.4|l0⟩+ 0.6|l1⟩
cLg3 = 0.99|l0⟩+ 0.01|l1⟩
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

9.6 Inference in Bayesian networks
317
The Grade channel cG : D × I →G looks as follows.
cGd0, i0 = 0.3|g1⟩+ 0.4|g2⟩+ 0.3|g3⟩
cGd0, i1 = 0.9|g1⟩+ 0.08|g2⟩+ 0.02|g3⟩
cGd1, i0 = 0.05|g1⟩+ 0.25|g2⟩+ 0.7|g3⟩
cGd1, i1 = 0.5|g1⟩+ 0.3|g2⟩+ 0.2|g3⟩
(Notice that we switched the order of i and d wrt. the tables in Figure 9.1; we
have done so in order to remain consistent with the order of the inputs D and I
as suggested in the network in Figure 9.1. This is actually a subtle issue, because
usually in graphs there is no order on the parents of a node, that is, the parents form
a set and not a list.)
We now discuss a number of inference questions from Koller and Friedman (2009)
and illustrate how they are answered systematically using our perspective with states,
predicates and channels.
(i) What are the a priori probabilities for the recommendation? To answer this
question we follow the graph in Figure 9.1 and see that the answer is given by
twice using state transformation, namely:
cL ≫
cG ≫ωD ⊗ωI
 = 0.498|l0⟩+ 0.502|l1⟩,
or, equivalently,
=
cL
cG
 ≫ωD ⊗ωI.
(ii) What if we know that the student is not intelligent? The non-intelligence
translates into the point predicate 1i0 on the set I, which we use to update the
intelligence state ωI before doing the same state transformations:
cL ≫
cG ≫ωD ⊗ωI|1i0
 = 0.611|l0⟩+ 0.389|l1⟩.
(iii) What if we additionally know that the test is easy? The easiness evidence
translates into the predicate 1d0 on D, which is used for updating the diﬃculty
state:
cL ≫
cG ≫ωD|1d0 ⊗ωI|1i0

= 0.487|l0⟩+ 0.513|l1⟩
=
cL
cG
 ≫
ωD ⊗ωI|1d0⊗1i0
.
The previous two outcomes are obtained by what is called 'causal reasoning'
or 'prediction' or 'forward inference', see the table at the end of Section 9.2.3.
We continue with 'backward inference', also called 'evidential reasoning' or
'explanation'.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

318
Jacobs and Zanasi: Logical Essentials of Bayesian Reasoning
(iv) What is the intelligence given a C-grade (g3)? The evidence predicate 1g3
is a predicate on the set G. We like to learn about the revised intelligence. This is
done as follows. Via predicate transformation we obtain a predicate cG ≪1g3 on
D × I. We can use it to update the product state ωD ⊗ωI. We then get the update
intelligence by taking the second marginal, as in:
M2
ωD ⊗ωI|cG≪1g3
 = 0.921|i0⟩+ 0.0789|i1⟩.
We see that the new intelligence (i1) is signiﬁcantly lower than the a priori value
of 0.3, once a low grade is observed. The updated diﬃculty (d1) probability is
higher than the original 0.4; it is obtained by taking the ﬁrst marginal:
M1
ωD ⊗ωI|cG≪1g3
 = 0.371|d0⟩+ 0.629|d1⟩.
(v) What is the intelligence given a weak recommendation? We now have a
point predicate 1l0 on the set L. Hence we have to do predicate transformation
twice, along the channels cL and cG, in order to reach the initial states. This is
done as:
M2
ωD ⊗ωI|cG≪cL≪1l0
 = 0.86|i0⟩+ 0.14|i1⟩,
or, equivalently,
= M2
ωD ⊗ωI|cL cG≪1l0
.
(vi) What is the intelligence given a C-grade but a high SAT score? We now
have two forms of evidence, namely the point predicate 1g3 on G for the C-grade,
and the point predicate 1s1 on S for the high SAT score. We can transform the
latter to a predicate cS ≪1s1 on the set I and update the state ωI with it. Then
we can procede as in question (iv):
M2
ωD ⊗ωI|cS≪1s1|cG≪1g3
 = 0.422|i0⟩+ 0.578|i1⟩.
Thus the probability of high intelligence is 57.8% under these circumstances.
Using earlier calculation rules, see notably in Lemma 9.7, this intelligence
distribution can also be computed by weakening the predicate cS ≪1s1 to
M
2cS ≪1s1 on D × I. Then we can take the conjunction with cG ≪1g3 and
perform a single update, as in:
M2
ωD ⊗ωI|
M
2cS≪1s1&cG≪1g3

But one can also do the update with cS ≪1s1 at the very end, after the
marginalisation, as in:
M2
ωD ⊗ωI|cG≪1g3
|cS≪1s1
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

9.6 Inference in Bayesian networks
319
The associated diﬃculty level is the ﬁrst marginal:
M1
ωD ⊗ωI|1s1|cG≪1g3
 = 0.24|d0⟩+ 0.76|d1⟩.
The answers to the above questions hopefully convey the systematic thinking that is
behind the use of channels - in forward or backward manner, following the network
structure - in order to capture the essence of Bayesian networks. This systematics is
elaborated further in subsequent sections. In the above 'student' example we have
obtained the same outcomes as in traditional approaches. We conclude with an
illustration where things diﬀer.
Example 9.14
The power of the channel-based approach is that it provides a 'logic'
for Bayesian inference, giving high-level expressions c ≫ω|p and ω|c≪q for forward
and backward inference. We include an illustration from Barber (2012) where our
method produces a diﬀerent outcome. The logical description may help to clarify
the diﬀerences.
Consider the following Bayesian network, with nodes for burglary (B), earthquake
(E), alarm (A) and radio (R).
PrB
0.01




burglary





earthquake
PrE
0.000001






alarm
B E
PrA
b
e 0.9999
b e⊥
0.99
b⊥e
0.99
b⊥e⊥0.0001




radio
E PrR
e
1
e⊥
0
In this case we have binary sets B = {b, b⊥}, E = {e, e⊥}, A = {a, a⊥} and
R = {r, r⊥} with initial states ωB = 0.01|b⟩+ 0.99|b⊥⟩and ωE = 0.000001|e⟩+
0.999999|e⊥⟩. There are two channels cA : B × E →A and cR : E →R based on
the above (two lower) tables. The predicted (a priori) alarm probability is 1%; it is
computed as cA ≫ωB ⊗ωE = 0.01|a⟩+ 0.99|a⊥⟩.
The following questions are asked in Barber (2012, Example 3.1 and 3.2).
(i) What is the probability of a burglary given that the alarm sounds? In this
case we have evidence 1a on the set A, we pull it back to B ×E along the channel
cA, and we update the joint state ωB ⊗ωE and take the ﬁrst marginal:
M1
ωB ⊗ωE|cA≪1a
 = 0.99000198|b⟩+ 0.00999802|b⊥⟩.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

320
Jacobs and Zanasi: Logical Essentials of Bayesian Reasoning
(ii) What is this probability if we additionally hear a warning on the radio? In
that case we have additional evidence 1r on R, which is pulled back along the
channel cR and used to update the state ωE. Then:
M1
ωB ⊗ωE|cR≪1r|cA≪1a
 = 0.010099|b⟩+ 0.989901|b⊥⟩.
(iii) . . . "imagine that we are only 70% sure we heard the burglar alarm sound-
ing" In this situation we have a fuzzy predicate q: A →0, 1 with qa = 0.7 and
qa⊥= 0.3. We perform the same computation as in question (i), but now with
evidence q instead of 1a. This yields:
M1
ωB ⊗ωE|cA≪q
 = 0.0229|b⟩+ 0.9771|b⊥⟩.
(9.14)
However, in Barber (2012) a completely diﬀerent computation is performed,
following Jeﬀrey's rule. The assumption about the alarm is not interpreted as
a predicate, but as a state σ = 0.7|a⟩+ 0.3|a⊥⟩. The result is computed via a
corresponding convex combination of states:
0.7 ·
update with evidence a
 + 0.3 ·
update with evidence a⊥
= 0.7 · M1
ωB ⊗ωE|cA≪1a
 + 0.3 · M1
ωB ⊗ωE|cA≪1a⊥

= 0.693|b⟩+ 0.307|b⊥⟩.
(9.15)
For questions (i) and (ii) our calculations coincide with the ones in Barber (2012),
but for question (iii) the answers clearly diﬀer. We brieﬂy analyse the situation. For
a more extensive analysis in terms of Jeﬀrey's rule versus Pearl's for updating with
soft/fuzzy evidence we refer to Jacobs (2019).
• The above computation (9.14) and the one (9.15) from Barber (2012) are based
on diﬀerent ways of understanding what soft evidence actually means. In Barber
(2012) this notion, even though it is not made mathematically precise, appears to
have an ontological interpretation: "the alarm was heard" is a new state of aﬀairs,
with 70% alarm probability, and is therefor used as a state (distribution). On the
other hand, our fuzzy predicate interpretation has an epistemological ﬂavour: it is
new information about an agent's belief.
• In line with the previous point, diﬀerent intuitive descriptions are developed
in Jacobs (2019): the approach in (9.14) factors the soft evidence in, as improve-
ment, using Bayesian rules. The approach (9.15) interpretes the soft evidence as a
'surprising' state of aﬀairs, that one has to adjust to - as correction - following
Jeﬀrey's rule.
The above formulation, quoted from Barber (2012), does not seem to suggest
that the 70% certainty is a new, surprising state of aﬀairs that we have to adjust to.
Instead, it seems to be more like an improvement, so that the calculation (9.14)
seems most appropriate.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

9.7 String diagrams for Bayesian probability
321
We shall brieﬂy return to these diﬀerent was of computation in Example 9.17 where
we show that the outcome in (9.14) also appears via 'crossover inference'.
9.7 String diagrams for Bayesian probability
Abstractly, channels are arrows of a category, which is symmetric monoidal: it
has sequential
and parallel ⊗composition. This categorical structure enables
the use of a graphical (yet completely formal) notation for channels in terms
of string diagrams (Selinger, 2011). We have no intention of giving a complete
account of the string diagrammatic calculus here, and refer instead to Fong (2012),
Jacobs and Zanasi (2016, Sec. 3), and Jacobs et al. (2019, Sec. 3) for details.
Nonetheless, it is worthwhile pointing similarities and diﬀerences between the
graphical representation of channels as string diagrams and the usual Bayesian
network notation, see also Jacobs et al. (2019). We shall also use string diagrams
to give a pictorial account of the important notion of disintegration (in the next
section).
Informally speaking, string diagrams for channels are similar to the kind of graphs
that is used for Bayesian networks, see Figure 9.1, but there are important diﬀerences.
(i) Whereas ﬂow in Bayesian networks is top-down, we will adopt the convention
that in string diagrams the ﬂow is bottom-up. This is an non-essential, but useful
diﬀerence, because it makes immediately clear in the current context whether we
are dealing with a Bayesian network or with a string diagram. Also, it makes our
presentation uniform with previous work, see e.g. Cho and Jacobs (2019).
(ii) The category where channels are arrows has extra structure, which allows for the
use of "special" string diagrams representing certain elementary operations. We
will have explicit string diagrams for copying and discarding variables, namely:
copy
=
and
discard
=
There are some 'obvious' equations between diagrams involving such copy and
discard, such as:
=
=
=
=
These equations represent the fact that copy is the multiplication and discard is
the unit of a commutative monoid.
(iii) With string diagrams one can clearly express joint states, on product domains
like X1 × X2, or X1 × · · · × Xn. This is done by using multiple outgoing pins,
coming out of a triangle shape - used for states - as for ω ∈DX1 × X2 and
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

322
Jacobs and Zanasi: Logical Essentials of Bayesian Reasoning
Diﬃculty
Intelligence
SAT
Grade
Letter
Figure 9.2 Student network from Figure 9.1 expressed as string diagram. Note that the two
arrows coming out of Intelligence in Figure 9.1 are translated here into a single wire coming out
the Intelligence state, followed by a copy.
σ ∈DX1 × · · · × Xn in:
ω
X1
X2
σ
X1
· · ·
Xn
With this notation in place we can graphically express the marginals via discarding
of wires:
M1ω
=
ω
X1
and
M2ω
=
ω
X2
(iv) Channels are causal or unitary in the sense that discarding their output is the
same as discarding their input:
c
=
The Intelligence node in Figure 9.1 has two outgoing arrows, but this does not
mean that Intelligence is a joint state. Instead, these two arrows indicate that the
outgoing wire should be copied, with one copy going to the Grade node and one to
the SAT node. In string diagram notation this copying is written explicitly as in the
string-diagrammatic analogue of the student network in Figure 9.2.
Recall that we wrote ωD = 0.6|d0⟩+ 0.4|d1⟩and ωI = 0.7|i0⟩+ 0.3|i1⟩for the
initial states of the student network. The product state
ωD ⊗ωI = 0.42|d0, i0⟩+ 0.18|d0, i1⟩+ 0.28|d1, i0⟩+ 0.12|d1, i1⟩
is non-entwined, since it equals the product of its marginals ωD and ωI. A basic
fact in probability is that conditioning can create entwinedness, see e.g. Jacobs and
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

9.8 From joint states to Bayesian networks
323
Zanasi (2017) for more information. We can see this concretely when the above
product state ωD ⊗ωI is conditioned as in the fourth question in the previous section:
ωD ⊗ωI|cG≪1g3
= 12600
34636|d0, i0⟩+
36
34636|d0, i1⟩+ 19600
34636|d1, i0⟩+ 2400
34636|d1, i1⟩.
With some eﬀort one can show that this state is not the product of its marginals: it
is entwined. In the language of string diagrams we can express this diﬀerence by
writing:
ωD ⊗ωI
=
ωD ⊗ωI|cG≪1g3
=
9.8 From joint states to Bayesian networks
Our framework allows to express states/distributions and Bayesian networks as
entities of the same kind, namely as channels. It is natural to ask how the process of
forming a Bayesian network from a distribution can be integrated in the picture.
In traditional probability theory, this procedure forms one of the original motiva-
tions for developing the notion of Bayesian network in the ﬁrst place. Such networks
allow for more eﬃcient representation of probabilistic information (via probability
tables, as in Figure 9.1) than joint states, which quickly become unmanageable via an
exponential explosion. We quote from Koller and Friedman (2009): ". . . the explicit
representation of the joint distribution is unmanageable from every perspective.
Computationally, it is very expensive to manipulate and generally too large to store
in memory" and from Russell and Norvig (2003): ". . . a Bayesian network can often
be far more compact than the full joint distribution".
The procedure of forming a Bayesian network from a given state usually goes
through a sub-routine called disintegration. For a channel-based deﬁnition of
disintegration, suppose we have a state ω ∈DX and a channel c: X →Y . Then we
can form a joint state σ ∈DX × Y as described by the following string diagram:
σ

ω
c
that is
σx, y = ωx · cxy.
(9.16)
The state ω is determined as the ﬁrst marginal ω = M1σ of σ. This can be seen by
discarding
the second wire - on the left and on the right in the above equation
- and using that channels are causal, and that discarding one wire of a copy is the
identity wire.
Disintegration is the process in the other direction, from a joint state to a channel.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

324
Jacobs and Zanasi: Logical Essentials of Bayesian Reasoning
Deﬁnition 9.15
Let σ ∈DX × Y be a joint state. A disintegration of σ is a
channel c: X →Y for which the equation (9.16) holds, where ω = M1σ.
There is a standard formula for disintegration of a state σ ∈DX × Y , namely:
cx  M2
σ|1x⊗1
 = y
σx, y
M1σx|y⟩.
(9.17)
We shall say that the channel c is 'extracted' from σ, or also that σ 'factorises' via c
as in (9.16). Intuitively, channel c captures the conditional probabilities expressed in
traditional notation as Prσy | x via a distribution on Y indexed by elements x ∈X.
Deﬁnition 9.15 gives the basic form of disintegration. There are several variations,
which are explored in Cho and Jacobs (2019) as part of a more abstract account of
this notion. For instance, by swapping the domains one can also extract a channel
Y →X, in the other direction. Also, if σ is a joint state on n domains, there
are in principle 2n ways of extracting a channel, depending on which pins are
marginalised out, and which (other) ones are reconstructed via the channel. For
instance, a disintegration of ω ∈DX ×Y ×Z can also be a channel c: Z →X ×Y .
This example suggests a digression on a channel-based deﬁnition of conditional
independence: X and Y are conditionally independent in ω given Z, written as
X⊥Y | Z, if any such disintegration c for ω can actually be decomposed into
channels c1 : Z →X and c2 : Z →Y . In string diagrams:
ω
X Y
Z
=
ω3
c
X
Y
Z
=
ω3
c1
c2
X
Y
Z
(9.18)
where ω3 = M3ω = Prωz is the third marginal. These channels c1, c2 may also be
obtained by disintegration from the state M1,2ω = Prωx, y obtained by marginalising
out the third variable. In more traditional notation, one can intuitively read (9.18)
as saying that Prωx, y, z = Prωx | z · Prωy | z · Prωz. We refer to Cho and
Jacobs (2019) for the adequacy of this deﬁnition of conditional independence and
its properties.
Another interesting observation is that disintegration forms a modular procedure.
The formula (9.16) shows that disintegration yields a new decomposition of a given
state: such a decomposition being a state itself, disintegration may be applied again.
In fact, this repeated application is how a joint state on multiple domains gets
represented as a Bayesian network. The channel-based approach understands this
process uniformly as a step-by-step transformation of a given channel (a state) into
another, equivalent channel (a Bayesian network). Once again, string diagrams are a
useful formalism for visualising such correspondence. For instance, the joint state
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

9.8 From joint states to Bayesian networks
325
joint

Diﬃculty
Intelligence
SAT
Grade
Letter
Figure 9.3 The joint distribution (9.19) for the student network from Figure 9.1 obtained as
string diagram with additional copiers for non-ﬁnal nodes.
associated with the Student network from Figures 9.1 and 9.2 can be expressed as in
Figure 9.3. Notice that the diagram in Figure 9.3 is just the one in Figure 9.2 where
each non-ﬁnal node has been made externally accessible via additional copiers
.
Figure 9.3 has the type of a joint state. Its value can then be calculated via state
transformation, via a composite channel that can be "read oﬀ" directly from the
graph in Figure 9.3, namely:
joint

id⊗id⊗cL⊗id⊗id
id⊗Δ⊗id⊗cS
id⊗cG⊗Δ
Δ⊗Δ

≫
ωD⊗ωI
.
(9.19)
The tool EfProb, see Cho and Jacobs (2017), has been designed precisely to evaluate
such systematic expressions.
Now that we have a formal description of the relationship between joint states and
Bayesian networks, we turn to comparing Bayesian inference in these two settings.
For reasons of simplicity, we concentrate on the binary case. Suppose we have a joint
state σ ∈DX × Y , now with evidence on X. In the present setting this evidence
can be an arbitrary predicate p ∈0, 1X and not only a point predicate 1x, as usual.
We like to ﬁnd out the distribution on Y , given the evidence p. Informally, this may
be written as PrY | p. More precisely, it is the second marginal of the state obtained
by updating with the weakened version
M
1p = p ⊗1, as in:
M2
σ|
M
1p
.
Now suppose we have factorised the joint state σ as a (mini) network (9.16) via
the extracted state c: X →Y . We can also perfom causal reasoning - i.e. forward
inference - and obtain the state:
c ≫ω|p
where
ω = M1σ.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

326
Jacobs and Zanasi: Logical Essentials of Bayesian Reasoning
The Bayesian inference theorem says that these outcomes are the same, not only for
forward reasoning, but also for backward reasoning.
Theorem 9.16
Let σ ∈DX ×Y be a joint state with extracted channel c: X →Y
as in (9.16). For predicates p ∈0, 1X and q ∈0, 1Y one has:
M2
σ|
M
1p
 = c ≫
M1σ|p

and
M1
σ|
M
2q
 = M1σ|c≪q.
Before giving a proof, we comment on the signiﬁcance of the statement. Inference
with joint states, as on the left-hand-side of the equations in Theorem 9.16, involves
weakening
M
of evidence in one coordinate and marginalisation M in another
coordinate. It uses the entwinedness of the joint state σ, so that one coordinate can
inﬂuence the other, see Jacobs and Zanasi (2017) where this is called crossover
inﬂuence. Therefor we like to call this form of inference via joint states crossover
inference.
In contrast, inference on the right-hand-side of the equations in Theorem 9.16
essentially uses state and predicate transformation ≫and ≪. Therefor we refer to
this form of inference as transformer inference. It consists of what we have called
backward and forward inference in the table at the end of Section 9.2.3.
Thus the Bayesian inference theorem states the equivalence of crossover inference
and transformer inference. Whereas crossover inference works well with small
samples (see the examples below), it does not scale to larger networks, where
transformations inference is preferable. The equivalence is widely known at some
implicit level, but its formulation in this explicit form only arises within the current
channel-based perspective on Bayesian networks.
We now provide a proof of the theorem. A purely diagrammatic argument is given
in Cho and Jacobs (2019).
Proof of Theorem 9.16 We conﬁne ourselves to proving the ﬁrst equation in con-
crete form, using the deﬁnition of extracted channel from (9.17):
c ≫M1σ|p
y
=
x cxy · M1σ|px
(9.17)
=
x
σx, y
M1σx · M1σx · px
M1σ |= p
(9.6)
=
x
σx, y · px
σ |=
M
1p
=
x
σx, y ·
M
1px, y
σ |=
M
1p
since
M
1px, y = p ⊗1x, y = px
=
x σ|
M
1px, y
=
M2
σ|
M
1p
y.
□
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

9.8 From joint states to Bayesian networks
327
We conclude this section by giving two demonstrations of the equivalence stated
in Theorem 9.16. First, we answer once again the six questions about the student
network in Section 9.6: whereas therein we applied transformer inference, we now
compute using crossover inference. We shall write:
joint ∈D
D × G × L × I × S

for the joint state associated with the student network, obtained in formula (9.19),
following Figure 9.3. We write Mi for the i-th marginal, obtained by summing out all
domains which are not in the i-th position. For the sake of clarity we do not use the
notation
M
for weakening, but use parallel product with the truth predicate 1 instead.
In agreement with Theorem 9.16, the outcomes are the same as in Section 9.6, but
they have been computed separately (in EfProb).
(i) What are the a priori probabilities for the recommendation?
M3joint = 0.498|l0⟩+ 0.502|l1⟩.
(ii) What if we know that the student is not intelligent?
M3
joint|1⊗1⊗1⊗1i0⊗1
 = 0.611|l0⟩+ 0.389|l1⟩.
(iii) What if we additionally know that the test is easy?
M3
joint|1d0⊗1⊗1⊗1i0⊗1
 = 0.487|l0⟩+ 0.513|l1⟩.
(iv) What is the intelligence given a C-grade (g3)?
M4
joint|1⊗1g3⊗1⊗1⊗1
 = 0.921|i0⟩+ 0.0789|i1⟩.
(v) What is the intelligence given a weak recommendation?
M4
joint|1⊗1⊗1l0⊗1⊗1
 = 0.86|i0⟩+ 0.14|i1⟩.
(vi) What is the intelligence given a C-grade but a high SAT score?
M4
joint|1⊗1g3⊗1⊗1⊗1s1
 = 0.422|i0⟩+ 0.578|i1⟩.
As a second demonstration of the theorem, we brieﬂy return to the controversy
around inference with soft predicates in Example 9.14.
Example 9.17
We ﬁrst re-arrange the Bayesian network from Example 9.14 in
string diagrammatic form so that we can compute the joint state ω ∈DB×A×E×R
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

328
Jacobs and Zanasi: Logical Essentials of Bayesian Reasoning
as:
ω 
ωB
ωE
cA
cR
i.e.
ω =
id ⊗id ⊗cR ⊗id
id ⊗cA ⊗Δ
Δ ⊗Δ
 ≫ωB ⊗ωE.
Recall that we have soft/fuzzy evidence qa = 0.7, qa⊥= 0.3 on A. Given this
evidence, we want to know the burglar probability. Using crossover inference it is
computed as:
M1
ω|1⊗q⊗1⊗1
 = 0.0229|b⟩+ 0.9771|b⊥⟩.
We obtain the same outcome as via transformer inference in (9.14). Of course, the
Bayesian Inference Theorem 9.16 tells that the outcomes should coincide in general.
This additional computation just provides further support for the appropriateness of
doing inference via forward and backward transformations along channels.
9.9 Conclusions
This chapter provides an introduction to an emerging area of channel-based probabil-
ity theory. It uses standard compositional techniques from programming semantics
in the area of Bayesian inference, giving a conceptual connection between forward
and backward inference (or: causal and evidential reasoning) on the one hand, and
crossover inﬂuence on the other.
Promising research directions within this framework include the development of
channel-based algorithms for Bayesian reasoning, see Jacobs (2018a). Moreover,
the abstract perspective oﬀered by the channel approach may apply to probabilistic
graphical models other than Bayesian networks, including models for machine
learning such as neural networks (see Jacobs and Sprunger, 2019 for ﬁrst steps).
Paired with the mathematical language of string diagrams, this framework may
eventually oﬀer a unifying compositional perspective on the many diﬀerent pictorial
notations for probabilistic reasoning.
Acknowledgements
Fabio Zanasi acknowledges support from EPSRC grant nr. EP/R020604/1. Bart
Jacobs' research has received funding from the European Research Council under
the European Union's Seventh Framework Programme (FP7/2007-2013) / ERC
grant agreement nr. 320571.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
329
References
Barber, D. 2012.
Bayesian Reasoning and Machine Learning.
Cambridge
Univ. Press. publicly available via http://web4.cs.ucl.ac.uk/staff/D.
Barber/pmwiki/pmwiki.php?n=Brml.HomePage.
Bartels, F., Sokolova, A., and de Vink, E. 2004. A hierarchy of probabilistic system
types. Theoretical Computer Science, 327(1-2), 3-22.
Cho, K., and Jacobs, B. 2017. The EfProb Library for Probabilistic Calculations.
In: Bonchi, F., and König, B. (eds), Conference on Algebra and Coalgebra in
Computer Science (CALCO 2017). LIPIcs, vol. 72. Schloss Dagstuhl.
Cho, K., and Jacobs, B. 2019. Disintegration and Bayesian inversion via string
diagrams. Math. Struct. in Comp. Sci., 29(7), 938-971.
Cho, K., Jacobs, B., Westerbaan, A., and Westerbaan, B. 2015. An Introduction to
Eﬀectus Theory. see arxiv.org/abs/1512.05813.
Culbertson, J., and Sturtz, K. 2014.
A Categorical Foundation for Bayesian
Probability. Appl. Categorical Struct., 22(4), 647-662.
de Vink, E., and Rutten, J. 1999. Bisimulation for probabilistic transition systems: a
coalgebraic approach. Theoretical Computer Science, 221, 271-293.
Dijkstra, E., and Scholten, C. 1990. Predicate Calculus and Program Semantics.
Berlin: Springer.
Dijkstra, E. W. 1997. A Discipline of Programming. 1st edn. Upper Saddle River,
NJ, USA: Prentice Hall PTR.
Dubois, D., and Prade, H. 1990.
The Logical View of Conditioning and Its
Application to Possibility and Evidence Theories. Int. Journ. of Approximate
Reasoning, 4, 23-46.
Fong, B. 2012. Causal Theories: A Categorical Perspective on Bayesian Networks.
M.Phil. thesis, Univ. of Oxford. see arxiv.org/abs/1301.6201.
Giry, M. 1982. A categorical approach to probability theory. Pages 68-85 of:
Banaschewski, B. (ed), Categorical Aspects of Topology and Analysis. Lect.
Notes Math., no. 915. Springer, Berlin.
Jacobs, B. 2011.
Probabilities, Distribution Monads, and Convex Categories.
Theoretical Computer Science, 412(28), 3323-3336.
Jacobs, B. 2013. Measurable Spaces and their Eﬀect Logic. In: Logic in Computer
ScienceComputer Science Press, for IEEE.
Jacobs, B. 2017. A recipe for State and Eﬀect Triangles. Logical Methods in Comp.
Sci., 13(2). See https://lmcs.episciences.org/3660.
Jacobs, B. 2018a. A Channel-based Exact Inference Algorithm for Bayesian Networks.
See arxiv.org/abs/1804.08032.
Jacobs, B. 2018b. From Probability Monads to Commutative Eﬀectuses. Journ. of
Logical and Algebraic Methods in Programming, 94, 200-237.
Jacobs, B. 2019. The Mathematics of Changing one's Mind, via Jeﬀrey's or via
Pearl's update rule. Journ. of Artif. Intelligence Res., 65, 783-806.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

330
References
Jacobs, B., and Sprunger, D. 2019, to appear. Neural Nets via Forward State
Transformation and Backward Loss Transformation. In: König, B. (ed), Math.
Found. of Programming Semantics. Elect. Notes in Theor. Comp. Sci. Elsevier,
Amsterdam. See arxiv.org/abs/1803.09356.
Jacobs, B., and Zanasi, F. 2016. A predicate/state transformer semantics for Bayesian
learning. Pages 185-200 of: Birkedal, L. (ed), Math. Found. of Programming
Semantics. Elect. Notes in Theor. Comp. Sci., no. 325. Elsevier, Amsterdam.
Jacobs, B., and Zanasi, F. 2017. A Formal Semantics of Inﬂuence in Bayesian
Reasoning. In: Larsen, K., Bodlaender, H., and Raskin, J.-F. (eds), Math. Found.
of Computer Science. LIPIcs, vol. 83. Schloss Dagstuhl.
Jacobs, B., Kissinger, A., and Zanasi, F. 2019. Causal Inference by String Diagram
Surgery. Pages 313-329 of: Bojańczyk, M., and Simpson, A. (eds), Foundations
of Software Science and Computation Structures. Lect. Notes Comp. Sci., no.
11425. Springer, Berlin.
Jones, C., and Plotkin, G. 1989. A probabilistic powerdomain of evaluations. Pages
186-195 of: Logic in Computer ScienceComputer Science Press, for IEEE.
Jung, A., and Tix, R. 1998. The Troublesome Probabilistic Powerdomain. Pages 70-
91 of: Edalat, A., Jung, A., Keimel, K., and Kwiatkowska, M. (eds), Comprox
III, Third Workshop on Computation and Approximation. Elect. Notes in Theor.
Comp. Sci., no. 13. Elsevier, Amsterdam.
Keimel, K. 2008. The monad of probability measures over compact ordered spaces
and its Eilenberg-Moore algebras. Topology and its Applications, 156, 227-239.
Keimel, K., and Plotkin, G. 2009. Predicate transformers for extended probability
and non-determinism. Math. Struct. in Comp. Sci., 19(3), 501-539.
Koller, D., and Friedman, N. 2009. Probabilistic Graphical Models. Principles and
Techniques. Cambridge, MA: MIT Press.
Kozen, D. 1981. Semantics of probabilistic programs. Journ. Comp. Syst. Sci, 22(3),
328-350.
Kozen, D. 1985. A probabilistic PDL. Journ. Comp. Syst. Sci, 30(2), 162-178.
Mermin, N.D. 2007. Quantum Computer Science: An Introduction. Cambridge
Univ. Press.
Mislove, M. 2012. Probabilistic Monads, Domains and Classical Information. Pages
87-100 of: Kasheﬁ, E., Krivine, J., and van Raamsdonk, F. (eds), Developments
of Computational Methods (DCM 2011). Elect. Proc. in Theor. Comp. Sci., no.
88.
Mrad, A. Ben, Delcroix, V., Piechowiak, S., Leicester, P., and Abid, M. 2015. An
explication of uncertain evidence in Bayesian networks: likelihood evidence
and probabilistic evidence. Applied Intelligence, 23(4), 802-824.
Panangaden, P. 2009. Labelled Markov Processes. London: Imperial College Press.
Russell, S., and Norvig, P. 2003. Artiﬁcial Intelligence. A Modern Approach. Prentice
Hall.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
331
Ścibior, A., Ghahramani, Z., and Gordon, A. 2015. Practical Probabilistic Program-
ming with Monads. Pages 165-176 of: Proc. 2015 ACM SIGPLAN Symp. on
Haskell. ACM.
Ścibior, A., Kammar, O., Vákár, M., Staton, S., Yang, H., Cai, Y., Ostermann, K.,
Moss, S., Heunen, C., and Ghahramani, Z. 2018. Denotational Validation of
Higher-order Bayesian Inference. Pages 60:1-60:29 of: Princ. of Programming
Languages. ACM Press.
Selinger, P. 2011. A survey of graphical languages for monoidal categories. Springer
Lecture Notes in Physics, 13(813), 289-355.
Sokolova, A. 2011. Probabilistic systems coalgebraically: A survey. Theoretical
Computer Science, 412(38), 5095-5110.
Staton, S., Yang, H., Heunen, C., Kammar, O., and Wood, F. 2016. Semantics for
probabilistic programming: higher-order functions, continuous distributions,
and soft constraints. In: Logic in Computer Science Computer Science Press,
for IEEE.
Tix, R., Keimel, K., and Plotkin, G. 2005. Semantic Domains for Combining
Probability and Non-Determinism. Elect. Notes in Theor. Comp. Sci., no. 129.
Elsevier, Amsterdam.
Valtorta, M., Kim, Y.-G., and Vomlel, J. 2002. Soft evidential update for probabilistic
multiagent systems. Int. Journ. of Approximate Reasoning, 29(1), 71-106.
Varacca, D., and Winskel, G. 2006. Distributing probability over non-determinism.
Math. Struct. in Comp. Sci., 16, 87-113.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

10
Quantitative Equational Reasoning
Giorgio Bacci
Aalborg University
Radu Mardare
University of Stratchclyde
Prakash Panangaden
McGill University
Gordon Plotkin
University of Edinburgh
Abstract:
Equational logic is central to reasoning about programs. What is the right
equational setting for reasoning about probabilistic programs? It has been understood
that instead of equivalence relations one should work with (pseudo)metrics in a
probabilistic setting. However, it is not clear how this relates to equational reasoning.
In recent work the notion of a quantitative equational logic was introduced and
developed. This retains many of the features of ordinary logic but ﬁts naturally with
metric reasoning. The present chapter is an elementry introduction to this topic.
In this setting one can deﬁne analogues of algebras and free algebras. It turns out
that the Kantorovich (Wasserstein) metric emerges as a free construction from a
simple quantitative equational theory. We give a couple of examples of quantitative
analogues of familiar eﬀects from programming language theory. We do not assume
any background in equational logic or advanced category theory.
10.1 Introduction
Equational reasoning is at the heart of mathematics and theoretical computer science.
In algebra, we deﬁne algebraic structures by giving (mostly) equational axioms. In
analysis there are numerous equations linking concepts; of course, inequalities play
a major role too but this just highlights the importance of equality. In programming
language semantics one has equations capturing notions of behavioural equivalence
of programs. The monadic approach, due to Moggi (1991), to incorporating eﬀects
in higher-order functional programming has been understood through the work of
a From Foundations of Probabilistic Programming, edited by Gilles Barthe, Joost-Pieter Katoen and Alexandra
Silva published 2020 by Cambridge University Press.
333
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

334
Bacci et al.: Quantitative Equational Reasoning
Plotkin and Power (2004), Hyland et al. (2006), and Hyland and Power (2007) and
others in terms of operations and equations.
With the emergence of probabilistic programming1 a new emphasis on quantitative
reasoning has become important. One thinks in terms of "how close are two
programs?" rather than "are they completely indistinguishable?" This concept is
captured by a metric and was ﬁrst advocated in Giacalone et al. (1990). The idea
here was that instead of using a behavioural equivalence relation like bisimulation
one should use a pseudometric whose kernel is bisimulation. Such a metric was ﬁrst
deﬁned in Desharnais et al. (1999). What we aim to do here is show how a version
of equational reasoning, which we call quantitative equational logic, captures such
metric reasoning principles. This work ﬁrst appeared in Mardare et al. (2016, 2017)
and Bacci et al. (2018).
The most compelling example of a programming language setting where quantita-
tive reasoning is important is probabilistic programming; the subject of this book.
While our work is not speciﬁcally adapted to this setting it does provide the general
framework for such reasoning. In particular, one of the most important ways of
comparing probability distributions is the Kantorovich (Wasserstein) metric and, for
example, in machine learning it has recently been a source of much attention. In
our quantitative equational framework this metric emerges naturally from simple
quantitative equations.
The key idea is to introduce equations indexed by positive rational numbers:
s =ε t
where s and t are terms of some language and ε is a (presumably small) positive
real number. One reads this as "s is within ε of t". Certainly, the relation =ε is not
an equivalence relation: transitivity does not hold, if s =ε t and t =ε u then there is
no reason to think s =ε u. Indeed, one can only say s =2ε u.
In the usual notion of equational reasoning one has a trinity of ideas: equations,
Lawvere theories, and monads on Set. The equational presentation of algebras was
systematically worked out by universal algebraists. Lawvere showed how to give a
cateorical presentation of algebraic theories which freed the subject from some of
the awkwardness of dealing with diﬀerent presentations of the same theory. In the
1950s it was understood that algebras arose as the "algebras of a monad" deﬁned
on the category Set. Essentially, the action of the monad is to construct the free
algebras.
These concepts can be generalized to other settings, see, for example, Robinson
(2002). In the present work we have quantitative equations and it turns out that one
can get monads on Met, for some suitable category of metric spaces.
1 To a lesser extent, real-time programming as well.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

10.2 Equational Logic
335
10.2 Equational Logic
In this section we review the standard familiar concepts of equational logic; where
we mean equations in the usual sense of the word. The equality concept is one of the
oldest abstract mathematical ideas and is well understood intuitively.
The basic syntax of equational logic starts with a signature of symbols
Ω = { fj : κi | i ∈I} ,
consisting of a set of function symbols (or operations) fi each having associated
with it a cardinal number (ﬁnite or inﬁnite) κi called its arity. The arity speciﬁes
how many arguments the function symbol takes. Some function symbols may have
arity 0; these are the constants of the language. We have not restricted the collection
of operations to be ﬁnite or countable, and one of our main examples will indeed
have uncountably many operations. It is possible to consider operations which take
inﬁnitely many arguments and we will consider such an example later.
Terms are constructed inductively starting from a ﬁxed countable set X of
variables, ranged over by x, y, z,. . . . Then the function symbols are applied to the
appropriate number of previously constructed terms to give new terms. We can
succinctly express the collection of terms through the following grammar:
t ::= x | f (ti)i∈κ ,
for x ∈X and f : κ ∈Ω
The set of terms constructed this way is denoted by TΩX. When the signature of
operation symbols Ω is clear from from the context, the set of terms will be simply
denoted as TX.
A substitution is a function σ: X →TX: it deﬁnes what it means to substitute a
variable for a term. It can be (homomorphically) extended to a function ˜σ: TX →TX
over terms as follows:
˜σ(x) = σ(x)
for x ∈X ,
˜σ( f (ti)i∈κ) = f (˜σ(ti))i∈κ
for f : κ ∈Ω .
In what follows we won't make any distinction between the substitution and its
extension. We will denote by Σ(X) the set of substitutions on TX.
The basic formulas of equational logic are equations of the form
s = t ,
for s,t ∈TX .
There are no quantiﬁers or logical connectives. We use E(TX) to denote the set of
equations over TX. Conjunction is implicit when one writes a sequence of equations,
but there is no disjunction, nor negation or implication. A judgement is an expression
of the form
Γ ⊢φ,
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

336
Bacci et al.: Quantitative Equational Reasoning
where Γ ⊆E(TX) is an enumerable set of equations and φ ∈E(TX). The judgment
Γ ⊢φ is intended to mean that under the assumptions in Γ the equation φ holds.
We refer to the elements of Γ as the hypotheses and to φ as the conclusion of the
judgment; J(TX) denotes the collection of judgments on TX.
Judgments are used for reasoning; we now deﬁne the important concept of
equational theory.
An equational theory of type Ω over X is a set U of judgements on TX such that,
for arbitrary s,t,u ∈TX and Γ,Θ ⊆E(TX)
(Reﬂ) ∅⊢t = t ∈U ,
(Symm) {s = t} ⊢t = s ∈U ,
(Trans) {s = u,u = t} ⊢s = t ∈U ,
(Cong) {si = ti | i ∈κ} ⊢f (si)i∈κ = f (ti)i∈κ ∈U ,
for any f : κ ∈Ω,
(Subst) if Γ ⊢s = t ∈U, then σ(Γ) ⊢σ(s) = σ(t) ∈U, for any σ ∈Σ(X),
(Cut) if Θ ⊢Γ ∈U and Θ ⊢s = t ∈U, then Γ ⊢s = t ∈U ,
(Assum) if s = t ∈Γ, then Γ ⊢s = t ∈U ,
where we write Γ ⊢Θ ∈U to mean that Γ ⊢φ ∈U holds for all φ ∈Θ; and
σ(Γ) = {σ(s) = σ(t) | s = t ∈Γ}.
The rules (Reﬂ), (Symm), and (Trans) capture the idea that equality is indeed an
equivalence relation. The congruence rule (Cong) describes how equality interacts
with the term-forming operations of the underlying term language. Finally, the
substitution rule (Subst) states that substitution preserve equality, while (Cut) and
(Assum) are the usual cut and assumption rules of logical reasoning.
A trivial consequence of the cut rule is that ∅⊢s = t ∈U implies that
Γ ⊢s = t ∈U, for any set of equations Γ. In other words, whatever can be proven
in a theory U without using any hypothesis, can also be proven from any set of
hypothesis. This is the familiar weakening rule.
Given an equational theory U and a set S ⊆U, we say that S is a set of axioms
for U, or S axiomatizes U, if U is the smallest equational theory that contains
S. An equational theory U is inconsistent if ∅⊢x = y ∈U for two distinct
variables x, y ∈X; U is consistent if it is not inconsistent. From the substitution
rule, inconsistency implies that every equation is derivable.
10.2.1 Algebra
Equational logic is intimately tied to algebra. For most of the familiar algebraic
structures one sees, the basic deﬁnition is given in terms of equations (although, there
are a few notable exceptions). To describe the equations characterising algebraic
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

10.2 Equational Logic
337
structures like a group or monoid, e.g., the associativity equation, one starts with
a set of variables X and signature of operations. This gives the term algebra over
which the equational properties are described. For example, for monoids one can
use the signature
{e: 0, ·: 2}
consisting of a 0-arity function symbol e (i.e., a constant) for the identity element
and an 2-arity function symbol "·" (typically used as an inﬁx operator). The terms
for this language look like x · (y · z), e · x, . . . 2.
The properties are spelled out as equations. For monoids, these are
e · x = x ,
x · e = x ,
(x · y) · z = x · (y · z),
for x, y, z ∈X variables.
Given a Ω-algebra, i.e., an algebraic structure over the signature Ω, such as a
monoid, we need to explain what it means for it to satisfy an equation, or more
generally a judgement.
A particular instance of an Ω-algebra A = (A,ΩA) consists of a set A, called the
carrier, containing the elements of the algebra, and a collection ΩA of interpretations
for each function symbol in Ω. If f : a ∈Ω is a function symbol of arity κ, then its
interpretation is a function fA : Aκ →A, where Aκ is the κ-fold cartesian product
of A; for a constant symbol this corresponds to select a designated element of A.
Thus a particular monoid M will be described by giving a set M of its elements, a
designated element eM ∈M to stand for e, and a binary operation ·M : M ×M →M.
Given the notion of algebra we can deﬁne a subalgebra. A subalgebra of A is
another algebra with the same signature and whose elements form a subset of A.
Given two algebras A = (A,ΩA), B = (B,ΩB) of the same signature, we can deﬁne
a homomorphism h to be a set-theoretic function from A to B, which preserves the
operations of the signature:
h( fA(ai)i∈κ) = fB(h(ai))i∈κ ,
for all f : κ ∈Ω,
where the equality symbol appearing in this equation means identity between
elements in B.
If we ﬁx a set of variables X and a signature Ω, the term algebra has the set
of terms TX build over X as carrier and interpretation for the function symbols
f : κ ∈Ω canonically given by
(ti)i∈κ ∈(TX)κ →f (ti)i∈κ ∈TX .
We denote as TX for this structure as well as its the underlying set of terms. Consider
a Ω-algebra A = (A,ΩA) and a assignment function ι: X →A from X to A,
2 Actually, it is even more common to leave it out altogether and indicate the operation by mere juxtaposition.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

338
Bacci et al.: Quantitative Equational Reasoning
interpreting variables as elements in A; this extends inductively to a function, also
written ι, from TX to A:
ι(x) = σ(x)
for x ∈X ,
ι( f (ti)i∈κ) = fA(ι(ti))i∈κ
for f : κ ∈Ω .
It is immediate from this deﬁnition that ι is a homomorphism from TX to A. It
should also be clear that every homomorphism from TX to A arises in this way; we
just have to restrict the homomorphism to X.
Deﬁnition 10.1. We say that a judgement Γ ⊢s = t in J(TX) is satisﬁed by A,
written A |= (Γ ⊢s = t), if for every assignment ι: X →A the following implication
holds:
 for all (s′ = t′) ∈Γ, ι(s′) = ι(t′)! implies ι(s) = ι(t) .
The "term algebra" that we have deﬁned so far is not really a proper algebra of the
type we have in mind because it does not satisfy the equations that deﬁne the class
of algebraic structures. We now repair this by an appropriate quotient construction.
Let S be a set of judgements and US the smallest equational theory that contains
S. We deﬁne a relation between terms s,t by
s ∼S t , if (∅⊢s = t) ∈US .
Since US is closed under the rules of equational logic, in other words, it is closed
under reﬂexivity, symmetry, transitivity, substitution, and congruence; this gives us a
congruence3 relation on TX. We write [t] for the equivalence class of t with respect
to the congruence ∼S. The quotient set TX/∼S is the collection of such equivalence
classes. It will be the underlying set of the term algebra. We deﬁne an interpretation,
written fS, for an operator f : κ ∈Ω of the signature on TX/∼S as follows:
fS([ti])i∈κ = [ f (ti)i∈κ] .
This is well deﬁned precisely because ∼S is a congruence. The set TX/∼S is now
a Ω-algebra; we denote it by TS[X], or simply T[X] when S is clear from the
context. It should be clear that by its construction, the algebra TS[X] satisﬁes all the
judgements in S (and US).
Examples of familiar algebras that can be presented purely equationally are
semigroups, monoids, groups, rings, lattices, and boolean algebras. Vector spaces
have two sorts of elements, but the theory described above can readily be extended
to this case and thus we include vector spaces as equationally deﬁned algebras.
Stacks as used in computer science are another familiar example. Some algebraic
structures require a strictly more powerful construct, namely Horn clauses in
3 We always implicitly include the notion of equivalence relation when we say "congruence."
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

10.2 Equational Logic
339
their axiomatizations. These are judgements with a nonempty set of hypothesis
representing a condition that must hold. For example, right-cancellative monoids
are required to satisfy the judgement
{x · z = y · z} ⊢x = y .
A familiar example of a right-cancellative monoid is the set of words over an alphabet
with the operation being concatenation of words.
Fields are not an example of equationally deﬁned class of algebras. One of the ﬁeld
axioms says: "if x  0 then there exist an element x−1 such that x · x−1 = x−1 · x = 1".
Here 1 is the multiplicative identity element. It is clearly not an equation because
of the side condition. It is not obvious to see that one cannot replace this with a
bona-ﬁde equation.
A very interesting example of an algebra that we will extensively discuss in the
quantitative setting are barycentric algebras. The signature of barycentric algebras
has uncountably many binary operations
{+e : 2 | e ∈[0,1]}
satisfying the following equations, due to Stone,
(B1) ∅⊢x +1 y = x ,
(B2) ∅⊢x +e x = x ,
(SC) ∅⊢x +e y = y +1−e x ,
(SA) ∅⊢(x +e1 y) +e2 z = x +e1e2 (y + e2−e1e2
1−e1e2 z),
for e1,e2 ∈(0,1),
axiomatizing the notion of convex combination of a pair of elements. Any convex
subset of a real vector space satisﬁes these axioms. Barycentric algebras can be
axiomatized in other ways. For example, instead of binary convex combinations one
can introduce n-ary convex combinations for all n ∈N. One of the most important
examples of a barycentric algebra is the set of probability measures on a ﬁnite set or
indeed on more complicated spaces. In Section 10.3.1 we review some probability
theory on metric spaces.
10.2.2 General Results
Given an equational theory U and an algebra A over the same signature, we write
A |= U to mean that A satisﬁes all the judgements in U. As is usual in model
theory, we write U |= (Γ ⊢φ) to mean that the judgement Γ ⊢φ is satisﬁed by any
algebra A for which A |= U holds.
The celebrated Birkhoﬀcompleteness theorem relates the semantic notion of
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

340
Bacci et al.: Quantitative Equational Reasoning
satisﬁability to deducibility (see, for example p. 95 of Burris and Sankappanavar,
1981).
Theorem 10.2 (Completeness). U |= (Γ ⊢φ), if and only if, (Γ ⊢φ) ∈U.
The proof is by construction of a suitable universal model: the algebra TU[X]
over the quotient TX/∼U introduced in Section 10.2.1. We will see that an analogous
result holds in the quantitative case.
Let K(Ω,U) denote the collection of Ω-algebras satisfying all the judgements
in U, i.e., A ∈K(Ω,U) if A |= U; K(Ω,U) becomes a category if we take the
morphisms to be Ω-homomorphisms. If we don't need to emphasize which signature
we use will simply write K(U).
Let X be a set of variables. We have seen that TU[X] is an algebra in K(U).
There is a map ηX : X →TU[X] given by ηX(x) = [x], which is universal in the
following sense:
in Set
in K(U)
X
TU[X]
TU[X]
A
A
α
ηX
h
h
for any algebra A ∈K(U) and function α from X to the underlying set A of A,
there exists a unique algebra homomorphism h: TU[X] →A such that h ◦ηX = α.
In other words any set theoretic function can be uniquely extended to an algebra
homomorphism. This makes TU[X] the free algebra in K(U) generated from X.
The construction of TU[X] from the set X is functorial and such a functor is left
adjoint to the forgetful functor from K(U) to Set. As usual with an adjunction, one
gets a monad: the term monad (TU,η, μ) on the category Set, with unit η: Id ⇒TU
assigning a variable x to the equivalence class [x] of terms provably equal in U,
and multiplication μ: T2
U ⇒TU expressing term composition up to provable
equivalence in U.
Moreover, the (Eilenberg-Moore) algebras for the monad TU are in one-to-one
correspondence with the algebras in K(U); actually this correspondence is and
isomorphism of categories.
The collection of algebras deﬁned by a set of equations is called a variety of
algebras4. A famous theorem, also due to Birkhoﬀ(1935) gives conditions under
which a collection of algebras can be a variety.
Theorem 10.3. A collection of algebras is a variety of algebras if and only if it is
closed under homomorphic images, subalgebras, and products.
4 Please do not confuse this with the notion of algebraic variety which means something completely diﬀerent.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

10.3 Background
341
There are analogous results for algebras deﬁned by Horn clauses: these are
called quasi-variety theorems. Consider Z2 × Z2. It is not a ﬁeld because, e.g.
(1,0) × (0,1) = (0,0); ﬁelds are not supposed to have zero-divisors. Hence ﬁelds
cannot be described by equations.
There is a quantitative analogue of this theorem (see Mardare et al., 2017) but we
will not discuss it in this article as it is rather more technical than is appropriate for
the present chapter.
10.3 Background
We assume that basic concepts of metric and topological spaces are well-known to
the reader.
Deﬁnition 10.4. Apseudometric on a set X is a function d : X × X →[0,∞)
satisfying
∀x ∈X ,
d(x, x) = 0,
∀x, y ∈X ,
d(x, y) = d(y, x),
∀x, y, z ∈X ,
d(x, y) ≤d(x, z) + d(z, y) .
Note that we do not require d(x, y) = 0 implies that x = y; if we impose this
condition we get what is usually called a metric. In a pseudometric one can have
distinct points at 0 distance. The relation of being at zero distance is easily seen
to be an equivalence relation called the kernel of the pseudometric. If we take the
quotient of the underlying space by the kernel there is a natural metric deﬁned on
the equivalence classes which will satisfy the additional axiom above. The concepts
of induced topology, convergence, continuity, completeness all work equally well
with pseudometrics as with metrics.
Let (X, dX), (Y, dY) be two (pseudo)metric spaces. A function f from to X to Y is
non-expansive if for all x, x′ ∈X, dX(x, x′) ≥dY( f (x), f (x′)).
Metric spaces with the non-expansive maps between them form a category, usually
called Met. Although Met has ﬁnite products and, more generally, ﬁnite limits, it
does not have countable products nor binary coproducts. A simple way to recover
completeness of the category, is to work with extended metric spaces: these are
spaces where the metric may take on inﬁnite values.
We deﬁne EMet to be the category where the objects are extended metric spaces
and the morphisms are non-expansiveness maps. In EMet the product of a collection
of spaces, {(Xi, di)}i∈I as the cartesian product of the individual spaces /
i∈I Xi and
the metric between two points (xi)i∈I,(yi)i∈I is supi∈I di(xi, yi). This supremum may,
of course, be inﬁnite; this is ﬁne in EMet but not in Met. Coproducts is EMet are
deﬁned by taking the coproduct as sets, i.e., the disjoint union; the distance between
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

342
Bacci et al.: Quantitative Equational Reasoning
two points in the same component is just whatever it is in the original space, while
the distance between two points in diﬀerent components is ∞. Whenever one has an
extended metric space (X, d), one can deﬁne an equivalence relation ∼by x ∼y iﬀ
d(x, y) < ∞. The equivalence classes are called components and in fact the original
space is just the coproduct of the components. One can extend many standard results
about ordinary metric spaces by using this decomposition. However, some things
require extra caution: for example, Banach's ﬁxed point theorem requires some care.
10.3.1 Measure Theory
Excellent sources for background on measure theory and probability are Billingsley
(1995) or Dudley (1989). A quicker introduction is in Panangaden (2009).
It is a fact that on many familiar spaces, like R, one cannot deﬁne a sensible
measure on all the sets. For example, on the real line one would like a measure
that that co-incides with the concept of length on intervals; but there is no such
measure deﬁned on all subsets of the real line. Accordingly, we have to choose "nice"
families of sets on which one can hope to do measure theory properly. Being able to
take countable unions and sums is the key.
Deﬁnition 10.5. A σ-algebra on a set X is a family of subsets of X which includes
X itself and which is closed under complementation and countable unions.
A set equipped with a σ-algebra is called a measurable space. Given a topological
space, we can deﬁne the σ-algebra generated by the open sets (or, equivalently, by
the closed sets). Here, when we say that a σ-algebra is generated by some family of
sets, say F , we mean the smallest σ-algebra containing F ; which always exists and
is unique. When the σ-algebra is generated by a topology it is usually referred to as
Borel σ-algebra.
Deﬁnition 10.6. Given a σ-algebra (X,Σ), a (subprobability) measure on X is a
([0,1]-valued) [0,∞]-valued set function, μ, deﬁned on Σ such that
• μ(∅) = 0,
• for a countable collection of pairwise disjoint sets, {Ai | i ∈I}, in Σ, we require
μ(

i∈I
Ai) =

i∈I
μ(Ai).
In addition, for probability measures we require μ(X) = 1, while for subprobability
measures we require μ(X) ≤1.
There is a unique measure that one can construct deﬁned on the Borel algebra of
the real line which coincides with the notion of length of an interval: this is called
Lebesgue measure.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

10.3 Background
343
It is worth clarifying how the word "measurable" is used in the literature. Given a
σ-ﬁeld Σ on a set X one says "measurable set" for a member of Σ. Suppose that one
has a measure μ. One can have the following situation. There can be sets of measure
zero which contain non-measurable subsets. Because these sets are not measurable
one cannot say that they have measure zero. This happens with Lebesgue measure
on the Borel sets in the real line, for example. There is a "completion" procedure5
which produces a larger σ-algebra and an extension of the original measure in such
a way that all subsets of sets of measure zero are measurable and have measure zero.
The completion works by adding to the σ-algebra all sets X such that there exist
Y, Z measurable sets with Y ⊆X ⊆Z and with Y and Z having the same measure.
When applied to the Borel subsets of the real line we get a much bigger σ-algebra
called the Lebesgue measurable sets. One often uses the phrase "measurable set" to
mean a set which belongs to the completed σ-ﬁeld rather than the original σ-ﬁeld.
Deﬁnition 10.7. A function f : (X,ΣX) →(Y,ΣY) between measurable spaces is
said to be measurable if ∀B ∈ΣY. f −1(B) ∈ΣX.
A very important class of spaces are the ones that come from metrics.
Deﬁnition 10.8. A Polish space is the topological space underlying a complete,
separable metric space; i.e., it has a countable dense subset.
Note that completeness is a metric concept but being Polish is a topological
concept. A space like (0,1) is not complete in its usual metric, however, it is
homeomorphic to the whole real line which is complete in its usual metric; thus,
(0,1) is a Polish space.
10.3.2 The Giry Monad
A very important monad that arises in probabilistic semantics is the Giry monad
described in Giry (1981). The idea was originally due to Lawvere (1962), who
described a category of probabilistic mappings. Later Giry described the monad
from which Lawvere's category emerges as the Kleisli category.
The underlying category is Mes: the objects are measurable spaces (X,Σ) and
the morphisms f : (X,Σ) →(Y,Λ) are measurable functions. The monad is an
endofunctor: G : Mes →Mes. The explicit deﬁnition is, on objects
G(X,Σ) = {p | p is a probability measure on Σ} .
We need to equip the set G(X,Σ) with a σ-algebra structure. For each A ∈Σ,
deﬁne eA: G(X,Σ) →[0,1] by eA(p) = p(A). We equip G(X,Σ) with the smallest
σ-algebra making all the eA measurable.
5 This is an unfortunate name because it gives the mistaken impression that the result cannot be further extended.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

344
Bacci et al.: Quantitative Equational Reasoning
The action of G on morphisms f : (X,Σ) →(Y,Λ) is given by
G( f ): G(X,Σ) →G(Y,Λ) :
G( f )(p)(B ∈Λ) = p( f −1(B)) .
Here p is a probability measure on (X,Σ). The eﬀect of the functor is to push forward
measures through the measurable function f .
Now we can deﬁne the monad structure as follows: ηX : X →G(X) is given by
ηX(x) = δx, where δx(A) = 1 if x ∈A and 0 if x  A. The monad multiplication is
μX(Q ∈G2(X))(A) =
∫
eAdQ .
One can think of this as an "averaging" over all the measures in G(X) where we use
Q as the weight for the averaging process.
Now we can present the Kleisli category as follows. The objects are the same as
Mes; the morphisms from (X,Σ) to (Y,Λ) are measurable functions from (X,Σ) to
G(Y,Λ). Kleisli composition of h: X →G(Y) and k : Y →G(Z) is given by the
formula:
(k ˜◦h) = μZ ◦G(k) ◦h,
where ˜◦denotes the Kleisli composition and ◦is composition in Mes.
If we curry the deﬁnition of Kleisli morphism from (X,Σ) to (Y,Λ) as h: X ×Λ →
[0,1] we get what are called Markov kernels. We call this category Ker. One can
think of these as the probabilistic analogue of relations just as ordinary relations are
the Kleisli category of the powerset monad. Kleisli composition can be written in
terms of kernels:
(k ˜◦h)(x,C) =
∫
y∈Y
k(y,C)dh(x,·),
for x ∈X and C a measurable subset in Z. In this form the analogy with relational
composition is much clearer. One can also see this as the analogue of matrix
multiplication; if the spaces were ﬁnite sets the kernels would be matrices and this
composition formula would be matrix multiplication.
10.3.3 Metrics between Probability Distributions
Let p,q be probability distributions on a metric space (X, d) equipped with its Borel
σ-algebra Σ. There are a number of important metrics one can place on the space of
probability distributions G(X,Σ).
The most basic is the total variation metric
TV(p,q) = sup
E ∈Σ
|p(E) −q(E)| .
This measures how much p and q disagree on particular measurable sets.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

10.3 Background
345
A more subtle metric is the Kantorovich metric which measures how diﬀerent are
the integrals deﬁned by the two measures being compared. The deﬁnition is
K(p,q) = sup
f
|
∫
f dp −
∫
f dq| ,
with supremum ranging over bounded and non-expansive (which implies continuous)
[0,1]-valued functions f on X. If we allowed any measurable functions then we could
exaggerate the value of the function being integrated on sets where the measures
disagree and obtain an inﬁnite sup every time. One can think of the total variation
metric as a variant of the Kantorovich metric by considering only indicator functions.
However, this is not quite right, as indicator functions are far from non-expansive.
There is an entirely diﬀerent way of thinking of the Kantorovich metric in terms
of transport theory. One thinks of the probability distribution as a "pile of sand" on
the space X. Then one needs to move some sand around to change the shape of
the pile from p to q. Moving a certain amount of sand has a cost associated with
it: this cost is measured by the distance that one has to move the sand. In order to
describe a speciﬁc "plan" for moving sand we introduce a measure on the product
space X × X. A coupling π between p,q is a probability distribution on X × X such
that the marginals of π are p,q; in other words we have
π(A × X) = p(A)
and
π(X × B) = q(B) .
Such a coupling describes a transport plan: π(A × B) describes how much of the
probability mass was moved from A to B.
We write C(p,q) for the space of couplings. Then we have the following theorem
called Kantorovich-Rubinstein duality
K(p,q) =
inf
π∈C(p,q)
∫
d(x, y)dπ(x, y) .
In other words the same metric is given by the cost of the minimum-cost transport
plan. The right hand side can also be taken to be the deﬁnition of the metric. This is
usually incorrectly called the Wasserstein metric6
A small variation of the Kantorovich metric can be obtained as follows:
W(m)(p,q) =
inf
π∈C(p,q)[
∫
d(x, y)mdπ(x, y)]1/m .
If we take m = 1 we get the usual Kantorovich metric. A fundamental fact is that
W(m)(δx,δy) = d(x, y).
6 Both versions of the metric were invented by Kantorovich. Years later Wasserstein used it in a minor way.
Perhaps the fact that Kantorovich used the letter W in his paper added to the confusion. It is also called the
"earth movers' distance" by people in the computer vision community and the Hutchinson metric by researchers
working on fractals.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

346
Bacci et al.: Quantitative Equational Reasoning
This says that the original space is isometrically embedded in the space of probability
measures.
10.3.4 Markov Processes
Markov processes provide the basic operational semantics for probabilistic pro-
gramming languages. A L-labelled Markov process (see Panangaden, 2009) is a
quadruple:
(X,Σ, L,(τa : X × Σ →[0,1])a∈L),
where the τa are Markov kernels. One thinks of a labelled Markov process as a
probabilistic labelled transition system with a state space that may be a general
measurable space or a Polish space.
One can deﬁne a notion of bisimulation as was done by Larsen and Skou (1991)
and later extended to the continuous case in Desharnais et al. (2002).
Deﬁnition 10.9. An equivalence relation R ⊆X × X on the state space of a Markov
Process as above is a bisimulation if whenever x R y, then
for all a ∈L ,
τa(x,C) = τa(y,C)
where C is a measurable union of R-equivalence classes.
Two states x, y are bisimilar if there is some bisimulation relation relating them.
There is a maximum bisimulation relation which we call simply bisimulation. There
is a logical characterization of bisimulation proved in Desharnais et al. (1998, 2002,
2003).
Giacalone et al. (1990) suggested that one move from equality between processes
to distances between processes. In Desharnais et al. (1999, 2004) a pseudometric
was deﬁned whose kernel was bisimulation. If two states are not bisimilar then
some formula distinguishes them. The idea of the metric is: if the smallest formula
separating two states is "big" the states are "close." Later Worrell and van Breugel
(2001) developed a ﬁxed-point deﬁnition of the metric and showed how ideas from
transport theory could be used to compute the metric more eﬃciently.
10.4 Quantitative Equational Logic
As we mentioned in the introduction, the basic idea is to introduce approximate
equations of the form: s =ε t, which we understand to mean that s is within ε
of t. Clearly, the phrase "within ε" is redolent of a metric but the theory has to be
developed to the point where it becomes clear that it is indeed a metric in the precise
technical sense.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

10.4 Quantitative Equational Logic
347
At the outset it should be clear that, whatever else it might be, the binary relation
denoted by =ε is not an equivalence relation. If we have s =ε t and t =ε u there is
no reason to expect s =ε u; indeed one might expect something more like s =2ε u.
The family of relations {=ε| ε ∈[0,∞]} deﬁnes a structure called a uniformity but
we will not stress this aspect here. We need to formalize what it means to reason
with the symbol =ε and see that it really corresponds to a quantitative analogue of
equational reasoning. In order to do this we will state analogues of the results one
has for ordinary equational logic: completeness results, universality of free algebras,
Birkhoﬀ-like variety theorem and monads arising from free algebras.
10.4.1 Quantitative Equations
We begin by following as closely as possible the presentation of ordinary equational
logic. We have a signature Ω and a set of variables X; in the usual inductive way we
get terms denoted by TX. A quantitative equation over these terms is of the form:
s =ε t ,
for s,t ∈TX and ε ∈Q+ .
We use I(TX) to denote the set of quantitative equations over TX. Note that =0
represents ordinary equality =, and consequently, E(TX) ⊆I(TX).
Let Q(TX) be the class of quantitative judgments on TX, which are expressions
of the form
Γ ⊢φ,
with as hypotheses is an enumerable set Γ ⊆I(TX) of quantitative equations and a
quantitative equation φ ∈I(TX) as conclusion. Since we are identifying = with =0,
we observe that J(TX) ⊆Q(TX).
Quantitative equations and quantitative judgments are used for reasoning, and to
this end we deﬁne the concept of quantitative equational theory, which, as might
be expected, will generalize the classical equational theory, in the sense that =0 is
ordinary term equality. However, for ε  0, =ε is not an equivalence: the transitivity
rule has to be replaced by a rule, (Triang) encoding the triangle inequality. We will
also have an inﬁnitary rule, (Cont), that reﬂects the density of rational numbers
within the reals.
A quantitative equational theory of type Ω over X is a set U of quantitative
judgements on TX such that for arbitrary terms s,t,u ∈TX, set of quantitative
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

348
Bacci et al.: Quantitative Equational Reasoning
judgements Γ,Θ ⊆I(TX), and positive rationals ε,ε′ ∈Q+
(Reﬂ) ∅⊢t =0 t ∈U ,
(Symm) {s =ε t} ⊢t =ε s ∈U ,
(Triang) {s =ε u,u =ε′ t} ⊢s =ε+ε′ t ∈U ,
(Max) {s = t} ⊢s =ε+ε′ t ∈U ,
(NExp) {si =ε ti | i ∈κ} ⊢f (si)i∈κ =ε f (ti)i∈κ ∈U ,
for any f : κ ∈Ω,
(Cont) {s =ε′ t | ε′ > ε} ⊢s =ε t ∈U ,
(Subst) if Γ ⊢s =ε t ∈U, then σ(Γ) ⊢σ(s) =ε σ(t) ∈U, for any σ ∈Σ(X),
(Cut) if Θ ⊢Γ ∈U and Θ ⊢s =ε t ∈U, then Γ ⊢s =ε t ∈U ,
(Assum) if s =ε t ∈Γ, then Γ ⊢s =ε t ∈U ,
Given a quantitative equational theory U and a set S ⊆U, we say, as in the
classical case, that S is a set of axioms for U, or S axiomatizes U, if U is the
smallest quantitative equational theory that contains S. A quantitative equational
theory U over TX is inconsistent if ∅⊢x =0 y ∈U, where x, y ∈X are two distinct
variables; U is consistent if it is not inconsistent.
10.4.2 Quantitative Algebras
Now that we have quantitative equations we can turn to deﬁning quantitative
analogues of the concept of algebra. Essentially, one combines the algebraic structure
from Section 10.2.1 with the concept of a metric space.
A quantitative Ω-algebra A = (A, d,ΩA) consists of an extended metric space
(A, d) and a collection ΩA of non-expansive interpretations for each operation
symbol in Ω. If f : a ∈Ω is a function symbol of arity κ, then its interpretation is a
non-expansive function fA : Aκ →A, where Aκ is the κ-fold cartesian product7 of
the metric space A.
An homomorphism from A = (A, dA,ΩA) to B = (B, dB,ΩB) is a non-expansive
homomorphism of Ω-algebras from (A,ΩA) to (B,ΩB).
Fixed a set of variables X and a signature Ω, we would like to deﬁne the quantitative
analogue of the term algebra, but to do so we don't yet have a metric on TX. To do
that, we need to explain what it means for an algebra to satisfy a judgement.
Deﬁnition 10.10. We say that a quantitative Ω-algebra A satisﬁes a quantitative
judgement Γ ⊢s =ε t in Q(TX), written A |= (Γ ⊢s =ε t), if for every assignment
ι: X →A the following implication holds:
 for all (s′ =ε′ t′) ∈Γ, d(ι(s′),ι(t′)) ≤ε′! implies d(ι(s),ι(t)) ≤ε .
7 Note that extended metric spaces have all small products; this is not the case for metric spaces.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

10.4 Quantitative Equational Logic
349
For a quantitative equational theory U, we write A |= U to mean that A satisﬁes
all the judgements in U. We write K(U,Ω) for the collection of Ω-algebras satisfying
U, or simply K(Ω) when the signature is clear.
We can now deﬁne a metric on TX over the quantitative theory U:
dU(s,t) = inf{ε | ∅⊢s =ε t ∈U} .
The idea is that we look at the equations we can derive with the smallest possible ε.
We allow only special judgements with empty set of hypotheses. Why not using the
following?
dU(s,t) = inf{ε | ∀Γ ⊆I(X), Γ ⊢s =ε t ∈U} .
It turns out that it deﬁnes exactly the same metric. Two things are to be noted: ﬁrst
we only have a pseudometric and second, the metric can take on inﬁnite values. To
get a proper quantitative algebra on TU[X], we have to do the analogue of what we
did in the case of ordinary equations: quotient by a suitable equivalence relation.
The kernel of the pseudometric is a congruence for Ω. If we take the quotient we get
an extended metric space.
We call the resulting quantitative algebra on TU[X], the quantitative term algebra
generated from X; by construction is in K(U).
10.4.3 General Results
In this section we describe the quantitative analogues of the results mentioned in
Section 10.2.2. The ﬁrst is completeness which was proved in Mardare et al. (2016).
Theorem 10.11 (Completeness). U |= (Γ ⊢φ), if and only if, (Γ ⊢φ) ∈U.
This is the analogue of the usual completeness theorem for equational logic. From
the right to the left is by deﬁnition. The reverse direction is also a model construction
argument as in the ordinary case but the proof needs to deal with quantitative aspects
and uses the inﬁnitary limit rule (Cont) in a crucial way.
Just as in the ordinary case the construction of the term algebra provides us
with free algebra. The diﬀerence this time is that we start from an extended metric
space instead of just a set. Starting from an extended metric space (M, d) and a
quantitative theory U, we can construct the free quantitative Ω-algebra TU[X]
generated from (M, d), by adding constants for each m ∈M and the judgements
∅⊢m =ε n to the generating quantitative theory U, for every rational ε ∈Q+ such
that d(m,n) ≤ε. Call this extended signature ΩM and the extended theory UM.
Clearly, any algebra in K(ΩM,UM) can be viewed as an algebra in K(Ω,U) by
forgetting the interpretations of the additional constants from M.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

350
Bacci et al.: Quantitative Equational Reasoning
Again, we have a non-expansive map ηM : (M, d) →(TU[M], dUM ), deﬁned as
ηM(m) = [m], which is universal in the following sense:
in EMet
in K(Ω,U)
M
TU[M]
TU[M]
A
A
α
ηM
h
h
for any quantitative algebra A ∈K(Ω,U) and function α from M to the underlying set
A of A, there exists a unique quantitative algebra homomorphism h: TU[M] →A
such that h ◦ηM = α. In other words, TU[M] is the free algebra in K(Ω,U)
generated from the space M.
The construction of TU[M] from the space (M, d) is functorial and gives the
left adjoint to the forgetful functor from K(U) to EMet, the category of extended
metric spaces and non-expansive maps. As usual, this gives rise to a monad on
EMet, namely, the quantitative term monad (TU,η, μ) with unit and multiplication
deﬁned as in the equational case.
Diﬀerently from the equational case, the (Eilenberg-Moore) algebras for the
monad TU are not always in one-to-one correspondence with the algebras in K(U).
However, the isomorphism of categories is recovered in the case the quantitative
theory U is basic, i.e., generated by judgements of the form
{xi =εi yi | i ∈I} ⊢s =ε t
where xi, yi are variables in X (see Bacci et al., 2018).
10.5 Examples
The subject as we have presented it so far may seem like generalization for its own
sake. In fact there are compelling examples that drove this investigation and these
examples come from the world of probabilistic programming.
10.5.1 Axiomatizing the Total Variation Metric
First we return to the example of barycentric algebras from the end of Section 10.2.1.
This time we present it as a quantitative algebra. Recall that the signature of
barycentric algebras has uncountably many binary operations
{+e : 2 | e ∈[0,1]} ,
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

10.5 Examples
351
satisfying the equations below (here given in the form of quantitative judgements)
expressing that +e is the convex combination of pair of elements
(B1) ∅⊢x +1 y =0 x ,
(B2) ∅⊢x +e x =0 x ,
(SC) ∅⊢x +e y =0 y +1−e x ,
(SA) ∅⊢(x +e1 y) +e2 z =0 x +e1e2 (y + e2−e1e2
1−e1e2 z),
for e1,e2 ∈(0,1),
To the above equations, which just use ordinary equality =0, we add a new quantitative
equation schema
(LI) ∅⊢x +e z =ε y +e z ,
for all e ≤ε ∈Q ∩[0,1],
called the left-invariant axiom schema. Here we are using a nontrivial instance of a
quantitative equation.
The barycentric algebras that satisfy (LI) are called left-invariant barycentric
algebras or LIB algebras for short. Denote by ULI the quantitative equational theory
generated form the axioms above. Clearly, the objects in K(ULI) are exactly the
LIB algebras.
If one were to draw a picture of what this means it would violate one's geometric
intuition; it is not meant to be understood in terms of euclidean distance in the
plane. What does this axiomatize? Remarkably, this axiomatizes the total variation
metric on probability distributions. This is striking because no mention was made of
probability in the above axiomatization and of all the metrics that one can imagine
there is nothing in the (LI) axiom schema that suggests the total variation metric.
Here we sketch the ideas, a detailed proof can be found in Mardare et al. (2016).
We know from the general theory that there is a freely generated LIB algebra
from an extended metric space (M, d). What is it concretely? Let us return to this
question after constructing a speciﬁc LIB algebra.
We recall the deﬁnition of the total variation metric from Section 10.3.3:
TV(p,q) = sup
E ∈Σ
|p(E) −q(E)|.
Here p and q are probability distributions on (M, d) with Borel σ-algebra Σ. There
is a beautiful duality theorem for the total variation metric just as there is for the
Kantorovich metric (see Lindvall, 2002) which is based on the notion of coupling
(see Section 10.3.3 for the deﬁnition):
TV(p,q) = min{π() | π ∈C(p,q)} .
where C(p,q) denote the space of couplings and  is the inequality relation on M.
Implicit in this statement is the claim that the minimum is attained.
It is easy to see that a convex combination of couplings is a coupling, hence
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

352
Bacci et al.: Quantitative Equational Reasoning
C(p,q) can be turned into a barycentric algebra. Moreover, one can prove (see
Mardare et al., 2016) that the following splitting lemma holds:
Lemma 10.12. If p,q are Borel probability distributions and e = TV(p,q), then
there are Borel probability distributions p′,q′,r such that
p = ep′ + (1 −e)r
and
q = eq′ + (1 −e)r .
With these tools in hand we investigate the space of Borel probability distributions
on (M, d).
Let Π[M] be the barycentric algebra obtained by taking the ﬁnitely-supported
probability distributions on M and interpreting +e as convex combination; it is
easy to verify that the barycentric axioms hold. Then we endow this algebra of
distributions with the total-variation metric to make it a quantitative algebra. Using
the convexity property of C(p,q) one can prove the following theorem.
Theorem 10.13. Π[M] ∈K(ULI).
Moreover, by using the splitting lemma we can prove:
Theorem 10.14. Π[M] is the free algebra generated from M in K(ULI).
Since free algebras are unique up to isomorphism, Π[M] and the term algebra
TULI [M] generated over the left-invariant barycentric axioms are essentially the
same algebra. In this sense, we say that the axioms of LIB algebras give rise to the
total-variation metric.
10.5.2 Interpolative Barycentric Algebras
We consider a (seemingly) slight variation of the above construction. We have the
same signature as barycentric algebras: we keep the axioms (B1), (B2), (SC), (SA)
but we drop (LI). Instead we add the following quantitative equation schema
(IBm) {x =ε1 y, x′ =ε2 y′} ⊢x +e x′ =δ y +e y′ ,
for all δ ∈Q+ such that
(eεm
1 + (1 −e)εm
2 )1/m ≤δ .
Note that now we have assumptions in the equation so this axiom is a judgment with
a nonempty left-hand side. We call this axiom (IBm), which stands for interpolative
barycentric and the m is a numerical parameter. The barycentric algebras satisfying
(IBm) are called interpolative barycentric algebras or IB algebras for short.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

10.5 Examples
353
To better understand the axiom (IBm), it is more illuminating to look at the special
case where m = 1:
{x =ε1 y, x′ =ε2 y′} ⊢x +e x′ =δ y +e y′ ,
where eε1 + (1 −e)ε2 ≤δ .
We can illustrate this with the picture shown in Figure 10.1.
x
y
x′
y′
x +e x′
y +e y′
ε1
ε2
eε1 + (1 −e)ε2
e
1 −e
Figure 10.1 The interpolative axiom
We can ask the same questions as we asked for the LIB algebras. What are free
IB algebras? We start with an extended metric space (M, d) and consider ﬁnitely-
supported Borel distributions on it, and interpret them as a barycentric algebra as
before. We endow it with the m-Kantorovich metric (see Section 10.3.3) and show
that we get an IB algebra. This uses the deﬁnition of the W(m) metrics as an inf and
convexity of couplings. Again, we can prove a splitting lemma for this case and show
that the space of ﬁnitely-supported probability distributions with the m-Kantorovich
metric is the free IB algebra. The arguments are similar to, but more involved than,
the total variation case (see Mardare et al., 2016 for more details).
In fact one can do more. The ﬁnitely-supported measures are weakly dense in the
space of all Borel probability measures. One can show that the space of all Borel
probability measures on an extended metric space (M, d), call it Gm(M), endowed
with the W(m) metric gives an IB algebra. One can show that if one constructs
the free algebra from (M, d) and then performs Cauchy completion one gets a
quantitative algebra isomorphic to Gm(M) by exploiting the weak denseness of the
ﬁnitely-supported measures.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

354
Bacci et al.: Quantitative Equational Reasoning
10.5.3 Quantitative Exceptions
In this and the next two subsections we discuss quantitative analogues of the
well-known work by Plotkin and Power (2001, 2002, 2003, 2004).
The simplest example of an equational theory of eﬀects is given by the algebraic
theory of exceptions. We ﬁx a set E of exceptions. For a given set of exception E,
the signature is given by a nullary operation symbol raisee : 0 for each exception
e ∈E:
ΩE = {raisee : 0 | e ∈E} .
The theory is simply the trivial one, that is the one that contains only identities t = t
between terms constructed over the signature.
The induced monad on Set, called the exception monad, maps a set A to the set
A + E, the disjoint union of sets A and E.
In the quantitative case one is allowed to view the set of exceptions as an
extended metric space with metric measuring the distance between exceptions. This
interpretation can be useful, for example, in scenarios where exceptions carry the
time-stamps of the moment they have been thrown. In this way one can compare
program implementations by measuring the frequency of which exception are
thrown.
For (E, dE), an extended metric space of exceptions, we deﬁne the quantitative
equational theory of exceptions over E by taking the same signature as above, namely
ΩE, and adding to the theory the quantitative equations
∅⊢raisee1 =ε raisee2 ,
for ε ≥dE(e1,e2)
for any pair of exceptions e1,e2 ∈E and positive rational ε. The role of this axiom
is to lift to the set of terms the underlying metric of E.
The monad TE on EMet induced by this quantitative equational theory is the one
that maps an extended metric space M to the extended metric space M + E, i.e., the
disjoint sum of the extended metric spaces M and E. This example is, admittedly, a
trivial extension of the non-metric case.
10.5.4 Quantitative Interactive Input/Output
For representing interactive input and output using equational theories of eﬀects,
we typically assume a countable alphabet I of inputs and a set O of outputs; for
a signature we take an operation symbol input of arity |I| and a unary operation
symbol outputo, for each output symbol o ∈O
ΩI/O = {input : |I|} ∪{outputo : 1 | o ∈O} .
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

10.5 Examples
355
The meaning behind the operation symbols is that input(t)i represents a computation
that waits for user's input and proceeds as t, if the user's entered input is i; while
outputo(t) represents a computation that outputs o and proceeds as t. For example,
given a mapping f : I →O from inputs to outputs, the term
input(outputf (i)(outputf (i)(t)))i ,
for all i ∈I
represents a computation that waits for the user's input i, repeats the output f (i)
twice, and then proceeds as t. Above, the term input(ti)i abbreviates the countably
branching term
input(ti1,ti2,. . . ),
where i1,i2,. . . is an enumeration of input alphabet I.
The equational theory for interactive input/output is given by the trivial theory over
the signature ΩI/O. The Set-monad TI/O for interactive I/O corresponding to this
equational theory is the free monad on the signature functor ΩI/O(Y) = Y I +(O ×Y),
which is given by the least ﬁxed point
TI/O(X) = μY.(Y I + (O × Y) + X) .
Now we consider the situation where the diﬀerence between the output symbols
produced is measured by a metric. For example we may produce output streams
and there are natural metrics between streams. We assume that (O, dO) is a metric
space of outputs and we deﬁne a quantitative equational theory to capture interactive
input/output eﬀects.
Recall that the general theory for quantitative equations requires every operation
symbol to satisfy the following axiom of non-expansiveness:
{xi =ε yi | i ∈I} ⊢input(xi)i =ε input(yi)i ,
{x =ε y} ⊢outputo(x) =ε outputo(y)
for all o ∈O .
In order to obtain a quantitative theory of interactive input/output eﬀects able to
reﬂect the diﬀerence of two computations producing sequences of outputs symbols,
in addition to the above quantitative equations we require the theory to have the
following axioms:
{x =ε y} ⊢outputo1(x) =δ outputo2(y),
for δ ≥max(ε, dO(o1,o2)),
for each pair o1,o2 ∈O of outputs symbols and positive rationals ε,δ.
As a consequence the theory will also contain the quantitative equation
∅⊢outputa1,...,an(x) =δ outputb1,...,bn(x),
for δ ≥
n
max
i=1 dO(ai, bi),
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

356
Bacci et al.: Quantitative Equational Reasoning
where outputo1,...,on(t) abbreviates the term
outputo1(outputo2(outputo3(. . . outputon(t)))),
representing a computation printing the word o1 · · · on and proceeding as t. Hence
the diﬀerence of printing two words of the same length is quantiﬁed as the maximal
point-wise distance between their characters. There are, of course, other variations
one can imagine.
This quantitative equational theory induces a monad TI/O for interactive in-
put/output determined as the following least ﬁxed point on EMet
TI/O(X) = μY.(Y I + (O × Y) + X) .
10.5.5 Quantitative Side-Eﬀects (State Monad)
To describe state with a ﬁnite set L of locations and a countable metric space (V, dV)
of data values, we take a signature containing an operation symbol lookupl of arity
|V| for each location l ∈L, and a unary operation symbol updatel,v for each location
l ∈L and data value v ∈V.
ΩState = {lookupl : |V| | l ∈L} ∪{updatel,v : 1 | l ∈L and v ∈V} .
The term lookupl(t)v represents a computation that looks up the contents of
location l and proceeds as t if the stored value is v. The term updatel,v(t) represents
a computation that updates the location l with v and proceeds as t. For example, the
term
lookupl1(updatel2,v(t))v
for all v ∈V
represents a computation that copies the contents of l1 into the location l2 and
proceeds as t. Note that, as for the case of the input operation in Section 10.5.4, the
term lookupl(tvi)vi is an abbreviation for the countably branching term
lookupl(tv1,tv2,. . . ),
where v1,v2,. . . is an enumeration of the data values in V.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

10.6 Conclusions
357
The quantitative theory of side-eﬀects is given by the following axioms
∅⊢lookupl(updatel,v(x))v =0 x ,
∅⊢lookupl(lookupl(x)v2)v1 =0 lookupl(y)v1 ,
∅⊢updatel,v1(lookupl(x)v2) =0 updatel,v1(y),
∅⊢updatel,v1(updatel,v2(x)) =0 updatel,v2(x),
∅⊢lookupl1(lookupl2(x)v2)v1 =0 lookupl2(lookupl1(x)v1)v2 ,
∅⊢updatel1,v1(lookupl2(x)v2) =0 lookupl2(updatel1,v1(x))v2 ,
∅⊢updatel1,v1(updatel2,v2(x)) =0 updatel2,v2(updatel1,v1(x)),
{x =ε y} ⊢updatel,v1(x) =δ updatel,v2(y),
for δ ≥max(ε, dV(v1,v2)),
where in the above, the locations l1, l2 are assumed to be distinct: l1  l2.
The ﬁrst four equations describe the behaviour of operations on a single location:
the ﬁrst one says that updating a location with its current contents has no eﬀect; the
second one that the state does not change between two consecutive lookups; the
third one that the state is determined immediately after an update; and the fourth one
that the second update overwrites the ﬁrst one. The next three ordinary equations
state that operations on diﬀerent locations commute. The last equation, which is also
the only truly quantitative one in the above list, states that the diﬀerence between
side-eﬀects depends on the distance of the values observed point-wise in each
location.
The monad on EMet induced by the above axioms maps an extended metric space
M to (S × M)S, where S = V L.
Remark 10.15. If we took an inﬁnite set L of locations, the induced monad would
not be the standard one for state. Since the elements of the free model are built
inductively from operations and represent computations that only update a ﬁnite
number of locations at a time. In contrast, the elements of the standard monad
represent computations that can perform an arbitrary modiﬁcation of the state.
10.6 Conclusions
This chapter introduces a new approach to approximate reasoning. Metrics for
probabilistic processes have been investigated for nearly twenty years by Desharnais
et al. (1999, 2004) and van Breugel and Worrell (2001b,a) and of course the deBakker
school has emphasized metric ideas in semantics for decades. Logics for reasoning
quantitatively have essentially been modal logics that were particularly crafted for
probabilistic systems but a generic way of capturing the notion of approximate
equality has been missing.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

358
References
The approach described in this chapter is just a beginning. We hope that the
striking emergence of the Kantorovich metric as a free algebra from a fairly simple
equational theory is a foretaste of what might be expected in the future. From the
programming point of view we have just presented very simple obvious extensions to
quantitative theories of eﬀects. We are actively investigating a more comprehensive
theory of eﬀects speciﬁcally for probabilistic programming languages. In recent
work (Bacci et al., 2018) we have shown how one can combine diﬀerent monads to
obtain, for example, an equational characterization of Markov processes.
The theory presented here has a number of restrictions introduced for ease of
exposition. For example, nonexpansiveness can certainly be weakened. We know
that we only require nonexpansiveness in each argument separately. However, we
expect that yet weaker conditions are possible, perhaps at the price of complicating
the underlying theory.
A number of other directions for future research are: (i) developing a quanti-
tative term rewriting theory that meshes with quantitative equational logic, (ii)
understanding better how much the bounds degrade as one manipulates sequences
of equations and (iii) algorithms based on quantitative equations. To elaborate
point (ii): in ordinary equational logic, a long series of equations comes without
cost but in quantitative equational logic a long series of quantitative equational
manipulations may well cause the ε's appearing to get larger and larger to the point
of being uninformative. It would be useful to get a handle on the "ergonomics"8 of
quantitative equational reasoning.
Acknowledgements
We have beneﬁtted from many discussions with colleagues. We mention William
Boshuk, Florence Clerc, Vincent Danos, Nathanaël Fijalkow, Marcelo Fiore, Jeremy
Gibbons, Bartek Klin, Dexter Kozen, Alexander Kurz, Bart Jacobs, Paul Levy,
Michael Mislove, Marcin Sabok, Dana Scott and Alexandra Silva. This research has
been supported by a grant from NSERC (Panangaden) and the Danish Research
Council (Mardare, Bacci).
References
Bacci, Giorgio, Mardare, Radu, Panangaden, Prakash, and Plotkin, Gordon D. 2018.
An Algebraic Theory of Markov Processes. Pages 679-688 of: Proceedings of
the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science, LICS
2018, Oxford, UK, July 09-12, 2018.
Billingsley, P. 1995. Probability and Measure. Wiley-Interscience.
8 We thank Jeremy Gibbons for bringing this point to our attention as well as coining this phrase.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
359
Birkhoﬀ, G. 1935. On the structure of abstract algebras. Proc. Cambridge Philos.
Soc., 31, 433-454.
Burris, Stanley, and Sankappanavar, Hanamantagouda P. 1981. A course in universal
algebra. Graduate Texts in Mathematics, vol. 78. Springer-Verlag.
Desharnais, J., Edalat, A., and Panangaden, P. 1998. A Logical Characterization of
Bisimulation for Labelled Markov Processes. Pages 478-489 of: proceedings
of the 13th IEEE Symposium On Logic In Computer Science, Indianapolis.
IEEE Press.
Desharnais, J., Gupta, V., Jagadeesan, R., and Panangaden, P. 1999. Metrics for
Labeled Markov Systems. In: Proceedings of CONCUR99. Lecture Notes in
Computer Science, no. 1664. Springer-Verlag.
Desharnais, J., Edalat, A., and Panangaden, P. 2002. Bisimulation for Labeled
Markov Processes. Information and Computation, 179(2), 163-193.
Desharnais, J., Gupta, V., Jagadeesan, R., and Panangaden, P. 2003. Approximating
Labeled Markov Processes. Information and Computation, 184(1), 160-200.
Desharnais, Josée, Gupta, Vineet, Jagadeesan, Radhakrishnan, and Panangaden,
Prakash. 2004. A metric for labelled Markov processes. Theoretical Computer
Science, 318(3), 323-354.
Dudley, R. M. 1989. Real Analysis and Probability. Wadsworth and Brookes/Cole.
Giacalone, A., Jou, C., and Smolka, S. 1990. Algebraic Reasoning for Proba-
bilistic Concurrent Systems. In: Proceedings of the Working Conference on
Programming Concepts and Methods. IFIP TC2.
Giry, M. 1981. A Categorical Approach to Probability Theory. Pages 68-85 of:
Banaschewski, B. (ed), Categorical Aspects of Topology and Analysis. Lecture
Notes In Mathematics, no. 915. Springer-Verlag.
Hyland, Martin, and Power, John. 2007. The Category Theoretic Understanding of
Universal Algebra: Lawvere Theories and Monads. Electronic Notes in Theor.
Comp. Sci., 172, 437-458.
Hyland, Martin, Plotkin, Gordon, and Power, John. 2006. Combining eﬀects: Sum
and tensor. Theoretical Computer Science, 357(1), 70-99.
Larsen, K. G., and Skou, A. 1991. Bisimulation through Probablistic Testing.
Information and Computation, 94, 1-28.
Lawvere, F. W. 1962. The category of probabilistic mappings. Unpublished
typescript. Available at
ncatlab.org/nlab/files/lawvereprobability1962.pdf.
Lindvall, Torgny. 2002. Lectures on the coupling method. Courier Corporation.
Mardare, Radu, Panangaden, Prakash, and Plotkin, Gordon. 2016. Quantitative
algebraic reasoning.
Pages 700-709 of: Proceedings of the 31st Annual
ACM-IEEE Symposium on Logic in Computer Science.
Mardare, Radu, Panangaden, Prakash, and Plotkin, Gordon. 2017. On the axiomatiz-
ability of quantitative algebras. In: Proceedings of the 32nd Annual ACM-IEEE
Symposium on Logic in Computer Science.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

360
References
Moggi, Eugenio. 1991. Notions of computation and monads. Information and
computation, 93(1), 55-92.
Panangaden, Prakash. 2009. Labelled Markov Processes. Imperial College Press.
Plotkin, Gordon, and Power, John. 2001.
Semantics for algebraic operations.
Electronic Notes in Theoretical Computer Science, 45, 332-345.
Plotkin, Gordon, and Power, John. 2002.
Notions of computation determine
monads. Pages 342-356 of: Foundations of Software Science and Computation
Structures. Springer.
Plotkin, Gordon, and Power, John. 2003. Algebraic operations and generic eﬀects.
Applied Categorical Structures, 11(1), 69-94.
Plotkin, Gordon, and Power, John. 2004. Computational eﬀects and operations: An
overview. Electronic Notes in Theoretical Computer Science, 73, 149-163.
Robinson, Edmund. 2002. Variations on Algebra:Monadicity and generalisations of
equational theories. Formal Aspects of Computing, 13, 308-326.
van Breugel, Franck. 2001. An introduction to metric semantics: operational and
denotational models for programming and speciﬁcation languages. Theoretical
Computer Science, 258(1), 1-98.
van Breugel, Franck, and Worrell, James. 2001a. An Algorithm for Quantitative
Veriﬁcation of Probabilistic Systems. Pages 336-350 of: Larsen, K. G., and
Nielsen, M. (eds), Proceedings of CONCUR'01. Lecture Notes In Computer
Science, no. 2154. Springer-Verlag.
van Breugel, Franck, and Worrell, James. 2001b. Towards Quantitative Veriﬁcation
of Probabilistic Systems. In: Proceedings of the Twenty-eighth International
Colloquium on Automata, Languages and Programming. Springer-Verlag.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

11
Probabilistic Abstract Interpretation:
Sound Inference and Application to Privacya
José Manuel Calderón Trilla
Galois, Inc.
Michael Hicks
University of Maryland, College Park
Stephen Magill
Galois, Inc.
Piotr Mardziel
Carnegie Mellon University
Ian Sweet
University of Maryland, College Park
Abstract:
Bayesian probability models uncertain knowledge and learning from
observations. As a deﬁning feature of optimal adversarial behaviour, Bayesian
reasoning forms the basis of safety properties in contexts such as privacy and
fairness. Probabilistic programming is a convenient implementation of Bayesian
reasoning but the adversarial setting imposes obstacles to its use: approximate
inference can underestimate adversary knowledge and exact inference is impractical
in cases covering large state spaces.
By abstracting distributions, the semantics of a probabilistic language, and
inference, jointly termed probabilistic abstract interpretation, we demonstrate
adversary models both approximate and sound.
We apply the techniques to build a privacy protecting monitor and describe how
to trade oﬀthe precision and computational cost in its implementation all the while
remaining sound with respect to privacy risk bounds.
11.1 Introduction
Bayesian probability is the de facto standard for modeling uncertainty and learning
from observations. Adversaries with uncertain information will employ Bayesian
reasoning if they wish to optimize the eﬀectiveness of their attacks. Defenders
a This research was developed with funding from the Defense Advanced Research Projects Agency (DARPA).
The views, opinions and/or ﬁndings expressed are those of the author and should not be interpreted as
representing the oﬃcial views or policies of the Department of Defense or the US Government.
b From Foundations of Probabilistic Programming, edited by Gilles Barthe and Joost-Pieter Katoen and Alexandra
Silva published 2020 by Cambridge University Press.
361
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

362
Calderón et al: Probabilistic Abstract Interpretation
must build systems assuming such canny attackers or else risk underestimating the
knowledge an adversary can gain and the damage it may inﬂict.
Probabilistic programming, a mechanization of Bayesian reasoning, oﬀers the
requisite elements for doing so. It is a tool for describing adversary knowledge;
for specifying the systems adversaries interact with, including the experiments or
channels through which they make observations; and for deﬁning and verifying
guarantees such as those bounding the damage adversaries can inﬂict.
Unfortunately, using a practical probabilistic programming system may lead one
to draw not entirely trustworthy conclusions about an adversary's bounds. Practical
systems are necessarily approximate, for reasons of performance and expressiveness,
and are often designed with the average or best case in mind, rather than the
worst case. However, when sensitive information is at stake, i.e., in a conservative
risk-averse analysis, an over-approximation of adversarial capabilities is acceptable
but an under-approximation is not.
Probabilistic abstract interpretation is a technique addressing exactly this point:
it is approximate and thus more practical than exact inference but it can be made
approximate in a manner that adversarial risks can be checked soundly, that is, never
underestimated. In our case soundness means simply that any likelihood is never
underestimated. We leverage this guarantee to bound Bayes' vulnerability, a measure
of adversary knowledge and privacy risk.
We begin in Section 11.2 with example privacy and algorithmic fairness properties
that motivate the approach to follow. In Section 11.3 we describe a language and
its probabilistic semantics suitable for deﬁning and verifying those properties. In
Section 11.4 we outline abstractions for probability and for probabilistic interpretation
of programs which we then instantiate in Section 11.5 and develop in Section 11.6.
We then apply abstract interpretation to implement a privacy monitor for limiting
adversary knowledge in Section 11.7. In Section 11.8 we discuss closely related
works and compare our approach with alternatives. We conclude with Section 11.9.
This chapter collects and expands on a progression of work on the development
and use of probabilistic abstract interpretation to compute upper bounds on the
likelihoods of outcomes of systems modeled using probabilistic languages (Mardziel
et al., 2011, 2013; Sweet et al., 2018).
11.2 Quantitative Properties
Across domains from information security to algorithmic fairness, probability
bounds impose limits on the likelihood of undesired outcomes. Consider, for
example, disparate impact ratio and the 80-20 rule (Feldman et al., 2015):
Deﬁnition 11.1 (Disparate Impact Ratio). Given a population random variable X
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

11.2 Quantitative Properties
363
with domain X, a jointly distributed sub-population indicator Z, and a decision
procedure f : X →{+,−}, the disparate impact ratio is the likelihood of a positive
outcome for a minority population as compared to the likelihood of a positive
outcome for the majority population:
DIR (X, f )
def= Pr [ f (X) = + | Z = minority]
Pr [ f (X) = + | Z = majority]
The 80-20 rule states that disparate impact ratio should not fall below 0.8 and is
the basis of arguments of discrimination in the U.S. where legal restrictions limit the
impact of gender, race, and other protected classes on decisions in hiring, housing,
lending, and other areas. Example instantiations of this or similar rules are plentiful
in the algorithmic fairness literature (Feldman et al., 2015).
Deﬁnition 11.2 (Posterior Bayes Vulnerability). Given a prior belief, or background
knowledge, r.v. X about a secret, and a program f : X →Y, the Posterior Bayes
vulnerability is the probability of the most probable input upon observing a particular
program output y.
V (X, f, y)
def= max
x
Pr [X = x | f (X) = y]
Bounds on quantities such as Bayes vulnerability are, likewise, plentiful in the
quantitative information ﬂow literature. They aim to model the potential risk in an
adversary learning the secret input and exploiting it in some manner (Alvim et al.,
2012). In the case of Bayes vulnerability, risk measures the chance an adversary will
guess the secret input in one try after making a particular observation on a given
program (Smith, 2009).
A Privacy Monitor A key thrust throughout this chapter will be the development of
a privacy monitor for a system that permits querying private information but wishes
to enforce bounds on Bayes vulnerability. The setting is motivated by proposals to
move personal private data from centralized services to individuals, allowing them
tighter controls over their own personal data (Seong et al., 2010; Baden et al., 2009).
An online query interface with a privacy monitor allows interested parties to
retrieve only the necessary data with the understanding that diﬀerent parties will
have interest in diﬀerent aspect of the data. For example, consider an individual's full
birth date, which has been shown to be privacy sensitive: along with zip-code1 and
gender, it suﬃces to uniquely identify 87% of Americans in the 1990 U.S. census
(Sweeney, 2000) and 63% in the 2000 census (Golle, 2006). A horoscope application
or "happy birthday" application might request only an individual's birth month and
day while a diﬀerent music recommendation application might instead request a
1 Zip-code is the postal code in the United States.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

364
Calderón et al: Probabilistic Abstract Interpretation
Variables
var ::= X | Y | Z | . . .
Expressions exp ::= var | const | op (exp1,exp2)
Statements stmt ::= var := exp |
skip | stmt1 ; stmt2 |
while exp do stmt |
if exp then stmt1 else stmt2 |
prob p then stmt1 or stmt2 |
var := uniform const1 const2
Figure 11.1 ImpWhile with probability: syntax.
user's age (i.e., birth year). A traditional access control system might restrict one
of these or the other, in order to hide the full date. But doing so excludes some
reasonable applications. A privacy monitor using the Bayes vulnerability bound
may allow services to query components of the birth date as they like as long as the
full birth date is protected up to a given bound.
The privacy monitor is developed in detail in Section 11.7. It appeared originally
in Mardziel et al. (2011), and was further developed in Mardziel et al. (2013)
and Sweet et al. (2018). The monitor was also extended to consider individual
privacy bounds on computations involving multiple parties, each with private
inputs (Mardziel et al., 2012).
11.3 Distribution Semantics
This section presents a minimal, imperative probabilistic programming language and
its formal, mathematical semantics. We will use the language to model systems of
interest, and reason about their properties, including those noted in the prior section.
Figure 11.1 gives the syntax of the language. It is a simple imperative language,
which we call ImpWhile, with (global) variables, (integer) constants, arithmetic
and relational expressions, and statements, which include assignments, no-ops
(skip), sequencing, iteration, and conditionals. ImpWhile programs manipulate
program states, which are maps from variables to their current integer values; these
values may be updated during execution, where the ﬁnal state upon termination is
termed the output state. The language also includes two probabilistic constructs:
probabilistic choice and probabilistic uniform assignment. The former, written
prob p then stmt1 or stmt2, has the following semantics: evaluate statement stmt1
with probability p (a ratio between 0 and 1) or otherwise evaluate statement stmt2.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

11.3 Distribution Semantics
365
X, Y, Z
Variable names.
x, y, z
Variable values.
Σ
def= Variables →Integers
Set of all program states.
σ,τ ∈Σ
Program states.
Σ
def= Σ →[0,1]
Set of all program state distributions.
X,Y,Z ∈Σ
Program state distributions.
ϵ,ϵ
Initial program state, and the point distribution assign-
ing probability 1 to only the initial state.
X(σ)
Probability of state σ in distribution X.
X(exp)
def=
	
σ:exp is true for σ X(σ)
Marginal probability of exp being true in distribution
X.
X(exp1 | exp2)
def=
X(exp1 ∧exp2)/X(exp2)
Marginal probability of exp1 being true conditioned on
exp2 being true in distribution X.
[[stmt]] : Σ →Σ
Concrete state semantics.
[[stmt]] : Σ →Σ
Concrete distribution semantics.
a, b,c ∈A
Regions; abstract program states of domain A.
a,b,c ∈A
Abstract distributions of domain A.
⟨⟨stmt⟩⟩: A →A
Abstract semantics for state domain A.
⟨⟨stmt⟩⟩: A →A
Abstract semantics for distribution domain A.
Table 11.1 Notations and conventions.
Likewise, the uniform assignment X := uniform l u assigns to X an integer value
uniformly at random from the range of integers between l and u inclusive. The
probabilistic elements of this language and their semantics derive from foundational
work on probabilistic programming (Kozen, 1981) and have appeared in a similar
form in the quantitative information ﬂow literature (Clarkson et al., 2009).
Before presenting the semantics of the language, we turn our attention to some
notation, gathered in Table 11.3. This notation will help us talk about the properties
of systems we are interested in. Non-bold capital letters, such as X, Y, and Z are
variable names (as already mentioned). The lowercase counterparts, x, y, and z, are
unspeciﬁed values attainable by variables. Lowercase Greek σ,τ denote program
states, drawn from the set Σ. We write ϵ to denote the initial state, which is the state
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

366
Calderón et al: Probabilistic Abstract Interpretation
that maps all variables to 0. Bold capital letters, X, Y, and Z, denote distributions2
over program states from the set Σ
def= Σ →[0,1].
Some of our conventions for the rest of this chapter depart from the standard
probability conventions used in Deﬁnitions 11.1 and 11.2 due to the use of an
imperative modeling language and the need to manipulate and distinguish distribu-
tions. First, we will no longer use random variables over values like X. Instead, we
use distributions like X and write X(σ) to designate the probability of the state σ
according to the distribution X. Second, we will no longer use f (X) to designate
the r.v. distributing output values of the function f given input values distributed
according to r.v. X. Instead we will write [[stmt]]X to describe the distribution of
output states after the evaluation of statement stmt starting from a distribution of
input states X.
We deﬁne two shorthands to make clear the connection between more familiar
probabilistic notation and the distribution notations in this chapter. Given a boolean
expression exp, we will write X(exp) to denote the marginal probability of the
event that the variable exp is true. That is, X(exp)
def= 	
σ:exp is true for σ X(σ). Given
boolean expressions exp1, exp2, we will write X(exp1 | exp2) to denote the marginal
probability of exp1 being true given exp2 being true. Formally, X(exp1 | exp2)
def=
X(exp1 ∧exp2)/X(exp2). Probabilities such as Pr [ f (X) = + | Z = minority] of
Deﬁnition 11.1 will now be written as ([[stmt]]X) (Y = + | Z = minority). In this
case we assumed stmt is the imperative implementation of f , the variable Y holds
its sole output, and Z holds the minority status of the input individual.3
Now we present the mathematical semantics of the language in Figure 11.1. We
call it the concrete probabilistic semantics [[stmt]]:Σ →Σ (as distinct from abstract
probabilistic semantics which will follow) and it describes the eﬀect of statements
on distributions (of states). It is presented in Figure 11.2. The meaning of a statement
stmt evaluated on a distribution X, written [[stmt]]X, captures informally the process
of evaluating stmt on states sampled according to X, and collecting the results in
a distribution.4 The probabilistic semantics described at the top of Figure 11.2
is deﬁned in terms distribution operations and combinators in the bottom part.
The two shorthand notations for marginal probability and marginal conditioned
probability can likewise be deﬁned in terms of these distribution operators. We note
that distributions for the language are discrete. For space reasons, we omit many
foundational probability theory details.
We can now rephrase our two example properties. Given a population of individuals
X and a program (statement) stmt over some set of variables including protected
class Z representing the individuals' attributes and producing its outcome in variable
2 For simplicity, we often use the term distribution even when we are technically dealing with sub-distributions.
3 When writing f in our language, the minority status { minority, majority } and outcome quality { +, - } would
be encoded as integers.
4 A formal treatment of distribution to distribution semantics ﬁrst deﬁnes the intermediate state to distribution
semantics to describe probabilistic statements and can be found in Clarkson et al. (2009).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

11.3 Distribution Semantics
367
[[skip]]X
def= X
[[X := exp]]X
def= X [X →exp]
[[stmt1 ; stmt2]]X
def= [[stmt2]]([[stmt1]]X)
[[if exp then stmt1 else stmt2]]X
def= [[stmt1]]([[exp]]X) + [[stmt2]]([[¬exp]]X)
[[stmt]]X
def= [[stmt]]([[stmt1]]([[exp1]]X)) + [[¬exp1]]X
where stmt = while exp1 do stmt1
[[prob q then stmt1 or stmt2]]X
def= [[stmt1]](q · X) + [[stmt2]]((1 −q) · X)
[[X := uniform l u]]X
def= 	u
x=l
1
u−l+1 · X [X →x]
X [X →exp]
def= λσ. 	
τ |τ[X→[[exp]]τ]=σ X(τ)
X1 + X2
def= λσ. X1(σ) + X2(σ)
[[exp]]X
def= λσ. if [[exp]]σ then X(σ) else 0
p · X
def= λσ. p · X(σ)
∥X∥
def= 	
σ X(σ)
normal(X)
def=
1
∥X∥· X
X | exp
def= normal([[exp]]X)
Figure 11.2 ImpWhile with probability: probabilistic semantics (top) and distribution operators
and combinators (bottom).
Y, we rewrite Deﬁnition 11.1 as below:
([[stmt]]X) (Y = + | Z = minority)
([[stmt]]X) (Y = + | Z = majority)
(11.1)
Likewise, given a program stmt processing variable X distributed according to
prior states X to output Y, the posterior Bayes vulnerability given output y, as in
Deﬁnition 11.2 is expressed as below:
max
x
{([[ f ]]X) (X = x | Y = y)}
(11.2)
Example 11.3. The Demographicsstmt program below computes a distribution for
the demographics—just the birth year and day—of a population of individuals.
Demographicsstmt
def=
BDAY := uniform 0 364;
BYEAR := uniform 1956 1992
If X0 = [[Demographicsstmt]]ϵ then X0(σ) =
1
365∗37 for states σ that have
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

368
Calderón et al: Probabilistic Abstract Interpretation
σ(BDAY) ∈{0,· · · ,364} and σ(BYEAR) ∈{1956,· · · ,1992}. X0 assigns prob-
ability 0 to all other states.
As the distribution is uniform it is not likely to represent a realistic population.
More realistic distributions, informed from actual demographic reports such as the
U.S. census, can be generated via combinations of the probabilistic choice prob and
uniform assignment uniform statements. Such a distribution could then be used to
represent an adversary's prior knowledge. Further, the abstraction described later in
this chapter relaxes the need to exactly capture background knowledge. A discussion
of background knowledge can be found in Section 11.8.
Example 11.4. The program Birthdaystmt below determines whether an individ-
ual's birth day (of the year) is within the week period starting from what is assumed
to be today.
Birthdaystmt
def=
TODAY := 260;
if BDAY ≥TODAY ∧BDAY < (TODAY + 7) then
OUTPUT := 1
else
OUTPUT := 0
If X1 =  [[Birthdaystmt]]X0
! | (OUTPUT = 0) then X1(σ) =
1
358∗37 for states σ
with σ(BDAY) ∈{0,· · · ,259,267,· · · ,364} and σ(BYEAR) ∈{1956,· · · ,1992}.
X1 assigns 0 probability to all other states.
Example 11.5. The program Decennialstmt determines whether an individual is
in a decennial year (their age is a multiple of 10), or otherwise gets lucky with a
probabilistic draw.
Decennialstmt
def=
AGE := 2011 −BYEAR;
if AGE = 20 ∨AGE = 30 ∨... ∨AGE = 60
then
OUTPUT := 1
else
OUTPUT := 0;
prob 0.1 then OUTPUT := 1 or skip
Let X2 = ([[Decennialstmt]]X1), that is, before conditioning on any particular
output. Then X2 has probability:
• X2(σ)
=
1
358∗37
for states σ with σ(OUTPUT)
=
1, σ(BDAY)
∈
{0,· · · ,259,267,· · · ,364}, and σ(BYEAR) ∈{1991,1981,1971,1961}.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

11.3 Distribution Semantics
369
259
1956
1962
1972
1982
1992
0
267
...
bday
byear
259
1956
1962
1972
1982
1992
0
267
...
bday
byear
1991
1981
1971
1961
(a) X2 | (OUTCOME = 0)
(b) X2 | (OUTCOME = 1)
Figure
11.3 Posterior
distributions
given
starting
demographics
according
to
Demographicsst mt, Birthdayst mt outputs in the negative, and Decennialst mt outputs
in the negative (a) or positive (b).
• X2(σ)
=
1
358∗37 ∗
1
10
for
states
σ
with
σ(OUTPUT)
=
1,
σ(BDAY) ∈{0,· · · ,259,267,· · · ,364}, and σ(BDAY) ∈{1956,· · · ,1992} \
{1991,1981,1971,1961}.
• X2(σ)
=
1
358∗37 ∗
9
10
for
states
σ
with
σ(OUTPUT)
=
0,
σ(BDAY) ∈{0,· · · ,259,267,· · · 364}, and σ(BYEAR) ∈{1956,· · · ,1992} \
{1991,1981,1971,1961}.
• X2(σ) = 0 for all other states σ.
The mass of the positive outcomes, ∥[[OUTPUT = 1]]X2∥, is
73
370 while the
mass of the negative outcomes, ∥[[OUTPUT = 0]]X2∥, is 297
370. Combining the
probabilities above with the masses, we let X+
2 = X2 | (OUTCOME = 1) and
X−
2
def= X2 | (OUTPUT = 0) have probabilities as below:
• X+
2(σ)
=
1
358∗37/ 73
370
=
10
358∗73
for
states
σ
with
σ(BDAY)
∈
{0,· · · ,259,267,· · · ,364} and σ(BYEAR) ∈{1991,1981,1971,1961}.
• X+
2(σ)
=
1
358∗37 ∗
1
10/ 73
370
=
1
358∗73
for states σ with σ(BDAY)
∈
{0,· · · ,259,267,· · · ,364}
and
σ(BYEAR)
∈
{1991,1981,1971,1961} \
{1991,1981,1971,1961}.
• X+
2(σ) = 0 for all other states σ.
• X−
2(σ)
=
1
358∗37 ∗
9
10/297
370
=
1
358∗33
for states σ with σ(BDAY)
∈
{0,· · · ,259,267,· · · ,364}
and
σ(BYEAR)
∈
{1991,1981,1971,1961} \
{1991,1981,1971,1961}
• X−
2(σ) = 0 for all other states σ.
The two posterior distributions are visualized in Figure 11.3 with negative outcome
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

370
Calderón et al: Probabilistic Abstract Interpretation
on the left and positive outcome on the right. Darker regions correspond to higher
probability.
As described and exempliﬁed, the probabilistic semantics are exact. Computational
issues, however, make it diﬃcult to directly apply these semantics in practice. When
the space of states becomes large, several aspects of the semantics and deﬁnitions
become intractable. The assignment statement (see Figure 11.2) and the conditioning
operator require sums to enumerate over potentially large number of states or even
all possible states. Likewise, properties like Bayes vulnerability refer to all possible
marginal states (X = x). Finally, while loops may require potentially an inﬁnite
number of iterations to evaluate. In the next section we introduce abstractions that can
overcome the state-space problems and conclude with a discussion on the problem
of adapting abstract interpretation techniques for analyzing looping constructs to the
probabilistic case.
11.4 Abstraction
Abstract interpretation is a technique for making tractable the veriﬁcation of otherwise
intractable program properties (Cousot and Cousot, 1977). As the term implies,
abstraction is its main principle: instead of reasoning about potentially large sets of
program states and behaviours, we abstract them and reason in terms of their abstract
properties. We begin by describing the two principal aspects of abstract interpretation
in general: an abstract domain and abstract semantics over that domain.
Deﬁnition 11.6 (Abstract Domain). Given a set of concrete objects C an abstract
domain A is a set of corresponding abstract elements as deﬁned by two functions:
• an abstraction function α : 2C →A, mapping sets of concrete elements to
abstract elements, and
• a concretization function γ : A →2C, mapping abstract elements to sets of
concrete elements.
In this chapter, C will be instantiated to either program states Σ or distributions
Σ over program states. In either case, we assume that concrete program semantics
for these elements are given. Because you can view a program's state as a point in
a multidimensional space, we often refer speciﬁc sets or distributions of program
states as regions.
We will ignore the abstraction function. For convenience we will consider abstract
domains that can be deﬁned as predicates over concrete states. I.e., γ : a →
{c ∈C : ϕa(c)} where ϕa is a predicate parameterized by the abstract element a.
The second aspect of abstract interpretation is the interpretation part: an abstract
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

11.4 Abstraction
371
Figure 11.4
The (over)approximation of a polyhedron (black) using an octagon (shaded, left)
and an interval (shaded, right).
semantics, written ⟨⟨stmt⟩⟩: A →A. We require that the abstract semantics be
sound in that it over-approximates the concrete semantics.
Deﬁnition 11.7 (Sound Abstraction). Given an abstract domain A and its abstract se-
mantics, the abstraction is sound if whenever c ∈γ (a) then [[stmt]]c ∈γ (⟨⟨stmt⟩⟩a).
Abstractions generally sacriﬁce some precision: the abstraction of a set of elements
C can be imprecise in that γ(α(C)) contains strictly more than just C and likewise
that γ (⟨⟨stmt⟩⟩a) contains strictly more elements than {[[stmt]]c : c ∈γ (a)}. For
this reason, an analysis satisfying Deﬁnition 11.7 is called a may analysis in that it
contains the set of all states that may arise during program execution.
Numeric abstractions A large class of abstractions are designed speciﬁcally to
model numeric values; in this chapter we restrict ourselves to integer-valued variables.
The interval domain I represents "boxes" or non-relational bounded ranges of values
for each variable Xi in a state (Cousot and Cousot, 1976):
γ : {(li,ui)}i →{σ ∈Σ : li ≤σ(Xi) ≤ui for every i}
Abstract elements here are sets of bound pairs, li and ui, forming the lower and
upper bound, respectively, for every variable Xi. Intervals are eﬃcient to compute,
but imprecise, in that they cannot characterize invariants among variables. More
precise, but less eﬃcient numeric domains can be used.
More generally, an abstract domain can be deﬁned in terms of a set of predicates
over states, interpreted conjunctively:
γ :

φj

j →

σ ∈Σ : φj(σ) for every j

Restrictions on the types of predicates allowed deﬁne a family of abstractions.
Examples include intervals I already mentioned, polyhedra P where φj are restricted
to linear inequalities, and octagons (Miné, 2001) where the linear inequality
coeﬃcients are further restricted to the set {−1,0,1}. Polyhedra and octagons are
relational in that they allow precise representations of states that constrain variables
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

372
Calderón et al: Probabilistic Abstract Interpretation
in terms of other variables (note this is not the case for intervals). In terms of
tractability, intervals are faster to compute with than octagons which are faster
than polyhedra. Precision follows the reverse ordering: polyhedra are more precise
than octagons which are more precise than intervals. In other words, intervals can
over-approximate the set of points represented by octagons which themselves can
over-approximate the set of points represented by polyhedra. This relationship is
visualized in Figure 11.4.
Other domains are speciﬁcally tailored to eﬃcient analysis of particular types
of systems. These include grids (Bagnara et al., 2006) for precisely handling
modulo operations and domains designed for analysis of numeric values with
overﬂow/underﬂow (Simon and King, 2007).
Abstract domains implement a set of standard operations including:
• Meet, a ⊓b is the smallest region containing the set of states in the intersection
of γ (a),γ (b). For convex linear domains this operation is least expensive and is
exact.
• Join, a ⊔b is the smallest region containing both γ (a) and γ (b). For linear convex
domains, this is supported by the convex hull operation.
• Transform, a [x →exp], computes an over-approximation of the state-wise assign-
ment x →exp. In the case of invertible assignments, this operation is supported
by linear domains via aﬃne transformation. Non-invertible assignments require
special consideration (Mardziel et al., 2011).
Abstraction combinators Abstractions can also be extended disjunctively as in
the powerset construction (Giacobazzi and Ranzato, 1998). For a base domain A,
the powerset 2A domain has concretization:
γ :

aj

j →

σ ∈Σ : σ ∈γ  aj
! for some j

= ∪jγ  aj
!
That is, an abstract element in 2A is itself a set of base elements from A and represents
the set of states represented by at least one of its constituents base elements.
Abstraction in the manner outlined can also be applied to probability distributions
which serve as the concrete elements. Earlier techniques (Monniaux, 2001) attached
probability constraints to standard state domains. Given a state domain A we form
the probabilistic (upper bound) domain D (A) that adds a probability bound on all
states represented by the base domain elements:
γ : (a, p) →{X ∈Σ : X(σ) ≤p for all σ ∈γ(a)}
We can combine the probabilistic upper bound construction the powerset con-
struction to deﬁne a domain for representing more complex distributions. A more
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

11.5 Sound Domains with Conditioning
373
expressive variant of powerset for probabilistic abstractions imposes a sum bound
(as opposed to disjunction of bounds):
γ :

(aj, pj)

j →
⎧⎪⎪⎨
⎪⎪⎩
X ∈Σ : X(σ) ≤

j:σ∈γ(aj)
pj for every σ
⎫⎪⎪⎬
⎪⎪⎭
We emphasize in these abstractions the focus on the upper bounds of probability;
such abstractions do not explicit track lower bounds (beyond the assumed trivial 0).
That is, for any probabilistic abstraction a and any state σ, there exists X ∈γ (a)
such that X(σ) = 0. Because of this, these upper bound abstractions lack sound
deﬁnitions of conditioning. Recall Bayes' rule or the deﬁnition of conditioning
in Figure 11.2 that involves a normalization by total mass of a (sub)distribution.
Upper bounds alone cannot exclude the possibility of 0 as the total mass in the
denominator. Posterior Bayes vulnerability of Deﬁnition 11.2 features conditioning
by program output and disparate impact ratio of Deﬁnition 11.1 features probability
in the denominator. Thus neither of these conditions can be soundly checked using
purely upper-bound abstractions of probability described thus far.
11.5 Sound Domains with Conditioning
As suggested, sound inference needs to account for both lower and upper bounds on
probability. The dual-bounded probabilistic construction does exactly this (Mardziel
et al., 2011)5. In this Section we deﬁne this domain. In the next section we outline
representative aspects of the implementation of its abstract semantics and outline
soundness proofs.
The construction imposes probability bounds along with several other constraints
used to preserve precision in the implementations of abstract operators to follow.
Deﬁnition 11.8. Given a state domain A, the dual-bounded probabilistic domain
D (A) is occupied by probabilistic regions deﬁned by 4-tuples (a, s, p,m). A proba-
bilistic region represent distributions satisfying 4 constraints: a ∈A bounds their
support, s = (smin,smax) bounds their number of support points, p = (pmin,pmax)
bounds their probability mass per support point, and m = (mmin,mmax) bounds their
total probability mass (recall we are working with sub-distributions). Formally these
conditions deﬁne the concretization function:
γ (a, s, p,m) →
⎧⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎩
X ∈Σ : support(X) ⊆γ(a),
smin ≤∥support(X)∥≤smax,
mmin ≤∥X∥≤mmax,
pmin ≤X(σ) ≤pmax for every σ ∈support(X)
⎫⎪⎪⎪⎪⎪⎪⎬
⎪⎪⎪⎪⎪⎪⎭
5 This is a generalization of the probabilistic polyhedra domain from earlier work (Mardziel et al., 2011).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

374
Calderón et al: Probabilistic Abstract Interpretation
We will use non-bold lowercase a to denote abstract states and bold lowercase a
to denote dual-bounded probabilistic regions. We will refer to the p parameters as
the point bounds, the s parameters as size bounds, the m parameters as mass bounds,
and the a parameter as the support bound.
This probabilistic construction applies to base domains that implement the standard
set of abstract operations from the prior section in addition to the counting operation:
• Region size, written #(a), is the number of states (integer vectors in the case
of integer-valued states being modeled) in the region, i.e., ∥γ (a)∥. For some
domains this is an expensive model counting operation and requires specialized
tools such as Latte (De Loera et al., 2008). On the other hand, for other domains
like intervals, this operation is trivial.
For convenience in the rest of this chapter, we use two additional operations that
can be deﬁned using the standard operations and size.
• Boolean expression conjunction on a region a, written ⟨⟨exp⟩⟩a, returns a region
containing at least the points in a that satisfy exp. This is the abstract equivalent
of [[exp]]σ of Figure 11.2.
• Boolean expression count on a region a, written as a#exp, is an upper bound on
the number of points in a that satisfy exp.
Example 11.9. In the powerset of probabilistic polyhedra D (P), we can represent
the negative outcome distributions of Figure 11.3(a), before normalization, with
two probabilistic polyhedra a1 and a2 containing polyhedra a1 and a2 bounding
regions 0 ≤BDAY ≤259,1956 ≤BYEAR ≤1992 and 267 ≤BDAY ≤354,1956 ≤
BYEAR ≤1992, respectively. The other parameters for a1 would be as follows:
pmin
1
= pmax
1
= 9/135050 =
1
37∗365 ∗9
10
smin
1
= smax
1
= 8580 = 260 ∗33
mmin
1
= mmax
1
= 7722/13505 = pmin
1
∗smin
1
Notice this over-approximation loses the fact that the states with BYEAR ∈
{1991,1981,1971,1961} have 0 probability in the concrete semantics. This is also
evident in that smin
1
= smax
1
= 8580 < #(a1) = 9620, illustrating that the "bounding
box" of the polyhedra covers more area than is strictly necessary for precision.
For the positive outcome of Figure 11.3(b), we can use the same two polyhedra
a1 and a2 with the other parameters for a1 as follows:
pmin
1
= 1/135050 =
1
37∗365 ∗1
10
pmax
1
= 10/135050 =
1
37∗365
smin
1
= 9620 = 260 ∗37
smax
1
= 9620 = 260 ∗37
mmin
1
= 26/185
mmax
1
= 26/185
(11.3)
In this case smin
1
= smax
1
= #(a1), meaning that all covered points are possible,
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

11.6 Abstract Semantics
375
but pmin
1
 pmax
1
as some points are more probable than others (i.e., those in the
darker band). An astute reader might notice that here mmin
1
 pmin
1
∗smin
1
and
mmax
1
 pmax
1
∗smax
1
. The beneﬁt of these seemingly redundant total mass quantities
in the representation is that they can sometimes be computed precisely. In this
case mmin
1
= mmax
1
=
4
37 ∗260
365 + 1
10 ∗33
37 ∗260
365. This quantity is the probability of
Decennialstmt returning 1 composed of having a decennial (ﬁrst term) plus not
having a decennial (second term).
Notice that the exempliﬁed representations are only some among many reasonable
options. First, the use of polyhedra as a base domain was not necessary and intervals
alone would have been suﬃcient. Second, more precise representations could have
been constructed by using more than just two probabilistic polyhedra (or intervals).
On the other hand, even less precise representations would use only a single
probabilistic polyhedron (interval). Further nuances come into play for schemes
with powerset abstractions that employ a dynamic number of probabilistic regions
that can increase or decrease in the process of evaluating programs. How to best
employ the representation power of powerset domains is not trivial remains an open
problem.
11.6 Abstract Semantics
The abstract semantics for dual-bounded probabilistic regions is deﬁned identically
to concrete semantics in Figure 11.2(top) except with supplanting each of the
concrete operations/combinators of Figure 11.2 (bottom) with abstract versions that
operate on abstract distributions instead of concrete distributions. Soundness of the
abstraction is then shown inductively on language statements from the soundness of
the abstracted operations and combinators. We present some of these operations in
this section; the full set of operations as well as the corresponding proofs can be
found in Mardziel et al. (2013).
Abstract Conjunction The concrete conjunction operation restricts a distribution
to states satisfying a boolean expression, nullifying probability mass of states that do
not: [[exp]]X
def= λσ. if [[exp]]σ then X(σ) else 0. Using the expression conjunction
and count for abstract states, we develop the abstract conjunction for probabilistic
regions as follows.
Deﬁnition 11.10. Given a probabilistic region a1 = (a1, s1, p1,m1) and boolean
expression exp, let n = a#exp and n = a#(¬exp) . That is, n is an over-approximation
of the number of states in a that satisfy the condition exp and n is an over-
approximation of the number of points in a that do not satisfy exp. Then, ⟨⟨exp⟩⟩a1
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

376
Calderón et al: Probabilistic Abstract Interpretation
is the probabilistic region a2 = (a2, s2, p2,m2) deﬁned by the parameters enumerated
below.
pmin
2
= pmin
1
smin
2
= max

smin
1
−n,0

pmax
2
= pmax
1
smax
2
= min

smax
1
,n

mmin
2
= max

pmin
2
· smin
2 , mmin
1
−pmax
1
· min

smax
1
,n

mmax
2
= min

pmax
2
· smax
2
, mmax
1
−pmin
1
· max

smin
1
−n,0

a2
= ⟨⟨exp⟩⟩a1
The soundness requirement for this and subsequent operations stipulates an
inclusion relation between the concrete variant and the abstract variant. In the case
of conjunction the statement is is thus: if X ∈γ (a) then [[exp]]X ∈γ (⟨⟨exp⟩⟩a).
Abstract Plus The concrete plus operation combines mass of two given distributions:
X1 + X2
def= λσ. X1(σ) + X2(σ). The abstract counterpart over-approximates the
result. Speciﬁcally, if X1 ∈γ (a1) and X2 ∈γ (a2) then X1 + X2 ∈γ (a1 + a2). For
the remainder of the chapter, we will leave the association between a probabilistic
region, a, and its constituents, (a, s, p,m), implicit. When more than one probabilistic
region is being discussed, the subscripts of the tuple elements will match the
subscript of the region.
The abstract sum of two probabilistic regions is deﬁned diﬀerently depending on
whether their support regions overlap. In the case they do not overlap, the sum a3
has a3 = a1 ⊔a2 and parameters as below:
pmin
3
=
min

pmin
1 ,pmin
2

pmax
3
=
max

pmax
1
,pmax
2

smin
3
=
smin
1
+ smin
2
smax
3
=
smax
1
+ smax
2
mmin
3
=
mmin
1
+ mmin
2
mmax
3
=
mmax
1
+ mmax
2
Otherwise, a1 and a2 overlap. We ﬁrst determine the minimum and maximum
number of points in the intersection that may be support points for both a and
for b. We refer to these counts as the pessimistic overlap and optimistic overlap,
respectively.
Deﬁnition 11.11. Given two distributions X1,X2, we refer to the set of states that are
in the support of both X1 and X2 as the overlap of X1,X2. The pessimistic overlap of
a and b, denoted a  b, is the cardinality of the smallest possible overlap between
any two distributions X1 ∈γ (a) and X2 ∈γ (b) and the optimistic overlap a  b is
the cardinality of the largest possible overlap. They are computed as follows:
a  b
def= max
1
smin
1
+ smin
2
−
(
#(a) + #(b) −#(a ⊓b)
)
, 0
2
a  b
def= min

smax
1
,smax
2
,#(a ⊓b)

https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

11.6 Abstract Semantics
377
The pessimistic overlap is derived from the inclusion-exclusion principle
∥A ∩B∥= ∥A∥+ ∥B∥−∥A ∪B∥while the optimistic overlap cannot exceed
the support size of either distribution or the size of the intersection.
Deﬁnition 11.12. The abstract sum of a and b, written a + b, is the probabilistic
region c with parameters as follows:
c
=
a ⊔b
pmin
3
=

pmin
1
+ pmin
2
if a  b = #(c)
min

pmin
1 ,pmin
2

otherwise
pmax
3
=

pmax
1
+ pmax
2
if a  b > 0
max

pmax
1
,pmax
2

otherwise
smin
3
=
max

smin
1
+ smin
2
−a  b, 0

smax
3
=
min

smax
1
+ smax
2
−a  b, #(c)

mmin
3
=
mmin
1
+ mmin
2
|
mmax
3
= mmax
1
+ mmax
2
The setting of parameters in the sum is chosen to be as precise as possible while
maintaining soundness: if X1 ∈γ (a) and X2 ∈γ (b) then X1 + X2 ∈γ (a + b). The
two cases for pmin
3
derive from: (ﬁrst case) the overlap between the operands is
complete (the support of both is identical) and (second case) there is a possibility of
a non-overlapping state that is in support of one of the operands but not the other.
Likewise, the cases for pmax
3
derive from: (ﬁrst case) there is a possibility of support
point overlap and (second case) there is no overlap possible between the operands.
The size parameters follow from the inclusion-exclusion principle and the mass
parameter is a mere sum that does not depend on where the operands distribute their
probability mass.
Together the abstract operation soundness claims (see Mardziel et al. (2013) for
the rest and their proofs) imply soundness of the abstract semantics:
Theorem 11.13 (Abstraction Semantics Soundness). If X ∈γ (a) then [[stmt]]X ∈
γ (⟨⟨stmt⟩⟩a).
Abstract Normalization Critically, the dual-bounded probabilistic domain allows
us to soundly deﬁne the conditioning operation which in turn is deﬁned primarily
via normalization operation. The normalization of a (sub) distribution produces a
distribution whose total mass is equal to 1: normal(X)
def=
1
∥X∥· X. If a probabilistic
region a has mmin = 1 and mmax = 1 then it represents a normalized distribution. We
deﬁne below an abstract counterpart to distribution normalization for transforming
an arbitrary probabilistic region into one containing only normalized distributions.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

378
Calderón et al: Probabilistic Abstract Interpretation
Deﬁnition 11.14. Assuming mmin
1
> 0, normal(a1) is the normalized region a2
with:
pmin
2
=
pmin
1
/mmax
1
smin
2
=
smin
1
pmax
2
=
pmax
1
/mmin
1
smax
2
=
smax
1
mmin
2
=
mmax
2
= 1
a2
=
a1
The normalization operator illustrates the interaction between under and over
approximation of probability in the abstraction: to ensure that the over-approximation
of a state's probability (pmax) is sound, we must divide by the under-approximation
of the total probability mass (mmin). This results in abstract normalization that is
sound: If X ∈γ (a) and X has non-zero mass, then normal(X) ∈γ (normal(a)).
Together with soundness of abstract conjunction presented earlier in this section
we arrive at the main goal of this work.
Theorem 11.15 (Soundness of Conditioning). If X ∈γ (a) and exp has non-zero
marginal probability in X then X | exp ∈γ (a | exp).
We can now show how to use our abstraction to soundly over-approximate
quantities such as disparate impact ratio (Deﬁnition 11.1) and posterior Bayes
vulnerability (Deﬁnition 11.2). We deﬁne upper and lower bounds on the probability
of states as well as the marginal probability bounds for boolean expressions according
to a dual-bounded probabilistic region.
Deﬁnition 11.16. Given probabilistic region a and a boolean expression exp,
the upper and lower bounds on the marginal probability of exp are deﬁned as
amin (exp)
def= mmin
1
and amax (exp)
def= mmax
1
where the mass bound parameters are
those of the probabilistic region a1 = ⟨⟨exp⟩⟩a. The upper and lower state bounds
are the bounds on the probability of any single (possible) state and are deﬁned
amin
def= pmin
1
and amax
def= pmax
1
.
Corollary 11.17. The marginal and state probability bounds are sound. That is, for
every X ∈γ (a):
amin (exp) ≤X (exp) ≤amax (exp)
For every σ ∈support(X):
amin ≤X(σ) ≤amax
Notice that the state bounds quantities amin and amax bound the probability of all
support states (state with non-zero probability). Quantities such as vulnerability can
thus be checked using state bounds without enumerating every possible state.
Returning to disparate impact ratio, let X be a distribution of individuals with
variable Z referring to minority status and presume we have X ∈γ (a). Let
a
def= ⟨⟨stmt⟩⟩(a | Z = minority) and b
def= ⟨⟨stmt⟩⟩(a | Z = majority).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

11.6 Abstract Semantics
379
([[stmt]]X) (Y = + | Z = minority)
([[stmt]]X) (Y = + | Z = majority) ≤(a)max (Y = +)
(b)min (Y = +)
Note that though the abstraction, its semantics, and operations allow us to soundly
check a disparate ratio bound, this check is outside the syntax and semantics of the
language modeled. Though some languages support both probabilistic interpretation
and subsequent manipulation of resulting distributions in the same host language,
this is not a goal of our toy language and manipulations of distributions like those
in the disparate impact ratio bound above have to be done in a separate language
hosting the probabilistic interpreter.
In the next section we show how to use the state probability bound, an indicator
of the probability of any support point in a distribution, to construct a vulnerability-
based privacy monitor.
Powerset Bounds Single regions are ﬁrmly on the tractability side of the tractabil-
ity/accuracy trade-oﬀ. Probabilistic regions can be additively combined using a
probabilistic powerset construction of Section 11.4. There an abstract probability
distribution is composed of a set of simpler abstract probability distributions (in
our case dual-bounded probabilistic regions). The set represents all distributions
equal to the distribution sum of the distributions represented by each of the abstract
elements:
γ :

aj

j →

X ∈Σ : X =

j
Xj where Xj ∈γ  aj
!

For sound base probabilistic abstractions as per Theorem 11.13 and with sound
event probability bounds as per Corollary 11.17, the powerset construction provides
similarly sound results. Details including the set operations taking part of the abstract
interpretation, the probability bound deﬁnitions, and proofs can be found in Mardziel
et al. (2013).
Widening A distinguishing aspect of abstract interpretation as compared to other
static analysis techniques is its handling of looping programs. Recall the semantics
of while:
[[stmt]]X
def=
[[stmt]]([[stmt1]]([[exp1]]X)) + [[¬exp1]]X
where stmt = while exp1 do stmt1
Notice the ﬁrst term includes the evaluation of the same while statement as we
are deﬁning the semantics of. We rewrite this as a monotonic sequence Yi via a
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

380
Calderón et al: Probabilistic Abstract Interpretation
recursive deﬁnition Xi (along with the abstract version of the same):
X0
def= X
a0
def= a
Xi+1
def= [[stmt1]]([[exp1]]Xi)
ai+1
def= ⟨⟨stmt1⟩⟩(⟨⟨exp1⟩⟩ai)
Yn
def=
n

i=0
[[¬exp1]]Xi
bn
def=
n

i=0
⟨⟨¬exp1⟩⟩ai
(11.4)
The result of [[stmt]]X is the ﬁxed-point of the sequence Yi, a point i at which
Yi+1 = Yi. The problem is that reaching the ﬁxed-point may require large number of
iterations. Given the motivation of large state spaces, it is plausible that the number
of iterations in a loop is likewise large. Worse yet, in the abstract version of the
semantics where abstractions may include concretely unrealizable distributions due
to precision loss, the ﬁxed-point may not be achieved in any ﬁnite number of steps
even if the while loop terminates concretely.
Abstract interpretation employs the widening operator to make sure ﬁxed-point
computations take only a ﬁnite number of iterations. Let ⊑be an ordering on
abstractions respecting the subset relation in their concretizations ( a ⊑b implies
γ (a) ⊆γ (b) ).
Deﬁnition 11.18. A widening operator ∇is a binary operator that deﬁnes for every
ascending chain of abstractions ci ⊑ci+1, a chain c′
0
def= c0, c′
i+1
def= c′
i∇ci+1 that
over-approximates the original chain (c′
i ⊑ci) and has a ﬁnite ﬁxed-point (c′
i+1 = c′
i
for some ﬁnite i).
The abstract semantics of a while loop written as bn of Equation 11.4 constitutes
an ascending chain and it can thus be over-approximated with a chain having a ﬁnite
ﬁxed-point by employing widening. Practically, for a widening operator to be deﬁned
for an abstraction, it must come with an ordering and must be able to represent
potentially inﬁnite concrete states. For example, the interval domain constraints
allows for variable bounds to be one-sided or even unbounded. That is, constraints for
variables to ranges like [c,+∞], [−∞,c], and [−∞,+∞], for constant c, are possible.
The state abstractions discussed in this chapter all come with widening operators
including the powerset constructions.
Widening for probabilistic abstractions, however, is another matter. For the integer-
valued programs discussed, the techniques we described rely heavily on counting
states. Merely admitting inﬁnite state counts into the counting arguments of this
section result in total loss of precision, distribution representations whose probability
bounds are uselessly between 0 and 1. As a result, deﬁning abstractions with
non-trivial widening operators for probabilistic semantics with sound conditioning
remains an open problem.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

11.7 Privacy Monitor
381
11.7 Privacy Monitor
In this section demonstrate an application of state bounds to an implementation of
an online query privacy monitor. Such a monitor allows clients to query private
information while owner can measure how much has been revealed by the queries
and can decide to block queries that would otherwise reveal too much. Mardziel
et al. (2011) motivate the use of such a system for retaining individual control
over personal information while selling partial access to entities such as advertiser
who might themselves derive full ﬁnancial beneﬁt from only limited access. A
birthday cake merchant, for example, might be content with knowing that a user's
birthday is within the next week in order to oﬀer them a coupon (as in the program
Birthdaystmt). An online query scheme allows the merchant to get the information
they need and nothing else. On the other hand, repeated queries reveal additional
information hence the proposed system tracks the knowledge of each querying party
while interacting with the monitor.
The primary tool for monitor is the upper state probability bound with which
posterior vulnerability can be soundly estimated. Given a program (the query)
stmt processing variable X distributed according to prior states X to output Y and
X ∈γ (a), we bound the posterior Bayes vulnerability given output y:
max
x
{([[ f ]]X) (X = x | Y = y)} ≤(⟨⟨stmt⟩⟩a | Y = y)max
def= V (a,stmt, y)
Speciﬁcally, the right hand inequality gives us a conservative overestimate of
the risk in revealing the output y of the program stmt to an adversary whose prior
knowledge is X ∈γ (a) where risk is the likelihood that the adversary can guess
value of the secret X correctly in one try. We will refer to the vulnerability bound
based on the abstraction a as V (a,stmt, y).
A common objection to privacy properties such as this is that they depend on
having the right model of what potential adversaries know. Abstraction alleviates
this problem. We need not know X exactly but only that whatever the adversary
knowledge actually is, we capture it in the abstraction a. We return to this point in
Section 11.9.
A monitor serves as the gateway to the protected information and will, given a
security parameter or vulnerability threshold t, make sure that the risk (in terms
of vulnerability) never rises beyond t. This application presumes a querier only
observes its interactions with the monitor (it does not infer anything about the secret
from any other source).
Given a vulnerability threshold t, a secret state σ, prior adversary knowledge a
with X(σ) > 0 for some X ∈γ (a), a query stmt whose output on the secret state
is the value y of variable Y the dynamic monitor has three components: one to
determine whether a query should be answered, one to determine what to return to
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

382
Calderón et al: Probabilistic Abstract Interpretation
the querier, and one to revise adversary knowledge:
Allowt(stmt) : a →
*
true
if V (a,stmt, y) ≤t ∀y
false
otherwise
Observet(stmt, y) : a →
* y
if Allowt(stmt)
deny
otherwise
Posteriort(stmt, y) : a →
* (⟨⟨stmt⟩⟩a) | (Y = y)
if Allowt(stmt)
a
otherwise
Note that in the Allow component, by way of a test for all possible outputs y,
we are evaluating the "worst-case" posterior vulnerability (Köpf and Basin, 2007).
Compared to making this check for conditional vulnerability given only the actual
output y from stmt evaluated on secret σ, the worst-case has the beneﬁt of being
simulatable (Kenthapadi et al., 2005) in that it can be determined without knowledge
of the secret value σ. The outcome of the vulnerability check in the Allow component,
therefore, leaks no information about it beyond what is assumed to be known by the
adversary.
Chaining applications of the monitor on a sequence of programs stmti whose
outputs are yi, we deﬁne ai+1 = Posteriort(stmti, yi) (ai) as the sequence of knowl-
edge revisions of a Bayesian adversary proposing queries stmti and observing
Observet (stmti, yi).
Theorem 11.19. Assume a Bayesian adversary has prior knowledge X ∈γ (a0)
consistent with secret σ (X(σ) > 0) and prior vulnerability bounded by threshold
t (maxσ X(σ) ≤t). Let yi be a the set of query outputs sampled from [[stmti]]σ. If
the adversary observes nothing but the sequence Observet (stmti, yi) (ai), then at no
stage will they have a likelihood of more than t of guessing the correct secret σ in a
single try.
We say that yi are sampled in the theorem as stmt may contain probabilistic
statements so more than one output value is possible. The theorem is principally based
on the soundness of our abstraction for modeling probabilistic program semantics
and conditioning. At each stage in the sequence, the abstraction ai includes what the
Bayesian adversary knows about the secret given their initial prior knowledge and
the outputs of the queries before that point, noting query rejections do not reveal
anything about the secret.
Example 11.20. Let us consider the sequence of queries, starting from prior
according to Demograhpicsstmt, evaluating Birthdaystmt which returns 0, and then
evaluating Birthday261stmt which has TODAY = 261. In concrete interpretation
we have distributions:
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

11.8 Related Work
383
• X0 = [[Demograhpicsstmt]]ϵ. At this point X0(σ) =
1
365∗37, meaning we could
reasonably employ the privacy monitor for any threshold t above
1
365∗37.
• X1 =  [[Birthdaystmt]]X0
! | (OUTPUT = 0). At this point we have X1(σ) =
1
358
for states σ that have σ(BDAY) ∈{0,· · · ,259,267,· · · ,364} (and for some values
of BYEAR). Thus if the threshold t was below
1
358∗37, the monitor would have
already rejected this ﬁrst query.
• X′
2 =  [[Birthday261stmt]]X1
!.
The monitor now needs to determine whether to evaluate the report the output
of the second birthday query. Were the output of this query to be 0, we would
have posterior X2(σ) =
1
357∗37 but if the query returned 1, we would instead have
X2(σ) =
1
1∗37, pinpointing the day of the year exactly. Thus for any threshold below
1
37, the monitor must reject this query, regardless of whether it would return 0 or 1
on the true value of BDAY.
The example above is described in terms of concrete probabilistic semantics.
Given soundness of the corresponding abstract semantics, the safe enforcement of
the posterior vulnerability can also be done in the abstract (Theorem 11.19).
11.8 Related Work
The work presented in this chapter has connections to techniques for program analysis,
notably abstraction interpretation, and methods for measuring and enforcing privacy.
We brieﬂy summarize the most related of these works. When considering privacy,
we speciﬁcally consider works that do, and do not, require modeling prior knowledge
when assessing information leakage.
Abstract Interpretation Static program analyses such as abstract interpreta-
tion(Cousot and Cousot, 1977) and symbolic execution (King, 1976; Cadar et al.,
2008) model program behaviour over large sets of inputs or starting conditions with
the goal of discovering or verifying the absence of undesirable conditions that would
be diﬃcult or close to impossible to verify with mere test cases or dynamic analyses.
Static techniques employ forms of abstraction to explore the space of executions.
The form of abstraction varies and has implications on the diﬀerences between the
analyses both in terms of their tractability, precision, and soundness in modeling
programs. The aspects of abstract interpretation that distinguish it from other static
analysis techniques include its limits on the complexity of representation and the
use of the widening operator to handle looping programs.
Abstract domains impose limits on the complexity of an analysis by abstract
interpretation (recall domains of Section 11.4). Powerset domains typically restrict
the number of disjuncts in a representation and the disjuncts themselves are limited by
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

384
Calderón et al: Probabilistic Abstract Interpretation
their underlying domain whose basic logical queries such as satisﬁability are trivial
or at least easy. This distinguishes abstract interpretation from analyses in which
logical representation can grow ever more complex and employ more expressive
theories, sometimes to the point where success of analysis depends primarily on an
undecidable logical satisﬁability test for an enormous formula employing potentially
incomplete theories.
The abstract interpretation of probabilistic programs has been tackled by Monniaux
(2001) who deﬁned probabilistic program semantics based on over-approximating
probabilities of program states. In other work, Di Pierro et al. (2005) described
abstract interpretation for probabilistic lambda calculus, and Smith (2008) who
used probabilistic abstract interpretation for veriﬁcation of quantitative program
properties. Such works are limited in their (lack of) sound handling of conditioning
which is a necessary component of a wide variety of quantitative privacy notions.
A theoretical investigation of probabilistic abstract interpretation as built atop
traditional abstractions can be found in Cousot and Monerau (2012).
Dynamic Probabilistic Programming Dynamic analysis works characterizes prop-
erties of concrete program evaluations. Such an analysis has the beneﬁt of not
requiring an abstraction of semantics and hence can be easily adopted to full-featured
languages. The analysis described in this chapter, on the other hand, works well for
programs containing only linear expressions over integer-valued variables. Adapting
such analyses to richer programs is possible but will invariably suﬀer in precision
when modeling language features not speciﬁcally designed for in the abstraction.
In the context of this chapter's privacy application, the pertinent aspect of a
probabilistic programming system is its ability to accurately or soundly approximate
probability or a privacy criterion. Though generally lacking ability to derive exact
probability or bounds, dynamic techniques and sampling have been used in privacy
contexts. Köpf and Rybalchenko (2010), for example, use sampling to derive
information ﬂow bounds.
More recently, Sweet et al. (2018) have shown that sampling can be used to
improve the precision of the abstract distribution representation discussed in this
chapter. However, in this and other sampling techniques, the soundness guarantees
become somewhat subtle. In the case of (Sweet et al., 2018), for example, the authors
provide for a conﬁdence bound (a probability over the sampling process) that the
derived probability values (like posterior Vulnerability) are within a certain range.
Privacy with Background Knowledge Assumptions Measurement of adversary
knowledge of private data as it is informed by a program's output has been a
well-studied problem since Robling Denning (1982). Clark et al. (2005) deﬁne a
static analysis that bounds the secret information a straight-line program can leak
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

11.8 Related Work
385
in terms of equivalence relations between the inputs and outputs. Backes et al.
(2009) automate the synthesis of such equivalence relations and quantify leakage by
computing the exact size of equivalence classes. Köpf and Rybalchenko (2010) extend
this approach, improving its scalability by using sampling to identify equivalence
classes and using under- and over-approximation to obtain bounds on their size. Mu
and Clark (2009) present a similar analysis that uses over-approximation only. In
all cases, the inferred equivalence classes can be used to compute entropy-based
metrics of information leakage.
Along with tools, there is a growing number of quantitative information ﬂow
measures in the literature, varying according to the operational interpretation of risk.
Instances include Bayes vulnerability (Smith, 2009) and Bayes risk (Chatzikokolakis
et al., 2008), Shannon entropy (Shannon, 1948), and guessing entropy (Massey,
1994). The g-vulnerability framework (Alvim et al., 2012) is meant to encompass a
more general set of operational interpretations.
Two important aspects of all of these works are (a) whether they deal with absolute
or relative information and (b) whether they incorporate background knowledge.
For the ﬁrst, an example absolute measure is posterior vulnerability discussed
in this chapter. Relative measures compare the absolute measurements before and
after an adversary makes an observation from some scrutinized system. Relative
measurements of information further have variants which do not assume particular
background knowledge on the adversary's part but instead quantify the worst-case
diﬀerence in prior and posterior over all possible distributions. Channel capacity in
FlowCheck (McCamant and Ernst, 2008) and various deﬁnitions of maximum
leakage measures in the quantitative information ﬂow literature are examples.
The reliance on having a sense of background knowledge of adversaries is the
problematic assumption motivating other popular approaches such as diﬀerential
privacy (Dwork, 2008). Unlike the approaches mentioned above, diﬀerential privacy
lacks a clear connection to harms induced by privacy loss and attempts at connecting
its privacy parameter to harms invariably make assumptions as problematic as those
regarding background knowledge (Kifer and Machanavajjhala, 2011).
Though we make the assumption of having adversary background knowledge in
our work, our use of probabilistic programming and abstract interpretation alleviates
it. First, for cases where a secret is generated by a program which is known by the
adversary, the distribution representing their background knowledge can be derived
by probabilistic evaluation of said generating program. An over-approximation
of the knowledge can likewise be generating using the techniques described in
this chapter. Second, probabilistic programs can be viewed as tools for modeling
background knowledge and can bring to bear their beneﬁts speciﬁcally in terms
of concisely describing distributions arising from generative processes. Finally,
probabilistic abstract interpretation makes the process easier by not requiring the
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

386
References
exact background knowledge of all adversaries to be known as long as it can be
approximated in some abstraction. To this end, we can extend our toy probabilistic
language with the "possibilistic" choice statement:
stmt ::= poss stmt1 and stmt2 | ...
The meaning of possibilistic choice is that either branch can occur. This cannot be
modeled in the concrete semantics but can be approximated in the abstract semantics
by making sure that when b = [[poss stmt1 and stmt2]]a then γ ([[stmt1]]a) ⊆γ (b)
and γ ([[stmt2]]a) ⊆γ (b). That is, the abstraction of possibility must include the
abstractions of both branches. As an adversary modeling tool, this lets us remain
uncertain which of the branches generates the true adversary knowledge, as long as
one of them does.
The techniques described in this chapter can incorporate such a modeling tool by
virtue of the imprecise but sound representations employed. The numeric abstractions,
however, were not designed with this use-case in mind. Taking advantage of this
feature of abstract interpretation for the purpose of modeling uncertainty in knowledge
is an open problem.
11.9 Conclusions
In this chapter we have described a probabilistic programming approach with
sound probability and inference bounds suitable for specifying fairness and privacy
properties. Based on abstract interpretation, the technique allows one to trade oﬀ
precision for speed of analysis all the while preserving a general soundness criterion.
Probabilistic abstract interpretation therefore oﬀers a unique set of beneﬁts from
among the probabilistic programming toolkit.
The ﬁeld of abstract interpretation is an active area of research and oﬀers many
open problems. New domains, combinators, and algorithms for eﬃciently and
accurately representing program states and reasoning about larger and more feature
rich programs are proposed regularly. Considerations for probability, however, are
not as thoroughly investigated. Fundamental aspects of abstraction such as widening
remain unavailable for languages with sound conditioning and thus pose a hurdle to
the wider adoption of the otherwise extremely successful program analysis technique
to probabilistic applications.
References
Alvim, Mário S., Chatzikokolakis, Konstantinos, Palamidessi, Catuscia, and Smith,
Geoﬀrey. 2012. Measuring Information Leakage Using Generalized Gain
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
387
Functions. In: Proceedings of the IEEE Computer Security Foundations
Symposium (CSF).
Backes, Michael, Köpf, Boris, and Rybalchenko, Andrey. 2009. Automatic Dis-
covery and Quantiﬁcation of Information Leaks. In: Proceedings of the IEEE
Symposium on Security and Privacy (S&P).
Baden, Randy, Bender, Adam, Spring, Neil, Bhattacharjee, Bobby, and Starin,
Daniel. 2009. Persona: an online social network with user-deﬁned privacy. In:
Proceedings of the ACM SIGCOMM Conference on Applications, Technologies,
Architectures, and Protocols for Computer Communications (SIGCOMM).
Bagnara, Roberto, Dobson, Katy, Hill, Patricia M, Mundell, Matthew, and Zaﬀanella,
Enea. 2006. Grids: A domain for analyzing the distribution of numerical
values. Pages 219-235 of: International Symposium on Logic-based Program
Synthesis and Transformation. Springer.
Cadar, Cristian, Ganesh, Vijay, Pawlowski, Peter M, Dill, David L, and Engler,
Dawson R. 2008. EXE: automatically generating inputs of death. ACM
Transactions on Information and System Security (TISSEC), 12(2), 10.
Chatzikokolakis, Konstantinos, Palamidessi, Catuscia, and Panangaden, Prakash.
2008. On the Bayes risk in information-hiding protocols. Journal of Computer
Security, 16(5).
Clark, David, Hunt, Sebastian, and Malacaria, Pasquale. 2005. Quantitative In-
formation Flow, Relations and Polymorphic Types. Journal of Logic and
Computation, 15, 181-199.
Clarkson, Michael R., Myers, Andrew C., and Schneider, Fred B. 2009. Quantifying
information ﬂow with beliefs. Journal of Computer Security, 17(5), 655-701.
Cousot, Patrick, and Cousot, Radhia. 1976. Static Determination of Dynamic
Properties of Programs. In: Proceedings of the Second International Symposium
on Programming.
Cousot, Patrick, and Cousot, Radhia. 1977. Abstract interpretation: a uniﬁed lattice
model for static analysis of programs by construction or approximation of
ﬁxpoints. In: Proceedings of the ACM SIGPLAN Conference on Principles of
Programming Languages (POPL).
Cousot, Patrick, and Monerau, Michael. 2012. Probabilistic Abstract Interpretation.
In: Proceedings of the European Symposium on Programming (ESOP).
De Loera, Jesus A., Haws, David, Hemmecke, Raymond, Huggins, Peter, Tauzer,
Jeremy, and Yoshida, Ruriko. 2008. LattE. http://www.math.ucdavis.
edu/latte.
Di Pierro, Alessandra, Hankin, Chris, and Wiklicky, Herbert. 2005. Probabilistic
Lambda-calculus and Quantitative Program Analysis. Journal of Logic and
Computation, 15(2), 159-179.
Dwork, Cynthia. 2008. Diﬀerential privacy: A survey of results. Pages 1-19 of:
International Conference on Theory and Applications of Models of Computation.
Springer.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

388
References
Feldman, Michael, Friedler, Sorelle A., Moeller, John, Scheidegger, Carlos, and
Venkatasubramanian, Suresh. 2015. Certifying and Removing Disparate Impact.
Pages 259-268 of: Proceedings of the 21th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining.
Giacobazzi, Roberto, and Ranzato, Francesco. 1998. Optimal domains for disjunctive
abstract interpretation. Science of Computer Programming, 32(1-3), 177-210.
Golle, Philippe. 2006. Revisiting the uniqueness of simple demographics in the
US population. In: Proceedings of the Workshop on Privacy in the Electronic
Society (WPES).
Kenthapadi, Krishnaram, Mishra, Nina, and Nissim, Kobbi. 2005. Simulatable
Auditing. In: Proceedings of the ACM SIGMOD Symposium on Principles of
Database Systems (PODS).
Kifer, Daniel, and Machanavajjhala, Ashwin. 2011. No free lunch in data privacy.
Pages 193-204 of: Proceedings of the 2011 ACM SIGMOD International
Conference on Management of data. ACM.
King, James C. 1976. Symbolic execution and program testing. Communications of
the ACM, 19(7), 385-394.
Köpf, Boris, and Basin, David. 2007. An Information-Theoretic Model for Adaptive
Side-Channel Attacks. In: Proceedings of the ACM Conference on Computer
and Communications Security (CCS).
Köpf, Boris, and Rybalchenko, Andrey. 2010. Approximation and Randomization
for Quantitative Information-Flow Analysis. In: Proceedings of the IEEE
Computer Security Foundations Symposium (CSF).
Kozen, Dexter. 1981. Semantics of probabilistic programs. Journal of Computer
and System Sciences, 22(3), 328-350.
Mardziel, Piotr, Magill, Stephen, Hicks, Michael, and Srivatsa, Mudhakar. 2011.
Dynamic Enforcement of Knowledge-based Security Policies. In: Proceedings
of the IEEE Computer Security Foundations Symposium (CSF).
Mardziel, Piotr, Hicks, Michael, Katz, Jonathan, and Srivatsa, Mudhakar. 2012.
Knowledge-Oriented Secure Multiparty Computation. In: Proceedings of
the ACM SIGPLAN Workshop on Programming Languages and Analysis for
Security (PLAS).
Mardziel, Piotr, Magill, Stephen, Hicks, Michael, and Srivatsa, Mudhakar. 2013. Dy-
namic Enforcement of Knowledge-based Security Policies using Probabilistic
Abstract Interpretation. Journal of Computer Security, Jan.
Massey, James L. 1994. Guessing and Entropy. In: Proceedings of the IEEE
International Symposium on Information Theory.
McCamant, Stephen, and Ernst, Michael D. 2008. Quantitative information ﬂow as
network ﬂow capacity. In: Proceedings of the ACM SIGPLAN Conference on
Programming Language Design and Implementation (PLDI).
Miné, Antoine. 2001. The Octagon Abstract Domain. In: Proceedings of the Working
Conference on Reverse Engineering (WCRE).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
389
Monniaux, David. 2001. Analyse de programmes probabilistes par interprétation
abstraite. Thèse de doctorat, Université Paris IX Dauphine.
Mu, Chunyan, and Clark, David. 2009. An Interval-based Abstraction for Quantifying
Information Flow. Elec. Notes in Theoretical Computer Science, 253(3), 119-
141.
Robling Denning, Dorothy Elizabeth. 1982.
Cryptography and data security.
Addison-Wesley Longman Publishing Co., Inc.
Seong, Seok-Won, Seo, Jiwon, Nasielski, Matthew, Sengupta, Debangsu, Hangal,
Sudheendra, Teh, Seng Keat, Chu, Ruven, Dodson, Ben, and Lam, Monica S.
2010. PrPl: a Decentralized Social Networking Infrastructure. In: Proceedings
of the Workshop on Mobile Cloud Computing & Services: Social Networks and
Beyond. Invited Paper.
Shannon, Claude. 1948. A Mathematical Theory of Communication. Bell System
Technical Journal, 27.
Simon, Axel, and King, Andy. 2007. Taming the wrapping of integer arithmetic.
Pages 121-136 of: International Static Analysis Symposium. Springer.
Smith, Geoﬀrey. 2009. On the Foundations of Quantitative Information Flow.
In: Proceedings of the Conference on Foundations of Software Science and
Computation Structures (FoSSaCS).
Smith, Michael J. A. 2008. Probabilistic Abstract Interpretation of Imperative Pro-
grams using Truncated Normal Distributions. Electronic Notes in Theoretical
Computer Science, 220(3), 43-59.
Sweeney, Latanya. 2000. Simple Demographics Often Identify People Uniquely.
Tech. rept. LIDAP-WP4. Carnegie Mellon University, School of Computer
Science, Data Privacy Laboratory.
Sweet, Ian, Trilla, José Manuel Calderón, Scherrer, Chad, Hicks, Michael, and
Magill, Stephen. 2018. What's the Over/Under? Probabilistic Bounds on
Information Leakage. Pages 3-27 of: Bauer, Lujo, and Küsters, Ralf (eds),
Principles of Security and Trust. Cham: Springer International Publishing.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12
Quantitative Information Flow with Monads in Haskell
Jeremy Gibbons
University of Oxford
Annabelle McIver
Macquarie University
Carroll Morgan
University of New South Wales, and Data61 (CSIRO)
Tom Schrijvers
KU Leuven
Abstract:
Monads are a popular feature of the programming language Haskell
because they can model many diﬀerent notions of computation in a uniform and
purely functional way. Our particular interest here is the probability monad, which
can be - and has been - used to synthesise models for probabilistic programming.
Quantitative Information Flow, or QIF, arises when security is combined with
probability, and concerns the measurement of the amount of information that 'leaks'
from a probabilistic program's state to a (usually) hostile observer: that is, not
"whether" leaks occur but rather "how much?"
Recently it has been shown that QIF can be seen monadically, a 'lifting' of the
probability monad from (simply) distributions to distributions of distributions -
so called "hyper-distributions". Haskell's support for monads therefore suggests a
synthesis of an executable model for QIF. Here we provide the ﬁrst systematic and
thorough account of doing that: using distributions of distributions to synthesise a
model for Quantitative Information Flow in terms of monads in Haskell.
12.1 Introduction
In contexts where programs have access to or manipulate private information,
assessing the control of how that information ﬂows is an essential aspect of the
veriﬁcation task. In some, probably most cases some part of the secret must be
released for the program to achieve anything useful at all - but it is the unintended
leaks, which could be avoided by more careful programming, that concern us
here. Preventing them is enormously challenging, and the idea of quantifying the
a From Foundations of Probabilistic Programming, edited by Gilles Barthe, Joost-Pieter Katoen and Alexandra
Silva published 2020 by Cambridge University Press.
391
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

392
Gibbons et al.: QIF with Monads in Haskell
information that does ﬂow was proposed by (Denning, 1982), (Millen, 1987), (Clark
et al., 2005b) and others to provide a sound framework to enable the analysis of the
severity and impact of such ﬂows. Our model for Quantitative Information Flow,
that is QIF, was originally expressed in terms of information-theoretic channels,
even to the extent of measuring (change in) Shannon Entropy 'by default' as the
method of choice (Millen, 1987); and as such it has been used successfully to assess
ﬂows related to conﬁdentiality and privacy for relevant operational scenarios. More
recently, however, this channel model has been generalised: more general entropies
than Shannon's are applicable (Alvim et al., 2012), and ﬂow can be deﬁned for
programs rather than just channels (McIver et al., 2010). (Programs can update the
private information, whereas channels can only read it.) The key to this generalisation
is hyper-distributions (McIver et al., 2010, 2014a) (§12.3 below) - based on 'hypers',
QIF in computer programs can be given a monadic semantics that supports many
diﬀerent entropies.
This chapter combines the monadic semantics with a second idea: that monads
(§12.2.1 below) abstract and unify common features of "notions of computation"
(Moggi, 1991) and that monadic features can be, and have been built into (functional)
programming languages (Wadler, 1992). Putting those two ideas together encourages
the synthesis of an implementation of a 'QIF-aware' programming language. We
present a prototype of such a language, which we have called "Kuifje".1 The
synthesis also provides an important tool for experimentation with and analysis of
how information ﬂows in real programming.
A helpful guide to what we present is the analogous, but more straightforward
synthesis that arises from a simpler combination: that simple probabilistic semantics
(i.e. without ﬂow) is also monadic (Lawvere, 1962; Giry, 1981). The result is easy
implementations of functional probabilistic programming languages (Ramsey and
Pfeﬀer, 2002; Erwig and Kollmansberger, 2006; Kiselyov and Shan, 2009). Our work
here beneﬁts from that, because QIF-aware programming languages are probabilistic
- the 'quantities' in the information ﬂow are derived from the probabilities occurring
in the programs and in the probability distributions over the hidden state to which
they are applied.
In the development of our functional implementation we use the notion of monoids
as a guiding structure. Indeed, we can see both the syntactic- and the semantic
domain of a simple programming language as a monoid, the former being free,
so that its denotational semantics is then a monoid morphism. The initial-algebra
representation of free monoids gives rise to a straightforward implementation
of this denotational semantics as a functional-programming-style fold. Moreover,
with 'fold fusion' (Malcolm, 1990; Hutton, 1999) we can easily derive an eﬃcient
implementation of the hyper-distribution semantics from its naïve speciﬁcation.
1 "Kuifje" is the Flemish/Dutch name of Hergé's Tintin, and refers to his hairstyle: a quiﬀ.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12.2 Background
393
12.2 Background
We begin by describing monads in general (brieﬂy) as they are used in Computer
Science (§12.2.1), how they relate to quantitative information ﬂow (§12.2.2), how
they are instantiated in the functional programming language Haskell (§12.2.3),
and how their Haskell instantiation can be used to build the tools necessary for
a probabilistic information-ﬂow-aware programming-language implementation
(§12.2.4). The Haskell-oriented reader may want to skip the theoretical background
and jump straight to §12.2.3.
12.2.1 Monads
The mathematical structure of monads was introduced to Computer Science by
Moggi in order to have a model of computation that was more general than the "gross
simpliﬁcation" of identifying programs with total functions from values to values, a
view that "wipes out completely behaviours like non-termination, non-determinism
or side eﬀects. . . " (Moggi, 1991). Here we will be using that generality to capture
the behaviour of programs that hide and, complementarily, leak information: and
our particular focus will be on using the monadic facilities of the programming
language Haskell (Peyton Jones, 2003) to illustrate our ideas (§12.2.3).
Moggi's insight was to model a "notion of computation" as a monad T, in order
to distinguish plain values of some type A from the computations TA that yield
such values. (Later, we will see T as a Haskell type-constructor.) Thus T might
enrich sets A of values to A⊥by adding an extra element ⊥denoting 'not a proper
value', perhaps the simplest computational monad; or it might enrich A to PA,
the subsets of A, for modelling demonic choice; or it might enrich A to W∗×A,
pairing with a sequence of W values, for modelling 'writing' such as to a log ﬁle;
or it might enrich A to DA, the discrete distributions on A which, below, will be
our starting point here. We say "enrich" because in each case the original A can
be found embedded within TA: a plain value can always be seen as a degenerate
computation. Thus A is found: within A⊥as that subset of computations yielding a
proper value; within W∗×A as the computations (⟨⟩,a) in which no writes have
yet occurred; within PA as the singleton sets {a} that represent the (degenerate)
demonic choice of only one value, i.e. no choice at all (Hobson's Choice); and A is
found within DA as the point distribution ⟨a⟩, the probabilistic choice 'certainly a',
this time no probabilistic choice at all.2
For a general monad T, the embeddings illustrated above are all instances of the
unit function, written η and of type A→TA, so that in the above four cases η a is
(the proper value) a, (the nothing-yet-written) (⟨⟩,a), (the singleton) {a}, and (the
2 For a: A we write ⟨a⟩for the point distribution in DA which assigns probability 1 to a and probability 0 to
all other elements of A (like a one-sided die).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

394
Gibbons et al.: QIF with Monads in Haskell
point) ⟨a⟩, respectively. Whereas a pure function taking values from A to values
in B has type A→B, Moggi modelled an 'impure function' for a particular notion of
computation T as a so-called Kleisli arrow A→TB - that is, a pure function yielding
a computation rather than a plain value. Thus partial functions are modelled as Kleisli
arrows A→B⊥, 'writing functions' as Kleisli arrows A→W∗×B, 'nondeterministic
functions' as Kleisli arrows A→PB, and 'probabilistic functions' as Kleisli arrows
A→DB.
If a monad T is to model a "notion of computation", then in particular it had
better support sequential composition: if a program f takes a value a:A to some
structure in TB, and it is followed by a compatible program g with the same notion
T of computation, i.e. a Kleisli arrow of type B→TC, then that second program g
must act as if it has type TB→TC if it is to be sequentially composed with f , since
the input type of g, the second stage, must in some sense match the output type of
the ﬁrst stage f . This is achieved by deﬁning a Kleisli-lifting (−)∗, which converts
Kleisli arrow g:B→TC to a 'lifted' version g∗, a function of type TB→TC. Then
the intuitive conclusion, that if f goes from A to B and g from B to C then their
composition should go from A to C, is realised by the Kleisli composition g• f
of f :A→TB and g:B→TC deﬁned as g• f = g∗◦f having type A→TC, using
Kleisli-lifting (−)∗and ordinary functional composition (◦) together.
A monad T can be seen as a functor which, among other things, means that for
any function h:A→B there is another function Th:TA→TB that behaves in a
sensible way (in particular, respecting identity and composition). Then an alternative
deﬁnition of Kleisli composition is to require that T have a multiplication operation
μ:T2C→TC. In that case, for Kleisi arrow g:B→TC one can deﬁne g∗by μ ◦Tg,
and the Kleisli composition g• f of f :A→TB and g:B→TC becomes μ ◦Tg ◦f ,
thus achieving the same end. With suitable conditions on unit η and multiply μ,
the two presentations, one in terms of Kleisli lifting and the other in terms of
multiplication, are equivalent and we will use them interchangeably.
The precise conditions for operation T on sets A to be a monad are that T must act
also on the functions between those sets, respecting typing (so that T f :TA→TB
when f :A→B), and it must support families of functions ηA:A→TA and
μA:T2A→TA that satisfy also the following algebraic identities (for f : A →B
and g : B →C):
(a) TidA = idTA
— T respects identity.
(b) Tg ◦T f = T(g◦f )
— T respects composition.
(c) ηB ◦f = T f ◦ηA
— η is a natural transformation 1→T.
(d) μB ◦T2 f = T f ◦μA
— μ is a natural transformation T2→T.
(e) μA ◦TμA = μA ◦μTA
— μ is associative.
(f) μA ◦TηA = μA ◦ηTA = idA
— η is unit of μ.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12.2 Background
395
Identities (a,b) are the conditions for T to be a functor, and (c,d) require that the
families η and μ form natural transformations, and ﬁnally (e,f) are the additional
conditions for (T,η, μ) to form a monad. In particular, it is a straightforward
exercise to use these identities to verify that (•) and η form a monoid: we have
h•(g• f ) = (h•g)• f and η• f = f = f •η.
To make those identities more concrete and familiar, we describe in words
what the analogous identities would be for the powerset monad P used to model
non-deterministic, i.e. 'demonic' programs. They are (in the same order)
(a) The image of a set X through the identity function id is X itself.
(b) The image of a set X through the composition g◦f is the image through g of
the image through f of X.
(c) Making a singleton set {x} from x, and then applying f to all elements of that
set, is the same as applying f to x ﬁrst and then making a singleton set from
that: in both cases you get the singleton set { f x}.
(d) Applying f to the elements of the elements of a set of sets (that is, applying f
'twice deep'), and then taking the distributed union of the result, is the same
as taking the distributed union of the set of sets ﬁrst, and then applying f
to its elements (i.e. once deep). Starting e.g. from {{x1}, {x2, x3}} you get
{ f x1, f x3, f x3} in both cases.
(e) Applying distributed union to each of the elements of a set of sets of sets
(i.e. three nested braces), and then taking the distributed union of that,
is the same as taking the distribution union twice. For example, start-
ing from {{{x1}}, {{x2, x3}, {x4}}} the former gives {{x1}, {x2, x3, x4}}
and then {x1, x2, x3, x4}, and the latter reaches the same result but via
{{x1}, {x2, x3}, {x4}} instead.
(f) Converting a set's elements to singleton sets, and then taking the distributed
union, is the same as converting the set to a singleton set (of sets) and then
taking the distributed union of that - and it is the identity in both cases. The
former takes {x1, x2} to {{x1}, {x2}} and then (back) to {x1, x2}; and the
latter goes via {{x1, x2}}.
12.2.2 Monads for probabilistic programming
Probabilistic computation is an instance of the more general monadic construction
introduced in §12.2.1 just above, and it provides the essential 'numeric component'
of moving from earlier, only qualitative descriptions of information ﬂow (Cohen,
1977; Goguen and Meseguer, 1984) to Quantitative Information Flow (Denning,
1982; Millen, 1987; Gray, 1990; Clark et al., 2005b), abbreviated "QIF": the study
of information leakage, typically from- or between computer programs, where -
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

396
Gibbons et al.: QIF with Monads in Haskell
crucially - the amount of information leaked can be measured and compared. Thus
in this section we concentrate on probabilistic computation alone; we move on to
information ﬂow in §12.3.
A (discrete) probabilistic computation over some A takes an initial state a:A to
a ﬁnal distribution α:DA - thus it has type A→DA. For example with A={h,t}
for the head and tail faces of a coin, a computation P that 'seeks heads' might be
Ph =
⟨h⟩
if heads already, don't ﬂip any more
Pt =
⟨h,t⟩
if t keep ﬂipping
(12.1)
where in general we write ⟨a, b,· · · , z⟩for the uniform distribution over the elements
listed inside ⟨· · · ⟩. As a special case ⟨a⟩is the point distribution on a.
To seek heads twice we run P twice, i.e. we compose P with itself; but, as already
noted more generally, the simple P◦P would be type-incorrect because the second-
executed P (the left one) expects an A but the ﬁrst P delivers a DA. Let us write a
distribution list ⟨· · · ⟩with superscripts summing to 1 for a discrete distribution with
those probabilities (rather than uniform), so that omitted superscripts are assumed
to be equal; and we write ¬p for 1−p. Then, following the Kleisli approach, we lift
the second P to P∗, so that its argument is of type DA, and note that
P∗⟨hp,t¬p⟩
=
{ deﬁnition (−)∗}
(μ ◦DP)⟨hp,t¬p⟩
=
{ function composition }
μ( DP⟨hp,t¬p⟩)
=
{ deﬁnition DP: see † below }
μ⟨⟨h⟩p, ⟨h,t⟩¬p ⟩
=
{ deﬁnition μ for monad D: see ‡ below }
⟨h
(1+p)/2,t
(1−p)/2 ⟩,
(12.2)
so that using P∗in its general form from (12.2) we can calculate
P2h = P∗(Ph) = P∗⟨h⟩= P∗⟨h1,t0⟩= ⟨h
(1+1)/2,t
(1−1)/2⟩= ⟨h1,t0⟩= ⟨h⟩,
and again from (12.2) we have
P2t = P∗(Pt) = P∗⟨h,t⟩= P∗⟨h
1/2,t
1/2⟩= ⟨h
(1+1/2)/2,t
(1−1/2)/2⟩= ⟨h
3/4,t
1/4⟩.
For "see † below" we note that DP is in monadic terms the application of functor
D to arrow h; in elementary probability this is the 'push forward' of h (Feller, 1971).
For f :A→B and α:DA and b:B the push forward D f of f has type DA→DB
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12.2 Background
397
and is deﬁned
(D f ) α b
=

a: A
f a=b
α a
=
β b
say , 3
i.e. so that the probability βb assigned by the DB-typed distribution β = D f α to
the element b of B is the total probability assigned by α in DA to those a's in A
such that f a = b.
For "see ‡ below" we have that the deﬁnition of multiply μ for D is the 'squash' or
'distributed average' that takes a distribution of distributions to a single distribution.
With D as our base set, 4 we take some Δ:D2D and d:D and have that μΔ ∈DD
and 5
μ Δ d
=

δ:Δ
Δδ × δd
.6
(12.3)
The above might seem quite general, particularly when there is a more conventional
- and simpler - view of P in (12.1) above, the 'seek h' operation, as a Markov chain.
We now look at that connection, strengthening the intuition for what the probability
monad D and its η, μ are doing, and preparing ourselves for when their generality
becomes more useful.
The Markov matrix for the head-seeking P is
after P
before P


1
0
1/2
1/2
Such matrices are called stochastic because their rows sum to one: the rows above
are (invisibly) labelled h above t, and the columns h before t; and each element of
the matrix gives the probability that one application of P takes that row label to
that column label. Thus for example h (upper row) is taken to h (left column) with
probability 1; but t (lower row) is taken to h with probability only 1/2. Now if the
3 Here we follow the practice of avoiding parentheses as much as possible (because otherwise there would be so
many). We don't write ((Df ) α) b, because function application associates to the left (and thus would allow
even D f α b); and we don't write D(f )(α)(b), because functional application is (in this area) usually indicated
by juxtaposition without parentheses. Note also that we are using currying, where what might be seen as a
multi-argument function is instead written as higher-order functions taking their single arguments one at a time
from left to right.
4 This is a temporary departure from A, B as typical base sets, because we need to use "capital Greek D" as an
element of D2D.
5 Concerning (:) vs. (∈) - we use the former to introduce a bound variable, both in text and in formulae. With for
example x∈X we are instead referring to x, X that are already deﬁned.
6 The deﬁnition of μ in the powerset monad P is analogous: it is a distributed union that takes a set of sets to a
single set by removing one level of set braces. Speciﬁcally, if we think of a set as its characteristic predicate (a
function from elements to booleans), then for a set of sets X:P2A, we have μ X a = (∃x:PA . X x ∧x a) -
that is, a ∈μ X iﬀthere exists some x:X with a ∈x.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

398
Gibbons et al.: QIF with Monads in Haskell
initial distribution of the coin faces were ⟨hp,t¬p⟩, then - as is well known - the
ﬁnal distribution of coin faces is given by the vector-matrix product
(p ¬p)
 1
0
1/2
1/2

=
1+p
2
1−p
2

,
agreeing with what was calculated above at (12.2). And the eﬀect of two P's in
succession, that is P(P⟨hp,t¬p⟩), is therefore given by the matrix product

(p ¬p)
 1
0
1/2
1/2

 1
0
1/2
1/2

which, because of the associativity of matrix multiplication, can of course be written
(p ¬p)
 1
0
1/2
1/2
  1
0
1/2
1/2

=
(p ¬p)
 1
0
3/4
1/4

.
(12.4)
Now we can observe that although the type of P itself is A→DA, the type of
'multiply by the square matrix' in the examples above is DA→DA - that is, the
matrix viewed 'row wise' is of type A→DA but, viewed as a whole (and using the
deﬁnition of matrix multiplication) it is of type DA→DA. Thus the matrix as a
whole corresponds to the Kleisli lifting P∗of its rows P. Then (12.4) goes on to
show that P∗◦P corresponds in turn to the matrix multiplication with itself of the
matrix corresponding to P∗. 7
The wide applicability of matrix algebra comes in part from the fact (fortuitiously)
that it has this monadic structure. In general, as Moggi explained, monads contribute
to ﬂexibility of general program-algebraic operations as well - and that ﬂexibility is
what we use here to explore - and implement - a program algebra for QIF.
Summary We will use the discrete-distribution monad D which takes a set A to
the set DA of its discrete distributions. The unit η of D takes an element of A to
the point distribution ⟨a⟩on a; the multiply μ takes a distribution-of-distributions
Δ:D2D to its 'squash' as shown at (12.3) above, which is however equivalent to the
'smaller' summation over the support ⌈Δ⌉of Δ only, thus
μ Δ d
=

δ: ⌈Δ⌉
Δδ × δd
,
(12.5)
where the support of Δ is those δ:DD such that Δδ  0. (This is important in
Haskell because we can then represent distributions as ﬁnite lists over their support,
omitting the possibly inﬁnitely many elements of probability zero.)
7 This corresponds to the general Kleisli identity (P∗◦P)∗= P∗◦P∗.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12.2 Background
399
12.2.3 Monads in Haskell
Monads were introduced into Haskell because their mathematical generality translates
into expressive power. They are modelled as a type class Functor with a method
fmap, and a subclass Monad of Functor providing two additional methods return
and (>>=); the latter is pronounced "bind". Their methods' types are
fmap :: (a →b) →m a →m b
return :: a →m a
(>>=) :: m a →(a →m b) →m b
where m and a,b correspond to the T and A,B of Section 12.2.1. Function fmap is
the functorial action of monad m, and return is the unit η of monad m, and (>>=)
is Kleisli lifting (but with the two arguments swapped). The multiplication μ is
modelled by
join :: m (m a) →m a
As noted above, Kleisli lifting and monad multiplication are interdeﬁnable: therefore
we have the further identities
join x
=
x >>= id
x >>= f
=
join (fmap f x)
All of those are just ordinary Haskell functions, deﬁned in plain Haskell code, and it
is straightforward to implement additional operations in terms of them. For example,
Kleisli lifting with the arguments in the traditional order (=<<) is deﬁned in terms of
bind by
(=<<) :: (a →m b) →(m a →m b)
g =<< x
=
x >>= g
and backwards Kleisli composition (<=<) (written "•" in Section 12.2.1) and its
forwards version (>=>) are deﬁned by
(<=<) :: (b →m c) →(a →m b) →(a →m c)
g <=< f
=
join ◦fmap g ◦f
(>=>) :: (a →m b) →(b →m c) →(a →m c)
f >=> g
=
join ◦fmap g ◦f
Clearly they are equal, operationally performing f 'and then' g; it is solely a matter
of convenience which way around to write it.
As a ﬁnal link back to the familiar, we mimic our use of the powerset monad
P in §12.2.1 to give a similar presentation here of the monad laws in Haskell, but
using this time the list monad - call it L. Then the functorial action of L on a
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

400
Gibbons et al.: QIF with Monads in Haskell
function f :: a →b is to produce map f of type [a] →[b]; unit η of L takes x to the
one-element list [x] containing just x, i.e. it is (:[ ]); and the multiply μ of L is the
function concat that 'squashes' a list of lists into a single list. We now have
id
=
map id
— (a)
map g ◦map f
=
map (g ◦f)
— (b)
map f ◦(:[ ])
=
(:[ ]) ◦f
— (c)
concat ◦map (map f)
=
map f ◦concat
— (d)
concat ◦map concat
=
concat ◦concat
— (e)
concat ◦map (:[ ])
=
concat ◦(:[ ]) = id
— (f)
We will see see the beneﬁt of all the above generality below, where these properties,
and others, are exploited in a monadic treatment of QIF and the construction of a
Haskell implementation of it.
12.2.4 Probabilistic programming in Haskell
With §12.2.2 and §12.2.3 as building blocks, we can model probabilistic programs
in Haskell as Kleisli arrows for the distribution monad D. Thus in this section we
recall in more detail the previous work that shows how that is done (Ramsey and
Pfeﬀer, 2002; Erwig and Kollmansberger, 2006; Kiselyov and Shan, 2009). (Note
that we are still not addressing QIF itself.)
Representation We limit probabilities to the rationals; and our distributions are
discrete, represented as (ﬁnite) lists of pairs with each pair giving an element of the
base type and the probability associated with that element. Usually (but not always)
the representation will be reduced in the sense that the list includes only elements of
the support of the distribution, and each of those exactly once, i.e. excluding both
repeated elements and elements with probability zero.
type Prob = Rational
newtype Dist a = D {runD :: [(a,Prob)]}
The 'essence' of the representation is the type [(a,Prob)], i.e. lists of pairs. The
D {runD :: . . .} above is Haskell notation for deﬁning Dist a as a record type, with
a single ﬁeld called runD that consists of a list of pairs, and introduces function
D :: [(a,Prob)] →Dist a to wrap up such a list as a record value. The ﬁeld-name
runD can be used as a function, to extract the 'bare' list of pairs.
Monad instance The make-probabilistic-monad functor is the type constructor
Dist above, whose argument type a is the base type of the distribution. The unit
return of the monad takes an element to the point distribution on that element. The
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12.2 Background
401
bind operator (>>=) takes a distribution d :: Dist a and a distribution-valued function
f :: a →Dist b and computes eﬀectively the application of the stochastic matrix f to
the initial distribution d. 8
instance Monad Dist where
return x = D [(x,1)]
d >>= f = D [(y,p × q) | (x,p) ←runD d,(y,q) ←runD (f x)]
Note that (>>=) can produce representations that are not reduced, since values of y
can be repeated between the supports of diﬀerent distributions f x as x itself varies
over the support of d. We will arrange to reduce the representations where necessary.
Operations Function uniform constructs a discrete distribution from a non-empty
list of elements, assigning the same probability to each element. (It is not deﬁned on
the empty list.)
uniform :: [a] →Dist a
uniform l = D [(x,1 / length l) | x ←l]
The three-argument function (−−⊕−) takes a probability p and two elements and
from them constructs a distribution in which the ﬁrst element has probability p and
the second 1−p.
−−⊕−:: Prob →a →a →Dist a
x p⊕y = D [(x,p),(y,1 −p)]
Again, the essence here is the two-element list [(x,p),(y,¬p)] of course. That is, the
distribution x p⊕y generally has two-element support - unless x and y coincide, in
which case it is a point distribution (in unreduced form).
Reduction Function reduction removes duplicates and zeroes from the concrete
representation of a distribution. That does not change the abstract distribution
represented, but makes its handling more eﬃcient. In the sequel it will be built-in to
monadic compositions (such as (>>=) above, and (>=>) etc.)
unpackD :: Ord a ⇒Dist a →[(a,Prob)]
— Recover list representation, reduced.
unpackD = removeDups ◦removeZeroes ◦runD
where
removeZeroes = ﬁlter (λ(x,p) →p  0)
removeDups = toList ◦fromListWith (+)
8 Think of f as taking a stochastic-matrix row-label to the distribution of column-label probabilities in that row.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

402
Gibbons et al.: QIF with Monads in Haskell
output
9:78
0
1
channel:
input
1
(
)
0
.99
.01
←sums to 1
1
.02
.98
←sums to 1
Figure 12.1 Channel matrix describing not-quite-perfect transmission
reduction :: Ord a ⇒Dist a →Dist a
reduction = D ◦unpackD
— Unpack and then repack.
Here (from right to left) function runD extracts the essence, namely the list of
pairs; then removeZeroes and removeDups reduce the list; and ﬁnally D replaces
the reduced list within the constructor, where it began. The Haskell library function
fromListWith requires an ordering on the elements, so it can make use of a binary
search tree in order to remove duplicates in O(n log n) time; one could instead require
only element equality rather than ordering, at the cost of O(n2) time.
12.3 QIF and hyper-distributions
With the above preliminaries, we can now move to quantitative information ﬂow.
12.3.1 Background
In the communication channels of (Shannon, 1948), information ﬂows in at the
source, is transmitted but possibly with errors introduced, and then ﬂows out at the
target. Typically the error-rate is described mathematically as a channel matrix that
gives explicit probabilities for message corruption. For example, Fig. 12.1 shows
a channel matrix representing correct transmission with high probability only - if
a 0 is input, there is a 1% probability that a 1 will come out instead; and for a 1
input, the probability of error is 2%. As noted earlier, the matrix is called stochastic
because its rows sum to one.
Analyses of channels like Fig. 12.1 assume a distribution over the inputs, and look
at the correlation with the resulting output. For example, if we assume a uniform
input distribution on {0,1}, then the joint distribution matrix between inputs and
outputs would be as in Fig. 12.2, obtained by multiplying the input probabilities
(1/2 here) along the rows. Here it's the matrix as a whole that sums to 1, not the
individual rows.
The 'information ﬂow' due to such channel matrices is often expressed as the
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12.3 QIF and hyper-distributions
403
output
9:78
0
1
channel:
uniform input
*


←sums to 1 overall
0
1/2
.495
.005
1
1/2
.01
.49
Figure 12.2 Joint distribution between input and output, based on Fig. 12.1 and uniform input
output
9:78
0
1
channel:
input
1
(
)
0
.51
.49
←sums to 1
1
.49
.51
←sums to 1
Figure 12.3 Channel matrix describing a 1% success-rate
diﬀerence between the Shannon Entropy of the input before- and after the output is
observed. 9 In this example the Shannon Entropy beforehand is the entropy of the
prior distribution: simply 1 bit, because that distribution is uniform over two values.
The Shannon Entropy afterwards is however the conditional Shannon Entropy
obtained by averaging the Shannon Entropies of the posterior distributions, with
the weights of that averaging being their probability of occurrence. In Fig. 12.2
for example, the marginal probability that a 0 is output is .495+.01 = .505 and
the conditional distribution on the input is then the normalised column for that
output, i.e. that it was 0 with probability .495/.505 = .980 and 1 with probability .020,
which distribution has Shannon Entropy .140. Similarly, for output 1 the marginal
probability is .495 and the conditional probability on the inputs is 0 with probability
.005/.495 = .010 and output 1 with probability .990, with Shannon Entropy .081.
The conditional Shannon Entropy overall is thus the weighted average of those two,
that is .505×.140 + .495×.081 = .111, and the number of bits transmitted is the
entropy-before vs. conditional-entropy-afterwards diﬀerence, that is 1−.111 = .889
bits in this case. It's a pretty good channel from the communication point of view.
When we look at this from the point of view of computer security however, it's a
terrible channel: it has leaked almost all (0.889 bits) of the secret (1 bit). Far better
for secrets would be the channel of Fig. 12.3 that has only a very slight bias induced
on the output with respect to the input. A similar calculation for the above shows the
conditional Shannon Entropy on the uniform input in this case to be 0.9997, so that
9 The Shannon Entropy of a p vs. 1−p distribution is −(p lg(p) + (1−p) lg(1−p)).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

404
Gibbons et al.: QIF with Monads in Haskell
this channel leaks only 0.0003 bits. This is more like what we want for our secure
programs. (For communication, however, it's Fig. 12.3 that is a terrible channel.)
Thus although the mathematics for ﬂow of communications and for ﬂow of secrets
(leaks) from programs is the same, the interpretation is complementary.
In spite of that correspondence, it turns out that Shannon Entropy is sometimes
(even often) very far from the best way to measure entropy where leaks from
computer programs are concerned. (Smith, 2009) argued that in some cases it might
be better to measure (in-)security by using instead the maximum probability that the
secret could be guessed: an intelligent attacker would guess the secret(s) she knows
to have the largest probability: this is called Bayes Vulnerability. As an entropy
(but not Shannon entropy) this is expressed as a real-valued function that takes a
distribution to 1 −maximum probability, where the subtraction from one (1−) is a
technical device that ensures increasing disorder leads to increasing entropy: that
function is called Bayes Risk. On a ﬁxed state space X of size N, the maximum Bayes
Risk is 1−1/N and - as for Shannon Entropy - occurs on the uniform distribution.
We illustrate the diﬀerence with an example of two possible distributions of
passwords. In one distribution, people choose alphabetic passwords uniformly, but
never use numbers or punctuation. In the other, people mostly choose their friends'
names (which are alphabetic) but, among those who do not, the choice is uniform
between all other passwords including other alphabetics and those with numbers
and punctuation.
To keep the calculations simple, we will suppose the password space is the
four-element set {A,a,9,%} for names, alphabetics generally, numbers and, ﬁnally,
other punctuation. Suppose that the ﬁrst distribution has probabilities (in that order)
of (1/2, 1/2,0,0) and that the second distribution is {(2/3, 1/9, 1/9, 1/9)}. In Fig. 12.4
we see a tabulation of the Shannon Entropy H and Bayes Risk R for these two
distributions.
Distribution π1 has Shannon Entropy H(π1)=1 and Bayes Risk R(π1)=1/2. For
π2 we ﬁnd H(π2) = 2/3 lg(3/2) + 3·1/9 lg(9) ≈1.45, and R(π2) = 1−2/3 = 1/3.
Thus 'from Shannon's point of view' distribution π2 is more secure than π1 -
that is H(π2)>H(π1). But Bayes would say the opposite, because R(π2)<R(π1) or,
equivalently, we have V(π2)>V(π1), indicating that π2 is more vulnerable, not less. In
summary, distribution π2 has more Shannon Entropy, i.e. more information-theoretic
disorder than π1, but still is more vulnerable to a a one-guess attacker than π1 is.
But it does not stop there: a later development (Alvim et al., 2012) was the further
generalisation of entropies to not just two (Shannon, Bayes) but in fact an inﬁnite
family of them based on 'gain functions' that captured the economics of the attacker:
How much is the secret worth to her? Both Shannon Entropy and Bayes Risk are
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12.3 QIF and hyper-distributions
405
Shannon
Bayes
Bayes
Entropy
Risk
Vulnerability
V() =
password →
A
a
9
%
H()
R()
1−R()
π1 probability
1/2
1/2
0
0
1
1/2
1/2
π2 probability
2/3
1/9
1/9
1/9
∼1.45
1/3
2/3
Distribution π2 has more Shannon Entropy than π1, but still π2 is an easier target than π1 for
the one-guess password hacker.
Figure 12.4 Entropies for two example password distributions
instances of these gain functions. 10 Then a ﬁnal generalisation (McIver et al., 2015)
(for now) was to recognise that, as functions, gain-function-determined entropies
are characterised simply by being concave and continuous over distributions. 11
Pulling back however from the brink of runaway generalisation, we simply note
that, whatever entropy is being used, it is applied to the prior before the channel, and
applied conditionally to the resulting joint distribution between input and output
determined after the channel. In that latter case, the joint distribution is regarded
as a distribution (the output marginal) over posterior distributions obtained by
conditioning the input distribution on the event that each particular output has
occurred (the normalised joint-matrix columns).
It is 'distributions on posterior distributions' that have been named hyper-
distributions (McIver et al., 2014a, 2010), a conceptual artefact synthesised by
asking "If we allow entropies from a general class of functions f on distributions
(including Shannon Entropy and Bayes Risk as special cases), what operation do we
carry out to determine the f -leakage of a channel with respect to a particular prior?"
The answer is "Apply the entropy to the prior, and take the expected value of the
same entropy over the hyper-distribution produced by the channel's acting on that
prior; then compare the two numbers obtained." 12
That is why we focus on hyper-distributions as a unifying concept for QIF - it
is the common feature of determining leakage in the generalised setting explained
above, where there are (inﬁnitely) many possible entropies to consider. In other
10 A technical detail for those familiar with (Alvim et al., 2012) - Shannon Entropy requires an inﬁnitary gain
funtion, and in fact is more neatly expressed with the complementary 'loss functions' that express how much
the attacker has to lose.
11 This generalisation was introduced in (McIver et al., 2015) as loss functions' determining 'uncertainty measures'
that were continuous and concave.
12 Popular comparisons include 'additive leakage', where you subtract the former from the latter, and 'multiplicative
leakage' where you take the quotient.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

406
Gibbons et al.: QIF with Monads in Haskell
output
9:78
0
1
perfect channel:
skewed input
*


0 0.9
1
0
1 0.1
0
1
The resulting hyper is 0.9×(1,0) + 0.1×(0,1), indicating that with probability 0.9 the
adversary will know the input was 0, and with probability 0.1 she will know that it was 1.
Figure 12.5 Perfect channel, 0-skewed input
output
9:78
0
1
nearly perfect channel:
skewed input
*


0 0.9
1
0
1 0.1
.01
.99
Figure 12.6 Nearly perfect channel, 0-skewed input
work we discuss extensively how hyper-distributions lead to a robust notion of a
program-reﬁnement-like 'leakage ordering' (⊑) on QIF programs (McIver et al.,
2014a, 2010, 2015).
An example of that uniﬁcation is the comparison of a perfect channel with a
nearly perfect channel applied to the same non-uniform prior. We will appeal to two
diﬀerent entropies.
The point is not the precise numbers in the hypers, but rather that those hypers, as an
abstraction, contain all the information needed to calculate the (conditional) Shannon
Entropy, the Bayes Risk, and indeed any other well behaved entropy we require. For
the perfect Fig. 12.5 the conditional Shannon Entropy is 0.9H(1,0) + 0.1H(0,1) = 0,
and the Bayes Risk is 0.9R(1,0) + 0.1R(0,1) = 0. In both cases the observer is in no
doubt about the input's value.
For the nearly perfect Fig. 12.6 however, the conditional Shannon Entropy is
0.901H(0.999,0.001) + 0.099H(0,1)
=
0.02
,
and the Bayes Risk is
0.901R(0.999,0.001) + 0.099R(0,1)
=
0.001
.
In this case there is some residual doubt - but not much.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12.3 QIF and hyper-distributions
407
12.3.2 Hyper-distribution and generalised entropies seen monadically
We now bring our two conceptual threads together: monads and QIF.
In §12.2.1 we saw that monads capture a notion of computation T by lifting a
base-type A to a type TA of computations over A; and in §12.2.2 we saw how in
particular the distribution monad D lifted a type to the probabilistic computations on
that type. Our approach to QIF is based on that; but to get the extra expressive power,
i.e. to describe not only probability but information ﬂow, we lift base-type DA,
rather than A itself. The 'ordinary' probabilistic computations of type A→DA are
replaced by computations of type DA→D(DA), or DA→D2A of 'information-
ﬂow aware' probabilistic computations on A. For that we are using the same monad
D as before, but we are starting 'one level up'. It is the D2A type that we have called
the hyper-distributions on A, or "hypers" for short.
The ﬁrst application of D takes us, as we saw in §12.2.2 and have seen in other
work in this area, to probabilistic computations - but with just the one D we
have only the probabilistic computations that are information-ﬂow unaware. For
information-ﬂow awareness we need the extra level that hypers provide, so that we
can do the before-after comparisons described in §12.3.1 just above.
We will see that it is the unit η that takes say a distribution δ:DA to a particular
hyper ⟨δ⟩that is information-ﬂow aware, but in a degenerate sense, as before: it is
aware of nothing. In fact it is only the point distribution on the original distribution
δ, and so this hyper will in fact denote the (eﬀect of) a probabilistic program that
leaks nothing, just as η earlier gave us possibly improper programs that in fact are
proper, sequence-writing programs that have not yet written, demonic programs that
behave deterministically, and probabilistic programs that use only one-sided dice.
This is indeed the kind of embedding that we mentioned before.
The multiplication μ, on the other hand, will now have a more interesting role
beyond its technical use in deﬁning Kleisli composition. Given a proper (i.e. not
necessarily point) hyper Δ in D2A, the squash μΔ of type DA is the result of the
'simple' probabilistic program from which all information-ﬂow properties have been
removed. In §12.7.1 we discuss the antecedents of that approach.
Thus monadic QIF programs for us will have type DA→D2A. If we express a
channel C that way, in the style of §12.3.1, and pick some uncertainty function f ,
then on a prior π the uncertainty beforehand is f π - and after observing the output
of channel C it is (μ◦D f )(Cπ). One then either subtracts or divides one from/by the
other to obtain the additive- or multiplicative f -leakage of C applied to π.
But a further advantage of this extra structure, introduced by the 'second D', is
that we can represent -within the same type - both
Markov program steps that change the state probabilistically, but leak no information
while they do that, and the complementary
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

408
Gibbons et al.: QIF with Monads in Haskell
Channel program steps that leak information but do not change the state while they
do that.
A (pure) Markov program M (for "Markov") will be of type DA→D2A and has
the characteristic that for any initial distribution δ we ﬁnd that Mδ = ηδ′ for some
δ′, i.e. that the result of the M is always a singleton hyper. And indeed M as a matrix
would take row δ, encoding the initial distribution, to row δ′ encoding the ﬁnal
distribution. On the other hand, a (pure) channel C again has type DA→D2A (the
same as a Markov program), but in addition has the characteristic that μ(Cδ) = δ,
i.e. that the state distribution is not changed: all that is possible is that information
can leak.
Recall that the trivial channel that leaks nothing, treating all inputs the same 13
takes any prior to the singleton hyper on that prior: that is, its action is π →⟨π⟩,
indicating that after the channel has run the adversary knows for sure that the
distribution on the input was. . . just π, which she knew before.
On the other hand, the channel that leaks everything (the identity matrix) takes input
π in general to a non-singleton hyper whose support is (only) point distributions: for
example the prior (2/3, 1/3) is taken by that channel to the hyper 2/3⟨(1,0) ⟩+1/3⟨(0,1) ⟩,
indicating that with probability 2/3 the adversary will know for sure that the input
was 0 and with probability 1/3 she will know that it was 1. That is just what a 'leak
everything' channel should do.
With the above as a starting point, Kleisli composition of hyper programs allows
the two possibilities above to be combined sequentially, while still remaining within
the same type, even though we are now one level up at DA rather than A: that's
what the generality of Kleisli composition does for us automatically. That is, we
can without any further deﬁnitions write C; M for a QIF-aware program that leaks
information and then changes the state; and similarly a program M; C changes the
state ﬁrst and then leaks that. 14 Either way, the result is a single function of type
DA→D2A. Further, the order-theoretic structure of the space DA, e.g. limits, allow
us to introduce smoothly all the apparatus of sequential programming, including
loops - with the probabilistic- and the QIF features added in 'for free' (McIver et al.,
2014b). 15
13 Concretely this is any channel matrix all of whose rows are equal: the nicest formulation is a 0-column matrix,
i.e. there is no output at all; but slightly less shocking is a one-column matrix of all 1's that gives the same
output for all inputs. With more than one column, there can clearly be more than one output: but since the rows
are the same, the relative frequencies of the outputs gives no information about which input produced them.
14 Observe that the combination C; M corresponds to a step of a Hidden Markov Model (Baum and Petrie, 1966):
in HMM's ﬁrst some information about the current state is released and then the state is probabilistically updated.
Here we arrange for those two eﬀects to be conceptually separated, which allows them to be put together in any
combination.
15 We do not discuss the QIF order theory in this chapter, however.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12.4 A concrete programming language Kuifje, and its semantics
409
12.4 A concrete programming language Kuifje, and its semantics
In §12.3 we introduced Markov steps and channel steps as program fragments, but
abstractly. Both are of type DA→D2A but, as we saw, each has further speciﬁc
and complementary properties: the Markov step releases no information, and the
channel step makes no change to the state. In this section we give concrete notations
for these program steps, together with constructions like conditional and iteration
for making more substantial programs. The functional components from §12.2.4
above are used for that.
The presentation takes the form of a sequence of three small languages, of
increasing expressivity. We start in §12.4.1 with a simple imperative command
language CL consisting of assignment statements, conditionals, and loops; in §12.4.2
we add probabilistic assignment statements, yielding the probabilistic command
language PCL (essentially pGCL of (McIver and Morgan, 2005)); and ﬁnally in
§12.4.3 we add observations, yielding our complete QIF language Kuifje.
We use an initial-algebra representation for the syntax of these languages because
it enables a straightforward implementation of their denotational semantics as
folds. Moreover, the representation pays oﬀin §12.5 where it allows us easily to
derive an eﬃcient implementation of the hyper-distribution semantics from its naïve
speciﬁcation.
12.4.1 Basic language CL
Concrete syntax We will start without probabilistic or QIF features, giving a basic
Command Language, or CL for short, that is just the usual "toy imperative language"
in which we can write programs like the following:
y := 0;
while (x > 0) {
y := y + x;
x := x - 1;
}
When this program is run with an initial state where x = 3, its ﬁnal state has x = 0
and y = 0 + 3 + 2 + 1 = 6.
Abstract syntax The obvious representation of a CL program over a state space of
type S is as the type [Instruction S] of lists of instructions acting on S, where each
instruction is either a state update, a conditional with a guard and two branches, or a
loop with a guard and a body:
type CL s = [Instruction s]
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

410
Gibbons et al.: QIF with Monads in Haskell
data Instruction s
= UpdateI (s →s)
| IfI (s →Bool) (CL s) (CL s)
| WhileI (s →Bool) (CL s)
However, because the mutual recursion between instructions and programs would
cause complications later on, we choose instead a 'continuation-style' representation
that is directly recursive. Each of its constructors takes an additional argument
representing 'the rest of the program', and there is an additional constructor Skip
representing the 'empty' program:
data CL s
= Skip
| Update (s →s) (CL s)
| If (s →Bool) (CL s) (CL s) (CL s)
| While (s →Bool) (CL s) (CL s)
(12.6)
In particular, CL S is isomorphic to [Instruction S].
For instance, in the example program above we could use the state
data S = S {x :: Int,y :: Int}
(a record with two ﬁelds), which would allow us to render the above example as
follows in Haskell: 16
example1 :: CL S
example1 =
Update (λs →s.y := 0)
(While (λs →s.x > 0)
(Update (λs →s.y := (s.y + s.x))
(Update (λs →s.x := (s.x −1))
Skip))
Skip)
(12.7)
We now discuss the constructions individually. Skip denotes the empty program.
The program Update f p denotes the program that ﬁrst transforms the state with f
and then proceeds with program p. Program If c p q r checks whether the current
state satisﬁes predicate c, and proceeds with p if it does and with q if it does not;
in either case, it subsequently continues with r. Finally, the program While c p q
checks whether the current state satisﬁes the predicate c; if it does, it executes p and
then repeats the while loop, and if it does not, it continues with q.
16 Note that notation like s.y := (s.y + s.x), with the obvious meaning, is not pseudo-code, but more familiar
rendering of valid Haskell code based on lens library17 operators. We refer the interested reader to this
chapter's companion code for the details.
17 https://hackage.haskell.org/package/lens
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12.4 A concrete programming language Kuifje, and its semantics
411
We now continue by using the abstract syntax to deﬁne several basic combinators
that will allow us to write programs more compactly:
skip :: CL s
skip = Skip
update :: (s →s) →CL s
update f = Update f skip
cond :: (s →Bool) →CL s →CL s →CL s
cond c p q = If c p q skip
while :: (s →Bool) →CL s →CL s
while c p = While c p skip
And we can deﬁne sequential composition:
() :: CL s →CL s →CL s
Skip
 k = k
Update f p  k = Update f (p  k)
If c p q r
 k = If c p q (r  k)
While c p q  k = While c p (q  k)
Using the combinators and (), the examples can be written equivalently as
example1 =
update (λs →s.y := 0) 
while (λs →s.x > 0)
(update (λs →s.y := (s.y + s.x)) 
update (λs →s.x := (s.x −1)))
Note that ⟨CL s,skip,()⟩forms a monoid.
Semantics We can deﬁne a compositional semantics for CL programs over a state
of type S as the carrier of a (CLF S)-algebra for the functor CLF S:
data CLF s a
= SkipF
| UpdateF (s →s) a
| If F (s →Bool) a a a
| WhileF (s →Bool) a a
Note that such a semantic deﬁnition, i.e. as a carrier of a syntactic algebra, is
compositional by construction. A (CLF S)-algebra is a pair (A,alg) consisting of a
type A and a function alg::CLF S A →A. In particular, (CL S,c) is a (CLF S)-algebra,
where
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

412
Gibbons et al.: QIF with Monads in Haskell
c :: CLF s (CL s) →CL s
c SkipF
= Skip
c (UpdateF f p) = Update f p
c (If F c p q r)
= If c p q r
c (WhileF c p q) = While c p q
Indeed, (CL S,c) is the initial (CLF S)-algebra; which is to say, for any other (CLF S)-
algebra (A,alg) there is a unique morphism of algebras CL S →A; informally, this
unique morphism 'propagates alg through the abstract syntax tree'. Since this unique
morphism is determined by the algebra alg, we introduce a notation alg for it.
Concretely, alg is deﬁned as follows:
− :: (CLF s a →a) →(CL s →a)
alg Skip
= alg SkipF
alg (Update f p) = alg (UpdateF f (alg p))
alg (If c p q r)
= alg (If F c (alg p) (alg q) (alg r))
alg (While c p q) = alg (WhileF c (alg p) (alg q))
which propagates alg through the abstract syntax of a given program; alg is known
as the fold for algebra (A,alg) (Hutton, 1999).
Any compositional semantics of CL s programs can be formalised as a fold with
an appropriate algebra. For example, one straightforward semantics is as an algebra
on the carrier s →s, i.e., interpreting programs as state-transformation functions.
sem :: CL s →(s →s)
sem = alg where
alg :: CLF s (s →s) →(s →s)
alg SkipF
= id
alg (UpdateF f p) = f >>> p
alg (If F c p q r)
= conditional c p q >>> r
alg (WhileF c p q) = let while = conditional c (p >>> while) q
in while
conditional :: (s →Bool) →(s →s) →(s →s) →(s →s)
conditional c t e = (λs →(c s,s)) >>>
(λ(b,s) →if b then t s else e s)
Here, (>>>) is forward function composition: f >>> g = g ◦f.
Note that sem is not only a fold over the abstract syntax, but also a monoid
morphism from the CL S monoid to ⟨S →S,id,(>>>)⟩.
sem skip
= id
sem (p  q) = sem p >>> sem q
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12.4 A concrete programming language Kuifje, and its semantics
413
The above has set out our general approach to deﬁning a language and its semantics,
illustrating it on the simplest (useful) language possible. We now add probability.
12.4.2 Adding probability: CL →pGCL
The probabilistic version of CL is called PCL, following Haskell's (upper-case)
convention for type constructors. It is eﬀectively the pGCL of (McIver and Morgan,
2005), in turn derived from the seminal work of (Kozen, 1983). Its diﬀerence from
CL is that state updates in PCL are probabilistic, i.e., an update does not assign a
single new state, but rather a probability distribution over (new) states. For instance,
we will be able to express that the variable x in our running example is decremented
probabilistically by either 1 (probability 2/3) or 2 (probability 1/3), as here:
y := 0;
while (x > 0) {
y := y + x;
x := x - (1
2/3⊕2);
}
(12.8)
Similarly, we will make the conditionals in our program probabilistic. For instance,
the following program's while loop chooses with probability 1/2 on each iteration
whether to apply the test x > 0 or x > 1 for termination:
y := 0;
while (x > 0
1/2⊕x > 1) {
y := y + x;
x := x - 1;
}
We can also model the probabilistic choice between entire statements rather than
merely expressions. For instance,
(y := y + 1)
5/6⊕(x := x + 1)
is short-hand for
if (true
5/6⊕false) {
y := y + 1
} else {
x := x + 1
}
The probabilistic nature of state updates is reﬂected as follows in the abstract
syntax:
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

414
Gibbons et al.: QIF with Monads in Haskell
data PCL s
= Skip
| Update (s →d s) (PCL s)
| If (s →d Bool) (PCL s) (PCL s) (PCL s)
| While (s →d Bool) (PCL s) (PCL s)
where →in (12.6) has been replaced by the Kleisli arrow →d for the probability
monad D, so that A →d B is the type of probabilistic programs from A to B:
type a →d b = a →Dist b
The abstract syntax of our ﬁrst probabilistic example (12.8) becomes:
example2 :: PCL S
example2 =
update (λs →return (s.y := 0)) 
while (λs →return (s.x > 0))
(update (λs →return (s.y := (s.y + s.x))) 
update (λs →(s.x := (s.x −1)) 2/3⊕(s.x := (s.x −2))))
Observe that what was written earlier in the example as an assignment of a
probabilistically chosen value is represented here as abstract syntax in the form of a
probabilistic choice between assignments of pure values.
We obtain an interpreter for PCL by reusing the constructions of §12.4.1, simply
adapting the target of the monoid morphism sem from the monoid ⟨s →s,id,(>>>)⟩
of endofunctions with function composition to the monoid ⟨s →d s,return,(>=>)⟩
of Kleisli arrows with forward Kleisli composition.
semd :: Ord s ⇒PCL s →(s →d s)
semd = alg where
alg :: Ord s ⇒PCLF s (s →d s) →(s →d s)
alg SkipF
= return
alg (UpdateF f p) = f >=> p
alg (If F c p q r)
= conditional c p q >=> r
alg (WhileF c p q) = let while = conditional c (p >=> while) q
in while
conditional :: (Ord s) ⇒s →d Bool →(s →d s) →(s →d s) →(s →d s)
conditional c p q = (λs →fmap (λb →(b,s)) (c s)) >=>
(λ(b,s) →if b then p s else q s)
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12.4 A concrete programming language Kuifje, and its semantics
415
12.4.3 Adding observations: pGCL →Kuifje
Finally, we extend PCL with 'observations' to yield our QIF language "Kuifje".
Observations are probabilistically chosen values that the computation outputs, or
'leaks', as a side-eﬀect. For instance, in our running example we express that we can
observe x at the end of each iteration by adding observe x there:
y := 0;
while (x > 0) {
y := y + x;
x := x - (1
2/3⊕2);
observe x
}
(12.9)
To express that we will observe either x or y, with equal probability, we would
write
y := 0;
while (x > 0) {
y := y + x;
x := x - (1
2/3⊕2);
observe x
1/2⊕observe y
}
(12.10)
And ﬁnally, we can express that we either observe x or observe y but we don't
know which with
y := 0;
while (x > 0) {
y := y + x;
x := x - (1
2/3⊕2);
observe (x
1/2⊕y)
}
(12.11)
As an example of that important distinction, suppose there were a secret number
x uniformly distributed with 0≤x<3, and that with probability 1/2 either x mod 2 or
x ÷ 2 were revealed in an observation, i.e. either its low- or high-order bit. If the
observer knew whether mod or ÷ had been used, then afterwards
knowing that mod was used:
with probability 1/3 she would be able to conclude that x was either 0 or 2, assigning
equal probability to each;
with probability 1/6 she would be able to conclude that x was certainly 1.
knowing that ÷ was used:
with probability 1/3 she would be able to conclude that x was either 0 or 1, assigning
equal probability to each; and
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

416
Gibbons et al.: QIF with Monads in Haskell
with probability 1/6 she would be able to conclude that x was certainly 2.
On the other hand, if she did not know which of mod or ÷ had been used, then
afterwards
not knowing which of mod or ÷ was used:
with probability 2/3 she would be able to conclude that x was either 0,1 or 2, with
probabilities 1/2, 1/4 and 1/4 respectively; and
with probability 1/3 she would be able to conclude that x was equally likely to be
1 or 2.
There's no denying that this is a subtle distinction - but it is a real one, and our
programming language expresses it easily. 18
To support observations - and to obtain our third and ﬁnal language Kuifje -
we add a new constructor Observe to the type PCL, based on a datatype Bits that
allows the observation to be eﬀectively of any type; in fact "Bits" is a temporary
expedient that, below, will allow us to construct in Haskell the lists of heterogeneous
element-type that accumulate the observations made. In our ﬁnal presentation, these
lists will disappear - taking "Bits" with them.
data Kuifje s
= Skip
| Update (s →d s) (Kuifje s)
| If (s →d Bool) (Kuifje s) (Kuifje s) (Kuifje s)
| While (s →d Bool) (Kuifje s) (Kuifje s)
| Observe (s →d Bits) (Kuifje s)
— added
The new form Observe f p uses f to probabilistically determine a sequence of bits
from the current state, observe them and then proceed with program p. Here a
sequence of bits is simply a list of booleans.
type Bit = Bool
type Bits = [Bit]
The new basic combinator
observe :: ToBits a ⇒(s →d a) →Kuifje s
observe f = Observe (fmap toBits ◦f) skip
allows us to observe values of any type a whose conversion to Bits has been deﬁned
via the ToBits type class
class ToBits a where
toBits :: a →Bits
18 An explanation of the precise probabilities above is given in App. 12A.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12.4 A concrete programming language Kuifje, and its semantics
417
For instance, Int values can be observed as bits through a binary encoding (here,
quot is division rounding towards zero, so the encoding consists of a sign bit
followed by a list of binary digits, least signiﬁcant ﬁrst; thus, −6 is encoded as
[True,False,True,True]):
instance ToBits Int where
toBits n = (n < 0) : unfoldr (λm →if m ≡0
then Nothing
else Just (odd m,quot m 2)) n
For syntax, the new constructor requires only a straightforward extension of the
composition function ():
() :: Kuifje s →Kuifje s →Kuifje s
Skip
 k = k
Update f p  k = Update f (p  k)
While c p q  k = While c p (q  k)
If c p q r
 k = If c p q (r  k)
Observe f p  k = Observe f (p  k)
— added
The abstract syntax tree of the ﬁrst example (12.9) with observations is:
example3a :: Kuifje S
example3a =
update (λs →return (s.y := 0)) 
while (λs →return (s.x > 0))
(update (λs →return (s.y := (s.y + s.x))) 
update (λs →(s.x := (s.x −1)) 2/3⊕(s.x := (s.x −2))) 
observe (λs →return (s.x)))
For the second (12.10), it is
example3b :: Kuifje S
example3b =
update (λs →return (s.y := 0)) 
while (λs →return (s.x > 0))
(update (λs →return (s.y := (s.y + s.x))) 
update (λs →(s.x := (s.x −1)) 2/3⊕(s.x := (s.x −2))) 
cond (λs →True 1/2⊕False)
(observe (λs →return (s.x)))
(observe (λs →return (s.y))))
And for the third (12.11) it is
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

418
Gibbons et al.: QIF with Monads in Haskell
example3c :: Kuifje S
example3c =
update (λs →return (s.y := 0)) 
while (λs →return (s.x > 0))
(update (λs →return (s.y := (s.y + s.x))) 
update (λs →(s.x := (s.x −1)) 2/3⊕(s.x := (s.x −2))) 
observe (λs →(s.x) 1/2⊕(s.y)))
For semantics, however, the domain of interpretation requires a more signiﬁcant
change. Indeed, we augment the distribution monad Dist with the capabilities of a
Bits-writer monad to accommodate the list of accumulated observations: 19 Thus
we interpret programs as Kleisli arrows s →db s of this augmented monad.
type a →db b = a →Dist (Bits,b)
Again because of our general approach, the structure of the interpreter remains
largely the same, because most cases are parametric in the underlying monad: ﬁrst
we had s →s; then we had s →d s and now we have s →db s. The two cases that
require attention are Update and Observe.
semdb :: Kuifje s →(s →db s)
semdb = algP where
algP :: (Ord s) ⇒KuifjeF s (s →db s) →(s →db s)
algP SkipF
= λx →return ([ ],x)
algP (UpdateF f p) = uplift f >=> p
algP (If F c p q r)
= conditional c p q >=> r
algP (WhileF c p q) = let while = conditional c (p >=> while) q
in while
algP (ObserveF f p) = obsem f >=> p
In the case of Update we lift the update function f from the distribution monad to
the augmented distribution monad, by adding an empty sequence of observations.
uplift :: (a →d b) →(a →db b)
uplift f = fmap (λb →([ ],b)) ◦f
In the case of Observe we extract the observation and return it alongside the current
state.
obsem :: (s →d Bits) →(s →db s)
obsem f = λs →fmap (λw →(w,s)) (f s)
19 This list of observations becomes ever longer as the program executes; but in §12.5.3 the whole list, and Bits,
will be 'quotiented away'.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12.5 Hyper-distributions: from leaked values
to leaked information 419
Finally, while we preserve the deﬁnition of If and While in terms of the more
primitive conditional, we do modify the conditional to leak its argument.
conditional :: (Ord s) ⇒(s →d Bool) →(s →db s) →(s →db s) →(s →db s)
conditional c p q = obsem (fmap toBits ◦c) >=>
(λ([b],s) →return ([b],(b,s))) >=>
(λ(b,s) →if b then p s else q s)
The consequence is that the programs skip andcond (λs →True 1/2⊕False) skip skip
now have diﬀerent semantics:
> semdb skip ()
1 ÷ 1
([ ],())
> semdb (cond (λs →True 1/2⊕False) skip skip) ()
1 ÷ 2
([False],())
1 ÷ 2
([True],())
There are two good reasons for having leaking conditionals. It is a common (though
not universal) assumption in QIF, a pragmatic principle that one should not 'branch
on high'. Much more important, however, is that it enables a compositional hyper-
semantics, as we explain in Section 12.5.3.
12.5 Hyper-distributions: from leaked values
to leaked information
In §12.4 we deﬁned the syntax and semantics of our language in three stages, of
which Kuifje - with probabilistic choice and observations - was the ﬁnal outcome.
We now undertake a major abstraction, removing the sequence of observed values
but leaving behind the information-ﬂow eﬀect they induce.
12.5.1 Abstracting from observed values
If an observer is interested only in information ﬂow about the value of a program's
ﬁnal state, then - we will argue - the values of the observations themselves are
irrelevant. An example of this is spies who speak diﬀerent languages. If they are
to report the value of a secret Booolean, it makes no diﬀerence whether they say
"True/False" or "Waar/Onwaar" or "Vrai/Faux" as long as their controller knows the
correspondence between the observed utterance and the hidden value that caused it.
Thus in our Bit-sequence semantics it should not matter whether the observations
are say
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

420
Gibbons et al.: QIF with Monads in Haskell
["true","true","false"]
or
["waar","waar","onwaar"]
or
["vrai","vrai","faux"] .
They all three result in exactly the same information ﬂow.
The abstraction we are about to implement, motivated by that, allows a drastic
simpliﬁcation of the semdb semantics: we throw away the sequences of Bits, but
we retain the distinctions they made. Further, if we propagate the abstraction to the
leaves of the abstract syntax tree, we never have to construct the sequences in the
ﬁrst place - and then we can throw away the Bits type itself. Here is how it is done.
In the above interpretation, the type S →Dist (Bits,S) denotes a map from initial
states of type S to probability distributions of sequences of observed Bits together
with a ﬁnal state of type S.
The resulting distributions dp of type Dist (Bits,S) are isomorphic to pairs (d,f) of
type (Dist Bits,Bits →Dist S), where the domain of f is restricted to bit sequences
that occur with non-zero probability in d. This isomorphism is witnessed by the
functions toPair and fromPair.
toPair :: (Ord s) ⇒Dist (Bits,s) →(Dist Bits,Bits →Dist s)
toPair dp = (d,f)
where
d
= fmap fst dp
f ws = let dpws = D [(s,p) | ((ws′,s),p) ←runD dp,ws′ ≡ws]
in D [(s,p / weight dpws) | (s,p) ←runD dpws]
fromPair :: (Dist Bits,Bits →Dist s) →Dist (Bits,s)
fromPair (d,f) = join (fmap (λws →fmap (λs →(ws,s)) (f ws)) d)
The function toPair allows us to determine the likelihood of each possible trace of
observations, together with the conditional distribution of possible states that the
trace induces.
For instance, for the program over two Booleans
example4 :: Kuifje (Bool,Bool)
example4 = observe (λ(b1,b2) →b1 1/2⊕b2)
and the uniform distribution of Boolean pairs as input distribution
boolPairs :: Dist (Bool,Bool)
boolPairs = uniform [(b1,b2) | b1 ←bools,b2 ←bools]
where bools = [True,False]
we can see the distribution of observations
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12.5 Hyper-distributions: from leaked values
to leaked information 421
> fst (toPair (boolPairs >>= semdb example4))
1 ÷ 2
[False]
1 ÷ 2
[True]
that is the sequence [False] with probability 1/2 and the sequence [True] the same;
and their respective conditional distributions of ﬁnal states
> snd (toPair (boolPairs >>= semdb example4)) [False]
1 ÷ 2
(False,False)
1 ÷ 4
(False,True)
1 ÷ 4
(True,False)
(12.12)
that is that if False is observed, the posterior distribution of states is as above, and
similarly
> snd (toPair (boolPairs >>= semdb example4)) [True]
1 ÷ 4
(False,True)
1 ÷ 4
(True,False)
1 ÷ 2
(True,True)
(12.13)
If True is observed, the posterior distribution of states is as here instead.
If we do not care about the particular trace of observations - our postulate - but
are only interested in the variation of distributions of ﬁnal states, we can eliminate
the sequences of observations altogether while retaining however the conditional
distributions they determine. This yields so-called hyper-distributions, i.e., distri-
butions of distributions, of type Dist (Dist s). Each of the 'inner' distributions of
the hyper has as its own 'outer' probability the probability that was assigned to the
no-longer-present Bits-sequence that gave rise to it. We do that with this function:
multiply :: (Dist Bits,Bits →Dist s) →Dist (Dist s)
multiply (d,f) = fmap f d
Thus, putting everything together, we can compute the hyper-distribution of ﬁnal
states as follows from a given distribution of initial states.
hyper :: (Ord s) ⇒Kuifje s →(Dist s →Dist (Dist s))
hyper p d0 = multiply (toPair (d0 >>= semdb p))
(12.14)
That yields the following result on our example program, where the outers are on
the left and the inners are on the right:
> hyper example4 boolPairs
1 ÷ 2
1 ÷ 4
(False,True)
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

422
Gibbons et al.: QIF with Monads in Haskell
1 ÷ 4
(True,False)
1 ÷ 2
(True,True)
1 ÷ 2
1 ÷ 2
(False,False)
1 ÷ 4
(False,True)
1 ÷ 4
(True,False)
12.5.2 Hyper-distributions in theory: why?
Although the deﬁnition of hyper calculates the sequences of observations, which
we can then remove, we will see in §12.5.3 below that these two steps can be fused
into one so that only the abstractions are used, and the Bits-sequences are never
constructed.
First however we look at the theoretical reasons for doing this.
Our model of a QIF-aware program is as an initial-state to ﬁnal-state mechanism
that chooses its ﬁnal state probabilistically, depending on the initial state, and might
release information about the state at the same time. The fundamental insight in
theory is that the actual value of the leak is unimportant: the leak's only role is
in allowing an adversary to make deductions about what the state must have been
at that point in order for that leak-value to have been observed. That is, we have
decided as a design principle that the two programs
observe b
and
observe (not b)
are the same: each one, if executed, will allow the adversary to deduce the (current)
value of b because, knowing the source-code, she also knows (in this example)
whether she must negate the leak or not; and - beyond leaking b - they are
operationally the same, since neither changes the state. This being so, we use hyper-
distributions in the (denotational) theory to abstract from those output values; and
the result is that two programs are behaviourally equal just when their denotations
are equal - i.e. this way we achieve full abstraction.
Further, this 'tidiness' in the semantic structures allows us in a more extensive
presentation to discuss the domain structure of the semantic space: its reﬁnement
order; whether it is complete; how ﬁxed-points are found etc. This is extensively
discussed in other work (McIver et al., 2014b).
12.5.3 Hyper-distributions in practice: why?
If we accept the arguments in §12.5.2 just above, that we are interested only in the
hyper-distribution of ﬁnal states for a given distribution of initial states then, as
we have suggested, hyper is not the most eﬃcient way to compute it: hyper ﬁrst
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12.5 Hyper-distributions: from leaked values
to leaked information 423
computes the full distribution Dist (Bits,s) before condensing it to the usually much
more compact hyper-distribution Dist (Dist s). In this section we explain how that
can be implemented. We work directly with the more compact hyper-distributions
throughout: programs are interpreted as hyper-arrows, and the writer-monad is no
longer used; and this increased eﬃciency is the 'why' of hyper-distributions in
practice. Thus we deﬁne
type a →dd b = Dist a →Dist (Dist b)
which happens to form a monoid as well: ⟨s →dd s,return,>=>⟩. Indeed, we can
derive the hyper semantics directly as a fold semdd,
semdd :: (Ord s) ⇒Kuifje s →(s →dd s)
semdd = algH
(12.15)
by solving the "fold fusion" equation for the algebra algH
post ◦algP
= algH ◦fmap hyper
(12.16)
where
post :: Ord s ⇒(s →db s) →(s →dd s)
post t = λd →multiply (toPair (d >>= t))
Using the following three properties of post
post return = return
(12.17)
post (f >=> g) = post f >=> post g
(12.18)
post (λs →(f s) w⊕(g s)) = λd →(post f d) w⊕(post g d)
(12.19)
it is possible to verify20 that the deﬁnition of algH below satisﬁes (12.16).
algH :: (Ord s) ⇒KuifjeF s (s →dd s) →(s →dd s)
algH SkipF
= return
algH (UpdateF f p) = huplift f >=> p
algH (If F c p q r)
= conditional c p q >=> r
algH (WhileF c p q) = let while = conditional c (p >=> while) q
in while
algH (ObserveF f p) = hobsem f >=> p
conditional :: Ord s ⇒(s →d Bool) →(s →dd s) →(s →dd s) →(s →dd s)
conditional c t e = λd →
let d′ = d >>= λs →c s >>= λb →return (b,s)
20 Note that Equation 12.19 only holds when there are no two inputs x and y such that f x and g y yield the same
observations. This is the case for two branches of a conditional, which, because they leak their condition, always
yield disjoint observations.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

424
Gibbons et al.: QIF with Monads in Haskell
w1 = sum [p | ((b,s),p) ←runD d′,b]
w2 = 1 −w1
d1 = D [(s,p / w1) | ((b,s),p) ←runD d′,b]
d2 = D [(s,p / w2) | ((b,s),p) ←runD d′,not b]
h1 = t d1
h2 = e d2
in if
null (runD d2) then h1
else if null (runD d1) then h2
else join (h1 w1⊕h2)
huplift :: Ord s ⇒(s →d s) →(s →dd s)
huplift f = return ◦(>>= f)
Because semdd immediately abstracts over the observations and never collects them
in a (homogeneously-typed) list, we do not ﬁrst have to convert them to Bits. This
means that we can generalize our syntax of programs to observations of arbitrary
type o:
data Kuifje s
= Skip
| Update (s →d s) (Kuifje s)
| If (s →d Bool) (Kuifje s) (Kuifje s) (Kuifje s)
| While (s →d Bool) (Kuifje s) (Kuifje s)
| ∀o . (Ord o,ToBits o) ⇒Observe (s →d o) (Kuifje s)
and interpret them without requiring a ToBits instance.
hobsem :: (Ord s,Ord o) ⇒(s →d o) →(s →dd s)
hobsem f = multiply ◦toPair ◦(>>= obsem f)
where
obsem :: Ord o ⇒(a →d o) →(a →d (o,a))
obsem f = λx →fmap (λw →(w,x)) (f x)
toPair :: (Ord s,Ord o) ⇒Dist (o,s) →(Dist o,o →Dist s)
toPair dp = (d,f)
where
d
= fmap fst dp
f ws = let dpws = D [(s,p) | ((ws′,s),p) ←runD dp,ws′ ≡ws]
in D [(s,p / weight dpws) | (s,p) ←runD dpws]
multiply :: (Dist o,o →Dist s) →Dist (Dist s)
multiply (d,f) = fmap f d
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12.6 Case Studies
425
In summary, with semdd from (12.15) we obtain the same results as with semdb
(12.12,12.13) - but without the need for post-processing:
> semdd example4 boolPairs
1 ÷ 2
1 ÷ 4
(False,True)
1 ÷ 4
(True,False)
1 ÷ 2
(True,True)
1 ÷ 2
1 ÷ 2
(False,False)
1 ÷ 4
(False,True)
1 ÷ 4
(True,False)
12.6 Case Studies
12.6.1 The Monty Hall problem
The (in)famous Monty Hall problem (Rosenhouse, 2009) concerns a quiz-show
where a car is hidden behind one of three curtains. The other two curtains conceal
goats. The show's host is Monty Hall, and a contestant (Monty's adversary) is trying
to guess which curtain conceals the car.
Initially, the contestant believes the car is equally likely to be behind each curtain.
She chooses one of the three, reasoning (correctly) that her chance of having chosen
the car is 1/3; but the host does not open the curtain. Instead Monty opens one of
the two other curtains, making sure that a goat is there. (Thus if the contestant has
chosen the car - though she does not know that - he will open either of the other
two curtains; but if she has not chosen the car he opens the (unique) other curtain
that hides a goat. Either way, from her point of view, he has opened a curtain where
there is a goat.)
Monty Hall then says "Originally you had a one-in-three chance of getting the
car. But now there are only two possible positions for the car: the curtain you chose,
and the other closed curtain. Would you like to change your mind?" The notorious
puzzle is then "Should she change?"
A qualitative (i.e. non-quantitative) approach to this, relying on intuition, suggests
that
(i) Since Monty Hall could have opened a goat-curtain no matter where the car is,
his doing so conveys nothing; and
(ii) Since the contestant still does not know where the car is, nothing has been
leaked.
But a quantitative approach enables more sophisticated reasoning.21 Even though the
21 . . . but also sometimes unsophisticated too: "Since there are now only two doors, the chance of the car's being
behind the door already chosen has risen to 1/2."
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

426
Gibbons et al.: QIF with Monads in Haskell
contestant does not know for sure where the car is, after Monty's action, is it really
true that she knows no more than before? Or has she perhaps learned something, but
not everything? Has some information ﬂowed? There are many compelling informal
arguments for that.22 But here we give one based on the information-ﬂow semantics
of Kuifje.
We declare the three-element type Door
data Door = DoorA | DoorB | DoorC deriving (Eq,Show,Ord)
and describe Monty's action with a single Kuifje statement: choose a door that is
neither the door already chosen by the contestant nor the one with the car. This is
the hall program just below, with argument ch for the contestant's choice; its initial
state d is where the car is:
hall :: Door →Kuifje Door
hall ch = observe (λd →uniform ([DoorA,DoorB,DoorC] \\ [d,ch]))
The list [DoorA,DoorB,DoorC] \\ [d,ch] is those doors that were not chosen by
the contestant and don't conceal the car: there can be one or two of them, depending
on whether the contestant (so far, unknowingly) chose the car.23
If the contestant initially chooses DoorA, then we obtain the following hyper-
distribution of the car's door after observing the goat revealed by Monty:
doors = uniform [DoorA,DoorB,DoorC]
monty = semdd (hall DoorA) doors
> monty
1 ÷ 2
1 ÷ 3
DoorA
2 ÷ 3
DoorB
1 ÷ 2
1 ÷ 3
DoorA
2 ÷ 3
DoorC
(12.20)
It expresses that the contestant will know (or should realise) that the car is with
probability 2/3 behind the still-closed curtain. The two 1/2 'outer' probabilities
reﬂects (given she chose DoorA) that the remaining closed door is equally likely to
be DoorB or DoorC.24 Since the program treats all doors in the same way, the same
argument holds even if another initial door was chosen: in every case, it is better to
change.
22 For those who still doubt: Suppose there were 100 doors, 99 goats and one car. The contestant chooses one
door, and Monty opens 98 others with goats behind every one. . .
23 The operator (\\) removes all elements of the right list from the left list.
24 That can happen in two ways. If she chose the car (unknowingly) at DoorA, then Monty is equallty likely to
open DoorB or DoorC; if she did not choose the car, it is equally likely to be behind DoorB or DoorC, and thus
equally likely that Monty will open DoorC or DoorB respectively.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12.6 Case Studies
427
Since we have captured the result hyper in the variable monty, we can carry
this analysis a bit further. (Note that we do not have to re-run the program: the
output hyper monty contains all we need for the analysis.) Recall that the Bayes
Vulnerability bv of a distribution (for which we wrote V() in Fig. 12.4) is precisely
the maximum probability of any element:
bv :: Ord a ⇒Dist a →Prob
bv = maximum ◦map snd ◦runD ◦reduction
and that this represents a rational adversary's strategy in guessing a secret whose
distribution is known: guess the secret of (possibly equal) greatest probability. To use
bv in the situation above, where there are two possible distributions the contestant
might face, we simply average her best-chance over each of the two distributions'
likelihood of occurring. For the ﬁrst, with probability 1/2, she will be able to guess
correctly with probability 2/3, giving 1/2×2/3 = 1/3 for the overall probability that
Monty will reveal DoorC and the car will be behind DoorB. We get 1/3 for the other
alternative (it is eﬀectively the same, with the doors changed), and so her overall
probability of ﬁnding the car is 1/3+1/3 = 2/3.
That process can be automated by deﬁning
condEntropy :: (Dist a →Rational) →Dist (Dist a) →Rational
condEntropy e h = average (fmap e h) where
average :: Dist Rational →Rational
— Average a distr. of Rational's.
average d = sum [r × p | (r,p) ←runD d]
which for any entropy, that is bv in the case just below, gives its average when applied
to all the inners of a hyper - yielding the conditional entropy. Thus we get
> condEntropy bv monty
2 ÷ 3
for the (smart) contestant's chance of getting her new car.
12.6.2 A defence against side-channels
Our second example here concerns a side-channel attack on the well known fast-
exponentiation algorithm used for public-key encryptions.
The algorithm is given in pseudo-code at Fig. 12.7. As usual we assume that the
program code is public, so that any side channels caused e.g. by 'branching on high'
might allow an adversary to make deductions about the inputs: in this case, a careful
analysis might be used to distinguish between the two branches of the IF, 25 as
25 For example it could be a timing leak.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

428
Gibbons et al.: QIF with Monads in Haskell
VAR B ←Base.
Global variables.
E ←Exponent.
p ←To be set to BE.
BEGIN VAR b,e:= B,E
Local variables.
p:= 1
WHILE e0 DO
VAR r:= e MOD 2
IF r0 THEN p:= p*b FI
←Side channel.
b,e:= b2,e÷2
END
END
{ p = BE }
Here we are assuming that the 'branch on high' is the undesired side-channel: by detecting
whether or not the branch is taken, the adversary can learn the bits of exponent E - which is
the secret key - one by one. When the loop ends, she will have learned them all.
Figure 12.7 Insecure implementation of public/private key encryption.
Global variables.
VAR B ←Base.
Global variables.
D ←Set of possible divisors.
p ←To be set to BE.
E:= uniform(0..N-1)
Choose exponent uniformly at random.
BEGIN VAR b,e:= B,E
Local variables.
p:= 1
WHILE e0 DO
VAR d:= uniform(D)
←Choose divisor uniformly from set D.
VAR r:= e MOD d
IF r0 THEN p:= p*br FI
←Side channel.
b,e:= bd,e÷d
END
END
{ p = BE }
What does the adversary know about E at this point?
Here the side channel is much less eﬀective: although the adversary learns whether r=0,
she knows nothing about d except that it was chosen uniformly from D, and thus learns little
about e, and hence E at that point. A typical choice for D would be [2,3,5]. When the loop
ends, she will have learned something about E, but not all of it. (In order to be able to
analyse the program's treatment of E as a secret, we have initialised it uniformly from N
possible values.)
Figure 12.8 Obfuscated implementation of public/private key encryption.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12.6 Case Studies
429
indicated in Fig. 12.7, which is equivalent to determining whether the current value
of e is divisible by 2. That occurs each time the loop iterates, and an adversary who
has access to this (e.g. by analysing timing) would therefore be able to ﬁgure out
exactly the initial value of E one bit at a time - and E is in fact the encryption key.
A defence against this side channel attack was proposed by (Walter, 2002)
and is implemented at Fig. 12.8. His idea is that rather than attempting to close
the side channel, instead one can reduce its eﬀectiveness. The problem with the
implementation at Fig. 12.7 is that 2 is always used as a divisor, which is why the ith
branching at the IF-statement is correlated exactly with the i'th bit of the original
secret E. In Fig. 12.8, that correlation is attenuated by adding an extra variable
d, used as divisor in place of 2 - and it is selected independently at random on
each iteration. That obfuscates the relationship between e and the branching at the
IF-statement, because the adversary does not know which value of d is being used.
The information transmitted by the channel is therefore no longer exactly correlated
with the i'th bit of the secret.
To compare the two programs we used the semantics of Kuifje to compute the ﬁnal
hyper-distribution resulting from Fig. 12.8 for an example range of E, determined
by N. We assume that all the variables are hidden, as we are only interested in
the information ﬂowing through the side channel and what it tells us about e's
divisibility by d. 26
Below is a translation of our obfuscated algorithm Fig. 12.8 into Kuifje. All
variables are global, so the state space is:
data SE = SE {base, exp, e, d,p :: Integer}
And we initialise the state as follows:
initSE :: Integer →Integer →SE
initSE base exp = SE {base = base, exp = exp, e = 0, d = 0,p = 0}
And here is the body of the algorithm, based on Fig. 12.8, taking a list ds of divisors:
exponentiation :: [Integer] →Kuifje SE
exponentiation ds =
update (λs →return (s.e := (s.exp))) 
update (λs →return (s.p := 1)) 
while (λs →return (s.e  0))
(update (λs →uniform [s.d := d′ | d′ ←ds]) 
cond (λs →return (s.e 'mod' s.d  0))
(update (λs →return (s.p := ((s.p) × ((s.base) ↑(s.e 'mod' s.d))))) 
update (λs →return (s.e := (s.e −(s.e 'mod' s.d)))))
— Then
26 We are not, in this analysis, considering a brute force attack that could invert the exponentiation.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

430
Gibbons et al.: QIF with Monads in Haskell
skip 
— Else
update (λs →return (s.base := ((s.base) ↑(s.d)))) 
update (λs →return (s.e := (s.e 'div' s.d)))
)
(12.21)
Finally, we project the program's output onto a hyper retaining only the variable E
(that is exp), using the following function:
project :: Dist (Dist SE) →Dist (Dist Integer)
project = fmap (fmap (λs →s.exp))
In the two runs below we choose E uniformly from [0 . . 15], that is a 4-bit exponent
(secret key). The ﬁrst case hyper2 is eﬀectively the conventional algorithm of
Fig. 12.7, because we restrict the divisor d to being 2 every time:
hyper2 = project (semdd (exponentiation [2])
(uniform [initSE 6 exp | exp ←[0 . . 15]]))
The value of hyper2, that is what is known about E after calculating the power p,
is shown in Fig. 12.9. The ﬁrst column (all 1 ÷ 16, that is 1/16) shows that there
are sixteen possible outcomes distributed just as the hidden input E was, that is
uniformly. The second- and third columns show that in each of those outcomes,
the adversary will know for certain (1 ÷ 1) what the secret ket E was. That is, with
probability 1/16 she will know for certain (i.e. with probability 1/1) that it was 0, with
probability 1/16 that it was 1, with 1/16 it was 2 etc. If the prior distribution were
diﬀerent, then the outer of the hyper would be correspondingly diﬀerent: but in each
case the second column, the inners, would be "probability 1" throughout. Compare
that with the "perfect channel" of Fig. 12.5 - it has the same eﬀect, making a hyper
all of whose inners are point distributions.
The second case hyper235, again with uniform choice of E over 4 bits, is what we
are more interested in: it is not a perfect channel for E. In that case we can see what
happens with divisor d's being chosen uniformly from [2,3,5]:
hyper235 = project (semdd (exponentiation [2,3,5])
(uniform [initSE 6 exp | exp ←[0 . . 15]]))
The value of hyper235 is shown in Fig. 12.10. Surprisingly, there are still cases
where E is learned exactly by the adversary: for example, with probability 1/432 she
will learn that E=12 is certain (and similarly 13, 14, 15). But her probability 1/432
of learning that is very low. On the other hand, with a higher probability 41/144,
i.e. about 1/3, the adversary will learn only that E is in the set {3..14} with certain
probabilities. Thus in the second case the hyper shows that with low probability the
adversary learns a lot, but with high probability the adversary learns only a little.
We now discuss further the signiﬁcance of hyper235 resulting from running the
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12.6 Case Studies
431
> hyper2
1 ÷ 16
1 ÷ 1
0
1 ÷ 16
1 ÷ 1
1
1 ÷ 16
1 ÷ 1
2
1 ÷ 16
1 ÷ 1
3
1 ÷ 16
1 ÷ 1
4
1 ÷ 16
1 ÷ 1
5
1 ÷ 16
1 ÷ 1
6
1 ÷ 16
1 ÷ 1
7
1 ÷ 16
1 ÷ 1
8
1 ÷ 16
1 ÷ 1
9
1 ÷ 16
1 ÷ 1
10
1 ÷ 16
1 ÷ 1
11
1 ÷ 16
1 ÷ 1
12
1 ÷ 16
1 ÷ 1
13
1 ÷ 16
1 ÷ 1
14
1 ÷ 16
1 ÷ 1
15
Figure 12.9 Hyper hyper2 produced by running the program of Fig. 12.8 when d=[2].
exponentiation program when d can be 2,3 or 5. A rational adversary will guess that
the value of exp is the one of highest probability: thus in the case 41/144 mentioned
above, she will guess that exp is 7. To ﬁnd out her overall probability of guessing
correctly, we take the average of those maxima.
As in the previous example (§12.6.1) we use the Bayes Vulnerability bv of a
distribution, the maximum probability of any element:
bv :: Ord a ⇒Dist a →Prob
bv = maximum ◦map snd ◦runD ◦reduction
and we average that value over hyper235 using condEntropy:
condEntropy :: (Dist a →Rational) →Dist (Dist a) →Rational
condEntropy e h = average (fmap e h) where
average :: Dist Rational →Rational
— Average a distr. of Rational's.
average d = sum [r × p | (r,p) ←runD d]
yielding the conditional entropy:
> condEntropy bv hyper235
7 ÷ 24
(12.22)
We see that her chance of guessing exp is now less than 1/3, signiﬁcantly less than
the 'can guess with certainty' of hyper2:
> condEntropy bv hyper2
1 ÷ 1
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

432
Gibbons et al.: QIF with Monads in Haskell
> hyper235
1 ÷ 16
1 ÷ 1
0
7 ÷ 72
1 ÷ 14
5
7 ÷ 48
3 ÷ 7
1
1 ÷ 7
7
2 ÷ 7
2
1 ÷ 14
8
1 ÷ 7
3
1 ÷ 21
9
1 ÷ 7
4
1 ÷ 14
10
5 ÷ 36
3 ÷ 20 2
3 ÷ 14
11
3 ÷ 20 3
1 ÷ 14
12
1 ÷ 10 4
4 ÷ 21
13
3 ÷ 20 5
5 ÷ 42
14
3 ÷ 20 6
17 ÷ 216 3 ÷ 34
6
1 ÷ 20 8
3 ÷ 34
8
1 ÷ 20 9
3 ÷ 34
9
1 ÷ 10 10
5 ÷ 34
10
1 ÷ 20 12
3 ÷ 17
12
1 ÷ 20 15
3 ÷ 17
14
41 ÷ 144
3 ÷ 41 3
4 ÷ 17
15
3 ÷ 41 4
2 ÷ 27
3 ÷ 32
7
5 ÷ 41 5
3 ÷ 32
9
3 ÷ 41 6
3 ÷ 32
10
6 ÷ 41 7
1 ÷ 4
11
5 ÷ 41 8
3 ÷ 16
13
4 ÷ 41 9
3 ÷ 32
14
1 ÷ 41 10
3 ÷ 16
15
3 ÷ 41 11
1 ÷ 108 1 ÷ 4
8
2 ÷ 41 12
3 ÷ 4
12
3 ÷ 41 13
5 ÷ 432 1 ÷ 5
9
3 ÷ 41 14
3 ÷ 5
13
31 ÷ 432
3 ÷ 31 4
1 ÷ 5
14
6 ÷ 31 6
1 ÷ 108 1 ÷ 4
10
2 ÷ 31 8
1 ÷ 2
14
3 ÷ 31 9
1 ÷ 4
15
6 ÷ 31 10
1 ÷ 144 1 ÷ 3
11
5 ÷ 31 12
2 ÷ 3
15
6 ÷ 31 15
1 ÷ 432 1 ÷ 1
12
1 ÷ 432 1 ÷ 1
13
1 ÷ 432 1 ÷ 1
14
1 ÷ 432 1 ÷ 1
15
Figure 12.10 Hyper hyper234 produced by running the program of Fig. 12.8 when d=[2, 3, 5].
A more interesting situation however is one where we look at the adversary in more
abstract terms: it is not the secret key E that she wants, but rather the money she
can get by using it. If that were say $1, then her expected proﬁt from an attack on
hyper235 is from (12.22) of course $161/1296, i.e. about 12 cents. But now - even
more abstractly - we imagine that if she guesses incorrectly, she is caught in the act
and is punished: the extra abstraction is then that we assign a notional cost to her of
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12.6 Case Studies
433
say $5 for being punished. In this setting then, one might imagine that she would
never bother to guess the key: as we saw, her probability of guessing correctly is
only about 1/8, and thus of guessing incorrectly is 7/8, giving an expected proﬁt of
1/8×1 −7/8×5, i.e. a loss of about $4.25.
If that were so then, since she is rational, she would not guess at all: it is too risky
because she will lose on average $4.25 every time she does. But it is not so: that is
the wrong conclusion. Recall for example that with probability 1/432 she will learn
that exp was 12 (and similarly for 13, 14, 15) 27 - and in those cases, she will guess.
With a bit of arithmetic, we capture the true scenario of gaining $1 if the guess is
correct and losing $5 if guess is incorrect as follows:
jail :: Ord a ⇒Dist a →Rational
jail d = let m = maximum (map snd (runD (reduction d))) in
(1 × m −5 × (1 −m)) 'max' 0
where the term 1×m −5×(1−m) represents her expected (abstract) proﬁt, and
bounding below by 0 encodes her strategy that if that proﬁt is negative, she won't
risk a guess at all. Now we ﬁnd
> condEntropy jail hyper235
31 ÷ 432
> condEntropy jail hyper2
1 ÷ 1
- that is, that by choosing rationally to guess the password only when her expected
gain is non-negative, the adversary gains 7 cents on average. We see also just above
that in the 2-only case she gets the full $1 on average, because she has no risk of
guessing incorrectly: the value of E is completely revealed.
Note that the calculations and experiments we just carried out were on the hyper-
distributions hyper2 and hyper235 and did not require the program exponentiation
at (12.21) to be re-run on each experiment. Just one run captures in the resulting
hyper all the information we need to evaluate various attacker strategies (like bv and
jail).
Finally, we note that Kuifje is not able currently to deal with the large inputs
required for realistic cryptographic computations. As our examples show however, it
is a useful experimental tool to increase the understanding of the underlying risks
associated with those computations, for example side channels in implementations
of cryptography, and what can be done about them.
27 There is also the case where exp is 0, in which case she learns that for sure - and guesses 0. In practical
circumstances that choice of exp would be forbidden; but to keep things simple in the presentation, we have left
it in.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

434
Gibbons et al.: QIF with Monads in Haskell
12.7 Conclusion
12.7.1 Related work
This chapter brings together two ideas for the ﬁrst time: quantitative information
ﬂow for modelling security in programs, and functional programming's generic use
of monads to incorporate computational eﬀects in programming languages. The
result is a clean implementation of a security-based semantics for programs written
in Haskell.
What makes this synthesis possible is that information ﬂows can be modelled in
program semantics using the Giry Monad for probabilistic semantics (Giry, 1981)
which, as explained above, is applied to the type DX rather than the more familiar
X for some state space.
Quantitative information ﬂow for modelling conﬁdentiality was described by
(Gray, 1990) and in even earlier work by (Millen, 1987), establishing a relationship
between information channels and non-interference of (Goguen and Meseguer, 1984)
and the strong dependence of (Cohen, 1977). This last treatment of non-interference
turned out however to be unable to impose the weaker security guarantees which are
required for practical implementations - it does not allow for partial information
ﬂows, for example, which are very diﬃcult and perhaps even impossible to eradicate.
The channel model for information ﬂow was mentioned by (Chatzikokolakis
et al., 2008) for studying anonymity protocols and was further developed by (Alvim
et al., 2012) to include the ideas of gain functions to generalise entropies and secure
reﬁnement to enable robust comparisons of information ﬂows between channels.
Both of these ideas were already present in earlier work (McIver et al., 2010) which
described a model for quantitative information ﬂow in a sequential programming
context. A special case of that model are programs which only leak information
without updating variables. Such programs correspond exactly to channels.
(McIver et al., 2015) demonstrated that information ﬂow in programs (and
therefore channels too) can be expressed in terms of the Giry monad, unifying the
sequential program operator for programs and 'parallel composition' for channels.
The idea of reﬁnement's merging posterior behaviour is a generalisation of the way
ignorance is handled in qualitative model for information ﬂow (Morgan, 2006, 2009)
which is similarly based on monads (for sets rather than distributions).
The abstraction for information ﬂow and state updates that is required for this
monadic program semantics is inspired by Hidden Markov Models (Baum and Petrie,
1966), but does not assume that all Markov updates and channel leaks are the same -
this generalisation was not present in the original concrete model. Others have also
used a concrete version of Hidden Markov Models for analysing information ﬂow in
programs (Clark et al., 2005a,b) and do not consider reﬁnement.
Probability in sequential program semantics to express randomisation (but not
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12.7 Conclusion
435
information ﬂow) was originally due to (Kozen, 1981) although it was not presented
in the monadic form used here; that seems to be due to (Lawvere, 1962) and then
later brought to a wider audience by (Giry, 1981), as mentioned above.
Haskell's use of monads goes back to (Moggi, 1991), who famously showed that
monads provide a semantic model for computational eﬀects, and (Jones and Plotkin,
1989) used this to present a monadic model of a probabilistic lambda calculus.
(Wadler, 1992) promoted Moggi's insight within functional programming, with
the consequence that monads now form a mainstream programming abstraction,
especially in the Haskell programming language. In particular, several people
(Ramsey and Pfeﬀer, 2002; Erwig and Kollmansberger, 2006; Gibbons and Hinze,
2011) have explored the representation of probabilistic programs as Kleisli arrows
for the probability monad.
12.7.2 Discussion
The approach we have taken to providing an executable model of QIF is as an
embedded domain-speciﬁc language (Hudak, 1996; Gibbons, 2013) called Kuifje,
hosted within an existing general-purpose language. That is, we have not taken
the traditional approach of designing a standalone language for QIF, and building
a compiler that translates from QIF concrete syntax to some more established
language. Instead, we have deﬁned a datatype Kuifje to represent QIF abstract syntax
trees as values, a semantic domain →dd to represent the behaviour of QIF programs,
and a translation function hyper :: Ord s ⇒Kuifje s →(s →dd s) from abstract
syntax to semantic domain - all within an existing host language. In our case, that
host language is Haskell, although that fact is not too important - we could have
chosen OCaml, or Scala, or F#, or any one of a large number of alternatives instead.
Embedded DSLs oﬀer a number of beneﬁts over standalone languages, especially
when it comes to early exploratory studies. For example, one can reuse existing tools
such as type-checkers, compilers, and editing modes, rather than having to build
one's own; moreover, programs in the DSL may exploit features of the host language
such as deﬁnition mechanisms, modules, and basic datatypes, so these do not have
to be added explicitly to the language. These beneﬁts make it quick and easy to build
a prototype for the purposes of studying a new language concept. On the other hand,
programs in the embedded DSL have to be encoded as abstract syntax trees, and
written using the syntactic conventions of the host language, rather than enjoying
a free choice of notation best suited to the task; this can be a bit awkward. Once
DSL design decisions have been explored and the language design is stable, and
the number of users and uses starts to grow, it is easier to justify the additional
eﬀort of developing a standalone implementation, perhaps taking the embedded
DSL implementation as a starting point.
Our Haskell implementation is inspired by work on algebraic eﬀects and han-
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

436
Gibbons et al.: QIF with Monads in Haskell
dlers (Pretnar, 2015), a language concept that assigns meaning to a syntax tree built
out of eﬀectful operations by folding over it with an appropriate algebra known as a
handler. While the conventional approach of algebraic eﬀects and handlers applies to
trees that have a free-monad structure, our approach is an instance of the generalized
framework of (Pieters et al., 2017) that admits handlers for trees with a generalized
monoid structure (Rivas and Jaskelioﬀ, 2017) like our plain monoids.
The monoidal representation of programs as state transformers, while relatively
simple, has one big limitation: it requires that the type of the initial state is the same
as that of intermediate states and of the ﬁnal state. This means that the program
cannot introduce local and result variables, or drop the initial variables and local
variables. This leads to awkward models where the initial state contains dummy
values for local variables that are initialized in the program. We can overcome
this limitation and model heterogenous state by moving - within the framework of
generalized monoids - from plain monoids over set to Hughes' arrows (Hughes,
2000), which are monoids in a category of so-called profunctors.
Acknowledgements
We are grateful for the helpful comments of Nicolas Wu and other members of IFIP
Working Group 2.1 on Algorithmic Languages and Calculi. Annabelle McIver and
Carroll Morgan thank the Australian Research Council for its support via grants
DP120101413 and DP141001119; Morgan thanks the Australian Government for its
support via CSIRO and Data61. Tom Schrijvers thanks the Research Foundation -
Flanders (FWO). Gibbons and Schrijvers thank the Leibniz Center for Informatics:
part of this work was carried out during Dagstuhl Seminar 18172 on Algebraic
Eﬀect Handlers go Mainstream.
Appendix 12A A-priori- and a-posteriori distributions
In §12.4.3 an example compared two programs that released information about a
variable x, initially distributed uniformly so that 0≤x<3. Here we show how those
numbers are calculated. Note that this is not an innovation of this chapter: we are
merely ﬁlling in the background of the conventional treatment of priors (a priori
distributions) and posteriors (a posteriori distributions), for those who might not be
familiar with them.
In our example x is initially either 0, 1 or 2 with probability 1/3 for each, i.e. the
uniform distribution: this is called a priori because it is what the observer believes
before any leaks have occurred. Prior is short for a-priori distribution.
If x mod 2 is leaked, then the observer will see either 0 - when x is 0 or 2; or
1 when x is 1. The 0 observation occurs with probability 2/3, because that is the
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12A A-priori- and a-posteriori distributions
437
probability that x is 0 or 2; observation 1 occurs with remaining probability 1/3. In
the 0 case, the observer reasons that x cannot be 1; and that its probability of being 0
or 2 is 1/2 each, because their initial probabilities were equal. This is the a posteriori
distribution, conditioned on the observation's being 0, so that x is equally likely to
be 0 or 2, and cannot be 1. In the 1 case, she reasons that x must be 1 (and can't be 0
or 2).
The corresponding calculations if x ÷ 2 is leaked are that when 0 is observed, she
reasons that x is equally likely to be 0 or 1; and if she sees 1, she knows for sure that
x is 2.
Now if the choice is made between x mod 2 and x ÷ 2 with probability 1/2, and
the observer knows whether mod or ÷ is used then, whichever it turns out to have
been used, she will be able to carry out the corresponding reasoning above. And so
overall her conclusions are the weighted sum of the separate outcomes, i.e. their
average in this case. Thus:
• with probability 1/2×2/3 = 1/3 she will know that x is either 0 or 2 (with equal
probability for each, as explained above);
• with probability 1/2×1/3 = 1/6 she will know that x is 1;
• with probability 1/2×2/3 = 1/3 she will know that x is either 0 or 1; and
• with probability 1/2×1/3 = 1/6 she will know that x is 2.
The other situation is when the observer does not know whether mod or (÷)
was used. In that case she will see 0 with probability 1/2×2/3 + 1/2×2/3 = 2/3, either
because mod was used and x was 0 or 2, or because (÷) was used and x was 0 or 1.
And in that case 0 is twice as likely as each of the other two, so that the posterior
is that x is 0 with probability 1/2 and is 1 or 2 with probability 1/4 each. When she
sees 1, with probability 1/2×1/3 + 1/2×1/3 = 1/3, she will reason a posteriori that x is
equally likely to be 1 or 2.
These two cases are handled automatically by the semantics we have deﬁned. The
ﬁrst is modelled by a conditional, leaking which branch is taken:
modOrDiv1 :: Kuifje Int
modOrDiv1 =
cond (λs →uniform [True,False])
(observe (λx →return (x 'mod' 2)))
(observe (λx →return (x 'div' 2)))
Its eﬀect is as follows:
> semdd modOrDiv1 (uniform [0 . . 2])
1 ÷ 3
1 ÷ 2
0
1 ÷ 2
1
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

438
Gibbons et al.: QIF with Monads in Haskell
1 ÷ 3
1 ÷ 2
0
1 ÷ 2
2
1 ÷ 6
1 ÷ 1
1
1 ÷ 6
1 ÷ 1
2
The second case is modelled by a probabilistic observation
modOrDiv2 :: Kuifje Int
modOrDiv2 = observe (λx →(x 'mod' 2) 1/2⊕(x 'div' 2))
whose eﬀect is
> semdd modOrDiv2 (uniform [0 . . 2])
2 ÷ 3
1 ÷ 2
0
1 ÷ 4
1
1 ÷ 4
2
1 ÷ 3
1 ÷ 2
1
1 ÷ 2
2
Appendix 12B A password checker
The state is a record of ﬁve ﬁelds: a password pw and a guess gs, each a list of
characters; a loop counter i; a list l of indices still to check; and a Boolean result
ans. Each of the programs uses either i or left to control the loop, but not both; for
simplicity, we use a common state record for them all the programs.
data SP = SP {pw :: [Char], gs :: [Char], l :: [Int], i :: Int, ans :: Bool}
deriving (Show,Eq,Ord)
Here is some boilerplate that invokes Template Haskell to generate a lens (a particular
higher-order function) for each of the state variables: each acts as a getter and setter
for its associated variable.
makeLenses " SP
Function makeState takes a value for the password pw and for the guess gs and
produces a state containing those values (setting the other variables to appropriate
defaults):
makeState :: [Char] →[Char] →SP
makeState pw gs = SP {pw = pw, gs = gs, l = [ ], i = 0, ans = True}
At the end of the run, we will project the ﬁve-variable hyper onto a hyper for pw
alone, since that is the secret the adversary is trying to discover:
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12B A password checker
439
basicI :: Int →Kuifje SP
basicI n =
update (λs →return (s.i := 0)) 
— i := 0;
update (λs →return (s.ans := True)) 
— ans := true
while (λs →return (s.ans ∧s.i < n))
— while (ans ∧i < N) do
(
— begin
cond (λs →return ((s.pw !! s.i)  (s.gs !! s.i)))
—
if (pw [i]  gs [i])
(update (λs →return (s.ans := False)))
—
then ans := false
skip 
—
else skip
(update (λs →return (s.i := (s.i + 1))))
—
i++
)
— end
Figure 12.11 Basic password checker, with early exit
projectPw :: Dist (Dist SP) →Dist (Dist [Char])
projectPw = fmap (fmap (λs →s.pw))
A number of versions of the program now follow. Each starts not from an initial
state, but rather from an initial distribution over states. We will make that a uniform
distribution over all permutations of a password, and a single ﬁxed guess.
initialDist pw gs = uniform [makeState pw′ gs | pw′ ←permutations pw]
The ﬁrst program, shown in Figure 12.11, checks the guess against the password
character-by-character, and exits the loop immediately if a mismatch is found.
Now we prepare to run the program and use projectPw to discover the hyper over
pw that results.
hyperI pw gs = projectPw (semdd (basicI (length pw)) (initialDist pw gs))
Here we choose as possible passwords all permutations of "abc" and actual guess
"abc". It yields the following output, showing that the early exit does indeed leak
information about the password: how long a preﬁx of it agrees with the guess:
> hyperI "abc" "abc"
1 ÷ 6
1 ÷ 1
"abc"
1 ÷ 6
1 ÷ 1
"acb"
2 ÷ 3
1 ÷ 4
"bac"
1 ÷ 4
"bca"
1 ÷ 4
"cab"
1 ÷ 4
"cba"
The ﬁrst inner, with probability 1/6, is the case where the password is correctly
guessed: only then will the loop run to completion, because of our choice of
passwords and guess - if the guess is correct for the ﬁrst two characters, it must be
correct for the third also.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

440
Gibbons et al.: QIF with Monads in Haskell
basicL :: Int →Kuifje SP
basicL n =
update (λs →return (s.i := 0)) 
— i := 0;
update (λs →return (s.ans := True)) 
— ans := true
while (λs →return (s.i < n))
— while i < N do
(
— begin
cond (λs →return ((s.pw !! s.i)  (s.gs !! s.i)))
—
if (pw [i]  gs [i])
(update (λs →return (s.ans := False)))
—
then ans := false
skip 
—
else skip
(update (λs →return (s.i := (s.i + 1))))
—
i++
)
— end
Figure 12.12 Basic password checker, without early exit
The second inner corresponds to the loop's exiting after the second iteration: here,
again because of the particular values we have chosen, the only possibility is that
the ﬁrst letter of the guess is correct but the second and third are swapped.
The third inner is the case where the loop is exited after one iteration: then the
ﬁrst letter must be incorrect (2 possibilities), and the second and third can be in
either order (2 more possibilities), giving 1/2×2 for the inner probabilities.
For our second example of this program, we use a guess "axc" that is not one
of the possible passwords: here, as just above, the 2/3 inner corresponds to an exit
after the ﬁrst iteration. Unlike the above, there is a 1/3 inner representing exit after
the second iteration - guaranteed because the second character "x" of the guess is
certainly wrong. In this case however, the adversary learns nothing about whether
the password ends with "bc" or with "cb".
> hyperI "abc" "axc"
1 ÷ 3
1 ÷ 2
"abc"
1 ÷ 2
"acb"
2 ÷ 3
1 ÷ 4
"bac"
1 ÷ 4
"bca"
1 ÷ 4
"cab"
1 ÷ 4
"cba"
In our second program basicL we try to plug the leak that basicI contains simply by
removing the loop's early exit. It is shown in Fig. 12.12.
We run it with
hyperL pw gs = projectPw (semdd (basicL (length pw)) (initialDist pw gs))
and obtain this surprising result:
> hyperL "abc" "abc"
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12B A password checker
441
basicM :: Int →Kuifje SP
basicM n =
update (λs →return (s.i := 0)) 
— i := 0;
update (λs →return (s.ans := True)) 
— ans := true
while (λs →return (s.i < n))
— while i < N do
(
— begin
(update (λs →return (s.ans :=
—
ans:=
(s.ans ∧(s.pw !! s.i) ≡(s.gs !! s.i))))) 
—
ans ∧(pw [i] = gs [i]);
(update (λs →return (s.i := (s.i + 1))))
—
i++
)
— end
Figure 12.13 Basic password checker, without early exit and without leaking conditional
1 ÷ 6
1 ÷ 1
"abc"
1 ÷ 6
1 ÷ 1
"acb"
1 ÷ 6
1 ÷ 1
"bac"
1 ÷ 3
1 ÷ 2
"bca"
1 ÷ 2
"cab"
1 ÷ 6
1 ÷ 1
"cba"
Still the program is leaking information about the password, even though the loop
runs to completion every time - and this, we now realise, is because the condition
statement within the loop is leaking its condition. We knew that, but had perhaps
forgotten it: remember "Don't branch on high."
Our next attempt therefore is to replace the leaking conditional with an assignment
of a conditional expression, which is how we make the Boolean pw [i]  gs [i]
unobservable. That is shown in Fig. 12.13, and we ﬁnd
hyperM pw gs = projectPw (semdd (basicM (length pw)) (initialDist pw gs))
> hyperM "abc" "abc"
1 ÷ 1
1 ÷ 6
"abc"
1 ÷ 6
"acb"
1 ÷ 6
"bac"
1 ÷ 6
"bca"
1 ÷ 6
"cab"
1 ÷ 6
"cba"
indicating that in this case the adversary discovers nothing about the password
at all: the resulting hyper, projected onto pw, is a singleton over an inner whose
probabilities are simply those we knew before running the program in the ﬁrst place.
But at this point we should wonder why the adversary does not discover the
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

442
Gibbons et al.: QIF with Monads in Haskell
basicN :: Int →Kuifje SP
basicN n =
update (λs →return (s.i := 0)) 
— i := 0;
update (λs →return (s.ans := True)) 
— ans := true
while (λs →return (s.i < n))
— while i < N do
(
— begin
(update (λs →return (s.ans :=
—
ans:=
(s.ans ∧(s.pw !! s.i) ≡(s.gs !! s.i))))) 
—
ans ∧(pw [i] = gs [i]);
(update (λs →return (s.i := (s.i + 1))))
—
i++
) 
— end;
observe (λs →return (s.ans))
— observe ans
Figure 12.14 Basic password checker, success observed
password when she guesses correctly; and we should wonder as well why we haven't
noticed that issue before. . .
The reason is that in our earlier examples the adversary was learning whether she
had guessed correctly merely by observing the side channel! That is, the leak was
so severe she did not even have to look to see whether the password checker had
accepted her guess or not. Only now, with the side channel closed, do we discover
that we have accidentally left oﬀthe ﬁnal observe ans that models the adversary's
learning the result of her guess. We remedy that in Fig. 12.14, and ﬁnd
hyperN pw gs = projectPw (semdd (basicN (length pw)) (initialDist pw gs))
> hyperN "abc" "abc"
1 ÷ 6
1 ÷ 1
"abc"
5 ÷ 6
1 ÷ 5
"acb"
1 ÷ 5
"bac"
1 ÷ 5
"bca"
1 ÷ 5
"cab"
1 ÷ 5
"cba"
that is that with probability 1/6 the adversary learns the password exactly, because
she guessed it correctly; but when she guesses incorrectly, she ﬁnds none of the
passwords she didn't guess to be any more likely than any other.
And now - ﬁnally - we come to our obfuscating password checker that compares
the characters of the password and the guess in a randomly chosen order. It is in
Fig. 12.15.
Running basicR we discover that in the 1/6 case the adversary guesses the password
correctly, she is of course still certain what it is. But now, when she does not guess
correctly, she knows much less than she did in the case hyperI, where we began,
where early exit leaked the length of the longest matching preﬁx.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12B A password checker
443
basicR :: Int →Kuifje SP
basicR n =
update (λs →return (s.l := [0 . . n −1])) 
— l := [0,. . .,n −1];
update (λs →return (s.ans := True)) 
— ans := true;
while (λs →return (s.ans ∧not (null (s.l))))
— while (ans ∧l  [ ]) do
(
— begin
update (λs →uniform [s.i := j | j ←s.l]) 
—
i := uniform (l);
(update (λs →return (s.ans :=
—
ans:=
(s.ans ∧(s.pw !! s.i) ≡(s.gs !! s.i))))) 
—
ans ∧(pw [i] = gs [i]);
(update (λs →return (s.l := (s.l \\ [s.i]))))
—
l := l −{i}
) 
— end;
observe (λs →return (s.ans))
— observe ans
Figure 12.15 Randomized password checker
hyperR pw gs = projectPw (semdd (basicR (length pw)) (initialDist pw gs))
> hyperR "abc" "abc"
1 ÷ 6
1 ÷ 1
"abc"
2 ÷ 3
1 ÷ 6
"acb"
1 ÷ 6
"bac"
1 ÷ 4
"bca"
1 ÷ 4
"cab"
1 ÷ 6
"cba"
1 ÷ 6
1 ÷ 3
"acb"
1 ÷ 3
"bac"
1 ÷ 3
"cba"
The diﬀerence in security between basicI and basicR is clearly revealed by taking
the conditional Bayes entropy of each, i.e. (as we saw in the exponential example)
the probability that an adversary will be able to guess the password after running
the checker. We ﬁnd
> condEntropy bv (hyperR "abc" "abc")
7 ÷ 18
> condEntropy bv (hyperI "abc" "abc")
1 ÷ 2
that is that the chance is 1/2 for the "check in ascending order" version basicI, but it
is indeed slightly less, at 7/18, in the case that the order is random.
For longer passwords, printing the hyper is not so informative; but still we can give
the conditional Bayes vulnerability (and other entropies too). We ﬁnd for example
that the obfuscated algorithm, even with its early exit, reduces the probability of
guessing the password by half:
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

444
Gibbons et al.: QIF with Monads in Haskell
> condEntropy bv (hyperI "abcde" "abcde")
1 ÷ 24
> condEntropy bv (hyperR "abcde" "abcde")
13 ÷ 600
There are other entropies, of course: one of them is "guessing entropy" which is the
average number of tries required to guess the secret: the adversary's strategy is to
guess possible secret values one-by-one in decreasing order of their probability. 28
We deﬁne
ge :: Ord a ⇒Dist a →Prob
ge = sum ◦zipWith (∗) [1 . .] ◦sortBy (ﬂip compare) ◦map snd ◦
runD ◦reduction
and ﬁnd
> condEntropy ge (hyperR "abc" "abc")
7 ÷ 3
> condEntropy ge (hyperI "abc" "abc")
2 ÷ 1
that is that the average number of guesses for a three-character password is just more
than in the sequential case, where the average number of guesses is exactly 2.
For ﬁve-character passwords (of which there are 5! = 120) we ﬁnd
> condEntropy ge (hyperR "abcde" "abcde")
5729 ÷ 120
> condEntropy ge (hyperI "abcde" "abcde")
1613 ÷ 40
that is about 47 guesses for the obfuscated version, on average, versus about 40
guesses for the sequential version. For six-character passwords we ﬁnd
> condEntropy bv (hyperI "abcdef" "abcdef")
1 ÷ 120
> condEntropy bv (hyperR "abcdef" "abcdef")
3 ÷ 800
> condEntropy ge (hyperI "abcdef" "abcdef")
20571 ÷ 80
> condEntropy ge (hyperR "abcdef" "abcdef")
214171 ÷ 720
28 This does not mean that the adversary runs the password checker many times: rather it means that she runs it
once (only) and, on the basis of what she learns, makes successive guesses "on paper" as to what the password
actually is.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

12B A password checker
445
basicS :: Int →Kuifje SP
basicS n =
update (λs →return (s.l := [0 . . n −1])) 
— l := [0,. . .,n −1];
update (λs →return (s.ans := True)) 
— ans := true;
while (λs →return (s.ans ∧not (null (s.l))))
— while (ans ∧l  [ ]) do
(
— begin
update (λs →uniform [s.i := j | j ←s.l]) 
—
i := uniform (l);
cond (λs →return ((s.pw !! s.i)  (s.gs !! s.i)))
—
if (pw [i]  gs [i])
(update (λs →return (s.ans := False)))
—
then ans := false
skip 
—
else skip
(update (λs →return (s.l := (s.l \\ [s.i]))))
—
l := l −{i}
) 
— end;
observe (λs →return (s.ans))
— observe ans
Figure 12.16 Randomized password checker, but with conditional reinstated.
which is about probability 0.008 vs. 0.004 for Bayes vulnerability, and expected
guesses 257 vs. 297 for guessing entropy of the sequential vs. randomised versions
respectively. Those results suggest that the extra security might not be worth the
eﬀort of the obfuscation, at least in these examples.
Finally, we might wonder that - since now we are again allowing an early (though
obfuscated) exit - whether there is any longer a reason to replace our original
conditional in basicI and basicL with the "atomic" assignment to ans in basicM
and its successors. After all, now that the loop's exit is (once again) observable, the
adversary knows what the "answers" ans must have been: a succession of true's and
then perhaps a false. The randomisation of i ensures however that, so to speak, she
does not know the questions. Thus (one last time) we re-deﬁne our program:
hyperS pw gs = projectPw (semdd (basicS (length pw)) (initialDist pw gs))
> hyperS "abc" "abc"
1 ÷ 6
1 ÷ 1
"abc"
2 ÷ 3
1 ÷ 6
"acb"
1 ÷ 6
"bac"
1 ÷ 4
"bca"
1 ÷ 4
"cab"
1 ÷ 6
"cba"
1 ÷ 6
1 ÷ 3
"acb"
1 ÷ 3
"bac"
1 ÷ 3
"cba"
And indeed we ﬁnd replacing the conditional seems to oﬀer no extra security.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

446
References
References
Alvim, Mário S., Chatzikokolakis, Kostas, Palamidessi, Catuscia, and Smith, Ge-
oﬀrey. 2012 (June). Measuring Information Leakage using Generalized Gain
Functions. Pages 265-279 of: Proc. 25th IEEE Computer Security Foundations
Symposium (CSF 2012).
Baum, L. E., and Petrie, T. 1966. Statistical Inference for Probabilistic Functions
of Finite State Markov Chains. The Annals of Mathematical Statistics, 37(6),
1554-1563.
Chatzikokolakis, Konstantinos, Palamidessi, Catuscia, and Panangaden, Prakash.
2008. Anonymity protocols as noisy channels. Information and Computation,
206(2), 378-401. Joint Workshop on Foundations of Computer Security and
Automated Reasoning for Security Protocol Analysis (FCS-ARSPA 06).
Clark, D., Hunt, S., and Malacaria, P. 2005a. Quantitative Information Flow,
Relations and Polymorphic Types. J. Logic and Computation, 15(2), 181-199.
Clark, David, Hunt, Sebastian, and Malacaria, Pasquale. 2005b. Quantiﬁed In-
terference for a While Language. Electr. Notes Theor. Comput. Sci., 112,
149-166.
Cohen, E.S. 1977. Information Transmission in Sequential Programs. ACM SIGOPS
Operatings Systems Review, 11(5), 133-9.
Denning, Dorothy. 1982. Cryptography and Data Security. Reading: Addison-
Wesley.
Erwig, Martin, and Kollmansberger, Steve. 2006. Probabilistic Functional Program-
ming in Haskell. Journal of Functional Programming, 16(1), 21-34.
Feller, W. 1971. An Introduction to Probability Theory and its Applications. second
edn. Vol. 2. Wiley.
Gibbons, Jeremy. 2013. Functional Programming for Domain-Speciﬁc Languages.
Pages 1-28 of: Zsók, Viktória, Horváth, Zoltán, and Csató, Lehel (eds), Central
European Functional Programming School. Lecture Notes in Computer Science,
vol. 8606. Springer.
Gibbons, Jeremy, and Hinze, Ralf. 2011 (Sept.). Just do It: Simple Monadic
Equational Reasoning. Pages 2-14 of: International Conference on Functional
Programming.
Giry, Michèle. 1981. A Categorical Approach to Probability Theory. In: Banachewski,
B. (ed), Categorical Aspects of Topology and Analysis. Lecture Notes in
Mathematics, vol. 915. Springer.
Goguen, J.A., and Meseguer, J. 1984. Unwinding and Inference Control. Pages
75-86 of: Proc. IEEE Symp on Security and Privacy. IEEE Computer Society.
Gray, J.W. 1990. Probabilistic interference. Pages 170-179 of: IEEE Symposium on
Security and Privacy.
Hudak, Paul. 1996.
Building Domain-Speciﬁc Embedded Languages.
ACM
Computing Surveys, 28(4es), 196.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
447
Hughes, John. 2000. Generalising Monads to Arrows. Science of Computer
Programming, 37(1-3), 67-111.
Hutton, Graham. 1999. A Tutorial on the Universality and Expressiveness of Fold.
Journal of Functional Programming, 9(4), 355-372.
Jones, Claire, and Plotkin, Gordon D. 1989. A Probabilistic Powerdomain of
Evaluations. Pages 186-195 of: Logic in Computer Science. IEEE Computer
Society.
Kiselyov, Oleg, and Shan, Chung-chieh. 2009. Embedded Probabilistic Programming.
Pages 360-384 of: Taha, Walid Mohamed (ed), IFIP TC2 Working Conference
on Domain-Speciﬁc Languages. Lecture Notes in Computer Science, vol. 5658.
Springer.
Kozen, D. 1983. A Probabilistic PDL. Pages 291-7 of: Proceedings of the 15th
ACM Symposium on Theory of Computing. New York: ACM.
Kozen, Dexter. 1981. Semantics of Probabilistic Programs. Journal of Computer
and System Sciences, 22(3), 328-350.
Lawvere, F. William. 1962. The Category of Probabilistic Mappings. Manuscript.
Malcolm, Grant. 1990. Data Structures and Program Transformation. Science of
Computer Programming, 14(2-3), 255-279.
McIver, A.K., and Morgan, C.C. 2005. Abstraction, Reﬁnement and Proof for
Probabilistic Systems. Monographs in Computer Science. New York: Springer
Verlag.
McIver, Annabelle, Meinicke, Larissa, and Morgan, Carroll. 2010. Compositional
Closure for Bayes Risk in Probabilistic Noninterference. Pages 223-235
of: Automata, Languages and Programming, 37th International Colloquium,
ICALP 2010, Bordeaux, France, July 6-10, 2010, Proceedings, Part II.
McIver, Annabelle, Morgan, Carroll, Smith, Geoﬀrey, Espinoza, Barbara, and
Meinicke, Larissa. 2014a. Abstract Channels and Their Robust Information-
Leakage Ordering. Pages 83-102 of: Abadi, Martín, and Kremer, Steve (eds),
Principles of Security and Trust - Third International Conference, POST 2014,
Held as Part of the European Joint Conferences on Theory and Practice of
Software, ETAPS 2014, Grenoble, France, April 5-13, 2014, Proceedings.
Lecture Notes in Computer Science, vol. 8414. Springer.
McIver, Annabelle, Meinicke, Larissa, and Morgan, Carroll. 2014b. Hidden-Markov
Program Algebra with Iteration. Mathematical Structures in Computer Science.
McIver, Annabelle, Morgan, Carroll, and Rabehaja, Tahiry. 2015. Abstract Hidden
Markov Models: a monadic account of quantitative information ﬂow. In: Proc.
LiCS 2015.
Millen, J. K. 1987 (April). Covert Channel Capacity. Pages 60-60 of: 1987 IEEE
Symposium on Security and Privacy.
Moggi, Eugenio. 1991. Notions of Computation and Monads. Information and
Computation, 93(1).
Morgan, C.C. 2006. The Shadow Knows: Reﬁnement of Ignorance in Sequential
Programs. Pages 359-78 of: Math Prog Construction.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

448
References
Morgan, C.C. 2009. The Shadow Knows: Reﬁnement of Ignorance in Sequential
Programs. Science of Computer Programming, 74(8), 629-653.
Peyton Jones, Simon L. 2003. The Haskell 98 Language. Journal of Functional
Programming, 13.
Pieters, Ruben, Schrijvers, Tom, and Rivas, Exequiel. 2017. Handlers for Non-
Monadic Computations. In: Implementation and Application of Functional
Programming Languages.
Pretnar, Matija. 2015. An Introduction to Algebraic Eﬀects and Handlers. Electronic
Notes in Theoretical Computer Science, 319, 19-35.
Ramsey, Norman, and Pfeﬀer, Avi. 2002. Stochastic Lambda Calculus and Monads
of Probability Distributions. Pages 154-165 of: Launchbury, John, and Mitchell,
John C. (eds), Principles of Programming Languages. ACM.
Rivas, Exequiel, and Jaskelioﬀ, Mauro. 2017. Notions of Computation as Monoids.
Journal of Functional Programming, 27, e21.
Rosenhouse, Jason. 2009. The Monty Hall Problem: The Remarkable Story of
Math's Most Contentious Brain Teaser. Oxford University Press.
Shannon, C.E. 1948. A mathematical theory of communication. Bell System
Technical Journal, 27, 379-423, 623-656.
Smith, Geoﬀrey. 2009. On the Foundations of Quantitative Information Flow. Pages
288-302 of: de Alfaro, Luca (ed), Proc. 12th International Conference on
Foundations of Software Science and Computational Structures (FoSSaCS '09).
Lecture Notes in Computer Science, vol. 5504.
Wadler, Philip. 1992. Monads for Functional Programming. In: Broy, Manfred (ed),
Program Design Calculi: Proceedings of the Marktoberdorf Summer School.
Walter, Colin D. 2002. MIST: An Eﬃcient, Randomized Exponentiation Algorithm
for Resisting Power Analysis. Pages 53-66 of: Topics in Cryptology - CT-RSA
2002, The Cryptographer's Track at the RSA Conference, 2002, San Jose, CA,
USA, February 18-22, 2002, Proceedings.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

13
Luck: A Probabilistic Language for Testing
Lampropoulos Leonidas, Benjamin C. Pierce and Li-yao Xia
University of Pennsylvania
Diane Gallois-Wong and Cătălin Hriţcu
INRIA Paris
John Hughes
Chalmers University
Abstract:
Property-based random testing à la QuickCheck requires building
eﬃcient generators for well-distributed random data satisfying complex logical
predicates, but writing these generators can be diﬃcult and error prone. This
chapter introduces a probabilistic domain-speciﬁc language in which generators
are conveniently expressed by decorating predicates with lightweight annotations
to control both the distribution of generated values and the amount of constraint
solving that happens before each variable is instantiated. This language, called Luck,
makes generators easier to write, read, and maintain.
We give Luck a probabilistic formal semantics and prove several fundamental
properties, including the soundness and completeness of random generation with
respect to a standard predicate semantics. We evaluate Luck on common examples
from the property-based testing literature and on two signiﬁcant case studies, showing
that it can be used in complex domains with comparable bug-ﬁnding eﬀectiveness
and a signiﬁcant reduction in testing code size compared to handwritten generators.
13.1 Introduction
Since being popularized by QuickCheck (Claessen and Hughes, 2000), property-
based random testing has become a standard technique for improving software
quality in a wide variety of programming languages (Arts et al., 2008; Lindblad,
2007; Hughes, 2007; Pacheco and Ernst, 2007) and for streamlining interaction with
proof assistants (Chamarthi et al., 2011; Bulwahn, 2012a; Owre, 2006; Dybjer et
al., 2003; Paraskevopoulou et al., 2015).
When using a property-based random testing tool, one writes properties in the
form of executable predicates. For example, a natural property to test for a list
a From Foundations of Probabilistic Programming, edited by Gilles Barthe, Joost-Pieter Katoen and Alexandra
Silva published 2020 by Cambridge University Press.
449
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

450
Lampropoulos et al.: Luck: A Probabilistic Language for Testing
reverse function is that, for any list xs, reversing xs twice yields xs again. In
QuickCheck notation:
prop_reverse xs
=
(reverse (reverse xs) == xs)
To test this property, QuickCheck generates random lists until either it ﬁnds a
counterexample or a predetermined number of tests succeed.
An appealing feature of QuickCheck is that it oﬀers a library of property
combinators resembling standard logical operators. For example, a property of
the form p ==> q, built using the implication combinator ==>, will be tested
automatically by generating valuations (assignments of random values, of appropriate
type, to the free variables of p and q), discarding those valuations that fail to satisfy
p, and checking whether any of the ones that remain are counterexamples to q.
QuickCheck users soon learn that this default generate-and-test approach some-
times does not give satisfactory results. In particular, if the precondition p is satisﬁed
by relatively few values of the appropriate type, then most of the random inputs
that QuickCheck generates will be discarded, so that q will seldom be exercised.
Consider, for example, testing a simple property of a school database system: that
every student in a list of registeredStudents should be taking at least one
course,
prop_registered studentId =
member studentId registeredStudents ==>
countCourses studentId > 0
where, as usual:
member x [] = False
member x (h:t) = (x == h) || member x t
If the space of possible student ids is large (e.g., because they are represented as
machine integers), then a randomly generated id is very unlikely to be a member of
registeredStudents, so almost all test cases will be discarded.
To enable eﬀective testing in such cases, the QuickCheck user can provide a
generator, a probabilistic program that produces inputs satisfying p - here, a generator
that always returns student ids drawn from the members of registeredStudents.
Indeed, QuickCheck provides a library of combinators for deﬁning such generators.
These combinators also allow ﬁne control over the distribution of generated values -
a crucial feature in practice (Claessen and Hughes, 2000; Hriţcu et al., 2013; Groce
et al., 2012).
Custom generators work well for small to medium-sized examples, but writing
them can become challenging as p gets more complex - sometimes turning into
a research contribution in its own right! For example, papers have been written
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

13.1 Introduction
451
about random generation techniques for well-typed lambda-terms (Pałka et al., 2011;
Fetscher et al., 2015; Tarau, 2015) and for "indistinguishable" machine states that
can be used for ﬁnding bugs in information-ﬂow monitors (Hriţcu et al., 2013,
2016). Moreover, if we aim to test an invariant property (e.g., type preservation),
then the same condition will appear in both the precondition and the conclusion of
the property, requiring that we express this condition both as a boolean predicate
p and as a generator whose outputs all satisfy p. These two artifacts must then
be kept in sync, which can become both a maintenance issue and a rich source
of confusion in the testing process. These diﬃculties are not hypothetical: Hriţcu
et al.'s machine-state generator (Hriţcu et al., 2013) is over 1500 lines of tricky
Haskell, while Pałka et al.'s generator for well-typed lambda-terms (Pałka et al.,
2011) is over 1600 even trickier ones. To enable eﬀective property-based random
testing of complex software artifacts, we need a better way of writing predicates and
corresponding generators.
A natural idea is to derive an eﬃcient generator for a given predicate p directly
from p itself. Indeed, two variants of this idea, with complementary strengths
and weaknesses, have been explored by others - one based on local choices and
backtracking, one on general constraint solving. Our language, Luck, synergistically
combines these two approaches.
The ﬁrst approach can be thought of as a kind of incremental generate-and-test:
rather than generating completely random valuations and then testing them against
p, we instead walk over the structure of p, instantiating each unknown variable x
at the ﬁrst point where we meet a constraint involving x. In the member example
above, on each recursive call, we make a random choice between the branches of the
||. If we choose the left, we instantiate x to the head of the list; otherwise we leave x
unknown and continue with the recursive call to member on the tail. This has the
eﬀect of traversing the list of registered students and picking one of its elements. It
is important to carefully control the probabilities guiding this choice to avoid getting
a distribution which is very skewed towards early elements.
This process resembles narrowing from functional logic programming (Antoy,
2000; Hanus, 1997; Lindblad, 2007; Tolmach and Antoy, 2003). It is attractively
lightweight, admits natural control over distributions (as we will see in the next
section), and has been used successfully (Fischer and Kuchen, 2007; Christiansen
and Fischer, 2008; Reich et al., 2011; Gligoric et al., 2010), even in challenging
domains such as generating well-typed programs to test compilers (Claessen et al.,
2014; Fetscher et al., 2015).
However, choosing a value for an unknown when we encounter the ﬁrst constraint
on it risks making choices that do not satisfy later constraints, forcing us to backtrack
and make a diﬀerent choice when the problem is discovered. For example, consider
the notMember predicate:
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

452
Lampropoulos et al.: Luck: A Probabilistic Language for Testing
notMember x []
=
True
notMember x (h:t)
=
(x /= h) && notMember x t
Suppose we wish to generate values for x such that notMember x ys for some
given list ys. When we ﬁrst encounter the constraint x /= h, we generate a value
for x that is not equal to the known value h. We then proceed to the recursive call of
notMember, where we check that the chosen x does not appear in the list's tail. Since
the values in the tail are not taken into account when choosing x, this may force us to
backtrack if our choice of x was unlucky. If the space of possible values for x is not
much bigger than the length of ys - say, just twice as big - then we will backtrack
50% of the time. Worse yet, if notMember is used to deﬁne another predicate - e.g.,
distinct, which tests whether each element of an input list is diﬀerent from all
the others - and we want to generate a list satisfying distinct, then notMember's
50% chance of backtracking will be compounded on each recursive call, leading to
unacceptably low rates of successful generation.
The second existing approach uses a constraint solver to generate a diverse set
of valuations satisfying a predicate.1 This approach has been widely investigated,
both for generating inputs directly from predicates (Carlier et al., 2010; Seidel et
al., 2015; Gotlieb, 2009; Köksal et al., 2011) and for symbolic-execution-based
testing (Godefroid et al., 2005; Sen et al., 2005; Cadar et al., 2008; Avgerinos et
al., 2014; Torlak and Bodík, 2014), which additionally uses the system under test to
guide generation of inputs that exercise diﬀerent control-ﬂow paths. For notMember,
gathering a set of disequality constraints on x before choosing its value avoids any
backtracking.
However, pure constraint-solving approaches do not give us everything we need.
They do not provide eﬀective control over the distribution of generated valuations.
At best, they might guarantee a uniform (or near uniform) distribution (Chakraborty
et al., 2014), but this is typically not the distribution we want in practice (see
Section 13.2). Moreover, the overhead of maintaining and solving constraints can
make these approaches signiﬁcantly less eﬃcient than the more lightweight, local
approach of needed narrowing when the latter does not lead to backtracking, as for
instance in member.
The complementary strengths and weaknesses of local instantiation and global
constraint solving suggest a hybrid approach, where limited constraint propagation,
under explicit user control, is used to reﬁne the domains (sets of possible values) of
unknowns before instantiation. This chapter explores such an approach by introducing
1 Constraint solvers can, of course, be used to directly search for counterexamples to a property of interest by
software model checking (Blanchette and Nipkow, 2010; Jackson, 2011; Ball et al., 2011; Jhala and Majumdar,
2009, etc.). We are interested here in the rather diﬀerent task of quickly generating a large number of diverse
inputs, so that we can thoroughly test systems like compilers whose state spaces are too large to be exhaustively
explored.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

13.2 Luck by Example
453
a probabilistic domain-speciﬁc language, Luck, for writing generators via lightweight
annotations on predicates. In Section 13.2 we illustrate Luck's novel features using
binary search trees as an example. We also place Luck's design on a ﬁrm formal
foundation, by deﬁning a probabilistic core calculus and establishing key properties:
the soundness and completeness of its probabilistic generator semantics with respect
to a straightforward interpretation of expressions as predicates (Section 13.3).
Finally, we provide a prototype interpreter (Section 13.4) using a custom constraint
solver that supports per-variable sampling. We evaluate Luck's expressiveness on a
collection of common examples from the random testing literature (Section 13.5)
and on two signiﬁcant case studies, demonstrating that Luck can be used (1) to ﬁnd
bugs in a widely used compiler (GHC) by randomly generating well-typed lambda
terms and (2) to help design information-ﬂow abstract machines by generating
"low-indistinguishable" machine states.
This chapter is accompanied by several auxiliary materials: (1) a Coq formalization
of the narrowing semantics of Luck and machine-checked proofs of its properties
(available at https://github.com/QuickChick/Luck) (Section 13.3.3); (2)
the prototype Luck interpreter and a battery of example programs, including all
the ones we used for evaluation (also at https://github.com/QuickChick/
Luck) (Section 13.5); (3) an extended version of the paper this chapter is based
on (Lampropoulos et al., 2017) with full deﬁnitions and paper proofs for the whole
semantics (https://arxiv.org/abs/1607.05443).
13.2 Luck by Example
Figure 13.1 shows a recursive Haskell predicate bst that checks whether a given
tree with labels strictly between low and high satisﬁes the standard binary-search
tree (BST) invariant (Okasaki, 1999). It is followed by a QuickCheck generator
genTree, which generates BSTs with a given maximum depth, controlled by the
size parameter. This generator ﬁrst checks whether low + 1 >= high, in which
case it returns the only valid BST satisfying this constraint - the Empty one.
Otherwise, it uses QuickCheck's frequency combinator, which takes a list of pairs
of positive integer weights and associated generators and randomly selects one of the
generators using the probabilities speciﬁed by the weights. In this example,
1
size+1
of the time it creates an Empty tree, while
size
size+1 of the time it returns a Node. The
Node generator is speciﬁed using monadic syntax: ﬁrst it generates an integer x that
is strictly between low and high, and then the left and right subtrees l and r by
calling genTree recursively; ﬁnally it returns Node x l r.
The generator for BSTs allows us to eﬃciently test conditional properties of the
form "if bst t then ⟨some other property of t⟩," but it raises some new issues of
its own. First, even for this simple example, getting the generator right is a bit tricky
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

454
Lampropoulos et al.: Luck: A Probabilistic Language for Testing
Binary tree datatype (in both Haskell and Luck):
data Tree a = Empty | Node a (Tree a) (Tree a)
Test predicate for BSTs (in Haskell):
bst :: Int -> Int -> Tree Int -> Bool
bst low high tree =
case tree of
Empty -> True
Node x l r ->
low < x && x < high
&& bst low x l && bst x high r
QuickCheck generator for BSTs (in Haskell):
genTree :: Int -> Int -> Int -> Gen (Tree Int)
genTree size low high
| low + 1 >= high = return Empty
| otherwise =
frequency [(1, return Empty),
(size, do
x <- choose (low + 1, high - 1)
l <- genTree (size 'div' 2) low x
r <- genTree (size 'div' 2) x high
return (Node x l r))]
Luck generator (and predicate) for BSTs:
sig bst :: Int -> Int -> Int -> Tree Int -> Bool
fun bst size low high tree =
if size == 0 then tree == Empty
else case tree of
| 1
% Empty -> True
| size % Node x l r ->
((low < x && x < high) !x)
&& bst (size / 2) low x l
&& bst (size / 2) x high r
Figure 13.1 Binary Search Tree tester and two generators
(for instance because of potential oﬀ-by-one errors in generating x), and it is not
immediately obvious that the set of trees generated by the generator is exactly the set
accepted by the predicate. Worse, we now need to maintain two similar but distinct
artifacts and keep them in sync. We can't just throw away the predicate and keep
the generator because we often need them both, for example to test properties like
"the insert function applied to a BST and a value returns a BST." As predicates
and generators become more complex, these issues can become quite problematic
(e.g., Hriţcu et al., 2013). Enter Luck.
The bottom of Figure 13.1 shows a Luck program that represents both a BST
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

13.2 Luck by Example
455
predicate and a generator for random BSTs. Modulo variations in concrete syntax, the
Luck closely code follows the Haskell bst predicate. The signiﬁcant diﬀerences are:
(1) the sample-after expression !x, which controls when node labels are generated,
and (2) the size parameter, which is used, as in the generator, to annotate the
branches of the case with relative weights. Together, these enable us to give the
program both a natural interpretation as a predicate (by simply ignoring weights
and sampling expressions) and an eﬃcient interpretation as a generator of random
trees with the same distribution as the QuickCheck version. For example, evaluating
the top-level query bst 10 0 42 u = True - i.e., "generate values t for the
unknown u such that bst 10 0 42 t evaluates to True" - will yield random
binary search trees of size up to 10 with node labels strictly between 0 and 42, with
the same distribution as the QuickCheck generator genTree 10 0 42.
An unknown in Luck is a special kind of value, similar to logic variables found
in logic programming languages and uniﬁcation variables used by type-inference
algorithms. Unknowns are typed, and each is associated with a domain of possible
values from its type. Given an expression e mentioning some set U of unknowns,
our goal is to generate valuations over these unknowns (maps from U to concrete
values) by iteratively reﬁning the unknowns' domains, so that, when any of these
valuations is substituted into e, the resulting concrete term evaluates to a desired
value (e.g., True).
Unknowns can be introduced both explicitly, as in the top-level query above (see
also Section 13.4), and implicitly, as in the generator semantics of case expressions.
In the bst example, when the Node branch is chosen, the pattern variables x, l, and
r are replaced by fresh unknowns, which are then instantiated by evaluating the
body of the branch.
Varying the placement of unknowns in the top-level bst query yields diﬀerent
behaviors. For instance, if we change the query to bst 10 ul uh u = True,
replacing the low and high parameters with unknowns ul and uh, the domains
of these unknowns will be reﬁned during tree generation and the result will be a
generator for random valuations (ul →i, uh →j, u →t) where i and j are lower
and upper bounds on the node labels in t.
Alternatively, we can evaluate the top-level query bst 10 0 42 t = True,
replacing u with a concrete tree t. In this case, Luck will return a trivial valuation
only if t is a binary search tree; otherwise it will report that the query is unsatisﬁable.
A less useful possibility is that we provide explicit values for low and high but
choose them with low > high, e.g., bst 10 6 4 u = True. Since there are no
satisfying valuations for u other than Empty, Luck will now generate only Empty
trees.
A sample-after expression of the form e !x controls instantiation of unknowns.
Typically, x will be an unknown u, and evaluating e !u will cause u to be instantiated
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

456
Lampropoulos et al.: Luck: A Probabilistic Language for Testing
to a concrete value (after evaluating e to reﬁne the domains of all of the unknowns
in e). If x reduces to a value v rather than an unknown, we similarly instantiate any
unknowns appearing within v.
As a concrete example, consider the compound inequality constraint 0 < x &&
x < 4. A generator based on pure narrowing (as in Gligoric et al., 2010), would
instantiate x when the evaluator meets the ﬁrst constraint where it appears, namely
0 < x (assuming left-to-right evaluation order). We can mimic this behavior in
Luck by writing ((0 < x) !x) && (x < 4). However, picking a value for x
at this point ignores the constraint x < 4, which can lead to backtracking. If, for
instance, the domain from which we are choosing values for x is 32-bit integers, then
the probability that a random choice satisfying 0 < x will also satisfy x < 4 is
minuscule. It is better in this case to write (0 < x && x < 4) !x, instantiating x
after the entire conjunction has been evaluated and all the constraints on the domain
of x recorded and thus avoiding backtracking completely. Finally, if we do not
include a sample-after expression for x here at all, we can further reﬁne its domain
with constraints later on, at the cost of dealing with a more abstract representation
of it internally in the meantime. Thus, sample-after expressions give Luck users
explicit control over the tradeoﬀbetween the expense of possible backtracking -
when unknowns are instantiated early - and the expense of maintaining constraints
on unknowns - so that they can be instantiated late (e.g., so that x can be instantiated
after the recursive calls to bst).
Sample-after expressions choose random values with uniform probability from
the domain associated with each unknown. While this behavior is sometimes
useful, eﬀective property-based random testing often requires ﬁne control over
the distribution of generated test cases. Drawing inspiration from the QuickCheck
combinator library for building complex generators, and particularly frequency
(which we saw in genTree (Figure 13.1)), Luck also allows weight annotations on
the branches of a case expression which have a frequency-like eﬀect. In the Luck
version of bst, for example, the unknown tree is either instantiated to an Empty
tree
1
1+size of the time or partially instantiated to a Node (with fresh unknowns for x
and the left and right subtrees)
size
1+size of the time.
Weight annotations give the user control over the probabilities of local choices.
These do not necessarily correspond to a speciﬁc posterior probability, but the
QuickCheck community has established techniques for guiding the user in tuning
local weights to obtain good testing. For example, the user can wrap properties inside
a collect x combinator; during testing, QuickCheck will gather information on x,
grouping equal values to provide an estimate of the posterior distribution that is being
sampled. The collect combinator is an eﬀective tool for adjusting frequency
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

13.2 Luck by Example
457
weights and dramatically increasing bug-ﬁnding rates (e.g., Hriţcu et al., 2013). The
Luck implementation provides a similar primitive.
One further remark on uniform sampling: while locally instantiating unknowns
uniformly from their domain is a useful default, generating globally uniform
distributions of test cases is usually not what we want, as this often leads to ineﬃcient
testing in practice. A simple example comes from the information ﬂow control
experiments of Hriţcu et al. (2013). There are two "security levels," called labels,
Low and High, and pairs of integers and labels are considered "indistinguishable" to
a Low observer if the labels are equal and, if the labels are Low, so are the integers.
In Haskell:
indist (v1,High) (v2,High)
=
True
indist (v1,Low ) (v2,Low)
=
v1 == v2
indist _
_
=
False
If we use 32-bit integers, then for every Low indistinguishable pair there are 232
High ones! Thus, a uniform distribution over indistinguishable pairs means that we
will essentially never generate pairs with Low labels. Clearly, such a distribution
cannot provide eﬀective testing; indeed, Hriţcu et al. found that the best distribution
was somewhat skewed in favor of Low labels.
We can easily validate this intuition using a probabilistic programming framework
with emphasis on eﬃcient sampling: R2 (Nori et al., 2014). We can model indistin-
guishability using the following probabilistic program, where labels are modeled by
booleans:
double v1 = Uniform.Sample(0, 10);
double v2 = Uniform.Sample(0, 10);
bool l1 = Bernoulli.Sample(0.5);
bool l2 = Bernoulli.Sample(0.5);
Observer.Observe(l1==l2 && (v1==v2 || l1));
Two pairs of doubles and booleans will be indistinguishable if the booleans are
equal and, if the booleans are false, so are the doubles. As predicted, all generated
samples have their booleans set to true. Of course, one could probably come up with
a better prior or use a tool that allows arbitrary conditioning to skew the distribution
appropriately. If, however, for such a trivial example the choices are non-obvious,
imagine replacing pairs of doubles and booleans with arbitrary lambda terms and
indistinguishability by a well-typedness relation. Coming up with suitable priors
that lead to eﬃcient testing would become an ambitious research problem on its
own!
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

458
Lampropoulos et al.: Luck: A Probabilistic Language for Testing
13.3 Semantics of Core Luck
We next present a core calculus for Luck - a minimal subset into which the examples
in the previous section can in principle be desugared. The core omits primitive
booleans and integers and replaces datatypes with binary sums, products, and
iso-recursive types.
We begin in Section 13.3.1 with the syntax and standard predicate semantics
of the core. (We call it the "predicate" semantics because, in our examples, the
result of evaluating a top-level expression will typically be a boolean, though
this expectation is not baked into the formalism.) We then build up to the full
generator semantics in three steps. First, we give an interface to a constraint solver
(Section 13.3.2), abstracting over the primitives required to implement our semantics.
Then we deﬁne a probabilistic narrowing semantics, which enhances the local-
instantiation approach to random generation with QuickCheck-style distribution
control (Section 13.3.3). Finally, we introduce a matching semantics, building on
the narrowing semantics, that uniﬁes constraint solving and narrowing into a single
evaluator (Section 13.3.4). The key properties of the generator semantics (both
narrowing and matching versions) are soundness and completeness with respect
to the predicate semantics (Section 13.3.6); informally, whenever we use a Luck
program to generate a valuation that satisﬁes some predicate, the valuation will
satisfy the boolean predicate semantics (soundness), and it will generate every
possible satisfying valuation with non-zero probability (completeness).
13.3.1 Syntax, Typing, and Predicate Semantics
The syntax of Core Luck is given in Figure 13.2. Except for the last line in the
deﬁnitions of values and expressions, it is a standard simply typed call-by-value
lambda calculus with sums, products, and iso-recursive types. We include recursive
lambdas for convenience in examples, although in principle they could be encoded
using recursive types.
Values include unit, pairs of values, sum constructors (L and R) applied to
values (and annotated with types, to eliminate ambiguity), ﬁrst class recursive
functions (rec), fold-annotated values indicating where an iso-recursive type should
be "folded," and unknowns drawn from an inﬁnite set. The standard expression forms
include variables, unit, functions, function applications, pairs with a single-branch
pattern-matching construct for deconstructing them, value tagging (L and R), pattern
matching on tagged values, and fold/unfold. The nonstandard additions are unknowns
(u), instantiation (e ←(e1,e2)), sample (!e) and after (e1
;
e2) expressions.
The "after" operator, written with a backwards semicolon, evaluates both e1 and
e2 in sequence. However, unlike the standard sequencing operator e1; e2, the result
of e1
;
e2 is the result of e1; the expression e2 is evaluated just for its side-eﬀects.
For example, the sample-after expression e !x of the previous section is desugared
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

13.3 Semantics of Core Luck
459
v ::= () | (v,v) | LT v | RT v
| rec ( f : T1 →T2) x = e | foldT v
| u
e ::= x | () | rec ( f : T1 →T2) x = e | (e e)
| (e,e) | case e of (x, y)  e
| LT e | RT e | case e of (L x  e) (R x  e)
| foldT e | unfoldT e
| u | e ←(e,e) | !e | e
;
e
T ::= X | 1 | T + T | T × T | μX. T
T ::= X | 1 | T + T | T × T | μX. T | T →T
Γ ::= ∅| Γ, x : T
Figure 13.2 Core Luck Syntax
to a combination of sample and after: e
;
!x. If we evaluate this snippet in a context
where x is bound to some unknown u, then the expression e is evaluated ﬁrst,
reﬁning the domain of u (amongst other unknowns); then the sample expression !u
is evaluated for its side eﬀect, instantiating u to a uniformly generated value from its
domain; and ﬁnally the result of e is returned as the result of the whole expression.
A reasonable way to implement e1
;
e2 using standard lambda abstractions would
be as (λ x. (λ_. x) e2) e1. However, there is a slight diﬀerence in the semantics of
this encoding compared to our intended semantics - we will return to this point in
Section 13.3.4.
Weight annotations like the ones in the bst example can be desugared using
instantiation expressions. For example, assuming a standard encoding of binary
search trees (Tree = μX. 1 + int × X × X) and naturals, plus syntactic sugar for
constant naturals:
case (unfoldTree tree < −(1,size)) of (L x  . . . )(R y  . . . )
Most of the typing rules are standard (these can be found in the extended version
of the paper). The four non-standard rules are given in Figure 13.3. Unknowns are
typed: each will be associated with a domain (set of values) drawn from a type T that
does not contain arrows. Luck does not support constraint solving over functional
domains (which would require something like higher-order uniﬁcation), and the
restriction of unknowns to non-functional types reﬂects this. To remember the types
of unknowns, we extend the typing context to include a component U, a map from
unknowns to non-functional types. When the variable typing environment Γ = ∅,
we write U ⊢e : T as a shorthand for ∅;U ⊢e : T. An unknown u has type T
if U(u) = T. If e1 and e2 are well typed, then e1
;
e2 shares the type of e1. An
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

460
Lampropoulos et al.: Luck: A Probabilistic Language for Testing
T-U
U(u) = T
Γ;U ⊢u : T
T-After
Γ;U ⊢e1 : T1
Γ;U ⊢e2 : T2
Γ;U ⊢e1
;
e2 : T1
T-Bang
Γ;U ⊢e : T
Γ;U ⊢!e : T
T-Narrow
Γ;U ⊢e : T1 + T2
Γ;U ⊢el : nat
Γ ⊢er : nat
Γ;U ⊢e ←(el,er) : T1 + T2
nat := μX. 1 + X
Figure 13.3 Typing Rules for Nonstandard Constructs
P-Narrow
e ⇓v
e1 ⇓v1
e2 ⇓v2
v1 > 0
v2 > 0
e ←(e1,e2) ⇓v
P-Bang
e ⇓v
!e ⇓v
P-After
e1 ⇓v1
e2 ⇓v2
e1
;
e2 ⇓v1
foldnat (L1+nat ())
=
0
foldnat (R1+nat v)
=
1 + v
Figure 13.4 Predicate Semantics for Nonstandard Constructs
instantiation expression e ←(el,er) is well typed if e has sum type T1 + T2 and el
and er are natural numbers. A sample expression !e has the (non-functional) type T
when e has type T.
The predicate semantics for Core Luck, written e ⇓v, are deﬁned as a big-step
operational semantics. We assume that e is closed with respect to ordinary variables
and free of unknowns. The rules for the standard constructs are unsurprising
(see the extended version). The only non-standard rules are the ones for narrow,
sample and after expressions, which are essentially ignored (Figure 13.4). With
the predicate semantics we can implement a naive generate-and-test method for
generating valuations satisfying some predicate by generating arbitrary well-typed
valuations and ﬁltering out those for which the predicate does not evaluate to True.
13.3.2 Constraint Sets
The rest of this section develops an alternative probabilistic generator semantics for
Core Luck. This semantics will use constraint sets κ ∈C to describe the possible
values that unknowns can take. For the moment, we leave the implementation of
constraint sets open (the one used by our prototype interpreter is described in the
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

13.3 Semantics of Core Luck
461
extended version of the chapter), simply requiring that they support the following
operations:
·
::
C−> Set Valuation
U
::
C−> Map U T
fresh
::
C →T
∗→(C × U∗)
unify
::
C →Val →Val →C
SAT
::
C →Bool
[·]
::
C →U →Maybe Val
sample
::
C →U →C∗
Here we describe these operations informally, deferring technicalities until after we
have presented the generator semantics (Section 13.3.6).
A constraint set κ denotes a set of valuations (κ), representing the solutions to
the constraints. Constraint sets also carry type information about existing unknowns:
U(κ) is a mapping from κ's unknowns to types. A constraint set κ is well typed (⊢κ)
if, for every valuation σ in the denotation of κ and every unknown u bound in σ,
the type map U(κ) contains u and ∅;U(κ) ⊢σ(u) : U(κ)(u).
Many of the semantic rules will need to introduce fresh unknowns. The fresh
function takes a constraint set κ and a sequence of (non-functional) types of length
k; it draws the next k unknowns (in some deterministic order) from the inﬁnite set
U and extends U(κ) with the respective bindings.
The main way constraints are introduced during evaluation is uniﬁcation. Given a
constraint set κ and two values, each potentially containing unknowns, unify updates
κ to preserve only those valuations in which the values match.
SAT is a total predicate that holds on constraint sets whose denotation contains at
least one valuation. The totality requirement implies that our constraints must be
decidable.
The value-extraction function κ[u] returns an optional (non-unknown) value: if
in the denotation of κ, all valuations map u to the same value v, then that value is
returned (written {v}); otherwise nothing (written ∅).
The sample operation is used to implement sample expressions (!e): given a
constraint set κ and an unknown u ∈U(κ), it returns a list of constraint sets
representing all possible concrete choices for u, in all of which u is completely
determined - that is ∀κ ∈(sample κ u). ∃v. κ[u] = {v}. To allow for reasonable
implementations of this interface, we maintain an invariant that the input unknown
to sample will always have a ﬁnite denotation; thus, the resulting list is also ﬁnite.
13.3.3 Narrowing Semantics
As a ﬁrst step toward a probabilistic semantics for Core Luck that incorporates both
constraint solving and local instantiation, we deﬁne a simpler narrowing semantics.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

462
Lampropoulos et al.: Luck: A Probabilistic Language for Testing
This semantics is of some interest in its own right, in that it extends traditional
"needed narrowing" with explicit probabilistic instantiation points, but its role here
is as a subroutine of the matching semantics in Section 13.3.4.
The narrowing evaluation judgment takes as inputs an expression e and a constraint
set κ. As in the predicate semantics, evaluating e returns a value v, but now it also
depends on a constraint set κ and returns a new constraint set κ′. The latter is
intuitively a reﬁnement of κ - i.e., evaluation will only remove valuations.
e
⊨
κ ⇓t
q κ′ ⊨v
The semantics is annotated with a representation of the sequence of random choices
made during evaluation, in the form of a trace t. A trace is a sequence of choices:
integer pairs (m,n) with 0 ≤m < n, where n denotes the number of possibilities
chosen among and m is the index of the one actually taken. We write ϵ for the empty
trace and t ·t′ for the concatenation of two traces. We also annotate the judgment with
the probability q of making the choices represented in the trace. Recording traces is
useful after the fact in calculating the total probability of some given outcome of
evaluation (which may be reached by many diﬀerent derivations), but they play no
role in determining how evaluation proceeds.
We maintain the invariant that both the input constraint set κ and the input
expression e are well typed, the latter with respect to an empty variable context
and unknown context U(κ). Another invariant is that every constraint set κ that
appears as input to a judgment is satisﬁable and the restriction of its denotation to
the unknowns in e is ﬁnite. These invariants are established at the top-level (see
Section 13.4). The ﬁniteness invariant ensures the output of sample will always be
a ﬁnite collection and therefore the probabilities involved will be positive rational
numbers. They also guarantee termination of constraint solving, as we will see
in Section 13.3.4. Finally, we assume that the type of every expression has been
determined by an initial type-checking phase. We write eT to show that e has type T.
This information is used in the semantic rules to type fresh unknowns.
The narrowing semantics is given in Figure 13.5 for the standard constructs
(omitting fold/unfold and N-R and N-Case-R rules analogous to the N-L and N-
Case-L rules shown) and in Figure 13.6 for instantiation expressions; Figure 13.8
and Figure 13.7 give some auxiliary deﬁnitions. Most of the rules are intuitive. A
common pattern is sequencing two narrowing judgments e1
⊨
κ ⇓t1q1 κ1 ⊨v and
e2
⊨
κ1 ⇓t2q2 κ2 ⊨v. The constraint-set result of the ﬁrst narrowing judgment (κ1)
is given as input to the second, while traces and probabilities are accumulated by
concatenation (t1 · t2) and multiplication (q1 ∗q2). We now explain the rules in detail.
Rule N-Base is the base case of the evaluation relation, handling values that are
not handled by other rules by returning them as-is. No choices are made, so the
probability of the result is 1 and the trace is empty.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

13.3 Semantics of Core Luck
463
N-Base
v = () ∨v = (rec ( f : T1 →T2) x = e′) ∨v ∈U
v
⊨
κ ⇓ϵ
1 κ ⊨v
N-Pair
e1
⊨
κ ⇓t1q1 κ1 ⊨v1
e2
⊨
κ1 ⇓t2q2 κ2 ⊨v2
(e1,e2)
⊨
κ ⇓t1·t2
q1∗q2 κ2 ⊨(v1,v2)
N-CasePair-P
e
⊨
κ ⇓t
q κa ⊨(v1,v2)
e′[v1/x, v2/y]
⊨
κa ⇓t′
q′ κ′ ⊨v
case e of (x, y)  e′
⊨
κ ⇓t·t′
q∗q′ κ′ ⊨v
N-CasePair-U
e
⊨
κ ⇓t
q κa ⊨u
(κb,[u1,u2]) = fresh κa [T1,T2]
κc = unify κb (u1,u2) u
e′[u1/x, u2/y]
⊨
κc ⇓t′
q′ κ′ ⊨v
case eT 1×T 2 of (x, y)  e′
⊨
κ ⇓t·t′
q∗q′ κ′ ⊨v
N-L
e
⊨
κ ⇓t
q κ′ ⊨v
LT1+T2 e
⊨
κ ⇓t
q κ′ ⊨LT1+T2 v
N-Case-L
e
⊨
κ ⇓t
q κa ⊨LT vl
el[vl/xl]
⊨
κa ⇓t′
q′ κ′ ⊨v
case e of (L xl  el)(R xr  er)
⊨
κ ⇓t·t′
q∗q′ κ′ ⊨v
N-Case-U
e
⊨
κ ⇓t1q1 κa ⊨u
(κ0,[ul,ur]) = fresh κa [Tl,Tr]
κl = unify κ0 u (LT l+T r ul)
κr = unify κ0 u (RT l+T r ur)
choose 1 κl 1 κr →t2q2 i
ei[ui/xi]
⊨
κi ⇓t3q3 κ′ ⊨v
case eT l+T r of (L xl  el)(R xr  er)
⊨
κ ⇓t1·t2·t3
q1∗q2∗q3 κ′ ⊨v
N-App
e0
⊨
κ ⇓t0q0 κa ⊨(rec ( f : T1 →T2) x = e2)
e1
⊨
κa ⇓t1q1 κb ⊨v1
e2[(rec ( f : T1 →T2) x = e2)/ f, v1/x]
⊨
κb ⇓t2q2 κ′ ⊨v
(e0 e1)
⊨
κ ⇓t0·t1·t2
q0∗q1∗q2 κ′ ⊨v
Figure 13.5 Narrowing Semantics of Standard Core Luck Constructs
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

464
Lampropoulos et al.: Luck: A Probabilistic Language for Testing
N-After
e1
⊨
κ ⇓t1q1 κ1 ⊨v1
e2
⊨
κ1 ⇓t2q2 κ2 ⊨v2
e1
;
e2
⊨
κ ⇓t1·t2
q1∗q2 κ2 ⊨v1
N-Bang
e
⊨
κ ⇓t
q κa ⊨v
sampleV κa v ⇒t′
q′ κ′
!e
⊨
κ ⇓t·t′
q∗q′ κ′ ⊨v
N-Narrow
e
⊨
κ ⇓t
q κa ⊨v
e1
⊨
κa ⇓t1q1 κb ⊨v1
e2
⊨
κb ⇓t2q2 κc ⊨v2
sampleV κc v1 ⇒
t′
1
q′
1 κd
sampleV κd v2 ⇒
t′
2
q′
2 κe
natκe(v1) = n1
n1 > 0
natκe(v2) = n2
n2 > 0
(κ0,[u1,u2]) = fresh κe [T1,T2]
κl = unify κ0 v (LT 1+T 2 u1)
κr = unify κ0 v (RT 1+T 2 u2)
choose n1 κl n2 κr →t′
q′ i
eT 1+T 2 < −(enat
1 ,enat
2 )
⊨
κ ⇓
t·t1·t2·t′
1·t′
2·t′
q∗q1∗q2∗q′
1∗q′
2∗q′ κi ⊨v
Figure 13.6 Narrowing Semantics for Non-Standard Expressions
SAT(κ1)
SAT(κ2)
choose n κ1 m κ2 →[(0,2)]
n/(n+m) l
¬SAT(κ1)
SAT(κ2)
choose n κ1 m κ2 →ϵ
1 r
SAT(κ1)
SAT(κ2)
choose n κ1 m κ2 →[(1,2)]
m/(n+m) r
SAT(κ1)
¬SAT(κ2)
choose n κ1 m κ2 →ϵ
1 l
Figure 13.7 Auxiliary relation choose
Rule N-Pair: To evaluate (e1,e2) given a constraint set κ, we sequence the
derivations for e1 and e2.
Rules N-CasePair-P, N-CasePair-U: To evaluate the pair elimination expression
case e of (x, y) →e′ in a constraint set κ, we ﬁrst evaluate e in κ. Typing ensures
that the resulting value is either a pair or an unknown. If it is a pair (N-CasePair-P),
we substitute its components for x and y in e′ and continue evaluating. If it is an
unknown u of type T1 × T2 (N-CasePair-U), we ﬁrst use T1 and T2 as types for
fresh unknowns u1, u2 and remember the constraint that the pair (u1,u2) must unify
with u. We then proceed as above, this time substituting u1 and u2 for x and y.
The ﬁrst pair rule might appear unnecessary since, even in the case where the
scrutinee evaluates to a pair, we could generate unknowns, unify, and substitute,
as in N-CasePair-U. However, unknowns in Luck only range over non-functional
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

13.3 Semantics of Core Luck
465
sample κ u = S
S[m] = κ′
sampleV κ u ⇒[(m,|S|)]
1/|S|
κ′
sampleV κ () ⇒ϵ
1 κ
sampleV κ v ⇒t
q κ′
sampleV κ (foldT v) ⇒t
q κ′
sampleV κ v ⇒t
q κ′
sampleV κ (LT v) ⇒t
q κ′
sampleV κ v ⇒t
q κ′
sampleV κ (RT v) ⇒t
q κ′
sampleV κ v1 ⇒t1q1 κ1
sampleV κ1 v2 ⇒t2q2 κ′
sampleV κ (v1,v2) ⇒t1·t2
q1∗q2 κ′
Figure 13.8 Auxiliary relation sampleV
types T, so this trick does not work when the type of the e contains arrows. The
N-CasePair-U rule also shows how the ﬁniteness invariant is preserved: when we
generate the unknowns u1 and u2, their domains are unconstrained, but before we
substitute them into an expression used as "input" to a subderivation, we unify them
with the result of a narrowing derivation, which already has a ﬁnite representation
in κa.
Rule N-L: To evaluate LT1+T2 e, we evaluate e and tag the resulting value with
LT1+T2, with the resulting constraint set, trace, and probability unchanged. RT1+T2 e
is handled similarly (the rule is elided) .
Rules N-Case-L,N-Case-U: As in the pair elimination rule, we ﬁrst evaluate
the discriminee e to a value, which must have one of the shapes LT vl, RT vr, or
u ∈U, thanks to typing. The cases for LT vl (rule N-Case-L) and RT vr (elided)
are similar to N-CasePair-P: vl or vr can be directly substituted for xl or xr in el
or er. The unknown case (N-Case-U) is similar to N-CasePair-U but a bit more
complex. Once again e shares with the unknown u a type Tl + Tr that does not
contain any arrows, so we can generate fresh unknowns ul, ur with types Tl, Tr. We
unify LT l+T r vl with u to get the constraint set κl and RT l+T r vr with u to get κr. We
then use the auxiliary relation choose (Figure 13.7), which takes two integers n and
m (here equal to 1) as well as two constraint sets (here κl and κr), to select either l or
r. If exactly one of κl and κr is satisﬁable, then choose will return the corresponding
index with probability 1 and an empty trace (because no random choice were made).
If both are satisﬁable, then the resulting index is randomly chosen. Both outcomes
are equiprobable (because of the 1 arguments to choose), so the probability is one
half in each case. This uniform binary choice is recorded in the trace t2 as either (0,2)
or (1,2). Finally, we evaluate the expression corresponding to the chosen index, with
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

466
Lampropoulos et al.: Luck: A Probabilistic Language for Testing
the corresponding unknown substituted for the variable. The satisﬁability checks
enforce the invariant that constraint sets are satisﬁable, which in turn ensures that κl
and κr cannot both be unsatisﬁable at the same time, since there must exist at least
one valuation in κ0 that maps u to a value (either L or R) which ensures that the
corresponding uniﬁcation will succeed.
Rule N-App: To evaluate an application (e0 e1), we ﬁrst evaluate e0 to rec ( f :
T1 →T2) x = e2 (since unknowns only range over arrow-free types T, the result
cannot be an unknown) and its argument e1 to a value v1. We then evaluate the
appropriately substituted body, e2[(rec ( f : T1 →T2) x = e2)/ f, v1/x], and
combine the various probabilities and traces appropriately.
Rule N-After is similar to N-Pair; however, the value result of the derivation is
that of the ﬁrst narrowing evaluation, implementing the reverse form of sequencing
described in the introduction of this section.
Rule N-Bang: To evaluate !e we evaluate e to a value v, then use the auxiliary
relation sampleV (Figure 13.8) to completely instantiate v, walking down the
structure of v. When unknowns are encountered, sample is used to produce a list of
constraint sets S; with probability
1
|S| (where |S| is the size of the list) we can select
the mth constraint set in S, for each 0 ≤m < |S|.
Rule N-Narrow is similar to N-Case-U, modulo the "weight" arguments e1
and e2. These are evaluated to values v1 and v2, and sampleV is called to ensure
that they are fully instantiated in all subsequent constraint sets, especially κe. The
relation natκe(v1) = n1 walks down the structure of the value v1 (like sampleV) and
calculates the unique natural number n1 corresponding to v1: when the input value
is an unknown, natκ(u) = n holds if κ[u] = v′ and v = n, where the notation v
is deﬁned in Figure 13.4. The rest of the rule is the same as N-Case-U, but with the
computed weights n1 and n2 given as arguments to choose to shape the distribution.
Using the narrowing semantics, we can implement a more eﬃcient method for
generating valuations than the naive generate-and-test described in Section 13.3.1:
instead of generating arbitrary valuations we only lazily instantiate a subset of
unknowns as we encounter them. This method has the additional advantage that, if a
generated valuation yields an unwanted result, the implementation can backtrack to
the point of the latest choice, which can drastically improve performance (Claessen
et al., 2014).
Unfortunately, using the narrowing semantics in this way can lead to a lot of
backtracking. To see why, consider three unknowns, u1,u2, and u3, and a constraint set
κ where each unknown has type Bool (i.e., 1+1) and the domain associated with each
contains both True and False (L1+1 () and R1+1 ()). Suppose we want to generate
valuations for these three unknowns such that the conjunction u1 && u2 && u3
holds, where e1 && e2 is shorthand for case e1 of (L x  e2)(R y  False). If we
attempt to evaluate the expression u1 && u2 && u3 using the narrowing semantics,
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

13.3 Semantics of Core Luck
467
we ﬁrst apply the N-Case-U rule with e = u1. That means that u1 will be uniﬁed
with either L or R (applied to a fresh unknown) with equal probability, leading to a
False result for the entire expression 50% of the time. If we choose to unify u1 with
an L, then we apply the N-Case-U rule again, returning either False or u3 (since
unknowns are values - rule N-Base) with equal probability. Therefore, we will have
generated a desired valuation only 25% of the time; we will need to backtrack 75%
of the time.
The problem here is that the narrowing semantics is agnostic to the desired result
of the whole computation - we only ﬁnd out at the very end that we need to backtrack.
But we can do better. . .
13.3.4 Matching Semantics
In this section we present a matching semantics that takes as an additional input a
pattern (a value not containing lambdas but possibly containing unknowns) and
propagates this pattern backwards to guide the generation process. By allowing
our semantics to look ahead in this way, we can often avoid case branches that
lead to non-matching results. The matching judgment is again a variant of big-step
evaluation; it has the form
p ⇐e
⊨
κ ⇑t
q κ?
where p can mention the unknowns in U(κ) and where the metavariable κ? stands
for an optional constraint set (∅or {κ}) returned by matching. Returning an option
allows us to calculate the probability of backtracking by summing the q's of all
failing derivations. (The combined probability of failures and successes may be less
than 1, because some reduction paths may diverge.)
We keep the invariants from Section 13.3.3: the input constraint set κ is well
typed and so is the input expression e (with respect to an empty variable context and
U(κ)); moreover κ is satisﬁable, and the restriction of its denotation to the unknowns
in e is ﬁnite. To these invariants we add that the input pattern p is well typed in U(κ)
and that the common type of e and p does not contain any arrows (e can still contain
functions and applications internally; these are handled by calling the narrowing
semantics).
The rules except for case are similar to the narrowing semantics. Figure 13.9
shows several; the rest appear in the extended version.
Rule M-Base: To generate valuations for a unit value or an unknown, we unify v
and the target pattern p under the input constraint set κ. Unlike N-Base, there is no
case for functions, since the expression being evaluated must have a non-function
type.
Rules M-Pair, M-Pair-Fail: To evaluate (e1,e2), where e1 and e2 have types T1
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

468
Lampropoulos et al.: Luck: A Probabilistic Language for Testing
M-Base
v = () ∨v ∈U
κ′ = unify κ v p
p ⇐v
⊨
κ ⇑ϵ
1 if SAT(κ′) then {κ′} else ∅
M-Pair
(κ′,[u1,u2]) = fresh κ [T1,T2]
κ0 = unify κ′ (u1,u2) p
u1 ⇐e1
⊨
κ0 ⇑t1q1 {κ1}
u2 ⇐e2
⊨
κ1 ⇑t2q2 κ?
2
p ⇐(eT 1
1 ,eT 2
2 )
⊨
κ ⇑t1·t2
q1∗q2 κ?
2
M-Pair-Fail
(κ′,[u1,u2]) = fresh κ [T1,T2]
κ0 = unify κ′ (u1,u2) p
u1 ⇐e1
⊨
κ0 ⇑t1q1 ∅
p ⇐(eT 1
1 ,eT 2
2 )
⊨
κ ⇑t1q1 ∅
M-App
e0
⊨
κ ⇓t0q0 κ0 ⊨(rec f x = e2)
e1
⊨
κ0 ⇓t1q1 κ′ ⊨v1
p ⇐e2[(rec f x = e2)/ f,v1/x]
⊨
κ′ ⇑t2q2 κ?
p ⇐(e0 e1)
⊨
κ ⇑t0·t1·t2
q0∗q1∗q2 κ?
M-After
p ⇐e1
⊨
κ ⇑t1q1 {κ1}
e2
⊨
κ1 ⇓t2q2 κ2 ⊨v
p ⇐e1
;
e2
⊨
κ ⇑t1·t2
q1∗q2 {κ2}
Figure 13.9 Matching Semantics of Selected Core Luck Constructs
and T2, we ﬁrst generate fresh unknowns u1 and u2. We unify the pair (u1,u2) with
the target pattern p, obtaining a new constraint set κ′. We then proceed as in N-Pair,
evaluating e1 against pattern u1 and e2 against u2, threading constraint sets and
accumulating traces and probabilities. M-Pair handles the case where the evaluation
of e1 succeeds, while M-Pair-Fail handles failure: if evaluating e1 yields ∅, the
whole computation immediately yields ∅as well; e2 is not evaluated, and the ﬁnal
trace and probability are t1 and q1.
Rules M-App, M-After: To evaluate an application e0 e1, we use the narrowing
semantics to reduce e0 to rec f x = e2 and e1 to a value v1, then evaluate
e2[(rec f x = e2)/ f,v2/x] against the original p. In this rule we cannot use a pattern
during the evaluation of e1: we do not have any candidates! This is the main reason
for introducing the sequencing operator as a primitive e1
;
e2 instead of encoding it
using lambda abstractions. In M-After, we evaluate e1 against p and then evaluate
e2 using narrowing, just for its side eﬀects. If we used lambdas to encode sequencing,
e1 would be narrowed instead, which is not what we want.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

13.3 Semantics of Core Luck
469
M-Case-1
(κ0,[u1,u2]) = fresh κ [T1,T2]
(LT 1+T 2 u1) ⇐e
⊨
κ0 ⇑t1q1 {κ1}
(RT 1+T 2 u2) ⇐e
⊨
κ0 ⇑t2q2 {κ2}
p ⇐e1[u1/xl]
⊨
κ1 ⇑
t′
1
q′
1 κ?
a
p ⇐e2[u2/yr]
⊨
κ2 ⇑
t′
2
q′
2 κ?
b
κ? = combine κ0 κ?
a κ?
b
p ⇐case eT 1+T 2 of (L xl  e1)(R yr  e2)
⊨
κ
⇑
t1·t2·t′
1·t′
2
q1∗q2∗q′
1∗q′
2 κ?
where combine κ ∅∅= ∅
combine κ {κ1} ∅= {κ1}
combine κ ∅{κ2} = {κ2}
combine κ {κ1} {κ2} = union κ1 (rename (U(κ1)-U(κ)) κ2)
M-Case-2
(κ0,[u1,u2]) = fresh κ [T1,T2]
(LT 1+T 2 u1) ⇐e
⊨
κ0 ⇑t1q1 ∅
(RT 1+T 2 u2) ⇐e
⊨
κ0 ⇑t2q2 {κ2}
p ⇐e2[u2/y]
⊨
κ2 ⇑
t′
2
q′
2 κ?
b
p ⇐case eT 1+T 2 of (L x  e1)(R y  e2)
⊨
κ ⇑
t1·t2·t′
2
q1∗q2∗q′
2 κ?
b
Figure 13.10 Matching Semantics for Constraint-Solving case
The interesting rules are the ones for case when the type of the scrutinee does
not contain functions. For these rules, we can actually use the patterns to guide
the generation that occurs during the evaluation of the scrutinee as well. Instead of
choosing which branch to follow with some probability (50% in N-Case-U), we
evaluate both branches, just like a constraint solver would exhaustively search the
entire domain.
Before looking at the rules in detail, we need to extend the constraint set interface
with two new functions:
rename
::
U∗→C →C
union
::
C →C →C
The rename operation freshens a constraint set by replacing all the unknowns in
a given sequence with freshly generated ones. The union of two constraint sets
intuitively denotes the union of their corresponding denotations.
Two of the rules appear in Figure 13.10. (A third is symmetric to M-Case-2;
a fourth handles failures.) We independently evaluate e against both an L pattern
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

470
Lampropoulos et al.: Luck: A Probabilistic Language for Testing
and an R pattern. If both of them yield failure, then the whole evaluation yields
failure (elided). If exactly one succeeds, we evaluate just the corresponding branch
(M-Case-2 or the other elided rule). If both succeed (M-Case-1), we evaluate both
branch bodies and combine the results with union. We use rename to avoid conﬂicts,
since we may generate the same fresh unknowns while independently computing
κ?
a and κ?
b. If desired, the user can ensure that only one branch will be executed by
using an instantiation expression before the case is reached. Since e will then begin
with a concrete constructor, only one of the evaluations of e against the patterns L
and R will succeed, and only the corresponding branch will be executed.
The M-Case-1 rule is the second place where the need for ﬁniteness of the
restriction of κ to the input expression e arises. In order for the semantics to
terminate in the presence of (terminating) recursive calls, it is necessary that the
domain be ﬁnite. To see this, consider a simple recursive predicate that holds for
every number:
rec ( f : nat →bool) u = case unfoldnat u of (L x  True)(R y  ( f y))
Even though f terminates in the predicate semantics for every input u, if we allow a
constraint set to map u to the inﬁnite domain of all natural numbers, the matching
semantics will not terminate. While this ﬁniteness restriction feels a bit unnatural,
we have not found it to be a problem in practice - see Section 13.4.
13.3.5 Example
To show how all this works, let's trace the main steps of the matching derivations
of two given expressions against the pattern True in a given constraint set. We
will also extract probability distributions about optional constraint sets from these
derivations.
We are going to evaluate A := (0 < u && u < 4)
;
!u and B := (0 < u
;
!u) &&
u < 4 against the pattern True in a constraint set κ, in which u is independent
from other unknowns and its possible values are 0,. . .,9. Similar expressions were
introduced as examples in Section 13.2; the results we obtain here conﬁrm the
intuitive explanation given there.
Recall that we are using a standard Peano encoding of naturals: nat = μX. 1 + X,
and
that
the
conjunction
expression
e1
&&
e2
is
shorthand
for
case e1 of (L a  e2)(R b  False). We elide folds for brevity. The inequality
a < b can be encoded as lt a b, where:
lt = rec ( f : nat →nat−> bool) x = rec (g : nat →bool) y =
case y of
(L _  False)
(R yR  case x of
(L _  True)
(R xR  f xR yR))
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

13.3 Semantics of Core Luck
471
Many rules introduce fresh unknowns, many of which are irrelevant: they might
be directly equivalent to some other unknown, or there might not exist any reference
to them. We use the same variable for two constraint sets which diﬀer only in the
addition of a few irrelevant variables in one.
Evaluation of A We ﬁrst derive True ⇐(0 < u)
⊨
κ ⇑ϵ
1 {κ0}. Since in the
desugaring of 0 < u as an application lt is already in rec form and both 0 and u are
values, the constraint set after the narrowing calls of M-App will stay unchanged. We
then evaluate case u of (L _  False)(R yR  . . .). Since the domain of u contains
both zero and non-zero elements, unifying u with L1+nat u1 and R1+nat u2 (M-Base)
will produce some non-empty constraint sets. Therefore, rule M-Case-1 applies.
Since the body of the left hand side of the match is False, the result of the left
derivation in M-Case-1 is ∅and in the resulting constraint set κ0 the domain of u is
{1,. . .,9}.
Next, we turn to True ⇐(0 < u && u < 4)
⊨
κ ⇑ϵ
1 {κ1}, where, by a similar
argument following the recursion, the domain of u in κ1 is {1,2,3}. There are 3
possible narrowing-semantics derivations for !u: (1) !u
⊨
κ1 ⇓[(0,3)]
1/3
κA
1 ⊨u, (2)
!u
⊨
κ1 ⇓[(1,3)]
1/3
κA
2 ⊨u, and (3) !u
⊨
κ1 ⇓[(2,3)]
1/3
κA
3 ⊨u, where the domain of u in κA
i
is {i}. (We have switched to narrowing-semantics judgments because of the rule
M-After.) Therefore all the possible derivations for A = (0 < u && u < 4)
;
!u
matching True in κ are:
True ⇐A
⊨
κ ⇑[(i−1,3)]
1/3
{κA
i }
for i ∈{1,2,3}
From the set of possible derivations, we can extract a probability distribution: for each
resulting optional constraint set, we sum the probabilities of each of the traces that
lead to this result. Thus the probability distribution associated with True ⇐A
⊨
κ
is
[{κA
1 } →1
3;
{κA
2 } →1
3;
{κA
3 } →1
3].
Evaluation of B The evaluation of 0 < u is the same as before, after which we
narrow !u directly in κ0 and there are 9 possibilities: !u
⊨
κ0 ⇓[(i−1,9)]
1/9
κB
i
⊨u
for each i ∈{1,. . .,9}, where the domain of u in κB
i is {i}. Then we evaluate
True ⇐u < 4
⊨
κB
i : if i is 1, 2 or 3 this yields {κB
i }; if i > 3 this yields a failure ∅.
Therefore the possible derivations for B = (0 < u
;
!u) && u < 4 are:
True ⇐B
⊨
κ ⇑[(i−1,9)]
1/9
{κB
i }
for i ∈{1,2,3}
True ⇐B
⊨
κ ⇑[(i−1,9)]
1/9
∅
for i ∈{4,. . .,9}
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

472
Lampropoulos et al.: Luck: A Probabilistic Language for Testing
We can again compute the corresponding probability distribution:
[{κB
1 } →1
9;
{κB
2 } →1
9;
{κB
3 } →1
9;
∅→2
3]
Note that if we were just recording the probability of an execution and not its trace,
we would not know that there are six distinct executions leading to ∅with probability
1
9, so we would not be able to compute its total probability.
The probability associated with ∅(0 for A, 2/3 for B) is the probability of
backtracking. As stressed in Section 13.2, A is much better than B in terms of
backtracking - i.e., it is more eﬃcient in this case to instantiate u only after all
the constraints on its domain have been recorded. For a more formal treatment of
backtracking strategies in Luck using Markov Chains, see Gallois-Wong (2016).
13.3.6 Properties
We close our discussion of Core Luck by summarizing some key properties; more
details and proofs can be found in the extended version. Intuitively, we show that,
when we evaluate an expression e against a pattern p in the presence of a constraint
set κ, we can only remove valuations from the denotation of κ (decreasingness), any
derivation in the generator semantics corresponds to an execution in the predicate
semantics (soundness), and every valuation that matches p will be found in the
denotation of the resulting constraint set of some derivation (completeness).
Since we have two ﬂavors of generator semantics, narrowing and matching, we
also present these properties in two steps. First, we present the properties for the
narrowing semantics; their proofs have been veriﬁed using Coq. Then we present
the properties for the matching semantics; for these, we have only paper proofs, but
these proofs are quite similar to the narrowing ones (details are in the extended
version; the only real diﬀerence is the case rule).
We begin by giving the formal speciﬁcation of constraint sets. We introduce one
extra abstraction, the domain of a constraint set κ, written dom(κ). This domain
corresponds to the unknowns in a constraint set that actually have bindings in κ.
For example, when we generate a fresh unknown u from κ, u does not appear in the
domain of κ; it only appears in the denotation after we use it in a uniﬁcation. The
domain of κ is a subset of the set of keys of U(κ). When we write that for a valuation
and constraint set σ ∈κ, it also implies that the unknowns that have bindings in
σ are exactly the unknowns that have bindings in κ, i.e., in dom(κ). We use the
overloaded notation σ|x to denote the restriction of σ to x, where x is either a set of
unknowns or another valuation.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

13.3 Semantics of Core Luck
473
Speciﬁcation of fresh
(κ′,u) = fresh κ T ⇒
⎧⎪⎪⎨
⎪⎪⎩
u  U(κ)
U(κ′) = U(κ) ⊕(u →T)
κ′ = κ
Intuitively, when we generate a fresh unknown u of type T from κ, u is really fresh
for κ, meaning U(κ) does not have a type binding for it. The resulting constraint
set κ′ has an extended unknown typing map, where u maps to T and its denotation
remains unchanged. That means that dom(κ′) = dom(κ).
Speciﬁcation of sample
κ′ ∈sample κ u ⇒
⎧⎪⎪⎨
⎪⎪⎩
U(κ′) = U(κ)
SAT(κ′)
∃v. κ′ = { σ | σ ∈κ, σ(u) = v }
When we sample u in a constraint set κ and obtain a list, for every member constraint
set κ′, the typing map of κ remains unchanged and all of the valuations that remain in
the denotation of κ′ are the ones that mapped to some speciﬁc value v in κ. We also
require a completeness property from sample, namely that if we have a valuation
σ ∈κ where σ(u) = v for some u,v, then is in some member κ′ of the result:
σ(u) = v
σ ∈κ
+
⇒∃κ′.
* σ ∈κ′
κ′ ∈sample κ u
Speciﬁcation of unify
U(unify κ v1 v2) = U(κ)
unify κ v1 v2 = { σ ∈κ | σ(v1) = σ(v2) }
When we unify in a constraint set κ two well-typed values v1 and v2, the typing map
remains unchanged while the denotation of the result contains the valuations from κ
that when substituted into v1 and v2 make them equal.
Speciﬁcation of union
U(κ1)|U(κ1)∩U(κ2) = U(κ2)|U(κ1)∩U(κ2)
union κ1 κ2 = κ
+
⇒
* U(κ) = U(κ1) ∪U(κ2)
κ = κ1 ∪κ2
To take the union of two constraint sets, their typing maps must obviously agree on
any unknowns present in both. The denotation of the union of two constraint sets is
then just the union of their corresponding denotations.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

474
Lampropoulos et al.: Luck: A Probabilistic Language for Testing
Properties of the Narrowing Semantics The ﬁrst theorem, decreasingness states
that we never add new valuations to our constraint sets; our semantics can only reﬁne
the denotation of the input κ.
Theorem 13.1 (Decreasingness).
e
⊨
κ ⇓t
q κ′ ⊨v ⇒κ′ ≤κ
Soundness and completeness can be visualized as follows:
ep
vp
e
⊨
κ
v ⊨κ′
⇓
σ∈κ
⇓tq
σ′∈κ′
Given the bottom and right sides of the diagram, soundness guarantees that we can
ﬁll in the top and left. That is, any narrowing derivation e
⊨
κ ⇓q
t κ′ ⊨v corresponds
to some derivation in the predicate semantics, with the additional assumption that
all the unknowns in e are included in the domain of the input constraint set κ (or
that e is well typed in κ).
Theorem 13.2 (Soundness).
e
⊨
κ ⇓q
t κ′ ⊨v
σ′(v) = vp ∧σ′ ∈κ′
∀u. u ∈e ⇒u ∈dom(κ)
⎫⎪⎪⎬
⎪⎪⎭
⇒∃σ ep.
⎧⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩
σ′|σ ≡σ
σ ∈κ
σ(e) = ep
ep ⇓vp
Completeness guarantees the opposite direction: given a predicate derivation
ep ⇓vp and a "factoring" of ep into an expression e and a constraint set κ such that
for some valuation σ ∈κ substituting σ in e yields ep, if is well typed, there is
always a nonzero probability of obtaining some factoring of vp as the result of a
narrowing judgment.
Theorem 13.3 (Completeness).
ep ⇓vp
σ(e) = ep
σ ∈κ ∧⊢κ
∅;U(κ) ⊢e : T
⎫⎪⎪⎪⎪⎬
⎪⎪⎪⎪⎭
⇒
∃v κ′ σ′ q t.
⎧⎪⎪⎨
⎪⎪⎩
σ′|σ ≡σ ∧σ′ ∈κ′
σ′(v) = vp
e
⊨
κ ⇓t
q κ′ ⊨v
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

13.4 Implementation
475
Properties of the Matching Semantics The decreasingness property for the match-
ing semantics is very similar to the narrowing semantics: if the matching semantics
yields {κ′}, then κ′ is smaller than the input κ.
Theorem 13.4 (Decreasingness).
p ⇐e
⊨
κ ⇑t
q {κ′} ⇒κ′ ≤κ
Soundness is again similar to the matching semantics.
Theorem 13.5 (Soundness).
p ⇐e
⊨
κ ⇑t
q {κ′}
σ′(p) = vp ∧σ′ ∈κ′
∀u. (u ∈e ∨u ∈p) ⇒u ∈dom(κ)
⎫⎪⎪⎬
⎪⎪⎭
⇒∃σ ep.
⎧⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩
σ′|σ ≡σ
σ ∈κ
σ(e) = ep
ep ⇓vp
For the completeness theorem, we need to slightly strengthen its premise; since
the matching semantics may explore both branches of a case, it can fall into a loop
when the predicate semantics would not (by exploring a non-terminating branch that
the predicate semantics does not take). Thus, we require that all input valuations
result in a terminating execution.
Theorem 13.6 (Completeness).
ep ⇓vp ∧σ ∈κ
∅;U(κ) ⊢e : T ∧⊢κ
σ(e) = ep ∧σ(p) = vp
∀σ′ ∈κ. ∃v′. σ′(e) ⇓v′
⎫⎪⎪⎪⎪⎬
⎪⎪⎪⎪⎭
⇒
∃κ′ σ′ q t.
⎧⎪⎪⎨
⎪⎪⎩
σ′|σ ≡σ
σ′ ∈κ′
p ⇐e
⊨
κ ⇑t
q {κ′}
13.4 Implementation
We next describe the Luck prototype: its top level, its treatment of backtracking
and its probability-preserving pattern match compiler. We refer the reader to the
extended version for the constraint set implementation.
At the Top Level The inputs provided to the Luck interpreter consist of an expression
e of type bool containing zero or more free unknowns 8u (but no free variables), and
an initial constraint set κ providing types and ﬁnite domains2 for each unknown in
8u, such that their occurrences in e are well typed (∅;U(κ) ⊢e : 1 + 1).
2
This restriction to ﬁnite domains appears to be crucial for our technical development to work, as discussed in
the previous section. In practice, we have not yet encountered a situation where it was important to be able
to generate examples of unbounded size (as opposed to examples up to some large maximum size). We do
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

476
Lampropoulos et al.: Luck: A Probabilistic Language for Testing
The interpreter matches e against True (that is, L1+1 ()), to derive a reﬁned
constraint set κ′:
L1+1 () ⇐e
⊨
κ ⇑t
q {κ′}
This involves random choices, and there is also the possibility that matching fails (and
the semantics generates ∅instead of {κ′}). In this case, a simple global backtracking
approach could simply try the whole thing again (up to an ad hoc limit). While not
strictly necessary for a correct implementation of the matching semantics, some local
backtracking allows wrong choices to be reversed quickly and leads to an enormous
improvement in performance (Claessen et al., 2015). Our prototype backtracks
locally in calls to choose: if choose has two choices available and the ﬁrst one fails
when matching the instantiated expression against a pattern, then we immediately
try the second choice instead. Eﬀectively, this means that if e is already known to be
of the form L_ _, then narrow will not choose to instantiate it using R_ _, and vice
versa. This may require matching against e twice, and our implementation shares
work between these two matches as far as possible. (It also seems useful to give the
user explicit control over where backtracking occurs, but we leave this for future
work.)
After the interpreter matches e against True, all the resulting valuations σ ∈κ′
should map the unknowns in 8u to some values. However, there is no guarantee that
the generator semantics will yield a κ′ mapping every 8u to a unique values. The
Luck top-level then applies the sample constraint set function to each unknown in 8u,
ensuring that σ|8u is the same for each σ in the ﬁnal constraint set. The interpreter
returns this common σ|8u if it exists, and backtracks otherwise.
Pattern Match Compiler In Section 13.2, we saw an example using a standard
Tree datatype and instantiation expressions assigning diﬀerent weights to each
branch. While the desugaring of simple pattern matching to core Luck syntax is
straightforward (Section 13.3.1), nested patterns - as in Figure 13.11 - complicate
things in the presence of probabilities. We expand such expressions to a tree of simple
case expressions that match only the outermost constructors of their scrutinees.
However, there is generally no unique choice of weights in the expanded predicate:
a branch from the source predicate may be duplicated in the result. We guarantee
the intuitive property that the sum of the probabilities of the clones of a branch is
proportional to the weights given by the user, but that still does not determine the
individual probabilities that should be assigned to these clones.
sometimes want to generate structures containing large numbers, since they can be represented eﬃciently, but
here, too, choosing an enormous ﬁnite bound appears to be adequate for the applications we've tried. The
implementation allows for representing all possible ranges of a corresponding type up to a given size bound.
Such bounds are initialized at the top level, and they are propagated (and reduced a bit) to fresh unknowns
created by pattern matching before these unknowns are used as inputs to the interpreter.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

13.5 Evaluation
477
data T = Var Int | Lam Int T | App T T
sig isRedex :: T -> Bool
-- Original
fun isRedex t =
case t of
| 2 % App (Lam _ _) _ -> True
-- 2/3
| 1 % _ -> False
-- 1/3
sig isRedex :: T -> Bool
-- Expansion
fun isRedex t =
case t of
| 1 % Var _ -> False
-- 1/9
| 1 % Lam _ _ -> False
-- 1/9
| 7 % App t1 _ -> case t1 of
| 1 % Var _ -> False
-- 1/18
| 12 % Lam _ _ -> True
-- 2/3
| 1 % App _ _ -> False
-- 1/18
Figure 13.11 Expanding case expression with a nested pattern and a wildcard. Comments show
the probability of each alternative.
The most obvious way to distribute weights is to simply share the weight equally
with all duplicated branches. But the probability of a single branch then depends on
the total number of expanded branches that come from the same source, which can
be hard for users to determine and can vary widely even between sets of patterns
that appear similar. Instead, Luck's default weighing strategy works as follows. For
any branch B from the source, at any intermediate case expression of the expansion,
the subprobability distribution over the immediate subtrees that contain at least one
branch derived from B is uniform. This makes modiﬁcations of the source patterns
in nested positions aﬀect the distribution more locally.
In Figure 13.11, the False branch should have probability 1
3. It is expanded into
four branches, corresponding to subpatterns Var _, Lam _ _, App (Var _) _,
App (App _ _) _ . The latter two are grouped under the pattern App _ _ , while
the former two are in their own groups. These three groups receive equal shares of
the total probability of the original branch, that is 1
9 each. The two nested branches
further split that into
1
18. On the other hand, True remains a single branch with
probability 2
3. The weights on the left of every pattern are calculated to reﬂect this
distribution.
13.5 Evaluation
To evaluate the expressiveness and eﬃciency of Luck's hybrid approach to test case
generation, we tested it with a number of small examples and two signiﬁcant case
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

478
Lampropoulos et al.: Luck: A Probabilistic Language for Testing
Figure 13.12 Red-Black Tree Experiment
studies: generating well-typed lambda terms and information-ﬂow-control machine
states. The Luck code is generally much smaller and cleaner than that of existing
handwritten generators, though the Luck interpreter takes longer to generate each
example - around 20× to 24× for the more complex generators.
Small Examples The literature on random generation includes many small examples
- list predicates such as sorted, member, and distinct, tree predicates like BSTs
(Section 13.2) and red-black trees, and so on. In the extended version we show the
implementation of many such examples in Luck, illustrating how to write predicates
and generators together with minimal eﬀort.
We use red-black trees to compare the eﬃciency of our Luck interpreter to
generators provided by commonly used tools like QuickCheck (random testing),
SmallCheck (exhaustive testing) and Lazy SmallCheck (Runciman et al., 2008). Lazy
SmallCheck leverages Haskell's laziness to greatly improve upon out-of-the-box
QuickCheck and SmallCheck generators in the presence of sparse preconditions, by
using partially deﬁned inputs to explore large parts of the search space at once. Using
both Luck and Lazy SmallCheck, we attempted to generate 1000 red black trees
with a speciﬁc black height bh - meaning that the depth of the tree can be as large as
2 · bh + 1. Results are shown in Figure 13.12. Lazy SmallCheck was able to generate
all 227 trees of black height 2 in 17 seconds, fully exploring all trees up to depth 5.
When generating trees of black height 3, which required exploring trees up to depth
7, Lazy SmallCheck was unable to generate 1000 red black trees within 5 minutes. At
the same time, Luck lies consistently within an order of magnitude of a very eﬃcient
handwritten QuickCheck generator that generates valid Red-Black trees directly.
Using rejection-sampling approaches by generating trees and discarding those that
don't satisfy the red-black tree invariant (e.g., QuickCheck or SmallCheck's ==>) is
prohibitively costly: these approaches perform much worse than Lazy SmallCheck.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

13.5 Evaluation
479
Well-Typed Lambda Terms Using our prototype implementation we reproduced
the experiments of Pałka et al. (2011), who generated well-typed lambda terms in
order to discover bugs in GHC's strictness analyzer. We also use this case study to
indirectly compare to two narrowing-based tools that are arguably closer to Luck
and that use the same case study to evaluate their work: Claessen et al. (2014, 2015)
and Fetscher et al. (2015).
We encoded a model of simply typed lambda calculus with polymorphism
in Luck, providing a large typing environment with standard functions from the
Haskell Prelude to generate interesting well-typed terms. The generated ASTs were
then pretty-printed into Haskell syntax and each one was applied to a partial list
of the form: [1,2,undefined]. Using the same version of GHC (6.12.1), we
compiled each application twice: once with optimizations (-O2) and once without
and compared the outputs.
A straightforward Luck implementation of a type system for the polymorphic
lambda calculus was not adequate for ﬁnding bugs eﬃciently. To improve its
performance we borrowed tricks from the similar case study of Fetscher et al.,
seeding the environment with monomorphic versions of possible constants and
increasing the frequency of seq, a basic Haskell function that introduces strictness,
to increase the chances of exercising the strictness analyzer. Using this, we discovered
bugs similar to those found by Pałka et al. and Fetscher et al.. For example, the
[Int] -> [Int] function
seq (id (\a -> seq a id) undefined),
when fed the singleton list [undefined], yields an exception immediately with
-O0 (following the semantics of seq), but prints the toplevel constructor of the result
[ before raising the exception if compiled with -O1.
Luck's generation speed was slower than that of Pałka's handwritten generator.
We generated terms of average size 50 (internal nodes), and, grouping terms together
in batches of 100, we got a total time of generation, unparsing, compilation and
execution of around 35 seconds per batch. This is a slowdown of 20x compared to
that of Pałka's. However, our implementation is a total of 82 lines of fairly simple
code, while the handwritten development is 1684 lines, with the warning ". . . the
code is diﬃcult to understand, so reading it is not recommended" in its distribution
page (Pałka, n.d.).
The derived generators of Claessen et al. (2014) achieved a 7x slowdown compared
to the handwritten generator, while the Redex generators (Fetscher et al., 2015)
also report a 7× slowdown in generation time for their best generator. However,
by seeding the environment with monomorphised versions of the most common
constants present in the counterexamples, they were able to achieve a time per
counterexample on par with the handwritten generator.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

480
Lampropoulos et al.: Luck: A Probabilistic Language for Testing
Information-Flow Control For a second large case study, we reimplemented a
method for generating information-ﬂow control machine states (Hriţcu et al., 2013).
Given an abstract stack machine with data and instruction memories, a stack,
and a program counter, one attaches labels - security levels - to runtime values,
propagating them during execution and restricting potential ﬂows of information
from high (secret) to low (public) data. The desired security property, termination-
insensitive noninterference, states that if we start with two indistinguishable abstract
machines s1 and s2 (i.e., all their low-tagged parts are identical) and run each of
them to completion, then the resulting states s1' and s2' are also indistinguishable.
Hriţcu et al. found that eﬃcient testing of this property could be achieved in
two ways: either by generating instruction memories that allow for long executions
and checking for indistinguishability at each low step (called LLNI, low-lockstep
noninterference), or by looking for counter-examples to a stronger invariant (strong
enough to prove noninterference), generating two arbitrary indistinguishable states
and then running for a single step (SSNI, single step noninterference). In both cases
one must ﬁrst generate one abstract machine s and then vary s, to generate an
indistinguishable one s'. In writing a generator for variations, one must reverse the
indistinguishability predicate between states and then keep the two artifacts in sync.
We ﬁrst investigated the stronger property (SSNI), by encoding the indistinguisha-
bility predicate in Luck and using our prototype to generate small, indistinguishable
pairs of states. In 216 lines of code we were able to describe both the predicate
and the generator for indistinguishable machines. The same functionality required
>1000 lines of complex Haskell code in the handwritten version. The handwritten
generator is reported to generate an average of 18400 tests per second, while the
Luck prototype generates 1450 tests per second, around 12.5 times slower.
The real promise of Luck, however, became apparent when we turned to LLNI.
Hriţcu et al. (2013) generate long sequences of instructions using generation by
execution: starting from a machine state where data memories and stacks are
instantiated, they generate the current instruction ensuring it does not cause the
machine to crash, then allow the machine to take a step and repeat. While intuitively
simple, this extra piece of generator functionality took signiﬁcant eﬀort to code,
debug, and optimize for eﬀectiveness, resulting in more than 100 additional lines of
code. The same eﬀect was achieved in Luck by the following 6 intuitive lines, where
we just put the previous explanation in code:
sig runsLong :: Int -> AS -> Bool
fun runsLong len st =
if len <= 0 then True
else case step st of
| 99 % Just st' -> runsLong (len - 1) st'
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

13.6 Related Work
481
| 1 % Nothing
-> True
We evaluated our generator on the same set of buggy information-ﬂow analyses
as in (Hriţcu et al., 2013). We were able to ﬁnd all of the same bugs, with similar
eﬀectiveness (number of bugs found per 100 tests). However, the Luck generator
was 24 times slower (Luck: 150 tests/s, Haskell: 3600 tests/s). We expect to be able
to improve this result (and the rest of the results in this section) with a more eﬃcient
implementation that compiles Luck programs to QuickCheck generators directly,
instead of interpreting them in a minimally tuned prototype.
This prototype gives the user enough ﬂexibility to achieve eﬀectiveness similar
to state-of-the-art generators, while signiﬁcantly reducing the amount of code and
eﬀort required, suggesting that the Luck approach is promising and pointing towards
the need for a real, optimizing implementation.
13.6 Related Work
Luck lies in the intersection of many diﬀerent topics in programming languages,
and the potentially related literature is huge. Here, we present just the closest related
work; a more comprehensive treatment of related work can be found in the extended
version of the paper.
Property-Based Testing The works that are most closely related to our own are
the narrowing based approaches of (Gligoric et al., 2010), (Claessen et al., 2014,
2015) and (Fetscher et al., 2015). Gligoric et al. use a "delayed choice" approach,
which amounts to needed-narrowing, to generate test cases in Java. Claessen et
al. exploit the laziness of Haskell, combining a narrowing-like technique with
FEAT (Duregård et al., 2012), a tool for functional enumeration of algebraic types,
to eﬃciently generate near-uniform random inputs satisfying some precondition.
Fetscher et al. (2015) also use an algorithm that makes local choices with the
potential to backtrack in case of failure. Moreover, they add a simple version of
constraint solving, handling equality and disequality constraints. This allows them
to achieve excellent performance in testing GHC for bugs (as in Pałka et al., 2011)
by monomorphizing the polymorphic constants of the context as discussed in the
previous section. However, both tools provide limited (locally, or globally, uniform)
distribution guarantees, with no user control over the resulting distribution.
Another interesting related approach appears in the inspiring work of Bulwahn
(2012b). In the context of Isabelle's (Nipkow et al., 2002) QuickCheck (Bulwahn,
2012a), Bulwahn automatically constructs enumerators for a given precondition via a
compilation to logic programs using mode inference. Lindblad (2007) and (Runciman
et al., 2008) also provide support for exhaustive testing using narrowing-based
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

482
Lampropoulos et al.: Luck: A Probabilistic Language for Testing
techniques. Instead of implementing mechanisms that resemble narrowing in standard
functional languages, Fischer and Kuchen (Fischer and Kuchen, 2007) leverage the
built-in engine of the functional logic programming language Curry (Hanus et al.,
1995) to enumerate tests satisfying a coverage criterion. While exhaustive testing
is useful and has its own merits and advantages over random testing in a lot of
domains, we turn to random testing because the complexity of our applications -
testing noninterference or optimizing compilers - makes enumeration impractical.
Probabilistic programming Semantics for probabilistic programs share many
similarities with the semantics of Luck (Milch et al., 2005; Goodman et al., 2008;
Gordon et al., 2014), while the problem of generating satisfying valuations shares
similarities with probabilistic sampling (Mansinghka et al., 2009; Łatuszyński et al.,
2013; Chaganty et al., 2013; Nori et al., 2014). For example, the semantics of PROB
in the recent probabilistic programming survey of Gordon et al. (Gordon et al., 2014)
takes the form of probability distributions over valuations, while Luck semantics
can be viewed as (sub)probability distributions over constraint sets, which induces
a distribution over valuations. Moreover, in probabilistic programs, observations
serve a similar role to preconditions in random testing, creating problems for
simplistic probabilistic samplers that use rejection sampling - i.e., generate and
test. Recent advances in this domain, like the work on Microsoft's R2 Markov
Chain Monte Carlo sampler (Nori et al., 2014), have shown promise in providing
more eﬃcient sampling, using pre-imaging transformations in analyzing programs.
An important diﬀerence is in the type of programs usually targeted by such tools.
The diﬃculty in probabilistic programming arises mostly from dealing with a
large number of complex observations, modeled by relatively small programs. For
example, Microsoft's TrueSkill (Herbrich et al., 2006) ranking program is a very
small program, powered by millions of observations. In contrast, random testing
deals with very complex programs (e.g., a type checker) and a single observation
(observe true).
13.7 Conclusions and Future Work
In this chapter we introduced Luck, a language for writing generators in the form
of lightly annotated predicates. We presented the semantics of Luck, combining
local instantiation and constraint solving in a uniﬁed framework and exploring their
interactions. We described a prototype implementation of this semantics and used it
to repeat state-of-the-art experiments in random generation. The results showed the
potential of Luck's approach, allowing us to replicate the distribution yielded by the
handwritten generators with reduced code and eﬀort. The prototype was slower by
an order of magnitude, but there is still signiﬁcant room for improvement.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
483
In the future it will be interesting to explore ways to improve the performance of our
interpreted prototype, by compiling Luck into generators in a mainstream language
and by experimenting with other domain representations. We also want to investigate
Luck's equational theory, showing that the encoded logical predicates satisfy the
usual logical laws. Moreover, the backtracking strategies in our implementation
can be abstractly modeled on top of our notion of choice-recording trace; Gallois-
Wong (Gallois-Wong, 2016) shows promising preliminary results using Markov
chains for this.
Another potential direction for future work is automatically deriving smart
shrinkers. Shrinking, or delta-debugging, is crucial in property-based testing, and
it can also require signiﬁcant user eﬀort and domain speciﬁc knowledge to be
eﬃcient (Regehr et al., 2012). It would be interesting to see if there is a counterpart
to narrowing or constraint solving that allows shrinking to preserve desired properties.
References
Antoy, Sergio. 2000. A Needed Narrowing Strategy. Pages 776-822 of: Journal of
the ACM, vol. 47. ACM Press.
Arts, Thomas, Castro, Laura M., and Hughes, John. 2008. Testing Erlang Data
Types with QuviQ QuickCheck. Pages 1-8 of: 7th ACM SIGPLAN Workshop
on Erlang. ACM.
Avgerinos, Thanassis, Rebert, Alexandre, Cha, Sang Kil, and Brumley, David. 2014.
Enhancing symbolic execution with Veritesting. Pages 1083-1094 of: 36th
International Conference on Software Engineering, ICSE '14, Hyderabad,
India: May 31-June 07, 2014.
Ball, Thomas, Levin, Vladimir, and Rajamani, Sriram K. 2011. A decade of software
model checking with SLAM. Commun. ACM, 54(7), 68-76.
Blanchette, Jasmin Christian, and Nipkow, Tobias. 2010. Nitpick: A Counterexample
Generator for Higher-Order Logic Based on a Relational Model Finder. Pages
131-146 of: First International Conference on Interactive Theorem Proving
(ITP). LNCS, vol. 6172. Springer.
Bulwahn, Lukas. 2012a. The New Quickcheck for Isabelle - Random, Exhaustive
and Symbolic Testing under One Roof. Pages 92-108 of: 2nd International
Conference on Certiﬁed Programs and Proofs (CPP). LNCS, vol. 7679.
Springer.
Bulwahn, Lukas. 2012b. Smart Testing of Functional Programs in Isabelle. Pages
153-167 of: 18th International Conference on Logic for Programming, Artiﬁcial
Intelligence, and Reasoning (LPAR). LNCS, vol. 7180. Springer.
Cadar, Cristian, Dunbar, Daniel, and Engler, Dawson. 2008. KLEE: unassisted and
automatic generation of high-coverage tests for complex systems programs.
Pages 209-224 of: 8th USENIX conference on Operating systems design and
implementation. OSDI. USENIX Association.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

484
References
Carlier, Matthieu, Dubois, Catherine, and Gotlieb, Arnaud. 2010.
Constraint
Reasoning in FocalTest. Pages 82-91 of: 5th International Conference on
Software and Data Technologies. SciTePress.
Chaganty, Arun T., Nori, Aditya V., and Rajamani, Sriram K. 2013 (April). Eﬃ-
ciently Sampling Probabilistic Programs via Program Analysis. In: Artiﬁcial
Intelligence and Statistics (AISTATS).
Chakraborty, Supratik, Meel, Kuldeep S., and Vardi, Moshe Y. 2014. Balancing
Scalability and Uniformity in SAT Witness Generator. Pages 60:1-60:6 of:
Proceedings of the 51st Annual Design Automation Conference. DAC '14. New
York, NY, USA: ACM.
Chamarthi, Harsh Raju, Dillinger, Peter C., Kaufmann, Matt, and Manolios, Panagi-
otis. 2011. Integrating Testing and Interactive Theorem Proving. Pages 4-19 of:
10th International Workshop on the ACL2 Theorem Prover and its Applications.
EPTCS, vol. 70.
Christiansen, Jan, and Fischer, Sebastian. 2008. EasyCheck - Test Data for Free.
Pages 322-336 of: 9th International Symposium on Functional and Logic
Programming (FLOPS). LNCS, vol. 4989. Springer.
Claessen, Koen, and Hughes, John. 2000. QuickCheck: a lightweight tool for
random testing of Haskell programs. Pages 268-279 of: 5th ACM SIGPLAN
International Conference on Functional Programming (ICFP). ACM.
Claessen, Koen, Duregård, Jonas, and Pałka, Michał H. 2014. Generating Constrained
Random Data with Uniform Distribution. Pages 18-34 of: Functional and
Logic Programming. LNCS, vol. 8475. Springer.
Claessen, Koen, Duregård, Jonas, and Palka, Michal H. 2015. Generating constrained
random data with uniform distribution. J. Funct. Program., 25.
Duregård, Jonas, Jansson, Patrik, and Wang, Meng. 2012. Feat: Functional Enumer-
ation of Algebraic Types. Pages 61-72 of: Proceedings of the 2012 Haskell
Symposium. Haskell '12. New York, NY, USA: ACM.
Dybjer, Peter, Haiyan, Qiao, and Takeyama, Makoto. 2003. Combining Testing and
Proving in Dependent Type Theory. Pages 188-203 of: 16th International
Conference on Theorem Proving in Higher Order Logics (TPHOLs). LNCS,
vol. 2758. Springer.
Fetscher, Burke, Claessen, Koen, Palka, Michal H., Hughes, John, and Findler,
Robert Bruce. 2015. Making Random Judgments: Automatically Generating
Well-Typed Terms from the Deﬁnition of a Type-System. Pages 383-405 of:
24th European Symposium on Programming. LNCS, vol. 9032. Springer.
Fischer, Sebastian, and Kuchen, Herbert. 2007. Systematic generation of glass-box
test cases for functional logic programs. Pages 63-74 of: 9th International ACM
SIGPLAN Conference on Principles and Practice of Declarative Programming
(PPDP). ACM.
Gallois-Wong, Diane. 2016 (Aug.). Formalising Luck: Improved Probabilistic
Semantics for Property-Based Generators. Inria Internship Report.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
485
Gligoric, Milos, Gvero, Tihomir, Jagannath, Vilas, Khurshid, Sarfraz, Kuncak,
Viktor, and Marinov, Darko. 2010. Test generation through programming in
UDITA. Pages 225-234 of: 32nd ACM/IEEE International Conference on
Software Engineering. ACM.
Godefroid, Patrice, Klarlund, Nils, and Sen, Koushik. 2005. DART: directed
automated random testing. Pages 213-223 of: ACM SIGPLAN Conference on
Programming Language Design and Implementation. PLDI. ACM.
Goodman, Noah D., Mansinghka, Vikash K., Roy, Daniel M., Bonawitz, Keith, and
Tenenbaum, Joshua B. 2008. Church: a language for generative models. Pages
220-229 of: UAI 2008, Proceedings of the 24th Conference in Uncertainty in
Artiﬁcial Intelligence, Helsinki, Finland, July 9-12, 2008.
Gordon, Andrew D., Henzinger, Thomas A., Nori, Aditya V., and Rajamani, Sriram K.
2014. Probabilistic programming. Pages 167-181 of: Herbsleb, James D., and
Dwyer, Matthew B. (eds), Proceedings of the on Future of Software Engineering,
FOSE 2014, Hyderabad, India, May 31-June 7, 2014. ACM.
Gotlieb, Arnaud. 2009. Euclide: A Constraint-Based Testing Framework for Critical
C Programs. Pages 151-160 of: ICST 2009, Second International Conference on
Software Testing Veriﬁcation and Validation, 1-4 April 2009, Denver, Colorado,
USA.
Groce, Alex, Zhang, Chaoqiang, Eide, Eric, Chen, Yang, and Regehr, John. 2012.
Swarm Testing.
Pages 78-88 of: Proceedings of the 2012 International
Symposium on Software Testing and Analysis. ISSTA 2012. New York, NY,
USA: ACM.
Hanus, M., Kuchen, H., and Moreno-Navarro, J.J. 1995. Curry: A Truly Functional
Logic Language. Pages 95-107 of: Proc. ILPS'95 Workshop on Visions for the
Future of Logic Programming.
Hanus, Michael. 1997. A Uniﬁed Computation Model for Functional and Logic
Programming. Pages 80-93 of: 24th ACM SIGPLAN-SIGACT Symposium on
Principles of Programming Languages (POPL). ACM Press.
Herbrich, Ralf, Minka, Tom, and Graepel, Thore. 2006. TrueSkillTM: A Bayesian
Skill Rating System. Pages 569-576 of: Advances in Neural Information
Processing Systems 19, Proceedings of the Twentieth Annual Conference on
Neural Information Processing Systems, Vancouver, British Columbia, Canada,
December 4-7, 2006.
Hriţcu, Cătălin, Hughes, John, Pierce, Benjamin C., Spector-Zabusky, Antal, Vytinio-
tis, Dimitrios, Azevedo de Amorim, Arthur, and Lampropoulos, Leonidas. 2013.
Testing Noninterference, Quickly. Pages 455-468 of: 18th ACM SIGPLAN
International Conference on Functional Programming (ICFP). ACM.
Hriţcu, Cătălin, Lampropoulos, Leonidas, Spector-Zabusky, Antal, Azevedo de
Amorim, Arthur, Dénès, Maxime, Hughes, John, Pierce, Benjamin C., and
Vytiniotis, Dimitrios. 2016. Testing Noninterference, Quickly. Journal of
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

486
References
Functional Programming (JFP); Special issue for ICFP 2013, 26(Apr.), e4 (62
pages). Technical Report available as arXiv:1409.0393.
Hughes, John. 2007. QuickCheck Testing for Fun and Proﬁt. Pages 1-32 of:
9th International Symposium on Practical Aspects of Declarative Languages
(PADL). LNCS, vol. 4354. Springer.
Jackson, Daniel. 2011. Software Abstractions: Logic, Language, and Anlysis. The
MIT Press.
Jhala, Ranjit, and Majumdar, Rupak. 2009. Software model checking. ACM Comput.
Surv., 41(4).
Köksal, Ali Sinan, Kuncak, Viktor, and Suter, Philippe. 2011. Scala to the Power of
Z3: Integrating SMT and Programming. Pages 400-406 of: 23rd International
Conference on Automated Deduction. LNCS, vol. 6803. Springer.
Lampropoulos, Leonidas, Gallois-Wong, Diane, Hritcu, Catalin, Hughes, John,
Pierce, Benjamin C., and Xia, Li-yao. 2017. Beginner's Luck: a language for
property-based generators. Pages 114-129 of: Proceedings of the 44th ACM
SIGPLAN Symposium on Principles of Programming Languages, POPL 2017,
Paris, France, January 18-20, 2017.
Łatuszyński, Krzysztof, Roberts, Gareth O., and Rosenthal, Jeﬀrey S. 2013. Adaptive
Gibbs samplers and related MCMC methods. The Annals of Applied Probability,
23(1), 66-98.
Lindblad, Fredrik. 2007. Property Directed Generation of First-Order Test Data.
Pages 105-123 of: 8th Symposium on Trends in Functional Programming.
Trends in Functional Programming, vol. 8. Intellect.
Mansinghka, Vikash K., Roy, Daniel M., Jonas, Eric, and Tenenbaum, Joshua B.
2009. Exact and Approximate Sampling by Systematic Stochastic Search.
Pages 400-407 of: Proceedings of the Twelfth International Conference on
Artiﬁcial Intelligence and Statistics, AISTATS 2009, Clearwater Beach, Florida,
USA, April 16-18, 2009.
Milch, Brian, Marthi, Bhaskara, Russell, Stuart J., Sontag, David, Ong, Daniel L., and
Kolobov, Andrey. 2005. BLOG: Probabilistic Models with Unknown Objects.
Pages 1352-1359 of: IJCAI-05, Proceedings of the Nineteenth International
Joint Conference on Artiﬁcial Intelligence, Edinburgh, Scotland, UK, July
30-August 5, 2005.
Nipkow, Tobias, Wenzel, Markus, and Paulson, Lawrence C. 2002. Isabelle/HOL: A
Proof Assistant for Higher-order Logic. Berlin, Heidelberg: Springer-Verlag.
Nori, Aditya V., Hur, Chung-Kil, Rajamani, Sriram K., and Samuel, Selva. 2014. R2:
An Eﬃcient MCMC Sampler for Probabilistic Programs. In: AAAI Conference
on Artiﬁcial Intelligence (AAAI). AAAI.
Okasaki, Chris. 1999. Red-Black Trees in a Functional Setting. Journal of Functional
Programming, 9(4), 471-477.
Owre, Sam. 2006. Random Testing in PVS. In: Workshop on Automated Formal
Methods.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
487
Pacheco, Carlos, and Ernst, Michael D. 2007. Randoop: feedback-directed random
testing for Java. Pages 815-816 of: 22nd ACM SIGPLAN Conference on
Object-Oriented Programming Systems And Applications. OOPSLA. ACM.
Pałka, Michał H. Testing an optimising compiler by generating random lambda
terms. http://www.cse.chalmers.se/~palka/testingcompiler/.
Pałka, Michał H., Claessen, Koen, Russo, Alejandro, and Hughes, John. 2011.
Testing an Optimising Compiler by Generating Random Lambda Terms. Pages
91-97 of: Proceedings of the 6th International Workshop on Automation of
Software Test. AST '11. New York, NY, USA: ACM.
Paraskevopoulou, Zoe, Hriţcu, Cătălin, Dénès, Maxime, Lampropoulos, Leonidas,
and Pierce, Benjamin C. 2015. Foundational Property-Based Testing. Pages
325-343 of: Urban, Christian, and Zhang, Xingyuan (eds), 6th International
Conference on Interactive Theorem Proving (ITP). LNCS, vol. 9236. Springer.
Regehr, John, Chen, Yang, Cuoq, Pascal, Eide, Eric, Ellison, Chucky, and Yang,
Xuejun. 2012. Test-case reduction for C compiler bugs. Pages 335-346 of: ACM
SIGPLAN Conference on Programming Language Design and Implementation,
PLDI '12, Beijing, China, June 11-16, 2012.
Reich, Jason S., Naylor, Matthew, and Runciman, Colin. 2011. Lazy Generation of
Canonical Test Programs. Pages 69-84 of: 23rd International Symposium on
Implementation and Application of Functional Languages. LNCS, vol. 7257.
Springer.
Runciman, Colin, Naylor, Matthew, and Lindblad, Fredrik. 2008. SmallCheck and
Lazy SmallCheck: automatic exhaustive testing for small values. Pages 37-48
of: 1st ACM SIGPLAN Symposium on Haskell. ACM.
Seidel, Eric L., Vazou, Niki, and Jhala, Ranjit. 2015. Type Targeted Testing. Pages
812-836 of: Programming Languages and Systems: 24th European Symposium
on Programming, ESOP 2015, Held as Part of the European Joint Conferences
on Theory and Practice of Software, ETAPS 2015, London, UK, April 11-18,
2015. Proceedings.
Sen, Koushik, Marinov, Darko, and Agha, Gul. 2005. CUTE: a concolic unit
testing engine for C. Pages 263-272 of: 10th European software engineering
conference held jointly with 13th ACM SIGSOFT international symposium on
Foundations of software engineering. ESEC/FSE-13. ACM.
Tarau, Paul. 2015. On Type-directed Generation of Lambda Terms. In: Proceedings
of the Technical Communications of the 31st International Conference on Logic
Programming (ICLP 2015), Cork, Ireland, August 31-September 4, 2015.
Tolmach, Andrew P., and Antoy, Sergio. 2003. A monadic semantics for core Curry.
Electr. Notes Theor. Comput. Sci., 86(3), 16-34.
Torlak, Emina, and Bodík, Rastislav. 2014. A lightweight symbolic virtual machine
for solver-aided host languages. Page 54 of: ACM SIGPLAN Conference on
Programming Language Design and Implementation. ACM.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

14
Tabular: Probabilistic Inference from the Spreadsheet
Andrew D. Gordon
Microsoft Research and University of Edinburgh
Claudio Russoa
DFINITY, Zürich
Marcin Szymczakb
RWTH Aachen University
Johannes Borgström
Uppsala University
Nicolas Rollanda and Thore Graepela
University College London
Daniel Tarlowa
Google Research, Brain Team, Montreal
Abstract:
Tabular is a domain-speciﬁc language for expressing probabilistic
models of relational data. Tabular has several features that set it apart from other
probabilistic programming languages including: (1) programs and data are stored
as spreadsheet tables; (2) programs consist of probabilistic annotations on the
relational schema of the data; and (3) inference returns estimations of missing
values and latent columns, as well as parameters. Our primary implementation is
for Microsoft Excel and relies on Infer.NET for inference. Still, the language can
be called independently of Excel and can target alternative inference engines.
14.1 Overview
Probabilistic programming languages promise to make machine learning more ac-
cessible by allowing users to write their generative models as computer programs
and providing generic inference engines capable of performing inference on all
valid programs expressible in the given language. However, as most of the cur-
rently existing languages are essentially probabilistic extensions of conventional
programming languages, they are arguably not ideally suited for the job.
For one thing, they are still diﬃcult to use for people who are not professional
programmers. Meanwhile, many people who may want to use probabilistic mod-
a The work was conducted while the authors were at Microsoft Research
b The work was conducted while the author was at University of Edinburgh and Oxford University
c From Foundations of Probabilistic Programming, edited by Gilles Barthe, Joost-Pieter Katoen and Alexandra
Silva published 2020 by Cambridge University Press.
489
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

490
Gordon et al: Tabular: Probabilistic Inference from the Spreadsheet
elling are domain experts, for instance business analysts, who often have limited
programming experience and could ﬁnd, for instance, systems based on functional
(Goodman et al., 2008; Wood et al., 2014) or logic (Van den Broeck et al., 2010)
programming baﬄing. Secondly, most existing languages require all the necessary
data to be loaded and placed in the right data structures. This can often be problem-
atic and require a large amount of data pre-processing, which could be a nuisance
even for experienced programmers and statisticians.
The Tabular language, ﬁrst presented by Gordon et al. (2014b), takes a diﬀerent
approach. Instead of extending an ordinary programming language with primitives
for sampling and conditioning, Tabular extends schemas of relational databases
with probabilistic model expressions and annotations. This idea is based on the
observation that in model-based Bayesian machine learning, the starting point is
not the model itself, but the dataset to which one wants to ﬁt a model, which has
to be stored in some sort of database - for example a spreadsheet. In Tabular, the
probabilistic model is built on top of the data, and the input database does not need
to be manipulated before being fed to the program.
A key strength of Tabular is that it is easier to use than standard programming
languages, because it does not require the user to write an actual program from
scratch - all that the user has to do to deﬁne a model is to annotate a database
schema with probabilistic expressions explaining how they believe the data was
generated and add latent columns for the unknown quantities of interest. Moreover,
Tabular's design allows it to be integrated with environments such as spreadsheet
applications, that are familiar to users who are not professional programmers.
Indeed, Tabular has been implemented as an Excel plugin and both the model and
the input database are speciﬁed as Excel spreadsheets. Inference results are also
saved to a spreadsheet, which allows for easier post-processing and visualisation.
The command-line version of Tabular is open source and the source code is available
at https://github.com/TabularLang/CoreTabular.
In this chapter, we present a new, substantially enhanced version of Tabular,
which features user-deﬁned functions and queries on inference results. We endow
Tabular with a structural, dependent type system, which helps understand the sample
space of a program and catch common modelling mistakes. We deﬁne a reduction
relation reducing Tabular programs with function applications to Core models
containing only simple expressions and corresponding directly to factor graphs. We
also demonstrate by example how these features make Tabular a useful language
for Bayesian modelling.
This chapter is based on Chapter 4 of Szymczak (2018), which is itself an
extended version of Gordon et al. (2015).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

14.2 Introduction and Examples
491
14.2 Introduction and Examples
In this section, we introduce Tabular informally, explaining its features by example.
14.2.1 Probabilistic Programming in Tabular
A Tabular program is constructed by extending a database schema with:
• Latent columns representing unknown parameters, not present in the database,
which we want to infer from the data,
• Annotations deﬁning roles of respective columns in the probabilistic model (input
variables, modelled output variables, local variables),
• Model expressions, which express our belief about how the values in the given
column of the database were generated.
In the simplest case, model expressions are ordinary expressions written in a
ﬁrst-order functional language with random draws. We refer to schemas and tables
containing only such simple expressions as Core schemas and tables. Other kinds of
models include function applications and indexed models, which will be discussed
later.
Let us begin the presentation of Tabular with an example based on one from
Gordon et al. (2014b), which implements the TrueSkill model (Herbrich et al.,
2007) for ranking players in online video games. Suppose we have a database
containing the outcomes of past matches between some players. This database
can have the following schema (where we assume that each table has an implicit,
integer-valued ID column, serving as the primary key of the table):
table Players
Name
string
table Matches
Player1
link(Players)
Player2
link(Players)
Win1
bool
where Win1 is true if the match was won by Player 1 and false if Player 2 won the
match (we assume there are no draws). Based on these past results, we want to infer
the relative skills of the players.
According to the TrueSkill model, we quantify the performance of a given player
in a certain match by a numeric value, which is a noisy copy of the player's skill. We
assume that each match was won by the player with higher performance value. We
can implement this model in Tabular by extending the above schema as follows1:
1 As explained in Section 14.3, in the formal syntax of Tabular, each column has a global and local name,
because of issues with α-conversion. In the introductory examples in this section, we only give each column
one name, serving both as a global and local identiﬁer, to simplify presentation.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

492
Gordon et al: Tabular: Probabilistic Inference from the Spreadsheet
table Players
Name
string!det
input
Skill
real!rnd
output
Gaussian(100.0, 100.0)
table Matches
Player1
link(Players)!det
input
Player2
link(Players)!det
input
Perf1
real!rnd
output
Gaussian(Player1.Skill, 100.0)
Perf2
real!rnd
output
Gaussian(Player2.Skill, 100.0)
Win1
bool!rnd
output
Perf1 > Perf2
We have added one new column, not present in the database, to the Players
table and two columns to the Matches table. The Players table now has a Skill
attribute. This column is not expected to be present in the input database - its
distribution is to be inferred from the observed data. By assigning the expression
Gaussian(100.0,100.0) to this column, we have deﬁned the prior distribution on
players' skills to be a Gaussian with mean 100 and variance 100. Similarly, the
values of the Perf1 and Perf2 columns are, in the generative interpretation of the
model, drawn from Gaussians centred at the skills of the corresponding players (the
expression Player1.Skill is a reference to the value of Skill in the row of Players
linked to by Player1, and similarly for Player2.Skill). Finally, the observed Win1
column is assigned the expression Perf1 > Perf2, which expresses the condition
that in every row of the Matches table, Perf1 must be greater than Perf2 if Win1
in this row is true in the database, and not greater than Perf2 if Win1 is false -
otherwise, the values of the parameters would be inconsistent with the observations.
The types in the second schema include det and rnd annotations which specify
whether the data in the given column is deterministic (known in advance) or random
(to be inferred by the inference algorithm). These annotations, which we call spaces,
are used by the type system to catch information ﬂow errors, such as supposedly
deterministic data depending on random variables. Tabular columns can also be in
space qry, which will be discussed later.
To perform inference in the above model, we need to parametrise it on a particular
dataset. In Tabular, like in BUGS (Gilks et al., 1994) and Stan (Carpenter et al.,
2017), input data is decoupled from the program and is loaded by the compiler
from a separate data source. This approach makes it possible to run inference in
the same model with multiple datasets without modifying the model. The TrueSkill
model, as implemented above, was designed to be applied to databases containing
thousands of matches and players, but the following is a valid tiny input database
for this schema:
Players
ID
Name
0
"Alice"
1
"Bob"
2
"Cynthia"
Matches
ID
Player1
Player2
Win1
0
0
1
false
1
1
2
false
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

14.2 Introduction and Examples
493
In this example, we have only three players, Alice, Bob and Cynthia, and we
assume that Bob beat Alice in the ﬁrst match and was beaten by Cynthia in the
second one.
The default inference algorithm of Tabular, Expectation Propagation (Minka,
2001), adds the approximate distributions of unobserved random columns to the
input database. The output database for the above tiny example is as follows:
Players
ID
Name
Skill
0
"Alice"
Gaussian(95.25, 82.28)
1
"Bob"
Gaussian(100.0, 70.66)
2
"Cynthia"
Gaussian(104.8, 82.28)
Matches
ID
P1
P2
Perf1
Perf2
Win1
0
0
1
Gaussian(90.49, 129.1)
Gaussian(104.8, 123.6)
false
1
1
2
Gaussian(95.25, 123.6)
Gaussian(109.5, 129.1)
false
This matches our intuition that Cynthia, having beaten the winner of the ﬁrst
match, is most likely to be the best of the three players, and Alice is probably the
weakest.
In addition to the style of inference described above, called query-by-latent-
column, Tabular also supports query-by-missing-value, where the database has
some missing entries for one or many output columns and the goal is to compute
the distributions on the missing values. For example, if we want to predict the
outcome of an upcoming match between Alice and Cynthia, we can extend the
matches table as follows:
Matches
ID
Player1
Player2
Win1
0
0
1
false
1
1
2
false
2
0
2
?
The Tabular inference engine will then compute the distribution of Win1 in the
third column.
Matches
ID
P1
P2
Perf1
Perf2
Win1
0
0
1
Gaussian(90.49, 129.1)
Gaussian(104.8, 123.6)
false
1
1
2
Gaussian(95.25, 123.6)
Gaussian(109.5, 129.1)
false
2
0
2
Gaussian(95.25, 182.3)
Gaussian(104.8, 182.3)
Bernoulli(0.3092)
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

494
Gordon et al: Tabular: Probabilistic Inference from the Spreadsheet
14.2.2 User-Deﬁned, Dependently-Typed Functions
Tabular supports functions, which are deﬁned in the same way as ordinary tables
and can be used to abstract away arbitrary repeated blocks of code which only
diﬀer by some values used in the model expressions. Functions can help users make
their schemas shorter and more concise. Tabular already comes with a library of
predeﬁned functions, representing, for instance, commonly used conjugate models,
and new functions can be deﬁned by the user.
To illustrate how functions can be used in Tabular, let us consider the well-known
problem of inferring the bias of a coin from the outcomes of coin tosses. Assuming
that each bias (between 0 and 1) is equally likely, this model can be represented in
Tabular as follows:
table Coins
V
real!rnd[2]
static output
Dirichlet[2]([1.0, 1.0])
Flip
mod(2)!rnd
output
Discrete[2](V)
where Dirichlet[2]([1.0,1.0]) is just the uniform distribution on pairs of two proba-
bilities adding up to 1, and Discrete[2](V) draws 0 or 1 (representing tails and heads,
respectively) with probability proportional to the corresponding component of V.
This model, in which the parameter to the discrete distribution has a uniform
Dirichlet prior, is an instance of the Conjugate Discrete model. Conjugate Discrete,
which is a building block of many more complex models, is deﬁned in the standard
function library as follows:
fun CDiscrete
N
int!det
static input
R
real!det
static input
V
real!rnd[N]
static output
Dirichlet[N]([for i < N →R])
ret
mod(N)!rnd
output
Discrete[N](V)
The arguments of this function, N and R, denote, respectively, the length of the
parameter vector and the value of each component of the hyperparameter vector
passed to the prior (the higher the value of R, the closer together the components of
the parameter vector are expected to be). This function also demonstrates the use of
dependent types: real!rnd[N] indicates that the given random column is an array of
reals of size determined by the variable N, and mod(N)!rnd denotes a non-negative
random integer smaller than N. It is worth noting that in the deﬁnition of CDiscrete
we could alternatively make the entire pseudocount vector passed to Dirichlet[N] an
argument of type real!det[N].
With this function in place, we can rewrite the coin toss model as follows:
table Coins
Flip
mod(2)!rnd
output
CDiscrete(N=2, R=1.0)
where setting R to 1.0 guarantees that the prior distribution on probabilities V of
heads and tails is uniform.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

14.2 Introduction and Examples
495
The reduction algorithm presented later in this chapter reduces this table to the
form shown earlier, modulo renaming of column names.
Tabular also supports indexing function applications, which results in turning
static parameters of the model into arrays, indexed by a categorical variable (that
is, a discrete random variable with a ﬁnite domain). For example, suppose that in
the above problem we have two coins with diﬀerent biases, and we always toss one
of them, chosen at random with equal probability. To infer the biases of the coins,
we can adapt the above Tabular program as follows:
table Coins
CoinUsed
mod(2)!rnd
output
Discrete[2]([0.5, 0.5])
Flip
int!rnd
output
CDiscrete(N=2, R=1.0)[CoinUsed < 2]
Now, we have two copies of the bias vector V, one for each coin, and at each row,
the vector indicated by the random variable CoinUsed is used.
14.2.3 Query Variables
Another novel feature of Tabular is the infer operator, which can be used to extract
properties of an inferred distribution, such as its mean (in case of, say, a Gaussian)
or bias (in case of a Bernoulli distribution). These properties can then be used to
compute some pseudo-deterministic data dependent on the inference results.
For instance, in the above biased coin example, we might be interested in extract-
ing the actual bias of the coin, as a numeric value rather than a distribution. Since
the posterior distribution of the bias is a Dirichlet distribution, parametrized by the
"pseudocounts" of the numbers of heads and tails, the bias itself is the count of
heads divided by the sum of the counts. Using the infer operator, we can compute
it as follows:
table Coins
V
real!rnd[2]
static output
Dirichlet[2]([1.0, 1.0])
Flip
mod(2)!rnd
output
Discrete[2](V)
counts
real!qry[2]
static local
infer.Dirichlet[2].pseudocount(V)
Bias
real!qry
static output
counts[1]/(counts[1]+counts[0])
For instance, if we apply this model to a tiny database consisting of three coin
ﬂip outcomes, two of them being heads and one being tails, the inference algorithm
returns the following static quantities:
Coins
V
counts
Bias
Dirichlet(2, 3)
[2,3]
0.6
In the expression infer.Dirichlet[2].pseudocount(V), Dirichlet[2] denotes the type
of distribution from which we want to extract a property, pseudocount is the name
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

496
Gordon et al: Tabular: Probabilistic Inference from the Spreadsheet
of the parameter we want to extract (in Tabular, all distributions have named pa-
rameters) and V is the column in which the distribution is deﬁned.
All columns containing calculations dependent on the result of a query are in the
qry space. Columns in this space can only reference random variables via the infer
operator.
After adding the infer operator, we now have three diﬀerent kinds of columns in
Tabular: deterministic columns, whose values are known before inference; random
columns, whose distributions are to be inferred and may depend on deterministic
columns, and query columns, depending on inferred distributions. The values or
distributions of these columns (in all rows) must be computed in the right order,
for instance, a random column cannot depend on the result of a query. To make
sure that there are no erroneous dependencies in the program, the columns are split
into three spaces: det, rnd and qry; space annotations ensure that the constraints
on dependencies between columns are preserved.
14.2.4 Related Work
Probabilistic programming is becoming an increasingly popular approach to Bayes-
ian inference and many new languages following diﬀerent paradigms were created
recently. These include functional languages like Fun (Borgström et al., 2013),
Church (Goodman et al., 2008), Anglican (Wood et al., 2014), Venture (Mans-
inghka et al., 2014), WebPPL (Goodman and Stuhlmüller, 2014) and monad-bayes
(Ścibior et al., 2015), procedural languages like R2 (Nori et al., 2014), Infer.NET
(Minka et al., 2012) and Stan (Carpenter et al., 2017), logical languages such as
ProbLog (Van den Broeck et al., 2010) and even an implementation of the prob-
abilistic process algebra ProPPA (Georgoulas et al., 2014). Recently, a new class
of probabilistic languages marrying Bayesian modelling with deep neural networks
saw the light of day. These include Pyro (Bingham et al., 2018) and ProbTorch
(Siddharth et al., 2017).
Designing a language involves a trade-oﬀbetween expressiveness and perfor-
mance. In this respect, probabilistic languages can be roughly divided into two
groups: universal, Turing-complete languages such as R2 and Church and its de-
scendants, which allow creation of arbitrary probabilistic models (including non-
parametric models with unbounded numbers of random variables) but can only use
a limited range of sampling-based inference algorithms, and more restricted lan-
guages like Infer.NET and BUGS (Gilks et al., 1994), in which models correspond
to factor graphs and which can therefore use a wider class of inference algorithms,
including algorithms for factor graphs. Tabular belongs to the second class and uses
Expectation Propagation (Minka, 2001) as its default inference algorithm.
In terms of the paradigm and user interface, the two probabilistic programming
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

14.2 Introduction and Examples
497
packages most related to Tabular are BayesDB (Mansinghka et al., 2015) and Sce-
narios (Wu et al., 2016). BayesDB is a probabilistic package based on relational
database schemas. Its modelling language is a probabilistic extension of SQL,
which is signiﬁcantly diﬀerent from the approach taken by Tabular, where models
are written by directly annotating database schemas. Scenarios is a commercial
Excel plugin which allows deﬁning probabilistic models in a spreadsheet environ-
ment. The diﬀerence between Scenarios and Tabular is that the former is shallowly
embedded in Excel and deﬁnes probabilistic models via special Excel functions,
while Tabular is a standalone probabilistic language which simply uses Excel as a
convenient development environment. Because of its shallow embedding within a
dynamically typed formula language, Scenarios does not have a static type system.
14.2.5 Retrospective and Related Projects
Tabular was ﬁrst presented by Gordon et al. (2014b) as a language based on database
schemas, with a standalone implementation in the form of a GUI program interfac-
ing directly with a relational database. This initial version of the language did not
support functions - models were either simple expressions or predeﬁned conjugate
models from a small, ﬁxed library. Tabular had a non-dependent type system with-
out spaces, in which the type of a schema was a quintuple of nested record types,
whose components speciﬁed the types of hyperparameters, parameters, inputs and
latent and observed variables of the model deﬁned by the table. The semantics of
Tabular was deﬁned by means of translation to Fun (Borgström et al., 2013), a ﬁrst-
order, functional probabilistic programming language. Post-processing of inference
results had to be done outside Tabular.
A revised version of the language, described by Gordon et al. (2015), added
support for user-deﬁned functions and queries, as described earlier in this section.
The original type system was replaced by a simpler one, in which types themselves
have a similar form to Core Tabular tables. The new type system supports basic de-
pendent types and provides space annotations dividing columns into deterministic,
random and query columns. The semantics of the new version of Tabular consists
of a reduction system reducing schemas with functions and indexing to the Core
form and a semantics of Core Tabular models (omitted in this chapter, see the long
version of the aforementioned paper (Gordon et al., 2014a)), deﬁned directly in
terms of measure theory. Reduction to Core form is proven type-sound.
Further improvements to Tabular were presented in the doctoral dissertation of
Szymczak (2018), which introduced double column names to ﬁx a problem with
α-conversion and presented a more rigorous proof of type soundness of schema re-
duction. The dissertation also described a new, arguably more rigorous and elegant,
semantics of Core Tabular models.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

498
Gordon et al: Tabular: Probabilistic Inference from the Spreadsheet
Fabular, presented by Borgström et al. (2016), extends Tabular with hierarchical
linear regression formulas, extending the formula notation used by R packages such
as lmer. Such formulas allow for a concise representation of a wide class of models
and can be used in Tabular like any other model expressions.
Additionally in his Master's dissertation, Hutchison (2016) presented a generative
grammar allowing dynamic creation of Tabular programs, which could serve as a
basis for an automated model suggestion tool for Tabular. Hence, Tabular was used
as part of a study of the internet-based trade in specimens of endangered species of
plants (Vaglica et al., 2017).
14.3 Syntax of Tabular
Having introduced Tabular informally, we now present the formal syntax of the
language. Since programs and data are decoupled in Tabular, we need to deﬁne the
syntax for both Tabular databases and schemas.
14.3.1 Syntax of Databases
A Tabular database is a tuple DB = (δin, ρsz), consisting of two maps whose domain
is the set of names of tables in the database. The ﬁrst map, δin = [ti →τii∈1..n],
assigns to each table another map τi = [cj →aj j∈1..mi] mapping each column ci to
an attribute ai. An attribute aj = ℓj(Vj) consists of a level ℓj and a value Vj, which
can be a scalar s (that is, an integer, a real or a Boolean) or an array of values. The
level of an attribute can be either static, in which case the given column has only
one value accross all rows, or inst, which means that the column has one value
per row. In the latter case, Vj is actually an array of values, with one value per
row. Column names cj have the same form as external column names in schemas
(described below), except that they are not allowed to be empty.
The second map, ρsz = [ti →szi i∈1..n], simply stores the sizes of tables. The
value of each inst-level attribute of table ti must be an array of size szi.
Any value Vj in the database can be nullable, that is, any static attribute can have
an empty value (denoted ?) and in any inst attribute, any number of component
values can be empty. An empty value in a row of an output column means that the
distribution on the given row and column is to be inferred from other data by the
inference algorithm.
Databases, Tables, Attributes, and Values:
δin ::= [ti →τi i∈1..n]
table map
c,o ::= b1.(. . . ).bn
column name
ρsz ::= [ti →szi i∈1..n]
table size map
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

14.3 Syntax of Tabular
499
a ::= ℓ(V)
attribute value: V with level ℓ
V ::= ? | s | [V0,. . .,Vn−1]
nullable value
ℓ, pc ::= static | inst
level (static < inst)
τ ::= [cj →aj
j∈1..m]
table in database
For example, the input database for the TrueSkill example from Section 14.2.1 can
be written as follows using the formal syntax of databases:
[Players →[ID →inst([0,1,2])],
Matches →[ID →inst([0,1,2]),Player1 →inst([0,1,0]),
Player2 →inst([1,2,2]),Win1 →inst([0,0,?])]
where player names are omitted (they are insigniﬁcant for the model, and the formal
syntax of Tabular does not allow strings2) and true and false are represented by 1
and 0, respectively.
14.3.2 Syntax of Core Schemas
We begin by giving the syntax of Core schemas, which have a straightforward
interpretation as factor graphs. We ﬁrst deﬁne the basic building blocks of a Tabular
column.
Index Expressions, Spaces and Dependent Types of Tabular:
e ::=
index expression
x
variable
s
scalar constant
sizeof(t)
size of a table
S ::= bool | int | real
scalar type
spc ::= det | rnd | qry
space
T,U ::= (S ! spc) | (mod(e) ! spc) | T[e]
(attribute) type
c,o ::= _ | b1.(. . . ).bn
external column name
space(S ! spc) ≜spc
space(mod(e) ! spc) ≜spc
space(T[e]) ≜space(T)
An index expression is a constant, a variable (referencing a previous column or
an array index) or a sizeof expression, returning the size of the given table (that is,
sizeof(t) returns ρsz(t) if ρsz is the map of table sizes). A scalar type is one of bool,
int or real. These correspond to scalar types in conventional languages. A space
of a column, being part of its type, can be either det, rnd or qry, depending on
2 The implementation of Tabular does support strings and implicitly converts them to integers
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

500
Gordon et al: Tabular: Probabilistic Inference from the Spreadsheet
whether the column is deterministic, random or at query-level. An attribute type can
be either a scalar type S with a space, a dependent bounded integer type mod(e),
whose bound is deﬁned by the indexed expression e, with a space, or a recursively
deﬁned array type T[e], where T is an arbitrary type and e an index expression
deﬁning the size of the array. We use link(t) as a shorthand for mod(sizeof(t)). An
external column name, used to reference a column from another table or to access
a ﬁeld of a reduced function body, is either empty (denoted by _) or consists of a
sequence of one or more atomic names bi, separated by dots.
The space operator, used in the remainder of this chapter, returns the unique
space annotation nested within the given type.
As an example, consider the type of the Flip column in the Coins table in Sec-
tion 14.2.2, mod(2)!rnd. This is a type of random non-negative integer-valued
expressions bounded by 2 (that is, admitting only values 0 and 1). It is clear by def-
inition of space that space(mod(2)!rnd) = rnd. Moreover, the type of the V column
in CDiscrete in Section 14.2.2, real!rnd[N], is a type of arrays of size N (where
the variable N represents a deterministic non-negative integer), whose elements all
have type real!rnd (that is, are random real-valued expressions). The space of this
type is given by space(real!rnd[N]) = space(real!rnd) = rnd.
Expressions of Tabular:
E, F ::=
expression
e
index expression
g(E1,. . ., En)
deterministic primitive g
D[e1,. . .,em](F1,. . ., Fn)
random draw from distribution D
if E then F1 else F2
if-then-else
[E1,. . ., En] | E[F]
array literal, lookup
[for x < e →F]
for loop (scope of index x is F)
infer.D[e1,. . .,em].c(E)
parameter c of inferred marginal of E
E : t.c
dereference link E to instance of c
t.c
dereference static attribute c of t
This grammar of expressions, deﬁning models of the particular columns of the
table, is mostly standard for a ﬁrst-order probabilistic functional language. The ex-
pression D[e1,. . .,em](F1,. . ., Fn) represents a draw from a primitive distribution
D with hyperparameters determined by the index expressions e1,. . .,em and param-
eters deﬁned by the expressions F1,. . ., Fn. The operator infer.D[e1,. . .,em].c(E)
returns an approximate value of the parameter c of the posterior distribution of
expression E, expected to be of the form D[e1,. . .,em]. Access to columns deﬁned
in previous tables is provided via the operators t.c and E : t.c, referencing, respec-
tively, the static attribute with global name c of table t and the E-th row of inst-level
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

14.3 Syntax of Tabular
501
attribute with global name c of table t. We assume a ﬁxed (but extensible) collection
of distributions and deterministic primitives, such as addition, multiplication and
comparison.
Distribution signatures are parametrized by spc, to distinguish the use of cor-
responding distributions in random models and inside queries. The signatures of
distributions include the following:
Distributions: Dspc : [x1 : T1,. . ., xm : Tm](c1 : U1,. . .,cn : Un) →T
Bernoullispc : (bias : real!spc) →bool!rnd
Betaspc :: (a : real!spc,b : real!spc) →real!rnd
Discretespc : [N : int!det](probs : real!spc[N]) →mod(N)!rnd
Dirichletspc : [N : int!det](pseudocount : (real!spc)[N]) →(real!rnd)[N]
Gammaspc : (shape : real!spc,scale : real!spc) →real!rnd
Gaussianspc : (mean : real!spc,variance : real!spc) →real!rnd
VectorGaussianspc :
[N : int!det](mean : (real!spc)[N],covariance : real!spc[N][N]) →
(real!rnd[N])
The names of parameters of distributions are ﬁxed and not α-convertible, as they
can be referenced by name by the infer operator.
Random draws and the infer operator were already used in examples in Sec-
tions 14.2.2 and 14.2.3. For instance, the expression Dirichlet[2]([1.0,1.0]) in the
column V in table Coins is a random draw from the Dirichlet distribution with
the single hyperparameter N (denoting the length of the parameter array and the
output array) set to 2 and the single parameter pseudocount (of type (real!spc)[2])
set to the array [1.0,1.0]. Meanwhile, Gaussian([100.0,100.0]) in the Skill column
in table Players is the Gaussian distribution with parameters mean and variance
both set to 100. The list of hyperparameters is empty, because (as is clear from the
signature) the Gaussian distribution admits no hyperparameters.
The infer operator is used in column counts in table Coins in Section 14.2.3.
In the expression infer.Dirichlet[2].pseudocount(V), V is the name of the column
whose posterior distribution we are interested in, Dirichlet[2] is the expected type
and hyperparameter vector of that distribution (which we know because of con-
jugacy) and pseudocount is the name of the parameter of the Dirichlet posterior
distribution in column V whose expected value we want to obtain. In other words,
if the posterior distribution of the column V returned by the inference algorithm is
Dirichlet[2][c1,c2], the expression infer.Dirichlet[2].pseudocount(V) returns [c1,c2],
which is the value of the pseudocount parameter of Dirichlet[2][c1,c2].
The list of random primitives can be extended by adding multiple signatures
for diﬀerent parametrisations of the same distribution - for instance, the Gaussian
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

502
Gordon et al: Tabular: Probabilistic Inference from the Spreadsheet
distribution, parametrised above by its mean and variance, can also be parametrised
by mean and precision (inverse of variance). This parametrisation is convenient
when deﬁning the conjugate Gaussian model.
Distributions: Dspc : [x1 : T1,. . ., xm : Tm](c1 : U1,. . .,cn : Un) →T
GaussianFromMeanAndPrecisionspc :
(mean : real!spc,prec : real!spc) →real!rnd
In the rest of this chapter, we will abbreviate GaussianFromMeanAndPrecision
as GaussianMP.
The syntax of Core Tabular schemas is as follows:
Core Tabular Schemas:
S ::= [] | (t1 = T1) :: S
(database) schema
T ::= [] | (c ▷x : T ℓviz M) :: T
table (or function) (scope of x is T)
viz ::= input | local | output
visibility
M, N ::= ϵ | E
model expression
A Tabular schema S consists of any number of named tables T, each of which is a
sequence of columns. Every column in Core Tabular has a ﬁeld name c (also called
a global or external name), an internal name x (also called a local name), a type T
(as deﬁned earlier), a level (static or inst), a visibility (input, output or local) and
a model expression, which is empty for input columns and is a simple expression
E for other types of columns. The local visibility is just like output, except that
local columns are not exported to the type of the schema (as deﬁned by the type
system, described in Section 14.5), and so can be considered local variables. The
default level of a column is inst, and we usually omit the level if it is not static.
Tables and schemas can also be represented in the formal syntax using list
notation. We deﬁne [(c1 ▷x1 : T1 ℓ1 viz1 M1),. . .,(cn ▷xn : Tn ℓn vizn Mn)] and
[t1 = T1,. . .,tn = Tn] to be syntactic sugar for (c1 ▷x1 : T1 ℓ1 viz1 M1) :: . . . ::
(cn ▷xn : Tn ℓn vizn Mn) :: [] and (t1 = T1) :: . . . :: (tn = Tn) :: [], respectively.
To illustrate the formal syntax of Tabular, let us consider again the simple Coins
table, which was presented in the grid-based form at the beginning of Section 14.2.2.
If we specify the global and local names explicitly, this table has the following form:
table Coins
V ▷V
real!rnd[2]
static output
Dirichlet[2]([1.0, 1.0])
Flip ▷Flip
mod(2)!rnd
output
Discrete[2](V)
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

14.3 Syntax of Tabular
503
In the formal Tabular syntax, this table would be written as follows:
[(V ▷V : real!rnd[2] static output Dirichlet[2]([1.0,1.0]),
(Flip ▷Flip : mod(2)!rnd inst output Discrete[2](V))]
The schema consisting of just this single table is:
[Coins = [(V ▷V : real!rnd[2] static output Dirichlet[2]([1.0,1.0]),
(Flip ▷Flip : mod(2)!rnd inst output Discrete[2](V))]]
In the rest of this chapter, col denotes a single column (c ▷x : T ℓviz M) of a
table, where its components are unimportant.
Motivation for double column names In the syntax of the new version of Tab-
ular presented in the paper which was the starting point for this work (Gordon
et al., 2015), each column only has one name. This causes a problem with alpha-
conversion: if a column is visible outside the given table, then its name cannot be
alpha-convertible, since renaming the column would break references to it from
outside the table. On the other hand, alpha-conversion is necessary for the sub-
stitution and function reduction to work properly. To mitigate this issue, we now
follow the standard approach used in module systems, ﬁrst presented by Harper
and Lillibridge (1994): we give each column two names, a local, alpha-convertible
name, which is only in scope of a given table, and a global, ﬁxed ﬁeld name, which
can only be used outside the table (or function). In practice, we can assume that the
internal and external name are initially the same.
14.3.3 Syntax of Schemas with Functions and Indexing
Tabular supports two additional kinds of model expressions: function applications
and indexed models.
A function is represented as a Core table whose last column is identiﬁed by the
name ret and has visibility output. A function T can be applied to a list of named
arguments R, whose types and number must match the types and number of input
columns in the function table. Note that function arguments are identiﬁed by the
ﬁeld name of the corresponding column. The reduction algorithm (presented in
Section 14.4) reduces a column containing a function application to the body of
the function with all input columns removed and the input variables in subsequent
model expressions replaced by the corresponding arguments.
The output column of a function can be referenced in the "caller" table simply
by the (local) name of the "caller" column. Other columns can be referenced by
means of a new operator e.c, where e is expected to be the local name x of the
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

504
Gordon et al: Tabular: Probabilistic Inference from the Spreadsheet
"caller" column and c is the ﬁeld name of the referenced column of the function
table (we need to use the ﬁeld name, because the local name is only in scope inside
the function).
An indexed model M[eindex < esize] represents the model M with all rnd static
attributes turned into arrays of size esize and references to them replaced by array
lookups extracting the element at index eindex.
Full Tabular Schemas:
E ::= · · · | e.c
expression
M, N ::= · · · | M[eindex < esize] | T R
model expression
R ::= [] | (c = e) :: R
function arguments
Function arguments can also be represented using the standard list notation as
R = (c1 = e1,. . .,cn = en). The function ﬁeld reference is only deﬁned to be e.c
rather than x.c in order for substitution to be well-deﬁned. The indexing operator is
only meaningful if it is applied (possibly multiple times) to a function application,
since it has no eﬀect on basic expressions.
In the Coins example in Section 14.2.2, a predeﬁned function (from the standard
library) was referenced in the main table by its name. Indeed, in the implementation,
functions are always deﬁned outside of the main schema and are called by identiﬁers.
In the formal syntax, however, functions are inlined. For instance, to represent the
function call CDiscrete(N = 2,R = 1.0) formally, we need to substitute CDiscrete
with its body. The resulting function application looks as follows:
[(N ▷N : int!det static input ϵ),
(R ▷R : real!det static input ϵ),
(V ▷V : real!rnd[N] static input Dirichlet[N]([for i < N →R)),
(ret ▷ret : mod(N)!rnd[N] static input Dirichlet[N]([for i < N →R))]
(N = 2,R = 1)
Free Variables and Core Columns
The free variables fv(T) of a table T are all local variables used in column types
and model expressions which are not bound by column declarations or for-loops.
Formally, the operator fv(T) can be deﬁned inductively in the usual way. Unbound
occurrences of ﬁeld names are not considered free variables, as they are a separate
syntactic category.
The predicate Core states that the given schema, table or column is in Core form,
as deﬁned earlier.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

14.4 Reduction to Core Tabular
505
14.4 Reduction to Core Tabular
We now deﬁne the reduction relation which reduces arbitrary well-typed Tabular
schemas (with function applications and indexing) to a Core form. Before discussing
the technical details of reduction, we present an example which will guide our
development. This time we make the distinction between local and ﬁeld names
explicit, to illustrate how substitution and renaming work.
Consider the following function implementing the widely used Conjugate Gaus-
sian model, whose output is drawn from a Gaussian with mean modelled by another
Gaussian and precision (inverse of variance) drawn from a Gamma distribution:
fun CG
M ▷M
real!det
static input
P ▷P
real!det
static input
Mean ▷Mean
real!rnd
static output
GaussianMP(M,P)
Prec ▷Prec
real!rnd
static output
Gamma(1.0, 1.0)
ret ▷ret
real!rnd
output
GaussianMP(Mean, Prec)
Suppose we want to use this function to model eruptions of the Old Faithful
geyser in the Yellowstone National Park. The eruptions of this geyser, known for its
regularity, can be split into two clusters based on their duration and time elapsed
since the previous eruption: some eruptions are shorter and occur more frequently,
others are longer but one has to wait longer to see them. Given a database consisting
of eruption durations and waiting times (not split into clusters), we want to infer the
means and precisions of the distributions of durations and waiting times in each of
the two clusters. If we simply modelled the duration and waiting time with a call
to CG, we would obtain a single distribution for the mean and precision of each
quantity, but we can turn each Mean and Prec column into an array of size 2 by
combining the function calls with indexing.
table Faithful
cluster ▷cluster
mod(2)!rnd
output
(CDiscrete(N=2)
duration ▷duration
real!rnd
output
CG(M=0.0, P=1.0)[cluster<2]
time ▷time
real!rnd
output
CG(M=60.0, P=1.0)[cluster<2]
14.4.1 Reducing Function Applications
Before we introduce the reduction of indexed models, let us consider a simpliﬁed
version of the above model, with just function applications:
table Faithful
duration ▷duration
real!rnd
output
CG(M=0.0, P=1.0)
time ▷time
real!rnd
output
CG(M=60.0, P=1.0)
To reduce the duration and time columns to Core form, we must expand the
applications. This is done by just replacing the given column with the body of the
function with the arguments substituted for the input variables. The ﬁeld name of
the last column, always expected to be the keyword ret, is replaced by the name of
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

506
Gordon et al: Tabular: Probabilistic Inference from the Spreadsheet
the "caller" column, and the ﬁeld names of previous columns are preﬁxed with the
ﬁeld name of the "caller" column. This is done to ensure that ﬁeld names in the
reduced table are unique, even if the same function is used several times.
Meanwhile, local names can be refreshed (by alpha-conversion), to make sure
they do not clash with variables which are free in the remainder of the "caller"
table or the remaining arguments. References to the columns of the function in the
"caller" table (of the form x.c) are then replaced with the refreshed local column
names.
In the end, the above table reduces to the following form:
table Faithful
duration.Mean ▷Mean
real!rnd
static output
GaussianMP(0.0,1.0)
duration.Prec ▷Prec
real!rnd
static output
Gamma(1.0,1.0)
duration ▷duration
real!rnd
output
GaussianMP(Mean,Prec)
time.Mean ▷Mean
real!rnd
static output
GaussianMP(60.0,1.0)
time.Prec ▷Prec
real!rnd
static output
Gamma(1.0,1.0)
time ▷time
real!rnd
output
GaussianMP(Mean,Prec)
Just like in ordinary languages, variable deﬁnitions can be overshadowed by
more closely scoped binders. The variable Mean in the duration column refers to
the deﬁnition in the column with external name duration.mean, and Mean in column
time refers to the deﬁnition in the column with ﬁeld name time.Mean, and similarly
with Prec.
Binders and Capture-avoiding Substitutions: T {e/x}, T⟨y/x.c⟩
In order to deﬁne the reduction rules, we ﬁrst need two capture-avoiding substitution
operators on tables: T {e/x}, which replaces free occurrences of the variable x
with the index expression e, and T⟨y/x.c⟩, which replaces function ﬁeld references
x.c with a single local variable y. These substitutions can be formally deﬁned
inductively, as usual. Here we omit these formal deﬁnitions (which can be found
in Szymczak, 2018) and show by example how the second, slightly less standard,
operator works.
Let us consider again the simpliﬁed version of the Old Faithful model from the
beginning of this section, but this time using diﬀerent local variable and ﬁeld names,
to emphasise the fact that they are not the same thing:
table Faithful
duration ▷x
real!rnd
output
CG(M=0.0, P=1.0)
time ▷x'
real!rnd
output
CG(M=60.0, P=1.0)
Suppose we want to calculate the mean of the posterior distribution of the mean
of duration (using the infer operator, described in 14.2.3). To this end, we need
to add an additional column to the above table, which references the column with
ﬁeld name Mean in the reduced application of CG in the column duration. As ﬁeld
names are not binders, we need to use the local name x of the column duration. On
the other hand, as the local names of the columns of CG are not visible outside the
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

14.4 Reduction to Core Tabular
507
function CG itself, we need to access the column Mean of CG by using its ﬁeld
name. Hence, the reference has the form x.Mean, and the full table is the following:
table Faithful
duration ▷x
real!rnd
output
CG(M=0.0, P=1.0)
time ▷x'
real!rnd
output
CG(M=60.0, P=1.0)
duration_mean ▷z
real!qry
output
infer.Gaussian.mean(x.Mean)
When the function application in column duration is reduced (as described later),
and the column Mean of the application of CG in duration is turned into a column
with local name y in the main table, we need to substitute references to the (no
longer existing) parameter Mean of the model in column x with the variable y in
the rest of the table by using the operator ⟨y/x.c⟩. Applying this substitution to the
last two columns of the above table yields:
time ▷x'
real!rnd
output
CG(M=60.0, P=1.0)
duration_mean ▷z
real!qry
output
infer.Gaussian.mean(y)
One might be concerned that the substitution ⟨y/x.c⟩would not work correctly
if the function application pointed to by x was assigned to another variable z, for
example in a part of a table of the form:
ﬁeld1 ▷z
real!rnd
output
x
ﬁeld2 ▷z'
real!rnd
output
z.c
However, it is impossible to assign a function application to another variable
in Tabular, as it is impossible to reference a function application as a whole. If
a variable x referencing a function application is used on its own (not in a ﬁeld
reference x.c), it always denotes the last column of the reduced application, not the
application itself. The expression z.c in the above table is not well-typed, as z does
not refer to a function.
Reduction Relation
The reduction is deﬁned by means of the small-step reduction relation, reducing
one column of the function table at a time, being the least relation closed under the
set of rules presented below.
Reduction to Core Tabular:
T →T′
table reduction
The judgment T →T′ states that table T reduces to T′ in one step. In the
reduction rules, we normally use o for the (ﬁeld) name of the "caller" column and
c for the name of a column in the function table, to disambiguate between the two.
The reduction system is deterministic and the assumptions guarantee that at most
one rule applies to each table (the same applies to the reduction rules for indexed
models and schemas presented in the following sections).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

508
Gordon et al: Tabular: Probabilistic Inference from the Spreadsheet
Reduction Rules for Tables: T →T′
(Red Appl Output) (for Core(T))
y  fv(T′, R) ∪{x}
c  ret
(o ▷x : T ℓviz ((c ▷y : T ′ ℓ′ output E) :: T) R) :: T′ →
(o.c ▷y : T ′ (ℓ∧ℓ′) viz E) :: (o ▷x : T ℓviz T R) :: T′⟨y/x.c⟩
(Red Appl Local) (for Core(T))
y  fv(T′, R) ∪{x}
(o ▷x : T ℓviz ((c ▷y : T ′ ℓ′ local E) :: T) R) :: T′ →
(_ ▷y : T ′ (ℓ∧ℓ′) local E) :: (o ▷x : T ℓviz T R) :: T′
(Red Appl Input) (for Core(T))
(o ▷x : T ℓviz (c ▷y : T ′ ℓ′ input ϵ) :: T (c = e) :: R) :: T′ →
(o ▷x : T ℓviz T
e/y

R) :: T′
(Red Appl Ret)
(o ▷x : T ℓviz [(ret ▷y : T ′ ℓ′ output E)] []) :: T′ →
(o ▷x : T ′ (ℓ∧ℓ′) viz E) :: T′
(Red Table Right)
T →T′
Core(col)
col :: T →col :: T′
The (Red Appl Output) rule (in which viz is expected to be local or output)
reduces a single output column of a function by appending it to the main table,
preceded by the "caller" column with the unevaluated part of the application T R
(which will be reduced in the following steps). If the function was called from
a static column, the level of the reduced function column is changed to static.
Similarly, if the function was called from a local column, the visibility of the
reduced column is dropped to local. Because the reduced column is appended to
the main table, it has to be referenced using its internal name (recall that ﬁeld names
are not binders). Hence, all references to it, of the form x.c, are replaced with its
internal name y. Meanwhile, the global name of the reduced column is preﬁxed by
the ﬁeld name of the "caller" column.
To avoid capturing free variables which are not bound by the reduced column in
the original top-level table, y is required not to be free in T′ and R. This is always
possible, because tables are identiﬁed up to alpha-conversion of internal column
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

14.4 Reduction to Core Tabular
509
names, so y can be refreshed if needed (formally, the reduction relation is a relation
on alpha-equivalence classes of syntactic terms).
(Red Appl Local) is similar, except that we do not need to substitute y for x.c in
T, because the given column is not visible outside the function. The external name
of a reduced column can be empty, because local columns are not exported.
The (Red Appl Input) rule removes an input column and replaces all references
to it in the rest of the function with the corresponding argument.
The last column of a function is reduced by (Red Appl Ret), which simply
replaces the application of the single ret column to the empty argument list with
the expression from the said column. The level is also changed to static if the ret
column was static. The internal and ﬁeld names of the top-level column are left
unchanged, and the names of the last column of the function are discarded, because
the last column of a function is always referenced by the name of the "caller" table.
(Red Table Right) is a congruence rule, allowing us to move to the next column
of the main table if the current ﬁrst column is already in Core form.
Example of Function Reduction To see how the reduction rules work, let us
consider again the simpliﬁed version of the Old Faithful example with the additional
duration_mean column:
table Faithful
duration ▷x
real!rnd
output
CG(M=0.0, P=1.0)
time ▷x'
real!rnd
output
CG(M=60.0, P=1.0)
duration_mean ▷z
real!qry
output
infer.Gaussian.mean(x.Mean)
The reduction rules reduce the duration column ﬁrst. In the beginning, the rule
(Red Appl Input) is applied twice, and reduces the columns M and P of the
function CG in duration, replacing references to M and P in the body of CG with
corresponding arguments. The reduced table has the following form:
table Faithful
duration ▷x
real!rnd
output
CG'()
time ▷x'
real!rnd
output
CG(M=60.0, P=1.0)
duration_mean ▷z
real!qry
output
infer.Gaussian.mean(x.Mean)
where CG' is the following partially evaluated function:
fun CG'
Mean ▷Mean
real!rnd
static output
GaussianMP(0.0,1.0)
Prec ▷Prec
real!rnd
static output
Gamma(1.0, 1.0)
ret ▷ret
real!rnd
output
GaussianMP(Mean, Prec)
The next rule to be applied is (Red Appl Output), which reduces the ﬁrst column
Mean of CG' and replaces references to it, of the form x.Mean, with the local name
of the reduced column (which we can assume is still Mean, as the name does not
conﬂict with any other variable), in the rest of the top-level table by using the ﬁeld
substitution operator. The reduced table has the following form:
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

510
Gordon et al: Tabular: Probabilistic Inference from the Spreadsheet
table Faithful
duration.Mean ▷Mean
real!rnd
static output
GaussianMP(0.0,1.0)
duration ▷x
real!rnd
output
CG''()
time ▷x'
real!rnd
output
CG(M=60.0, P=1.0)
duration_mean ▷z
real!qry
output
infer.Gaussian.mean(Mean)
where CG'' is:
fun CG"
Prec ▷Prec
real!rnd
static output
Gamma(1.0, 1.0)
ret ▷ret
real!rnd
output
GaussianMP(Mean, Prec)
Note that Mean in CG'' refers to the column deﬁned outside the function (which
is in scope of CG'', as functions are assumed to be deﬁned inline, even though the
implementation uses named functions).
The remaining columns of function applications are reduced similarly, except
that the local name Mean in the second application of CG has to be changed by
α-conversion, as Name is free in the last column of the top-level table.
14.4.2 Reducing Indexed Models
In order to reduce a column with an indexed function application, we need to
transform the function into an indexed form before applying it to the arguments. In
the case of the duration column of the original table of the running example, this
transformation needs to turn the expressions in all static rnd columns into arrays
of size 2, with each element modelled by the original expression, and replace all
references to these columns in the rest of the table with array accesses, returning
the component at index cluster.
For instance, applying indexing [cluster < 2] to the function CG yields the
following indexed function
M ▷M
real!det
static input
P ▷P
real!det
static input
Mean ▷Mean
real!rnd
static output
[for _ < 2 →GaussianMP(M,P)]
Prec ▷Prec
real!rnd
static output
[for _ < 2 →Gamma(1.0, 1.0)]
ret ▷ret
real!rnd
output
GaussianMP(Mean[cluster], Prec[cluster])
parametrised on the free variable cluster deﬁned outside the function.
Reducing the application of this function to (M = 0.0,P = 1.0) in the duration
column gives the following table:
duration.Mean ▷Mean
real!rnd[2]
static output
[for _ < 2 →GaussianMP(0.0,1.0)]
duration.Prec ▷Prec
real!rnd[2]
static output
[for _ < 2 →Gamma(1.0,1.0)]
duration ▷duration
real!rnd
output
GaussianMP (Mean[cluster], Prec[cluster)
More generally, table indexing is formalised via the operator indexA(T,e1,e2),
where T is the table (reduced application) to index, e1 and e2 are, respectively, the
index variable and the number of clusters and A is the (initially empty) set of static
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

14.4 Reduction to Core Tabular
511
rnd columns, which needs to be available to convert variables into array accesses
correctly.
We disallow indexing tables with qry columns, since substituting a reference
to a query column with an array access with a random index would break the
information ﬂow constraints, so indexed query columns would not have a well-
deﬁned semantics. Below, the predicate NoQry states that a given Core table or
model has no qry-level columns. The requirement that tables with qry columns
cannot be indexed is enforced by the type system, presented in Section 14.5.
The indexing operator makes use of a new capture-avoiding substitution operator:
E[A,e] denotes E with every variable x in the set of variables A (supposed to
contain only static rnd variables) replaced with the array access x[e], as long as the
syntax allows it. For instance, Gaussian(x, y)[{x, y},i] is Gaussian(x[i], y[i]), but
(Discrete[z](y))[{z, y},i] is Discrete[z](y[i]), and not Discrete[z[i]](y[i]), because
hyperparameters of distributions are index expressions, so they cannot be array
accesses. However, we do not need to worry about variables which cannot be
replaced with array accesses, such as z above, as (in non-qry columns of functions)
they are always expected to be deterministic or occur in function ﬁeld references
of the form x.c, while indexing is only supposed to modify random variables
referencing Core columns. We elide the formal deﬁnition of the operator, which
can be found in Szymczak (2018).
The indexing operator is deﬁned inductively below.
Table Indexing: indexA(T,e1,e2), where NoQry(T)
indexA([],e1,e2) ≜[]
indexA((c ▷x : T static viz E) :: T,e1,e2) ≜
(c ▷x : T[e2] static viz [for i < e2 →E[A,i]]) :: indexA∪{x}(T,e1,e2)
if viz  input and rnd(T) and x  fv(e1) ∪fv(e2) ∪A and i  fv(E)
indexA((c ▷x : T ℓinput ϵ) :: T,e1,e2) ≜
(c ▷x : T ℓinput ϵ) :: indexA(T,e1,e2) if x  fv(e1) ∪fv(e2) ∪A
indexA((c ▷x : T ℓviz E) :: T,e1,e2) ≜
(c ▷x : T ℓviz E[A,e1]) :: indexA(T,e1,e2)
otherwise if x  fv(e1) ∪fv(e2) ∪A.
Unsurprisingly, indexing an empty table returns an empty table. In any static
rnd column, the model expression E is turned into an array of e2 elements, each
modelled by E. Since E may contain references to previous static rnd columns
of the original table, which have been turned into arrays, we must replace these
references (by means of the E[A,i] operator) with array accesses, returning values
at indices corresponding to the positions of the expressions. Before index is applied
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

512
Gordon et al: Tabular: Probabilistic Inference from the Spreadsheet
recursively to the rest of the table, the variable x is added to the set A of rnd static
variables, so that each reference to x in subsequent rnd static and rnd inst columns
would be replaced with an appropriate array access.
Input columns are left unchanged by index, and in inst-level random columns,
references to previous static rnd columns are replaced by array accesses returning
the e1 -th component. Note that E[A,i] leaves expressions in deterministic columns
unchanged, because all variables in the set A are expected to be random.
With the index operator in place, we can deﬁne the reduction relation reducing
indexed models.
Reduction to Core Tabular:
M →M′
model reduction
The above judgment, which states that indexed model M reduces to M′ in one
step (that is, that M′ is M with one level of indexing eliminated), is derived by the
following rules:
Reduction Rules for Models: M →M′
(Red Index)
Core(T)
NoQry(T)
(T R)[eindex < esize] →(index∅(T,eindex,esize)) R
(Red Index Inner)
M →M′
M[eindex < esize] →M′[eindex < esize]
(Red Index Expr)
E[eindex < esize] →E
Reduction Rules for Tables: T →T′
(Red Model)
M →M′
(c ▷x : T ℓviz M) :: T →(c ▷x : T ℓviz M′) :: T
The (Red Index) rule applies the index operator to the function table in an
application, returning a pure function application which will be reduced at table
level. The (Red Index Inner) rule simply allows reducing a model nested in an
indexed expression, in case this model is an indexed model itself. Since simple
expressions have no static parameters of their own, indexing a simple expression
has no eﬀect, so the (Red Index Expr) rule just discards the indexing. The (Red
Model) rule allows reducing a model (other than a function application) in a column
of a table.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

14.4 Reduction to Core Tabular
513
14.4.3 Reducing Schemas
Finally, we can deﬁne the reduction relation for schemas:
Reduction to Core Tabular:
S →S′
schema reduction
The judgment S →S′ states that the schema S reduces to S′ in one step - that
is, S′ is S with one table reduced to Core form. This judgment is derived by the
following two rules:
Reduction Rules for Schemas: S →S′
(Red Schema Left)
T →T′
(t = T) :: S →(t = T′) :: S
(Red Schema Right)
S →S′
Core(T)
(t = T) :: S →(t = T) :: S′
The (Red Schema Left) rule reduces the ﬁrst table, while (Red Schema Right)
proceeds to the following table if the ﬁrst one has already been fully reduced.
Putting all these rules together, we can ﬁnally reduce the Old Faithful model to
Core form:
table faithful
cluster.V ▷V
real!rnd[2]
static output
Dirichlet[2]([for i < 2 →1.0])
cluster ▷cluster
mod(2)!rnd
output
Discrete[2](V)
duration.Mean ▷Mean
real!rnd[2]
static output
[for i < 2 →GaussianMP(0.0, 1.0)]
duration.Prec ▷Prec
real!rnd[2]
static output
[for i < 2 →Gamma(1.0, 1.0)]
duration ▷duration
real!rnd
output
GaussianMP(Mean[cluster], Prec[cluster])
time.Mean ▷Mean
real!rnd[2]
static output
[for i < 2 →GaussianMP(60.0, 1.0)]
time.Prec ▷Prec
real!rnd[2]
static output
[for i < 2 →Gamma(1.0, 1.0)]
time ▷time
real!rnd
output
GaussianMP(Mean[cluster], Prec[cluster])
As noted before, a Tabular model in Core form has a straightforward interpretation
as a factor graph. Assuming that the table faithful has n rows, the reduced Old Faithful
model corresponds to the (directed) factor graph shown in Figure 14.1, in which we
use abbreviated variable names (for example dM for duration.Mean) to make the
presentation cleaner:
The boxes with solid edges are plates, which create multiple copies of given
variables and factors - for instance, we have n values of dMi, one for each i, each
drawn from the same distribution GaussianMP(0.0,1.0). The boxes with dotted
lines are gates (Minka and Winn, 2009), which select a factor based on the value of
a categorical variable (cj in this case). While the graph above is directed to make the
dependency structure explicit, the arrow heads can be removed to obtain a standard,
undirected factor graph.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

514
Gordon et al: Tabular: Probabilistic Inference from the Spreadsheet
dj
GaussianMP(dMcj , dPcj )
dMi
dPi
GaussianMP(0.0, 1.0)
Gamma(1.0, 1.0)
tj
GaussianMP(tMcj , tPcj )
tMi
tPi
GaussianMP(60.0, 1.0)
Gamma(1.0, 1.0)
cj
cV
Discrete[2](cV)
Dirichlet[2]([1.0, 1.0])
i ∈0, 1
j ∈0..n −1
Figure 14.1 Reduced Old Faithful model as a factor graph
Once a schema is reduced to Core form, the Tabular backend can perform in-
ference on it using Expectation Propagation or another algorithm provided by
Infer.NET. Figure 14.2 presents the results of inference shown as in the Excel in-
terface and visualised by Excel plots. A new column assignment has been added to
the model - this column uses the infer operator to assign each eruption to the more
likely cluster.
14.5 Type System
Type systems are useful in probabilistic languages because they specify the domain
of each random variable and ensure that each random draw is used where a value
in the given domain is expected. Thus, types guide the modelling process and help
prevent incorrect dependencies between variables.
As seen in examples in the previous sections, Tabular makes use of basic depen-
dent types and determinacy and binding time annotations. All the type constraints
in Tabular are checked statically, which allows some modelling errors to be caught
before the inference procedure is started, thus saving the user time on debugging.
Tabular's type system ensures that the role of each variable in the program is
immediately clear and checks that each random variable is deﬁned on the right
domain. Dependent types additionally allow checking array sizes and bounds on
categorical variables in functions, even though these may depend on function argu-
ments. This helps to check that functions are indeed correctly deﬁned and make the
right use of their arguments. Moreover, because of space annotations, the compiler
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

14.5 Type System
515
Figure 14.2 Old Faithful inference results in Excel
can split a Tabular program into the probabilistic model and the post-processing
code, and process them at the right time in the pipeline - the user is not required
to deﬁne rnd and qry variables in separate blocks. These annotations also disallow
models which the default inference engine cannot handle, such as mixture models
with an random number of components.
In this section, we deﬁne the Tabular type system formally and present the type
soundness property of the reduction system shown in Section 14.4 (whose proof
can be found in Szymczak (2018)).
In addition to the column types introduced in Section 14.3, we also give types to
model expressions, tables and schemas. These types deﬁne the spaces of input and
output variables of the probabilistic models deﬁned by programs or their parts.
Limitations of the Type System The type system does not enforce conjugacy,
which is required by the default inference engine of Tabular, because we wanted
to keep the developments in this chapter independent of a particular inference
algorithm. Moreover, well-typedness of a Tabular program does not guarantee that
Expectation Propagation inference will always succeed. Lack of conjugacy and
other algorithm-speciﬁc issues may result in the inference algorithm failing at
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

516
Gordon et al: Tabular: Probabilistic Inference from the Spreadsheet
runtime, in which case an error message from the inference backend is shown to
the user in the implementation.
14.5.1 Syntax of Tabular Types
To each model and table, we assign a type Q (hereafter called Q-type), which
consists of a list of column names (local and ﬁeld names), column types, levels and
visibilities (which cannot be local, because local attributes of tables and functions
are not exported to types). A single component of type Q is just a table column
without a model expression. The Q-types used here are akin to right-associating
dependent record types (Pollack, 2002), except that in their inhabitants, the values
of ﬁelds may depend on previous ﬁelds, like in translucent sums (Harper and
Lillibridge, 1994).
The type Sty of a schema is just a list of table identiﬁers paired with corresponding
table types. These types are notably simpler than the nested record types used in
the original formulation of Tabular (Gordon et al., 2014b).
We deﬁne three predicates on Q-types: fun(Q), which means that the given type
Q is a valid function type, whose last column is marked as the return column,
table(Q), which states that Q has no deterministic static columns and can type a
top-level (i.e. non-function) table, and red(Q), which states that Q is the type of a
reduced function application, having no input columns.
Table and Schema Types:
Q ::= [] | (c ▷x : T ℓviz) :: Q
table type (scope of x is Q, viz  local)
Sty ::= (t : Q) :: Sty
schema type
fun(Q) iﬀvizn = output and cn = ret
table(Q) iﬀfor each i ∈1..n, ℓi = static ⇒rnd(Ti) ∨qry(Ti)
red(Q) iﬀtable(Q) and for each i ∈1..n, vizi = output
The predicate table(Q) ensures that no top-level columns can be referenced in
subsequent column types (because only static det columns can appear in types),
which guarantees that all column types in Core tables (including reduced tables) are
closed, except possibly for table size references. This property is necessary because
columns can be referenced from other tables, and any variables in a type would be
free outside the table in which the corresponding column was deﬁned.
We deﬁne fv(Q) to be the set of local variables in column types in Q which are
not bound by column deﬁnitions.
Schemas, tables, models and expressions are all typechecked in a given typing
environment Γ, which is an ordinary typing environment except that it has three
kinds of entries (for variables denoting previous Core columns, for previous tables
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

14.5 Type System
517
and for reduced function applications) and the entries for Core columns include
level annotations as well as column types (recall that column types themselves
contain binding type annotations).
Tabular Typing Environments:
Γ ::= ∅| (Γ, x :ℓT) | (Γ,t : Q) | (Γ, x : Q)
environment
The domain dom(Γ) of an environment Γ is the set of all variables and table
names in the environment:
Below is the list of all judgments of the Tabular type system, which will be
described in the remainder of this section.
Judgments of the Tabular Type System:
Γ ⊢⋄
environment Γ is well-formed
Γ ⊢T
in Γ, type T is well-formed
Γ ⊢pc e : T
in Γ at level pc, index expression e has type T
Γ ⊢Q
in Γ, table type Q is well-formed
Γ ⊢Sty
in Γ, schema type Sty is well-formed
Γ ⊢T <: U
in Γ, T is a subtype of U
Γ ⊢pc E : T
in Γ at level pc, expression E has type T
Γ ⊢pc R : Q →Q′ R sends function type Q to model type Q′
Γ ⊢pc M : Q
model expression M has model type Q
Γ ⊢pc T : Q
table T has type Q
Γ ⊢S : Sty
schema S has type Sty
Tabular programs and types are identiﬁed up to α-conversion of internal column
names and variables bound by for-loops.
14.5.2 Type Well-formedness and Expression Types
We begin by discussing the well-formedness rules for environments and column and
table types and typing rules for index expressions (which are mutually dependent).
We do not present all the rules in detail to save space.
The judgment Γ ⊢⋄holds if the variable names in Γ are unique and all (column
and table) types in Γ are well-formed. The column type well-formedness judgment
Γ ⊢T requires all index expressions in T to be deterministic integers well-formed
in Γ. For instance, the well-formedness rule for T = U[e] has the following form:
(Type Array)
Γ ⊢U
Γ ⊢static e : int ! det
Γ ⊢U[e]
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

518
Gordon et al: Tabular: Probabilistic Inference from the Spreadsheet
The judgment Γ ⊢pc e : T states that the index expression e has type T in Γ and
only depends on data at level up to pc. Recall that static < inst. Typing rules for
constants and table sizes are trivial, but if e is a variable, then it can correspond to
either a variable in Γ or the last column of a Q-type in Γ:
Selected Rules for Index Expressions:
(Index Var) (for ℓ≤pc)
Γ ⊢⋄
Γ = Γ1, x :ℓT,Γ2
Γ ⊢pc x : T
(FunRefRet)
Γ ⊢⋄
Γ = Γ′, x : Q,Γ′′
Q = Q′@[(ret ▷y : T ℓoutput)]
ℓ≤pc
Γ ⊢pc x : T
Next, we deﬁne well-formedness rules for Q-types and schema types:
Formation Rules for Table and Schema Types: Γ ⊢Q
Γ ⊢Sty
(Table Type [])
Γ ⊢⋄
Γ ⊢[]
(Table Type Input)
Γ ⊢T
Γ, x :ℓT ⊢Q
c  names(Q)
Γ ⊢(c ▷x : T ℓinput) :: Q
(Table Type Output)
Γ ⊢T
Γ, x :ℓT ⊢Q
c  names(Q)
Γ ⊢(c ▷x : T ℓoutput) :: Q
(Schema Type [])
Γ ⊢⋄
Γ ⊢[]
(Schema Type Table)
Γ ⊢Q
table(Q)
Γ,t : Q ⊢Sty
Γ ⊢(t : Q) :: Sty
These rules simply require all column types in a Q-type and all table types in a
schema type to be well-formed (in the environments formed by preceding columns
and tables), all local identiﬁers to be unique and all ﬁeld names to be unique within
the Q-types in which they are deﬁned. Tables in a schema must also satisfy the
table predicate.
Every expression in Tabular belongs to one of the three spaces det, rnd and qry,
determined by the expression's type. We want to allow information ﬂow from det
to rnd space, because it is harmless to use a deterministic value where a value
potentially "tainted" by randomness is expected. Similarly, we want to allow ﬂow
from det to qry. However, since we assume qry columns to be deterministic given
the inferred posterior distributions of rnd columns, we do not allow qry columns to
reference rnd columns directly - information ﬂow from rnd to qry is only possible
via the infer operator, which references posterior distributions of random variables,
rather than random variables themselves.
We also disallow ﬂows from qry to det and rnd, because we want to ensure that
a run of a Tabular program consists of a single round of inference, determining the
posterior distributions of rnd columns, followed by a single post-processing phase,
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

14.5 Type System
519
which computes the values of qry columns given the (already known) approximate
distributions of rnd columns. Tabular does not support nested inference, where, for
instance, a rnd column used in the second round of inference could depend on a
qry column computed after the ﬁrst round of inference.
We embed these restrictions in the type system by means of a subtyping relation
on column types. We ﬁrst deﬁne a preorder ≤on spaces as the least reﬂexive relation
satisfying det ≤rnd and det ≤qry. We also deﬁne a (partial) least upper bound
spc ∨spc′.
Least upper bound: spc ∨spc′ (if spc ≤spc′ or spc′ ≤spc)
spc ∨spc = spc
det ∨rnd = rnd
det ∨qry = qry
(The combination rnd ∨qry is intentionally not deﬁned.)
We can lift the ∨operation to types in the straightforward way.
We deﬁne the subtyping judgment Γ ⊢T <: U to hold if and only if both T and U
are well-formed in Γ, they are of the same form and space(T) ≤space(U).
Selected Typing Rules for Expressions: Γ ⊢pc E : T
(Deref Static)
Γ ⊢⋄
Γ = Γ′,t : Q,Γ′′
Q = Q′@[(c ▷x : T static viz)]@Q′′
Γ ⊢pc t.c : T
(Deref Inst)
Γ ⊢pc E : link(t) ! spc
Γ = Γ′,t : Q,Γ′′
Q = Q′@[(c ▷x : T inst viz)]@Q′′
Γ ⊢pc E : t.c : T ∨spc
(Random) (where σ(U) ≜U{e1/x1} . . . {em/xm})
Drnd : [x1 : T1,. . ., xm : Tm](c1 : U1,. . .,cn : Un) →T
Γ ⊢static ei : Ti
∀i ∈1..m
Γ ⊢pc Fj : σ(Uj)
∀j ∈1..n
Γ ⊢⋄
{x1,. . ., xm} ∩(
i fv(ei)) = ∅
xi  xj for i  j
Γ ⊢pc D[e1,. . .,em](F1,. . ., Fn) : σ(T)
(Infer) (where σ(U) ≜U{e1/x1} . . . {em/xm})
Dqry : [x1 : T1,. . ., xm : Tm](c1 : U1,. . .,cn : Un) →T
Γ ⊢static ei : Ti
∀i ∈1..m
Γ ⊢pc E : σ(T)
j ∈1..n
{x1,. . ., xm} ∩(
i fv(ei)) = ∅
xi  xj for i  j
Γ ⊢pc infer.D[e1,. . .,em].cj(E) : σ(Uj)
(FunRef)
Γ ⊢⋄
Γ = Γ′, x : Q,Γ′′
Q = Q′@[(c ▷y : T ℓviz)]@Q′′
ℓ≤pc
c  ret
Γ ⊢pc x.c : T
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

520
Gordon et al: Tabular: Probabilistic Inference from the Spreadsheet
Above, we present some of the non-standard typing rules for basic model ex-
pressions. Most of them are similar to the typing rules of Fun (Borgström et al.,
2013), the language on which the grammar of expressions is based, except that they
also handle spaces. We also need to add rules for dereference operators, function
column accesses and the infer primitive.
The rule (Deref Static) checks that there is an entry for table t in the environment
and that its Q-type has column c with type T. (Deref Inst) is similar, except that
it typechecks a reference to an inst-level column. The index E must be an integer
bounded by the size of table t. An instance dereference is only deterministic if both
the index and the reference column are deterministic, and a reference to the value of
a deterministic column at a random index (or vice versa) is random (and similarly
for queries), so we need to join the type of the referenced column with the space of
the index.
The (Random) rule requires all hyperparameters e1,. . .,em of a distribution to
be static and have the right types, as speciﬁed by the distribution signature. Since
the types U1,. . .,Un of parameters and the output type T may depend on these
hyperparameters, we need to substitute their values in these types. This is done by
the σ operator. The expressions F1,. . ., Fn deﬁning parameter values must check
against the corresponding types U1,. . .,Un in the signature of the distribution with
hyperparameter values substituted by σ. The requirements that the (α-convertible)
formal hyperparameter names x1,. . ., xm and free variables in e1,. . .,em are disjoint
and that no hyperparameter name appears twice guarantee that the substitution σ
is well-deﬁned.
To see how the (Random) rule works, consider the expression Discrete[2](V) in
table Coins in Section 14.2.2. While typechecking the (original, functionless) Coins
table, Discrete[2](V) is typeckecked at level inst in the environment Γ = V :static
real!rnd[2]. The signature of the Discrete distribution in space rnd is Discreternd :
[N : int!det](probs : real!rnd[N]) →mod(N)!rnd. In Discrete[2](V), the value
of the only hyperparameter N is e1 = 2, which obviously checks against the type
int!det in the signature. After substituting this value for N in the type of the only
parameter probs, we get real!rnd[2]. We need to check that Γ ⊢inst V : real!rnd[2].
This follows instantly from (Index Var), because V has exactly the type
real!rnd[2] in Γ. Thus, the expression typechecks correctly and the output type,
obtained by substituting 2 for N in mod(N)!rnd, is mod(2)!rnd.
The (Infer) rule has a similar form to (Random), but instead of typing the distri-
bution arguments, it checks whether the type of the expression E deﬁning the distri-
bution of interest (and normally expected to reference a previous column), matches
the output type T in the signature of the distribution D (with hyperparameters
x1,. . ., xm again substituted by their values em,. . .,em).As infer.D[e1,. . .,em].cj(E)
is supposed to return the expected value of the parameter cj of the posterior dis-
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

14.5 Type System
521
tribution of expression E, the type of infer.D[e1,. . .,em].cj(E) is the type of the
argument cj in the signature of D, again with the hyperparameter values substituted.
Note that the rule uses the qry version of the signature of D, in which the types
of arguments are in qry-space. This ensures that the type of a post-inference query
is in qry-space, and thus the query is not part of the probabilistic model.
Let us demonstrate how the rule works by going back to the example in Section
14.2.3. As the table Coins with the additional qry-level columns counts and Bias
is typechecked, the expression infer.Dirichlet[2].pseudocount(V) is typeckeched at
level static in environment Γ = V :static real!rnd[2],Flip :inst mod(2)!rnd. The
signature of Dirichlet in qry-space is Dirichletqry : [N : int!det](pseudocount :
(real!qry)[N]) →(real!rnd)[N]. As in the above example for (Random), the value
of the only hyperparameter N, which is 2, must be checked at level static against
the type of N in the signature of Dirichletqry - that is, int!det.
As the posterior distribution of V is expected to be Dirichlet with N = 2, we need
to check that the type of the column referenced by V actually matches the output
type of Dirichlet with the given hyperparameter, which we obtain by substituting
2 for N in (real!rnd)[N]. Looking at the environment Γ, we immediately see that
Γ ⊢static V : real!rnd[2] indeed holds.
The parameter of the Dirichlet posterior of V whose expected value the infer
operator is supposed to return is pseudocount, which has type (real!qry)[N] in the
signature. After substituting N by its value, this type becomes (real!qry)[2]. Hence,
this is the type of the entire expression infer.Dirichlet[2].pseudocount(V).
The (FunRef) rule deﬁnes the type of a column access to be the type of the given
column in the type of the reduced table, as long as this column is visible at level pc.
All the other typing rules (including the subsumption rule) are standard.
14.5.3 Model Types
Before we extend the type system to compound models, we deﬁne typing rules for
function argument lists. The judgment Γ ⊢pc R : Q →Q′ means that applying a
function of type Q to R at level pc yields a table of type Q′. The typing rules for
arguments are presented below. Recall that in functions called at static level, the
level of every column is reduced to static, hence the need to join ℓwith pc in output
types.
Typing Rules for Arguments: Γ ⊢pc R : Q →Q′
(Arg Input)
Γ ⊢ℓ∧pc e : T
Γ ⊢pc R : Q{e/x} →Q′
Γ ⊢pc ((c = e) :: R) : ((c ▷x : T ℓinput) :: Q) →Q′
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

522
Gordon et al: Tabular: Probabilistic Inference from the Spreadsheet
(Arg Output)
Γ, x :ℓ∧pc T ⊢pc R : Q →Q′
c  ret
x  fv(R)
Γ ⊢pc R : ((c ▷x : T ℓoutput) :: Q) →((c ▷x : T (ℓ∧pc) output) :: Q′)
(Arg Ret)
Γ ⊢T
Γ ⊢pc R : (ret ▷x : T ℓoutput) →(ret ▷x : T (ℓ∧pc) output)
The (Arg Input) rule typechecks the argument e, substitutes it for the input
variable x and proceeds with checking the rest of R, without copying the input
column x to the output type. If the column level ℓis static, e must be a static
expression to be a valid argument, and if pc is static, then e may be referenced in
the subsequent static columns of the reduced table, hence we need to typecheck e
at level ℓ∧pc. The following rule, (Arg Output), just adds x to the environment
(as it may appear in the types of subsequent columns) and proceeds with processing
the rest of Q, copying the current column into the output with updated level.
Finally, (Arg Ret) just checks the well-formedness of the type of the output
column and updates its level.
In order to simplify typechecking indexed models, we also deﬁne an indexing
operator for Q-types, which changes the types of all non-input static rnd columns
in Q into array types.
Indexing a Table Type: Q[e]
∅[e] ≜∅
((c ▷x : T inst viz) :: Q)[e] ≜(c ▷x : T inst viz) :: (Q[e])
if x  fv(e)
((c ▷x : T static viz) :: Q)[e] ≜(c ▷x : T static viz) :: (Q[e])
if viz = input or det(T) and x  fv(e)
((c ▷x : T static viz) :: Q)[e] ≜(c ▷x : T[e] static viz) :: (Q[e])
if viz  input and rnd(T) and x  fv(e)
We also need to make sure function tables are Core and have no trailing local
and input columns:
Table and Schema Types:
fun(T) iﬀCore(T) and T = T1@[(ret ▷x : T ℓoutput E)]
where @ denotes table concatenation.
The typing rules for (non-simple) models can now be deﬁned as follows:
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

14.5 Type System
523
Typing Rules for Model Expressions: Γ ⊢pc M : Q
(Model Appl)
Γ ⊢pc T : Q
fun(T)
Γ ⊢pc R : Q →Q′
Γ ⊢pc T R : Q′
(Model Indexed)
Γ ⊢pc M : Q
Γ ⊢pc eindex : mod(esize) ! rnd
NoQry(M)
Γ ⊢pc M[eindex < esize] : Q[esize]
The (Model Appl) rule typechecks the function table and the argument lists,
returning the output type of the argument typing judgment. Meanwhile, (Model
Indexed) uses the Q-type indexing to construct the type of an indexed model from
the type of its base model. As stated in Section 14.4, only tables with no qry columns
can be indexed, so we need to ensure that the table nested in M satisﬁes NoQry.
14.5.4 Table Types
The rules below are used for typechecking both top-level tables and function tables,
which can be called from static columns, so we need to add the pc level to the
typing judgment. To preserve information ﬂow restrictions, a model expression
in a column at level ℓcan only reference variables at level at most ℓ. Similarly,
expressions in a function at level pc cannot use variables at level greater than pc.
Hence, all model expressions are typechecked at level ℓ∧pc.
Tables with Core columns
We start with rules for typechecking Core columns. The operator names(Q), used
below and in the rest of this section, returns the set of global names of all columns
in Q.
Typing Rules for Tables - Core columns: Γ ⊢pc T : Q
(Table [])
Γ ⊢⋄
Γ ⊢pc [] : []
(Table Input)
Γ, x :ℓ∧pc T ⊢pc T : Q
c  names(Q)
Γ ⊢pc (c ▷x : T ℓinput ϵ) :: T : (c ▷x : T (ℓ∧pc) input) :: Q
(Table Core Output)
Γ ⊢ℓ∧pc E : T
Γ, x :ℓ∧pc T ⊢pc T : Q
c  names(Q)
Γ ⊢pc (c ▷x : T ℓoutput E) :: T : (c ▷x : T (ℓ∧pc) output) :: Q
(Table Core Local) (where x  fv(Q))
Γ ⊢ℓ∧pc E : T
Γ, x :ℓ∧pc T ⊢pc T : Q
Γ ⊢pc (c ▷x : T ℓlocal E) :: T : Q
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

524
Gordon et al: Tabular: Probabilistic Inference from the Spreadsheet
The (Table []) rule is obvious. The (Table Input) rule just adds the variable x
to the environment (at level ℓ∧viz) and checks the rest of the table. The (Table
Core Output) rule checks the model expression E and then typechecks the rest of
the table in the environment extended with x. The type of the current column (with
level joined with pc) is concatenated with the (recursively derived) type of the rest
of the table. (Table Core Local) is similar to (Table Core Output), except that
the type of the current column does not appear in the table type and x cannot be
free in Q (otherwise Q could contain a variable not deﬁned in the environment Γ in
the conclusion of the rule).
Example: checking Core Tabular functions To illustrate how the typing rules for
Core tables work, recall the functions CDiscrete from Section 14.2.2 and CGaussian
from Section 14.4. In this and the following examples, we will use the same column-
based notation for Q-types as for Tabular tables.
The function CDiscrete has the following form, with local and ﬁeld names:
fun CDiscrete
N ▷N
int!det
static input
R ▷R
real!det
static input
V ▷V
real!rnd[N]
static output
Dirichlet[N]([for i < N →R])
ret ▷ret
mod(N)!rnd
output
Discrete[N](V)
To typecheck CDiscrete in an empty environment at level inst, we ﬁrst add the
arguments N and R to the environment, by applying (Table Input).
Now, let Γ = N :static int!det,R :static real!det. Then, by inspecting the signature
of Dirichlet and applying (Random), we can show that
Γ ⊢inst Dirichlet[N]([for i < N →R]) : real ! rnd[N]
By applying (Random) again, we get
Γ,V :static real ! rnd[N] ⊢inst Discrete[N](V) : mod(N) ! rnd
By (Table Core Output), the last column has type
ret ▷ret
mod(N)!rnd
output
in the environment Γ,V :static real ! rnd[N]. Applying (Table Core Output) again
adds the column
V ▷V
real!rnd[N]
static output
to this type. Finally, by applying (Table Input) twice, we get the type of CDiscrete:
N ▷N
int!det
static input
R ▷R
real!det
static input
V ▷V
real!rnd[N]
static output
ret ▷ret
mod(N)!rnd
output
Similarly, CG can be shown to have the following type in the empty environment:
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

14.5 Type System
525
M ▷M
real!det
static input
P ▷P
real!det
static input
Mean ▷Mean
real!rnd
static output
Prec ▷Prec
real!rnd
static output
ret ▷ret
real!rnd
output
Example: typing function applications Recall the coin ﬂip example from Sec-
tion 14.2.2, shown here with double column names:
table Coins
Flip ▷Flip
int!rnd
output
CDiscrete(N=2, R=1.0)
This example contains a single call to CDiscrete. By the argument typing rules,
we have
∅⊢inst (N = 2,R = 1.0) : QCD →Q′
CD
where QCD is the type of CDiscrete, shown above, and QCD' is the type of the
reduced function application, having the following form:
V ▷V
real!rnd[2]
static output
ret ▷ret
mod(2)!rnd
output
By (Model Appl), the type of the function application is Q′
CD:
∅⊢inst CDiscrete(N = 2,R = 1.0) : Q′
CD
Example: indexing model types In the Old Faithful example, we applied indexing
[cluster < 2] to the application CG(M = 0.0,P = 1.0). It can be easily shown (like
in the example above) that in any environment Γ, this application has the following
type Q′
CG:
Mean ▷Mean
real!rnd
static output
Prec ▷Prec
real!rnd
static output
ret ▷ret
real!rnd
output
According to the (Model Indexed) rule, in an environment Γ such that Γ ⊢inst
cluster : mod ! rnd, the indexed application CG(M = 0.0,P = 1.0)[cluster < 2] has
the following type:
Mean ▷Mean
real!rnd[2]
static output
Prec ▷Prec
real!rnd[2]
static output
ret ▷ret
real!rnd
output
Full Tabular Tables
To typecheck columns with non-basic models, we need a preﬁxing operator for
Q-types and two additional rules.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

526
Gordon et al: Tabular: Probabilistic Inference from the Spreadsheet
Preﬁxing function type column names: c.Q
c.((d ▷x : T ℓviz) :: Q) = (c.d ▷x : T ℓviz) :: c.Q
if d  ret
c.([(ret ▷x : T ℓviz)]) = [(c ▷x : T ℓviz)]
c.([(d ▷x : T ℓviz)]) = [(c.d ▷x : T ℓviz)]
if d  ret
Typing Rules for Tables: Γ ⊢pc T : Q
(Table Output)
Γ ⊢ℓ∧pc M : Qc
Γ, x : Qc ⊢pc T : Q
Qc = Q′
c@[(ret ▷y : T ℓ′ output)]
names(c.Qc) ∩names(Q) = ∅
Γ ⊢pc (c ▷x : T ℓoutput M) :: T : (c.Qc)@Q
(Table Local)
Γ ⊢ℓ∧pc M : Qc
Γ, x : Qc ⊢pc T : Q
Qc = Q′
c@[(ret ▷y : T ℓ′ output)]
Γ ⊢pc (ϵ ▷x : T ℓlocal M) :: T : Q
The (Table Output) rule typechecks the model M and then recurses into the
rest of the table with the environment extended with the type Qc of M, assigned to
x. Note that local attributes of M cannot be referenced in T. This is a design choice
- local columns in functions are only meant to be used locally. (Table Local) is
similar, except it does not export the type of the model.
Example: typing tables with compound models Recall the coin ﬂip model:
table Coins
Flip ▷Flip
mod(2)!rnd
output
CDiscrete(N=2, R=1.0)
We have already shown that the application CDiscrete(N = 2,R = 1.0) has the
following type:
V ▷V
real!rnd[2]
static output
ret ▷ret
mod(2)!rnd
output
By (Table Output), the type of the Coins table is:
Flip.V ▷V
real!rnd[2]
static output
Flip ▷Flip
mod(2)!rnd
output
Similarly, we can show that the Old Faithful model from the beginning of Sec-
tion 14.4.1 has the following type:
cluster.V ▷V
real!rnd[2]
static output
cluster ▷cluster
mod(2)!rnd
output
duration.Mean ▷Mean
real!rnd[2]
static output
duration.Prec ▷Prec
real!rnd[2]
static output
duration ▷duration
real!rnd
output
time.Mean ▷Mean
real!rnd[2]
static output
time.Prec ▷Prec
real!rnd[2]
static output
time ▷time
real!rnd
output
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

14.5 Type System
527
Example: accessing function ﬁelds Let us consider once again the simpliﬁed
version of the Old Faithful model with an additional column containing a function
ﬁeld access:
table Faithful
duration ▷x
real!rnd
output
CG(M=0.0, P=1.0)
time ▷x'
real!rnd
output
CG(M=60.0, P=1.0)
duration_mean ▷z
real!qry
output
infer.Gaussian.mean(x.Mean)
As shown before, each application of CG has the following type Q′
CG:
Mean ▷Mean
real!rnd
static output
Prec ▷Prec
real!rnd
static output
ret ▷ret
real!rnd
output
According to the typing rules, if the initial typing environment is empty, the ﬁnal
column is checked in the environment Γ = x : Q′
CG, x′ : Q′
CG. This ﬁnal column
must be typechecked by the (Table Core Output) rule, which requires that
Γ ⊢inst infer.Gaussian.mean(x.Mean) : real ! rnd
By (Infer), this only holds if
Γ ⊢inst x.Mean : real ! rnd
The environment Γ can be easily shown to be well-formed. Since x has type Q′
CG
in the environment, and this Q-type has a column with ﬁeld name Mean and type
real ! rnd, the above judgment can be derived with (FunRef).
14.5.5 Schema Types
We round oﬀthe description of the type system with the following two self-
explanatory rules for schemas:
Typing Rules for Schemas: Γ ⊢S : Sty
(Schema [])
Γ ⊢⋄
Γ ⊢[] : []
(Schema Table)
Γ ⊢inst T : Q
table(Q)
Γ,t : Q ⊢S : Sty
Γ ⊢(t = T) :: S : (t : Q) :: Sty
Top-level tables in a schema are typechecked at level inst, because they can
deﬁne both static and inst-level columns. The table typing judgment only includes
the level parameter because it is also used for typing functions, which can be called
from static columns.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

528
Gordon et al: Tabular: Probabilistic Inference from the Spreadsheet
14.5.6 Type Soundness and Termination of Reduction
In this section, we present the key property of the reduction system: every well-
typed schema reduces to a Core schema with the same type. To prove the type
soundness property, we need to state and prove three separate propositions: type
preservation, progress and termination of reduction. The proofs of these properties
are mostly standard inductive proofs and are omitted in this chapter. They can be
found in Szymczak (2018).
The type preservation proposition states that if a schema can be reduced, this
reduced schema is well-typed and has the same type as the original schema:
Proposition 14.1 (Type preservation)
(1) If Γ ⊢pc M : Q and M →M′, then Γ ⊢pc M′ : Q
(2) If Γ ⊢inst T : Q and T →T′, then Γ ⊢inst T′ : Q
(3) If Γ ⊢S : Sty and S →S′, then Γ ⊢S′ : Sty.
The progress property states that every well-typed schema which is not in Core
form can be reduced.
Proposition 14.2 (Progress)
(1) If Γ ⊢pc T : Q then either Core(T) or there is T′ such that T →T′.
(2) If Γ ⊢pc S : Sty then either Core(S) or there is S′ such that S →S′.
The ﬁnal property needed for the type soundness theorem is termination of
reduction:
Proposition 14.3 (Termination)
There does not exist an inﬁnite chain of reductions
S1 →S2 →· · · .
By putting these propositions together, we obtain the key theoretical result of
this chapter, the type soundness theorem (where we write →∗for the reﬂexive and
transitive closure of the reduction relation):
Theorem 14.4
If ∅⊢S : Sty, then S →∗S′ for some unique S′ such that Core(S′)
and ∅⊢S′ : Sty.
Proof
By Propositions 14.1 and 14.2, we can construct a maximal chain of re-
ductions S →S1 →S2 · · · such that ∅⊢Si : Sty for all i and either Core(Si) or
Si →Si+1. By Proposition 14.3, we know that this chain must be ﬁnite, so we must
have Core(Si) for some Si. The uniqueness of this Si follows from the determinacy
of the reduction rules.
□
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

14.6 Conclusions
529
14.6 Conclusions
We have presented a new, signiﬁcantly extended version of the Tabular schema-
based probabilistic programming language, with user-deﬁned functions serving as
reusable, modular model components, a primitive for computing quantities depend-
ing on inference results, useful in decision theory, and dependent types for catching
common modelling errors.
We endowed the language with a rigorous metatheory, strengthening its design.
We have deﬁned a system of structural types, in which each table or model type
shows the variables used in the model, their domains, determinacies, numbers of
instances (one or many) and roles they play in the model. We have shown how to
reduce compound models to the Core form, directly corresponding to a factor graph,
by providing a set of reduction rules akin to operational semantics in conventional
languages, and have proven that this operation is type-sound.
One possible direction of future work is adding support for inference in time-
series models. Another possible extension is to allow nested inference Rainforth
(2018); Mantadelis and Janssens (2011) by extending the lattice of spaces, so that the
distributions computed in one run of inference could be queried by the probabilistic
model "active" in the following run. The new lattice would include indexed spaces
of the form rndi and qryi, where the result of infer applied to a random variable in
rndi would be in qryi and data in rndi+1 could reference columns in space qryi.
References
Bingham, Eli, Chen, Jonathan P., Jankowiak, Martin, Obermeyer, Fritz, Pradhan,
Neeraj, Karaletsos, Theofanis, Singh, Rohit, Szerlip, Paul, Horsfall, Paul, and
Goodman, Noah D. 2018. Pyro: Deep Universal Probabilistic Programming.
arXiv preprint arXiv:1810.09538.
Borgström, Johannes, Gordon, Andrew D., Greenberg, Michael, Margetson, James,
and Gael, Jurgen Van. 2013. Measure Transformer Semantics for Bayesian
Machine Learning. Logical Methods in Computer Science, 9(3). Preliminary
version at ESOP'11.
Borgström, Johannes, Gordon, Andrew D., Ouyang, Long, Russo, Claudio, Ścibior,
Adam, and Szymczak, Marcin. 2016. Fabular: Regression Formulas As Proba-
bilistic Programming. Pages 271-283 of: Proceedings of the 43rd Annual ACM
SIGPLAN-SIGACT Symposium on Principles of Programming Languages.
POPL '16. New York, NY, USA: ACM.
Carpenter, Bob, Gelman, Andrew, Hoﬀman, Matthew D., Lee, Daniel, Goodrich,
Ben, Betancourt, Michael, Brubaker, Marcus, Guo, Jiqiang, Li, Peter, and
Riddell, Allen. 2017. Stan: A probabilistic programming language. Journal
of Statistical Software, 76(1).
Georgoulas, Anastasis, Hillston, Jane, Milios, Dimitrios, and Sanguinetti, Guido.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

530
References
2014. Probabilistic Programming Process Algebra. Pages 249-264 of: Quan-
titative Evaluation of Systems - 11th International Conference, QEST 2014,
Florence, Italy, September 8-10, 2014. Proceedings.
Gilks, W R, Thomas, A, and Spiegelhalter, D. J. 1994. A language and program
for complex Bayesian modelling. The Statistician, 43, 169-178.
Goodman, Noah, Mansinghka, Vikash K., Roy, Daniel M., Bonawitz, Keith, and
Tenenbaum, Joshua B. 2008. Church: a language for generative models. Pages
220-229 of: Uncertainty in Artiﬁcial Intelligence (UAI'08). AUAI Press.
Goodman, Noah D., and Stuhlmüller, Andreas. 2014. The Design and Implemen-
tation of Probabilistic Programming Languages. http://dippl.org.
Gordon, Andrew D., Russo, Claudio, Szymczak, Marcin, Borgström, Johannes,
Rolland, Nicolas, Graepel, Thore, and Tarlow, Daniel. 2014a. Probabilistic
Programs as Spreadsheet Queries. Tech. rept. MSR-TR-2014-135. Microsoft
Research.
Gordon, Andrew D., Graepel, Thore, Rolland, Nicolas, Russo, Claudio, Borgstrom,
Johannes, and Guiver, John. 2014b. Tabular: A Schema-driven Probabilistic
Programming Language. Pages 321-334 of: Proceedings of the 41st ACM
SIGPLAN-SIGACT Symposium on Principles of Programming Languages.
POPL '14. New York, NY, USA: ACM.
Gordon, Andrew D., Russo, Claudio V., Szymczak, Marcin, Borgström, Johannes,
Rolland, Nicolas, Graepel, Thore, and Tarlow, Daniel. 2015. Probabilistic Pro-
grams as Spreadsheet Queries. Pages 1-25 of: Vitek, Jan (ed), Programming
Languages and Systems (ESOP 2015). Lecture Notes in Computer Science,
vol. 9032. Springer.
Harper, Robert, and Lillibridge, Mark. 1994. A Type-theoretic Approach to Higher-
order Modules with Sharing. Pages 123-137 of: Proceedings of the 21st ACM
SIGPLAN-SIGACT Symposium on Principles of Programming Languages.
POPL '94. New York, NY, USA: ACM.
Herbrich, Ralf, Minka, Tom, and Graepel, Thore. 2007. TrueSkill™: A Bayesian
Skill Rating System. Pages 569-576 of: Schölkopf, B., Platt, J. C., and Hoﬀ-
man, T. (eds), Advances in Neural Information Processing Systems 19. MIT
Press.
Hutchison, Dylan. 2016. ModelWizard: Toward Interactive Model Construction.
CoRR, abs/1604.04639.
Mansinghka, Vikash K., Selsam, Daniel, and Perov, Yura N. 2014. Venture: a
higher-order probabilistic programming platform with programmable infer-
ence. CoRR, abs/1404.0099.
Mansinghka, Vikash K., Tibbetts, Richard, Baxter, Jay, Shafto, Patrick, and Eaves,
Baxter. 2015. BayesDB: A probabilistic programming system for querying the
probable implications of data. CoRR, abs/1512.05006.
Mantadelis, Theofrastos, and Janssens, Gerda. 2011. Nesting Probabilistic Infer-
ence. CoRR, abs/1112.3785.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
531
Minka, T., Winn, J.M., Guiver, J.P., and Knowles, D.A. 2012.
Infer.NET 2.5.
Microsoft Research Cambridge. http://research.microsoft.com/infernet.
Minka, Thomas P. 2001. Expectation Propagation for approximate Bayesian in-
ference. Pages 362-369 of: Uncertainty in Artiﬁcial Intelligence (UAI'01).
Morgan Kaufmann.
Minka, Tom, and Winn, John. 2009. Gates. Pages 1073-1080 of: Koller, D., Schu-
urmans, D., Bengio, Y., and Bottou, L. (eds), Advances in Neural Information
Processing Systems 21. Curran Associates, Inc.
Nori, Aditya V., Hur, Chung-Kil, Rajamani, Sriram K., and Samuel, Selva. 2014.
R2: An Eﬃcient MCMC Sampler for Probabilistic Programs. Pages 2476-
2482 of: Proceedings of the Twenty-Eighth AAAI Conference on Artiﬁcial
Intelligence. AAAI'14. AAAI Press.
Pollack, Robert. 2002. Dependently Typed Records in Type Theory. Formal Aspects
of Computing, 13, 386-402.
Rainforth, Tom. 2018. Nesting Probabilistic Programs. Pages 249-258 of: Glober-
son, Amir, and Silva, Ricardo (eds), Proceedings of the Thirty-Fourth Confer-
ence on Uncertainty in Artiﬁcial Intelligence, UAI 2018, Monterey, California,
USA, August 6-10, 2018. AUAI Press.
Ścibior, Adam, Ghahramani, Zoubin, and Gordon, Andrew D. 2015. Practical
probabilistic programming with monads. Pages 165-176 of: Lippmeier, Ben
(ed), Proceedings of Haskell 2015. ACM.
Siddharth, N., Paige, Brooks, van de Meent, Jan-Willem, Desmaison, Alban, Good-
man, Noah D., Kohli, Pushmeet, Wood, Frank, and Torr, Philip. 2017. Learning
Disentangled Representations with Semi-Supervised Deep Generative Mod-
els. Pages 5927-5937 of: Guyon, I., Luxburg, U. V., Bengio, S., Wallach,
H., Fergus, R., Vishwanathan, S., and Garnett, R. (eds), Advances in Neural
Information Processing Systems 30. Curran Associates, Inc.
Szymczak, Marcin. 2018. Programming Language Semantics as a Foundation for
Bayesian Inference. Ph.D. thesis, University of Edinburgh.
Vaglica, V., Sajeva, M., McGough, H. N., Hutchison, D., Russo, C., Gordon, A. D.,
Ramarosandratana, A. V., Stuppy, W., and Smith, M. J. 2017. Monitoring
internet trade to inform species conservation actions. Endangered Species
Research, 32, 223-235.
Van den Broeck, Guy, Thon, Ingo, van Otterlo, Martijn, and De Raedt, Luc. 2010.
DTProbLog: A Decision-theoretic Probabilistic Prolog. Pages 1217-1222 of:
Proceedings of the Twenty-Fourth AAAI Conference on Artiﬁcial Intelligence.
AAAI'10. AAAI Press.
Wood, Frank, Meent, Jan Willem, and Mansinghka, Vikash. 2014. A New Ap-
proach to Probabilistic Programming Inference. Pages 1024-1032 of: Kaski,
Samuel, and Corander, Jukka (eds), Proceedings of the Seventeenth Interna-
tional Conference on Artiﬁcial Intelligence and Statistics. Proceedings of
Machine Learning Research, vol. 33. Reykjavik, Iceland: PMLR.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

532
References
Wu, Mike, Perov, Yura N., Wood, Frank D., and Yang, Hongseok. 2016. Spreadsheet
Probabilistic Programming. CoRR, abs/1606.04216. (see also the Scenarios
tool at invrea.com).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

15
Programming Unreliable Hardware
Michael Carbin
Massachusetts Institute of Technology
Sasa Misailovic
University of Illinois
Abstract:
Emerging high-performance architectures are anticipated to contain
unreliable components that may exhibit soft errors, which silently corrupt the
results of computations. Full detection and masking of soft errors is challenging,
expensive, and, for some applications, unnecessary. For example, approximate
computing applications (such as multimedia processing, machine learning, and big
data analytics) can often naturally tolerate soft errors.
We present Rely, a programming language that enables developers to reason about
the quantitative reliability of an application - namely, the probability that it produces
the correct result when executed on unreliable hardware. Rely allows developers to
specify the reliability requirements for each value that a function produces.
We present a static quantitative reliability analysis that veriﬁes quantitative
requirements on the reliability of an application, enabling a developer to perform
sound and veriﬁed reliability engineering. The analysis takes a Rely program with a
reliability speciﬁcation and a hardware speciﬁcation that characterizes the reliability
of the underlying hardware components and veriﬁes that the program satisﬁes
its reliability speciﬁcation when executed on the underlying unreliable hardware
platform. We demonstrate the application of quantitative reliability analysis on six
computations implemented in Rely.
15.1 Introduction
Reliability is a major concern in the design of computer systems. The current goal of
delivering systems with negligible error rates restricts the available design space and
imposes signiﬁcant engineering costs. And as other goals such as energy eﬃciency,
circuit scaling, and new features and functionality continue to grow in importance,
maintaining even current error rates will become increasingly diﬃcult.
a From Foundations of Probabilistic Programming, edited by Gilles Barthe, Joost-Pieter Katoen and Alexandra
Silva published 2020 by Cambridge University Press.
533
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

534
Carbin and Misailovic: Programming Unreliable Hardware
In response to this situation, researchers have developed numerous techniques for
detecting and masking errors in both hardware (Ernst et al., 2003) and software (Reis
et al., 2005; Perry et al., 2007; de Kruijf et al., 2010). Because these techniques
typically come at the price of increased execution time, increased energy consumption,
or both, they can substantially hinder or even cripple overall system performance.
Many computations, however, can easily tolerate occasional errors. An approxi-
mate computation (including many multimedia, ﬁnancial, machine learning, and big
data analytics applications) can tolerate occasional errors in its execution and/or the
data that it manipulates (Rinard, 2006; Misailovic et al., 2010; Carbin and Rinard,
2010). A checkable computation can be augmented with an eﬃcient checker that
veriﬁes either the exact correctness (Blum and Kanna, 1989; Leveson et al., 1990)
or the approximate acceptability of the results that the computation produces. If the
checker does detect an error, it can reexecute the computation to obtain an acceptable
result.
For both approximate and checkable computations, operating without (or with
at most selectively applied) mechanisms that detect and mask errors can produce
(1) faster and more energy eﬃcient execution that (2) delivers acceptably accurate
results often enough to satisfy the needs of their users.
15.1.1 Background
Approximate computations have emerged as a major component of many computing
environments. Motivated in part by the observation that approximate computations
can often acceptably tolerate occasional computation and/or data errors (Rinard, 2006;
Misailovic et al., 2010; Carbin and Rinard, 2010), researchers have developed a range
of new mechanisms that forgo exact correctness to optimize other objectives. Typical
goals include maximizing program performance subject to an accuracy constraint
and altering program execution to recover from otherwise fatal errors (Rinard et al.,
2004).
Software Techniques Most software techniques deploy unsound transformations -
transformations that change the semantics of an original exact program. Proposed
mechanisms include skipping tasks (Rinard, 2006), loop perforation (skipping
iterations of time-consuming loops) (Misailovic et al., 2010; Sidiroglou et al., 2011),
sampling reduction inputs (Zhu et al., 2012), multiple selectable implementations of
a given component or components (Baek and Chilimbi, 2010; Ansel et al., 2011;
Hoﬀman et al., 2011; Zhu et al., 2012), dynamic knobs (conﬁguration parameters that
can be changed as the program executes) (Hoﬀman et al., 2011) and synchronization
elimination (forgoing synchronization not required to produce an acceptably accurate
result) (Misailovic et al., 2013). The results show that aggressive techniques such
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

15.1 Introduction
535
as loop perforation can deliver up to a four-fold performance improvement with
acceptable changes in the quality of the results that the application delivers.
Hardware Techniques The computer architecture community has begun to investi-
gate new designs that improve performance by breaking the traditional fully reliable
digital abstraction that computer hardware has traditionally sought to provide. The
goal is to reduce the cost of implementing a reliable abstraction on top of physical
materials and manufacturing methods that are inherently unreliable. For example,
researchers are investigating designs that incorporate aggressive device and voltage
scaling techniques to provide low-power ALUs and memories. A key aspect of these
components is that they forgo traditional correctness checks and instead expose
timing errors and bitﬂips with some non-negligible probability (de Kruijf et al.,
2010; Esmaeilzadeh et al., 2012; Leem et al., 2010; Liu et al., 2011; Narayanan
et al., 2010; Palem, 2005; Sampson et al., 2011).
In this work, we focus on hardware techniques that manifest as soft errors - errors
that occur in the system nondeterministically. They may aﬀect the values computed
by individual instruction executions or data stored in individual memory locations.
We can associate the probability of soft-error occurrence with each (unprotected)
instruction. However, soft errors do not last over multiple instruction executions or
permanently damage the hardware.
15.1.2 Reasoning About Approximate Programs
Approximate computing violates the traditional contract that the programming
system must preserve the standard semantics of the program. It therefore invalidates
standard paradigms and motivates new, more general, approaches to reasoning about
program correctness, and acceptability.
One key aspect of approximate applications is that they typically contain critical
regions (which must execute without error) and approximate regions (which can
execute acceptably even in the presence of occasional errors) (Rinard, 2006; Carbin
and Rinard, 2010). Existing systems, tools, and type systems have focused on helping
developers identify, separate, and reason about the binary distinction between
critical and approximate regions (Rinard, 2006; Carbin and Rinard, 2010; Liu
et al., 2011; Sampson et al., 2011; Esmaeilzadeh et al., 2012). However, in practice,
no computation can tolerate an unbounded accumulation of errors - to execute
acceptably, executions of even approximate regions must satisfy some minimal
requirements.
Approximate computing therefore raises a number of fundamental new research
questions. For example, what is the probability that an approximate program will
produce the same result as a corresponding original exact program? How much do
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

536
Carbin and Misailovic: Programming Unreliable Hardware
the results diﬀer from those produced by the original program? And is the resulting
program safe and secure?
Because traditional correctness properties do not provide an appropriate conceptual
framework for addressing these kinds of questions, we instead work with acceptability
properties - the minimal requirements that a program must satisfy for acceptable
use in its designated context. We identify three kinds of acceptability properties
and use the following program (which computes the minimum element min in an
N-element array) to illustrate these properties:
int min = INT_MAX;
for (int i = 0; i < N; ++i)
if (a[i] < min) min = a[i];
Integrity Properties: Integrity properties are properties that the computation
must satisfy to produce a successful result. Examples include both computation-
independent properties (no out of bounds accesses, null dereferences, divide by
zero errors, or other actions that would crash the computation) and computation-
dependent properties (for example, the computation must return a result within a
given range). One integrity property for our example is that accesses to the array a
must always be within bounds.
Reliability Properties: Reliability properties characterize the probability that the
produced result is correct. Reliability properties are often appropriate for approximate
computations executing on unreliable hardware platforms that exhibit occasional
nondeterministic errors. A potential reliability property for our example program is
that min must be the minimum element in a[0]-a[N-1] with probability at least
95%.
Accuracy Properties: Accuracy properties characterize how accurate the produced
result must be. For example, an accuracy property might state that the transformed
program must produce a result that diﬀers by at most a speciﬁed percentage from the
result that a corresponding original program produces (Misailovic et al., 2011; Zhu
et al., 2012). Alternatively, a potential accuracy property for our example program
might require the min to be within the smallest N/2 elements a[0]-a[N-1].
Such an accuracy property might be satisﬁed by, for example, a loop perforation
transformation that skips N/2-1 of the loop iterations.
In other research, we have developed techniques for reasoning about integrity
properties (Carbin et al., 2012, 2013a) and both worst-case and probabilistic accuracy
properties (Misailovic et al., 2011; Zhu et al., 2012; Carbin et al., 2012). We have
extended the research presented in this chapter to include combinations of reliability
and accuracy properties (Misailovic et al., 2014), and more recently to reason about
message-passing parallel programs with approximate communication (Fernando
et al., 2019).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

15.2 Example
537
15.1.3 Verifying Reliability (Contributions)
To meet the challenge of reasoning about reliability, we present a programming
language, Rely, and an associated program analysis that computes the quantitative
reliability of the computation - i.e., the probability with which the computation
produces a correct result when parts of the computation execute on unreliable
hardware. Speciﬁcally, given a hardware speciﬁcation and a Rely program, the
analysis computes, for each value that the computation produces, a conservative
probability that the value is computed correctly despite the possibility of soft errors.
Rely supports and is speciﬁcally designed to enable partitioning a program into
critical regions (which must execute without error) and approximate regions (which
can execute acceptably even in the presence of occasional errors) (Rinard, 2006;
Carbin and Rinard, 2010). In contrast to previous approaches, which support only a
binary distinction between critical and approximate regions, quantitative reliability
can provide precise static probabilistic acceptability guarantees for computations
that execute on unreliable hardware platforms. This chapter describes the following
contributions we initially presented in Carbin et al. (2013b).
Quantitative Reliability Speciﬁcations We present quantitative reliability speciﬁ-
cations, which characterize the probability that a program executed on unreliable
hardware produces the correct result, as a constructive method for developing
applications. Quantitative reliability speciﬁcations enable developers who build
applications for unreliable hardware architectures to perform sound and veriﬁed
reliability engineering.
Language We present Rely, a language that enables developers to specify reliability
requirements for programs that allocate data in unreliable memory regions and use
unreliable arithmetic/logical operations.
Quantitative Reliability Analysis We present a program analysis that veriﬁes
that the dynamic semantics of a Rely program satisﬁes its quantitative reliability
speciﬁcations. For each function, the analysis computes a symbolic reliability
precondition that characterizes the set of valid speciﬁcations for the function.
The analysis then veriﬁes that the developer-provided speciﬁcations are valid
according to the reliability precondition.
15.2 Example
Figure 15.1 presents the syntax of the Rely language. Rely is an imperative language
for computations over integers, ﬂoats (not presented), and multidimensional arrays.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

538
Carbin and Misailovic: Programming Unreliable Hardware
n
∈
IntM
r
∈
Q
x,ℓ
∈
Var
a
∈
ArrVar
e ∈Exp
→
n | x | (Exp) | Exp iop Exp
b ∈BExp
→
true | false | Exp cmp Exp | (BExp) |
BExp lop BExp | !BExp | !.BExp
CExp
→
e | a
m
∈
MVar
V
→
x | a | V, x | V,a
RSpec
→
r | R(V) | r * R(V)
T
→
int | int<RSpec>
F
→
(T | void) ID (P∗) { S }
P
→
P0 [in m]
P0
→
int x | T a(n)
S
→
D∗Ss S?
r
D
→
D0 [in m]
D0
→
int x [= Exp] | int a[n+]
Ss
→
skip | x = Exp | x = a[Exp+] | a[Exp+] = Exp |
ID(CExp∗) | x = ID(CExp∗) | ifℓBExp S S | S ; S
whileℓBExp [: n] S | repeatℓn S
Sr
→
return Exp
Figure 15.1 Rely's Language Syntax
To illustrate how a developer can use Rely, Figure 15.2 presents a Rely-based
implementation of a pixel block search algorithm derived from that in the x264
video encoder (x264, 2013).
The function search_ref searches a region (pblocks) of a previously encoded
video frame to ﬁnd the block of pixels that is most similar to a given block of pixels
(cblock) in the current frame. The motion estimation algorithm uses the results
of search_ref to encode cblock as a function of the identiﬁed block. This is an
approximate computation that can trade correctness for more eﬃcient execution
by approximating the search to ﬁnd a block. If search_ref returns a block that
is not the most similar, then the encoder may require more bits to encode cblock,
potentially decreasing the video's peak signal-to-noise ratio or increasing its size.
However, previous studies on soft error injection (de Kruijf et al., 2010) and more
aggressive transformations like loop perforation (Misailovic et al., 2010; Sidiroglou
et al., 2011) have demonstrated that the quality of x264's ﬁnal result is only slightly
aﬀected by perturbations of this computation.
15.2.1 Reliability Speciﬁcations
The function declaration on Line 6 speciﬁes the types and reliabilities of search_ref's
parameters and return value. The parameters of the function are pblocks(3), a
three-dimensional array of pixels, and cblock(2), a two-dimensional array of pix-
els. In addition to the standard signature, the function declaration contains reliability
speciﬁcations for each result that the function produces.
Rely's reliability speciﬁcations express the reliability of a function's results -
when executed on an unreliable hardware platform - as a function of the reliabil-
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

15.2 Example
539
i
1
#define nblocks 20
2
#define height
16
3
#define width
16
4
5
int<0.99*R(pblocks, cblock)>
6
search_ref (
7
int<R(pblocks)> pblocks(3) in urel,
8
int<R(cblock)> cblock(2) in urel)
9
{
10
int minssd = INT_MAX,
11
minblock = -1 in urel;
12
int ssd, t, t1, t2 in urel;
13
int i = 0, j, k;
14
15
repeat nblocks
{
16
ssd = 0;
17
j = 0;
18
repeat height {
19
k = 0;
20
repeat width {
21
t1 = pblocks[i,j,k];
22
t2 = cblock[j,k];
23
t = t1 -. t2;
24
ssd = ssd +. t *. t;
25
k = k + 1;
26
}
27
j = j + 1;
28
}
29
30
if (ssd <. minssd) {
31
minssd = ssd;
32
minblock = i;
33
}
34
35
i = i + 1;
36
}
37
return minblock;
38
}
Figure 15.2 Rely Code for Motion Estimation

	






Figure 15.3 Machine Model.
reliability spec {
operator (+.) = 1 - 10^-7;
operator (-.) = 1 - 10^-7;
operator (*.) = 1 - 10^-7;
operator (<.) = 1 - 10^-7;
memory rel {rd = 1, wr = 1};
memory urel {rd = 1 - 10^-7, wr = 1};
}
Figure 15.4 Hardware Reliability Speciﬁcation
(3)
{Q0 ∧Aret ≤r4
0 · R(i, ssd, minssd)
∧Aret ≤r4
0 · R( minblock, ssd, minssd)}
if (ssd <. minssd) {
(2)
{Q0 ∧Aret ≤r0 · R(i, ℓ30)}
minssd = ssd;
{Q0 ∧Aret ≤r0 · R(i, ℓ30)}
minblock = i;
{Q0 ∧Aret ≤r0 · R(minblock, ℓ30)}
} else {
(2)
{Q0 ∧Aret ≤r0 · R(minblock, ℓ30)}
skip;
{Q0 ∧Aret ≤r0 · R(minblock, ℓ30)}
}
(1)
{Q0 ∧Aret ≤r0 · R(minblock, ℓ30)}
Figure 15.5 if Statement Analysis in Last Iteration
ities of its inputs. The speciﬁcation for the reliability of search_ref's result is
int<0.99*R(pblocks,cblock)>. This states that the return value is an integer
with a reliability that is at least 99% of the joint reliability of the parameters
pblocks and cblock (denoted by R(pblocks, cblock)). The joint reliability
of a set of parameters is the probability that they all have the correct value when
passed in from the caller. The joint reliability is a key abstraction for our veriﬁcation;
we will formalize it in Section 15.4.2.
The reliability speciﬁcation holds for all possible values of the joint reliability
of pblocks and cblock. For instance, if the contents of the arrays pblocks and
cblock are fully reliable (correct with probability one), then the return value is
correct with probability 0.99.
In Rely, arrays are passed by reference and the execution of a function can, as
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

540
Carbin and Misailovic: Programming Unreliable Hardware
a side eﬀect, modify an array's contents. The reliability speciﬁcation of an array
therefore allows a developer to constrain the reliability degradation of its contents.
Here pblocks has an output reliability speciﬁcation of R(pblocks) (and similarly
for cblock), meaning that all of pblock's elements are at least as reliable when
the function exits as they were on entry to the function.
15.2.2 Unreliable Computation
Rely targets hardware architectures that expose both reliable operations (which
always execute correctly) and more energy-eﬃcient unreliable operations (which
execute correctly with only some probability). Speciﬁcally, Rely supports reasoning
about reads and writes of unreliable memory regions and unreliable arithmetic/logical
operations.
Memory Region Speciﬁcation Each parameter declaration also speciﬁes the mem-
ory region in which the data of the parameter is allocated. Memory regions correspond
to the physical partitioning of memory at the hardware level into regions of varying
reliability. Here pblocks and cblock are allocated in an unreliable memory region
named urel.
Lines 10-13 declare the local variables of the function. By default, variables in
Rely are allocated in a default, fully reliable memory region. However, a developer
can also optionally specify a memory region for each local variable. For example,
the variables declared on Lines 10-12 reside in urel.
Unreliable Operations The operations on Lines 23, 24, and 30 are unreliable
arithmetic/logical operations. In Rely, every arithmetic/logical operation has an
unreliable counterpart that is denoted by suﬃxing a period after the operation symbol.
For example, "-." denotes unreliable subtraction and "<." denotes unreliable
comparison.
Using these operations, search_ref's implementation approximately computes
the index (minblock) of the most similar block, i.e. the block with the minimum
distance from cblock. The repeat statement on line 15, iterates a constant
nblock number of times, enumerating over all previously encoded blocks. For
each encoded block, the repeat statements on lines 18 and 20 iterate over the
height*width pixels of the block and compute the sum of the squared diﬀerences
(ssd) between each pixel value and the corresponding pixel value in the current
block cblock. Finally, the computation on lines 30 through 33 selects the block
that is - approximately - the most similar to cblock.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

15.2 Example
541
15.2.3 Hardware Semantics
Figure 15.3 illustrates the conceptual machine model behind Rely's reliable and
unreliable operations; the model consists of a CPU and a memory.
CPU The CPU consists of (1) a register ﬁle, (2) arithmetic logical units that perform
operations on data in registers, and (3) a control unit that manages the program's
execution.
The arithmetic-logical unit can execute reliably or unreliably. We have represented
this in Figure 15.3 by physically separate reliable and unreliable functional units,
but this distinction can be achieved through other mechanisms, such as dual-voltage
architectures (Esmaeilzadeh et al., 2012). Unreliable functional units may omit
additional checking logic, enabling the unit to execute more eﬃciently but also
allowing for soft errors that may occur due to, for example, power variations within
the ALU's combinatorial circuits or particle strikes. As is provided by existing
computer architecture proposals (Sampson et al., 2011; Esmaeilzadeh et al., 2012),
the control unit of the CPU reliably fetches, decodes, and schedules instructions;
given a virtual address in the application, the control unit correctly computes a
physical address and operates only on that address.
Memory Rely supports machines with memories that consist of an arbitrary number
of memory partitions (each potentially of diﬀerent reliability), but for simplicity
Figure 15.3 partitions memory into two regions: reliable and unreliable. Unreliable
memories can, for example, use decreased DRAM refresh rates to reduce power
consumption at the expense of increased soft error rates (Liu et al., 2011; Sampson
et al., 2011).
Hardware Reliability Speciﬁcation
We abstract the behavior of the unreliable hardware platforms through a reliability
speciﬁcation. It speciﬁes the reliability of arithmetic/logical and memory operations.
Figure 15.4 presents a hardware reliability speciﬁcation that is inspired by the results
from existing computer architecture literature (Ernst et al., 2003; Liu et al., 2011).
Each entry speciﬁes the reliability - the probability of a correct execution - of
arithmetic operations (e.g., +.) and memory read/write operations.
For ALU operations, the presented reliability speciﬁcation uses the reliability
of an unreliable multiplication operation that we selected from Ernst et al. (2003,
Figure 9). For memory operations, the speciﬁcation uses the probability of a bit ﬂip
in a memory cell that we selected from Liu et al. (2011, Figure 4) with extrapolation
to the probability of a bit ﬂip within a 32-bit word. Note that a memory region
speciﬁcation includes two reliabilities: the reliability of a read (rd) and the reliability
of a write (wr).
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

542
Carbin and Misailovic: Programming Unreliable Hardware
15.2.4 Reliability Analysis
Given a Rely program, Rely's reliability analysis veriﬁes that each function in the
program satisﬁes its reliability speciﬁcation when executed on unreliable hardware.
The analysis takes as input a Rely program and a hardware reliability speciﬁcation.
The analysis consists of two components: the precondition generator and the
precondition checker. For each function, the precondition generator produces a
precondition that characterizes the reliability of the function's results given a
hardware reliability speciﬁcation that characterizes the reliability of each unreliable
operation. The precondition checker then determines if the function's speciﬁcations
satisfy the constraint. If so, then the function satisﬁes its reliability speciﬁcation
when executed on the underlying unreliable hardware in that the reliability of its
results exceed their speciﬁcations.
Design As a key design point, the analysis generates preconditions according to
a conservative approximation of the semantics of the function. Speciﬁcally, it
characterizes the reliability of a function's result according to the probability that
the function computes that result fully reliably.
To illustrate the intuition behind this design point, consider the evaluation of an
integer expression e. The reliability of e is the probability that it evaluates to the
same value n in an unreliable evaluation as in the fully reliable evaluation. There are
two ways that an unreliable evaluation can return n: (1) the unreliable evaluation of
e encounters no faults and (2) the unreliable evaluation possibly encounters faults,
but still returns n by chance.
Rely's analysis conservatively approximates the reliability of a computation by
only considering the ﬁrst scenario. This design point simpliﬁes the reasoning to
the task of computing the probability that a result is reliably computed as opposed
to reasoning about a computation's input distribution and the probabilities of all
executions that produce the correct result. As a consequence, the analysis requires as
input only a hardware reliability speciﬁcation that gives the probability with which
each arithmetic/logical operation and memory operation executes correctly. The
analysis is therefore oblivious to a computation's input distribution and does not
require a full model of how soft errors aﬀect its result.
Precondition Generator
For each function, Rely's analysis generates a reliability precondition that con-
servatively bounds the set of valid speciﬁcations for the function. A reliability
precondition is a conjunction of predicates of the form Aout ≤r · R(X), where Aout
is a placeholder for a developer-provided reliability speciﬁcation for an output with
name out, r is a numerical value between 0 and 1, and the term R(X) is the joint
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

15.2 Example
543
reliability of the set X of variables (including the function parameters) on entry to
the function.
The analysis starts at the end of the function from a postcondition that must be true
when the function returns and then works backward to produce a precondition such
that if the precondition holds before execution of the function, then the postcondition
holds at the end of the function.
Postcondition The postcondition for a function is the constraint that the reliability
of each array argument exceeds that given in its speciﬁcation. For search_ref, the
postcondition Q0 is
Q0 = Apblocks ≤R(pblocks) ∧Acblock ≤R(cblock),
which speciﬁes that the reliability of the arrays pblocks and cblock - R(pblocks)
and R(cblock) - should be at least that speciﬁed by the developer - Apblocks and
Acblock.
Precondition Generation The analysis of the body of the search_ref function
starts at the return statement. Given the postcondition Q0, the analysis creates a
new precondition Q1 by conjoining to Q0 a predicate that states that the reliability
of the return value (r0 · R( minblock)) is at least that of its speciﬁcation (Aret):
Q1 = Q0 ∧Aret ≤r0 · R(minblock).
The reliability of the return value is the probability of correctly reading minblock
from unreliable memory - which is r0 = 1 −10−7 according to the hardware
reliability speciﬁcation - multiplied by R(minblock), the probability that the
preceding computation correctly computed and stored minblock.
Loops The statement that precedes the return statement is the repeat statement
on Line 15. A key diﬃculty with reasoning about the reliability of variables
modiﬁed within a loop is that if a variable is updated unreliably and has a loop-
carried dependence then its reliability monotonically decreases as a function of the
number of loop iterations. Because the reliability of such variables can, in principle,
decrease arbitrarily in an unbounded loop, Rely provides both an unbounded loop
statement (with an associated analysis) and an alternative bounded loop statement
that lets a developer specify a compile-time bound on the maximum number of its
iterations that therefore bounds the reliability degradation of modiﬁed variables.
The loop on Line 15 iterates nblocks times and therefore decreases the reliability
of any modiﬁed variables nblocks times. Because the reliability degradation is
bounded, Rely's analysis uses unrolling to reason about the eﬀects of a bounded
loop.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

544
Carbin and Misailovic: Programming Unreliable Hardware
Conditionals The analysis of the body of the loop on Line 15 encounters the if
statement on Line 30.1 This if statement uses an unreliable comparison operation
on ssd and minssd, both of which reside in unreliable memory. The reliability of
minblock when modiﬁed on Line 32 therefore also depends on the reliability of
this expression because faults may force the execution down a diﬀerent path.
Figure 15.5 presents a Hoare logic style presentation of the analysis of the
conditional statement. The analysis works in three steps; the preconditions generated
by each step are numbered with the corresponding step.
Step 1 To capture the implicit dependence of a variable on an unreliable condition,
Rely's analysis ﬁrst uses latent control ﬂow variables to make these dependencies
explicit. A control ﬂow variable is a unique program variable (one for each statement)
that records whether the conditional evaluated to true or false. We denote the control
ﬂow variable for the if statement on Line 30 by ℓ30.
To make the control ﬂow dependence explicit, the analysis adds the control ﬂow
variable to all joint reliability terms in Q1 that contain variables modiﬁed within the
body of the if conditional (minssd and minblock).
Step 2 The analysis next recursively analyses both the "then" and "else" branches
of the conditional, producing one precondition for each branch. As in a standard pre-
condition generator (e.g., weakest-preconditions) the assignment of i to minblock
in the "then" branch replaces minblock with i in the precondition. Because reads
from i and writes to minblock are reliable (according to the speciﬁcation) the
analysis does not introduce any new r0 factors.
Step 3 In the ﬁnal step, the analysis leaves the scope of the conditional and conjoins
the two preconditions for its branches after transforming them to include the direct
dependence of the control ﬂow variable on the reliability of the if statement's
condition expression.
The reliability of the if statement's expression is greater than or equal to the
product of (1) the reliability of the <. operator (r0), (2) the reliability of reading
both ssd and minssd from unreliable memory (r2
0), and (3) the reliability of
the computation that produced ssd and minssd (R(ssd,minssd)). The analysis
therefore transforms each predicate that contains the variable ℓ30, by multiplying the
right-hand side of the inequality with r3
0 and replacing the variable ℓ30 with ssd and
minssd.
This produces the precondition Q2:
Q2 = Q0 ∧Aret ≤r4
0 · R(i,ssd,minssd) ∧Aret ≤r4
0 · R(minblock,ssd,minssd).
1 This happens after encountering the increment of i on Line 35, which does not modify the current precondition
because it does not reference i.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

15.2 Example
545
Simpliﬁcation After unrolling a single iteration of the loop that begins at Line 15,
the analysis produces
Q0 ∧Aret ≤r2564
0
· R(pblocks,cblock,i,ssd,minssd)
as the precondition for a single iteration of the loop's body. The constant 2564
represents the number of unreliable operations within a single loop iteration.
Note that there is one less predicate in this precondition than in Q2. As the analysis
works backwards through the program, it uses a simpliﬁcation technique that identiﬁes
that a predicate Aret ≤r1 · R(X1) subsumes another predicate Aret ≤r2 · R(X2).
Speciﬁcally, the analysis identiﬁes that r1 ≤r2 and X2 ⊆X1, which together mean
that the second predicate is a weaker constraint on Aret than the ﬁrst and can therefore
be removed. This follows from the fact that the joint reliability of a set of variables
is less than or equal to the joint reliability of any subset of the variables - regardless
of the distribution of their values.
This simpliﬁcation is how Rely's analysis achieves scalability when there are
multiple paths in the program. Speciﬁcally, the simpliﬁed precondition is a lower
bound of the reliability speciﬁcation of all its program paths.
Final Precondition When the analysis reaches the beginning of the function
after fully unrolling the loop on Line 15, it has a precondition that bounds the
set of valid speciﬁcations as a function of the reliability of the parameters of the
function. For search_ref, the analysis generates the precondition Aret ≤0.994885·
R(pblocks,cblock) ∧Apblocks ≤R(pblocks) ∧Acblock ≤R(cblock).
Precondition Checker
The ﬁnal precondition is a conjunction of predicates of the form Aout ≤r · R(X),
where Aout is a placeholder for the reliability speciﬁcation of an output. Because
reliability speciﬁcations are all of the form r · R(X) (Figure 15.1), each predicate
in the ﬁnal precondition (where each Aout is replaced with its speciﬁcation) is of
the form form r1 · R(X1) ≤r2 · R(X2), where r1 · R(X1) is a reliability speciﬁcation
and r2 · R(X2) is computed by the analysis. Similar to the analysis's simpliﬁer
(Section 15.2.4), the precondition checker veriﬁes the validity of each predicate by
checking that (1) r1 is less than r2 and (2) X2 ⊆X1.
For search_ref, the analysis computes the predicates
0.99 · R(pblocks,cblock) ≤0.994885 · R(pblocks,cblock),
R(pblocks) ≤R( pblocks), and also R(cblock) ≤R(cblock).
Because these predicates are valid according to the checking procedure, search_ref
satisﬁes its reliability speciﬁcation when executed.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

546
Carbin and Misailovic: Programming Unreliable Hardware
15.3 Language Semantics
Because soft errors may probabilistically change the execution path of a program,
we model the semantics of a Rely program with a probabilistic transition system.
Speciﬁcally, the dynamic semantics deﬁnes probabilistic transition rules for each
arithmetic/logical operation and each read/write on an unreliable memory region.
Over the next several sections, we develop a small-step semantics that speciﬁes
the probability of each individual transition of an execution. In Section 15.3.4, we
provide big-step deﬁnitions that specify the probability of an entire execution.
15.3.1 Preliminaries
Rely's semantics is given in the terms of an abstract machine that consists of a heap
and a stack. The heap is an abstraction over the physical memory of the concrete
machine, including its various reliable and unreliable memory regions. Each variable
(both scalar and array) is allocated in the heap. The stack consists of frames - one
for each function invocation - which contain references to the locations of each
allocated variable. This conceptual model of local variables does not need to be
concretized in the compilation model. For example, placing local variables in a
reliable stack can achieve competitive performance (Misailovic et al., 2014).
Hardware Reliability Speciﬁcation A hardware reliability speciﬁcation ψ ∈Ψ =
(iop + cmp + lop + Mop) →Q≥0 is a ﬁnite map from arithmetic/logical opera-
tions (iop,cmp,lop) and memory region operations (Mop) to reliabilities (i.e., the
probability that the operation executes correctly).
Arithmetic/logical operations iop, cmp, and lop include both reliable and unreliable
versions of each integer, comparison, and logical operation. The reliability of each
reliable operation is 1 and the reliability of an unreliable operation is as provided by
a speciﬁcation (Section 15.2.3).
The ﬁnite maps rd ∈M →Mop and wr ∈M →Mop deﬁne memory region
operations as reads and writes (respectively) on memory regions m ∈M, where M
is the set of all memory regions in the reliability speciﬁcation.
The hardware reliability speciﬁcation 1ψ denotes the speciﬁcation for fully reliable
hardware in which all arithmetic/logical and memory operations have reliability 1.
References Given a ﬁnite, contiguous address space Loc, a reference is a tuple
⟨nb, ⟨n1,. . .,nk⟩,m⟩∈Ref consisting of a base address nb ∈Loc, a dimension
descriptor ⟨n1,. . .,nk⟩, and a memory region m. Base addresses and the components
of dimension descriptors range over the ﬁnite set of bounded-width machine integers
n ∈IntM.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

15.3 Language Semantics
547
References describe the location, dimensions, and memory region of variables
in the heap. For scalars, the dimension descriptor is the single-dimension, single-
element descriptor ⟨1⟩. The projections πbase and πdim select the base address and
the dimension descriptor of a reference, respectively.
Frames, Stacks, Heaps, and Environments A frame σ ∈Σ = Var →Ref is a
ﬁnite map from variables to references. A stack δ ∈Δ ::= σ | σ :: Δ is a non-empty
list of frames. A heap h ∈H = Loc →IntM is a ﬁnite map from addresses to
machine integers. An environment ε ∈E = Δ × H is a stack and heap pair, ⟨δ, h⟩.
Memory Allocator The abstract memory allocator new is a partial function that
executes reliably. It takes a heap h, a memory region m, and a dimension descriptor
and returns a fresh address nb that resides in memory region m and a new heap h′
that reﬂects updates to the internal memory allocation data structures.
Auxiliary Probability Distributions Each nondeterministic choice in Rely's se-
mantics must have an underlying probability distribution so that the set of possible
transitions at any given small step of an execution constitutes a probability distri-
bution - i.e., the probabilities of all possibilities sum up to one. In Rely, there are
two points at which an execution can make a nondeterministic choice: (1) the result
of an incorrect execution of an unreliable operation and (2) the result of allocating
a new variable in the heap.
The discrete probability distribution Pf (nf | op,n1,...,nk) models the manifesta-
tion of a soft error during an incorrect execution of an operation. Speciﬁcally, it gives
the probability that an incorrect execution of an operation op on operands n1,. . .,nk
produces a value nf that is diﬀerent from the correct result of the operation. This
distribution is inherently tied to the properties of the underlying hardware.
The discrete probability distribution Pm(nb, h′ | h,m, d) models the semantics
of a nondeterministic memory allocator. It gives the probability that a memory
allocator returns a fresh address nb and an updated heap h′ given an initial heap h, a
memory region m, and a dimension descriptor d.
We deﬁne these distributions only to support a precise formalization of the
dynamic semantics of a program; they do not need to be speciﬁed for a given
hardware platform or a given memory allocator to use Rely's analysis.
15.3.2 Semantics of Expressions
Figure 15.6 presents a selection of the rules for the dynamic semantics of integer
expressions. The labeled probabilistic small-step evaluation relation ⟨e,σ, h⟩
θ, p
−→ψ e′
states that from a frame σ and a heap h, an expression e evaluates in one step with
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

548
Carbin and Misailovic: Programming Unreliable Hardware
E-Var-C
⟨nb, ⟨1⟩, m⟩= σ(x)
⟨x, σ, h⟩
C, ψ(rd(m))
−→ψ
h(nb)
E-Var-F
⟨nb, ⟨1⟩, m⟩= σ(x)
p = (1 −ψ(rd(m))) · Pf (nf | rd(m), h(nb))
⟨x, σ, h⟩
⟨F,n f ⟩, p
−→ψ
nf
E-Iop-R1
⟨e1, σ, h⟩
θ , p
−→ψ e′
1
⟨e1 iop e2, σ, h⟩
θ , p
−→ψ e′
1 iop e2
E-Iop-R2
⟨e2, σ, h⟩
θ , p
−→ψ e′
2
⟨n iop e2, σ, h⟩
θ , p
−→ψ n iop e′
2
E-Iop-C
⟨n1 iop n2, σ, h⟩
C, ψ(iop)
−→ψ
iop(n1, n2)
E-Iop-F
p = (1 −ψ(iop)) · Pf (nf | iop, n1, n2)
⟨n1 iop n2, σ, h⟩
⟨F,n f ⟩, p
−→ψ
nf
Figure 15.6 Dynamic Semantics of Integer Expressions
probability p to an expression e′ given a hardware reliability speciﬁcation ψ. The
label θ ∈{C, ⟨C,n⟩, ⟨F,nf ⟩} denotes whether the transition corresponds to a correct
(C or ⟨C,n⟩) or a faulty (⟨F,nf ⟩) evaluation of that step. For a correct transition
⟨C,n⟩, n ∈IntM records a nondeterministic choice made for that step. For a faulty
transition ⟨F,nf ⟩, nf ∈IntM represents the value that the fault introduced in the
semantics of the operation.
To illustrate the meaning of the rules, consider the rules for variable reference
expressions. A variable reference x reads the value stored in the memory address for
x. A variable reference can be evaluated in two ways:
• Correct [E-Var-C]. The variable reference evaluates correctly and successfully
returns the integer stored in x. This happens with probability ψ(rd(m)), where m
is the memory region in which x allocated. This probability is the reliability of
reading from x's memory region.
• Faulty [E-Var-F]. The variable reference experiences a fault and returns another
integer nf . The probability that the faulty execution returns a speciﬁc integer
nf is (1 −ψ(rd(m))) · Pf (nf | rd(m), h(nb)). Pf is the distribution that gives the
probability that a failed memory read operation returns a value nf instead of the
true stored value h(nb) (Section 15.3.1).
15.3.3 Semantics of Statements
Figure 15.7 presents the semantics of the scalar and control ﬂow fragment of Rely.
The labeled probabilistic small-step execution relation ⟨s,ε⟩
θ, p
−→ψ ⟨s′,ε′⟩states
that execution of the statement s in the environment ε takes one step yielding a
statement s′ and an environment ε′ with probability p under the hardware reliability
speciﬁcation ψ. As in the dynamic semantics for expressions, a label θ denotes
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

15.3 Language Semantics
549
E-Decl-R
⟨e, σ, h⟩
θ , p
−→ψ e′
⟨int x = e in m, ⟨σ :: δ, h⟩⟩
θ , p
−→ψ ⟨int x = e′ in m, ⟨σ :: δ, h⟩⟩
E-Decl
⟨nb, h′⟩= new(h, m, ⟨1⟩)
pm = Pm(nb, h′ | h, m, ⟨1⟩)
⟨int x = n in m, ⟨σ :: δ, h⟩⟩
⟨C,nb⟩, pm
−→ψ
⟨x = n, ⟨σ[x →⟨nb, ⟨1⟩, m⟩] :: δ, h′⟩⟩
E-Assign-R
⟨e, σ, h⟩
θ , p
−→ψ e′
⟨x = e, ⟨σ :: δ, h⟩⟩
θ , p
−→ψ ⟨x = e′, ⟨σ :: δ, h⟩⟩
E-Assign-C
⟨nb, ⟨1⟩, m⟩= σ(x)
p = ψ(wr(m))
⟨x = n, ⟨σ :: δ, h⟩⟩
C, p
−→ψ ⟨skip, ⟨σ :: δ, h[nb →n]⟩⟩
E-Assign-F
⟨nb, ⟨1⟩, m⟩= σ(x)
p = (1 −ψ(wr(m))) · Pf (nf | wr(m), h(nb), n)
⟨x = n, ⟨σ :: δ, h⟩⟩
⟨F,n f ⟩, p
−→ψ
⟨skip, ⟨σ :: δ, h[nb →nf ]⟩⟩
E-If
⟨b, σ, h⟩
θ , p
−→ψ b′
⟨ifℓb s1 s2, ⟨σ :: δ, h⟩⟩
θ , p
−→ψ ⟨ifℓb′ s1 s2, ⟨σ :: δ, h⟩⟩
E-If-True
⟨ifℓtrue s1 s2, ε⟩
C, 1
−→ψ ⟨s1, ε⟩
E-If-False
⟨ifℓfalse s1 s2, ε⟩
C, 1
−→ψ ⟨s2, ε⟩
E-Seq-R1
⟨s1, ε⟩
θ , p
−→ψ ⟨s′
1, ε′⟩
⟨s1 ; s2, ε⟩
θ , p
−→ψ ⟨s′
1 ; s2, ε′⟩
E-Seq-R2
⟨skip ; s2, ε⟩
C, 1
−→ψ ⟨s2, ε⟩
E-While
⟨whileℓb s, ε⟩
C, 1
−→ψ ⟨ifℓb {s ; whileℓb s} {skip}, ε⟩
E-While-Bounded
⟨whileℓb : n s, ε⟩
C, 1
−→ψ ⟨ifℓb {s ; whileℓb : (n −1) s} {skip}, ε⟩
Figure 15.7 Dynamic Semantics of Statements
whether the transition evaluated correctly (C or ⟨C,n⟩) or experienced a fault
(⟨F,nf ⟩). The semantics of the statements in the language is largely similar to that
of traditional presentations except that the statements have the ability to encounter
faults during execution.
The semantics we present here is designed to allow unreliable computation at
all points in the application - subject to the constraint that the application is still
memory safe and exhibits control ﬂow integrity.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

550
Carbin and Misailovic: Programming Unreliable Hardware
Memory Safety To protect references that point to memory locations from cor-
ruption, the stack is allocated in a reliable memory region and stack operations
- i.e., pushing and popping frames - execute reliably. To prevent out-of-bounds
memory accesses that may occur due to an unreliable array index computation, Rely
requires that each array read and write include a bounds check. These bounds check
computations execute reliably. We presented the semantics of memory accesses
in Carbin et al. (n.d.).
Control Flow Integrity To prevent execution from taking control ﬂow edges that
do not exist in the program's static control ﬂow graph, Rely assumes that (1)
instructions are stored, fetched, and decoded reliably (as supported by existing
unreliable processor architectures (Sampson et al., 2011; Esmaeilzadeh et al., 2012))
and (2) targets of control ﬂow branches are reliably computed. These two properties
allow for the control ﬂow transfers in the rules [E-If-True], [E-If-False], and
[E-Seq-R2] to execute reliably with probability 1.
Note that the semantics does not require a speciﬁc underlying mechanism to
achieve reliable execution and, therefore, an implementation can use any applicable
software or hardware technique (Reis et al., 2005; Perry et al., 2007; de Kruijf et al.,
2010; Feng et al., 2010; Pattabiraman et al., 2008; Schlesinger et al., 2011; Hiller
et al., 2002; Thomas and Pattabiraman, 2013).
15.3.4 Big-step Notations
We use the following big-step execution relations in this paper.
Deﬁnition 15.1 (Big-step Trace Semantics).
⟨s,ε⟩
τ, p
=⇒ψ ε′ ≡⟨s,ε⟩
θ1, p1
−→ψ . . .
θn, pn
−→ψ ⟨skip,ε′⟩
where τ = θ1,. . .,θn and p = Π
i pi
The big-step trace semantics is, conceptually, a reﬂexive transitive closure
of the small-step execution relation that records a trace of the execution. We
deﬁne a trace, τ ∈T ::= · | θ :: T, as the sequence of small-step transition labels,
τ = θ1 :: ... :: θn :: ·. The probability of a trace, p, is the product of the probabilities
of each transition, p = /n
i=1 pi.
Deﬁnition 15.2 (Big-step Aggregate Semantics).
⟨s,ε⟩
p
=⇒ψ ε′ where p = 	 {{pτ | ∃τ ∈T.⟨s,ε⟩
τ, pτ
=⇒ψ ε′}}
The big-step aggregate semantics computes the aggregate probability (over all
ﬁnite length traces) that a statement s evaluates to an environment ε′ from an
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

15.4 Semantics of Quantitative Reliability
551
environment ε given a hardware reliability speciﬁcation ψ. The big-step aggregate
semantics therefore gives the total probability that a statement s starts from an
environment ε and terminates in an environment ε′.2
Termination and Errors An unreliable execution of a statement may experience
a run-time error (due to an out-of-bounds array access) or not terminate at all.
The big-step aggregate semantics does not collect such executions. Therefore, the
sum of the probabilities of the big-step transitions from an environment ε may not
equal to 1. Speciﬁcally, let p ∈E →R≥0 be a measure for the set of environments
reachable from ε, i.e., ∀ε′.⟨s,ε⟩
p(ε′)
=⇒ψ ε′. Then p is subprobability measure, i.e.,
0 ≤	
ε′∈E p(ε′) ≤1 (Kozen, 1981).
15.4 Semantics of Quantitative Reliability
We next present deﬁnitions that give a semantic meaning to the reliability of a Rely
program.
15.4.1 Paired Execution
The paired execution semantics is the primary execution relation that enables one to
reason about the reliability of a program. Speciﬁcally, the relation pairs the semantics
of the program when executed reliably with its semantics when executed unreliably.
Deﬁnition 15.3 (Paired Execution).
ϕ ∈Φ = E →R≥0
⟨s, ⟨ε, ϕ⟩⟩⇓ψ ⟨ε′, ϕ′⟩such that ⟨s,ε⟩
1
=⇒1ψ ε′ and
ϕ′(ε′
u) = 	 {{ϕ(εu) · pu | εu ∈E, ⟨s,εu⟩
pu
=⇒ψ ε′
u}}
The relation states that from a conﬁguration ⟨ε, ϕ⟩consisting of an environment
ε and an unreliable environment distribution ϕ, the paired execution of a statement
s yields a new conﬁguration ⟨ε′, ϕ′⟩.
The environments ε and ε′ are related by the fully reliable execution of s. Namely,
an execution of s from an environment ε yields ε′ under the fully reliable hardware
model 1ψ.
The unreliable environment distributions ϕ and ϕ′ are probability mass functions
that map an environment to the probability that the unreliable execution of the
program is in that environment. In particular, ϕ is a distribution on environments
before the unreliable execution of s whereas ϕ′ is the distribution on environments
2 The inductive (versus co-inductive) interpretation of T yields a countable set of ﬁnite-length traces and therefore
the sum over T is well-deﬁned.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

552
Carbin and Misailovic: Programming Unreliable Hardware
P ∈P(E × Φ)
true = E × Φ
false = ∅
P1 ∧P2 = P1 ∩P2
R1 ≤R2 = {⟨ε, ϕ⟩| R1(ε, ϕ) ≤R2(ε, ϕ)}
R ∈E × Φ →R≥0
r(ε, ϕ) = r
R1 · R2(ε, ϕ) = R1(ε, ϕ) · R2(ε, ϕ)
R(X)(ε, ϕ) =

εu ∈E(X ,ε)
ϕ(εu)
E ∈P(Var + ArrVar) × E →P(E)
E(X, ε) = {ε′ | ε′ ∈E ∧∀v. v ∈X ⇒equiv(ε′, ε, v)})
equiv(⟨σ′ :: δ′, h′⟩, ⟨σ :: δ, h⟩, v) = ∀i . 0 ≤i < len(v, σ) ⇒h′(πbase(σ′(v)) + i) = h(πbase(σ(v)) + i)
len(v, σ) = let ⟨n0, . . . , nk ⟩= πdim(σ(v)) in
C
0≤i≤k
ni
Figure 15.8 Predicate Semantics
after executing s. These distributions specify the probability of reaching a speciﬁc
environment as a result of faults during the execution.
The unreliable environment distributions are discrete because E is a countable
set (Lemma 15.4). Therefore, ϕ′ can be deﬁned pointwise: for any environment
ε′
u ∈E, the value of ϕ′(ε′
u) is the probability that the unreliable execution of the
statement s results in the environment ε′
u given the distribution on possible starting
environments, ϕ, and the aggregate probability pu of reaching ε′
u from any starting
environment εu ∈E according to the big-step aggregate semantics. In general, ϕ′ is a
subprobability measure because it is deﬁned using the big-step aggregate semantics,
which is also a subprobability measure (Section 15.3.4).
Lemma 15.4 (Discrete Distribution). The probability space of unreliable environ-
ments (E, ϕ) is discrete.
Sketch
A probability distribution is discrete if it is deﬁned on a countable sample
space. Therefore, we need to prove that the set E is countable. We can accomplish
it by proving that both the stack and the heap are countable. We demonstrate the
former by observing that the number of variables in each stack frame is ﬁnite, and
the number of frames is countable. We demonstrate the latter by noting that the
number of locations is ﬁnite, and each is of the ﬁnite size. Full proof is available
in Carbin et al. (n.d.).
□
15.4.2 Reliability Predicates and Transformers
The paired execution semantics enables a deﬁnition of the semantics of statements as
transformers on reliability predicates that bound the reliability of program variables.
A reliability predicate P is a predicate of the form:
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

15.4 Semantics of Quantitative Reliability
553
P
→
true | false | R ≤R | P ∧P
R
→
r | R(X) | R · R
A predicate can either be the constant true, the constant false, a comparison
between reliability factors (R), or a conjunction of predicates. A reliability factor
is real-valued quantity that is either a rational constant r in the range [0,1]; a joint
reliability factor R(X) that gives the probability that all program variables in the
set X have the same value in the unreliable execution as they have in the reliable
execution; or a product of reliability factors, R · R.
This combination of predicates and reliability factors enables a developer to specify
bounds on the reliability of variables in the program, such as 0.99999 ≤R({x}),
which states that the probability that x has the correct value in an unreliable execution
is at least 0.99999.
Semantics of Reliability Predicates.
Figure 15.8 presents the denotational semantics of reliability predicates via the
semantic function P. The denotation of a reliability predicate is the set of
conﬁgurations that satisfy the predicate. A key new element in the semantics of this
predicate language is the semantics of joint reliability factors.
Joint Reliability Factor A joint reliability factor R(X) represents the probability
that an unreliable environment εu sampled from the unreliable environment distri-
bution ϕ has the same values for all variables in the set X as that in the reliable
environment ε. To deﬁne this probability, we use the function E(X,ε), which gives
the set of environments that have the same values for all variables in X as in the
environment ε. The denotation of a joint reliability factor is then the sum of the
probabilities of each of these environments according to ϕ.
Auxiliary Deﬁnitions We deﬁne predicate satisfaction and validity as:
⟨ε, ϕ⟩|= P
≡
⟨ε, ϕ⟩∈P
|= P
≡
∀ε.∀ϕ. ⟨ε, ϕ⟩|= P
Reliability Transformer
Given a semantics for predicates, it is now possible to view the paired execution of a
program as a reliability transformer - namely, a transformer on reliability predicates
that is reminiscent of Dijkstra's Predicate Transformer Semantics (Dijkstra, 1975).
Deﬁnition 15.5 (Reliability Transformer).
ψ |= {P} s {Q} ≡
∀ε.∀ϕ.∀ε′.∀ϕ′. (⟨ε, ϕ⟩|= P ∧⟨s, ⟨ε, ϕ⟩⟩⇓ψ ⟨ε′, ϕ′⟩) ⇒⟨ε′, ϕ′⟩|= Q
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

554
Carbin and Misailovic: Programming Unreliable Hardware
The paired execution of a statement s is a transformer on reliability predicates,
denoted ψ |= {P} s {Q}. Speciﬁcally, the paired execution of s transforms P to Q if
for all ⟨ε, ϕ⟩that satisfy P and for all ⟨ε′, ϕ′⟩yielded by the paired execution of s
from ⟨ε, ϕ⟩, ⟨ε′, ϕ′⟩satisﬁes Q. The paired execution of s transforms P to Q for any
P and Q where this relationship holds.
Reliability predicates and reliability transformers enable Rely to use symbolic
predicates to characterize and constrain the shape of the unreliable environment
distributions before and after execution of a statement. This approach provides a
well-deﬁned domain in which to express Rely's reliability analysis as a generator
of constraints on the shape of the unreliable environment distributions for which a
function still satisﬁes its speciﬁcation.
15.5 Reliability Analysis
For each function in a program, Rely's reliability analysis generates a symbolic
reliability precondition with a precondition generator style analysis. The reliability
precondition is a reliability predicate that constrains the set of speciﬁcations that are
valid for the function. Speciﬁcally, the reliability precondition is the conjuction of the
terms of the form Ri ≤Rj where Ri is the reliability factor for a developer-provided
speciﬁcation of a function output and Rj is a reliability factor that gives a conservative
lower bound on the reliability of that output. If the reliability precondition is valid,
then the developer-provided speciﬁcations are valid for the function.
15.5.1 Preliminaries
Transformed Semantics We formalize Rely's analysis over a transformed seman-
tics of the program that is produced via a source-to-source transformation function
T that performs two transformations:
• Conditional Flattening: Each conditional has a unique control ﬂow variable ℓ
associated with it that T uses to ﬂatten a conditional of the form ifℓ(b) {s1} {s2}
to the sequence ℓ= b ; ifℓ(ℓ) {s1} {s2}. This transformation reiﬁes the control
ﬂow variable as an explicit program variable that records the value of the
conditional.
• SSA: The transformation function also transforms a Rely program to a SSA
renamed version of the program. The φ-nodes for a conditional include a reference
to the control ﬂow variable for the conditional. For example, T transforms a
sequence of statements of the form
ℓ= b ; ifℓ(ℓ) {x = 1} {x = 2}
to the sequence of statements
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

15.5 Reliability Analysis
555
ℓ= b ; ifℓ(ℓ) {x1 = 1} {x2 = 2} ; x = φ(ℓ, x1, x2).
We rely on standard treatments for the semantics of φ-nodes (Barthe et al., 2012)
and arrays (Knobe and Sarkar, 1998). We also note that T applies the SSA
transformation such that a reference of a parameter at any point in the body of the
function refers to its initial value on entry to the function. This property naturally
gives a function's reliability speciﬁcations a semantics that refers to the reliability
of variables on entry to the function.
These two transformations together make explicit the dependence between the
reliability of a conditional's control ﬂow variable and the reliability of variables
modiﬁed within.
Auxiliary Maps The map Λ ∈Var →M is a map from program variables to their
declared memory regions. We compute this map by inspecting the parameter and
variable declarations in the function. The map Γ ∈Var →R is the unique map from
the outputs of a function - namely, the return value and arrays passed as parameters
- to the reliability factors (Section 15.4.2) for the developer-provided speciﬁcation of
each output. We allocate a fresh variable named ret that represents the return value
of the program.
Substitution A substitution e0[e2/e1] replaces all occurrences of the expression e1
with the expression e2 within the expression e0. Multiple substitution operations are
applied from left to right. The substitution matches set patterns. For instance, the
pattern R({x} ∪X) represents a joint reliability factor that contains the variable x,
alongside with the remaining variables in the set X. Then, the result of the substitution
r1 · R({x, z})[r2 · R({y} ∪X)/R({x} ∪X)] is the expression r1 · r2 · R({y, z}).
15.5.2 Precondition Generation
The analysis generates preconditions according to a conservative approximation of
the paired execution semantics. Speciﬁcally, it characterizes the reliability of a value
in a function according to the probability that the function computes that value -
including its dependencies - fully reliably given a hardware speciﬁcation.
Figure 15.9 presents a selection of Rely's reliability precondition generation rules.
The generator takes as input a statement s, a postcondition Q, and (implicitly) the
maps Λ and Γ. The generator produces as output a precondition P, such that if P
holds before the paired execution of s, then Q holds after.
We have designed the analysis so that Q is the constraint over the developer-
provided speciﬁcations that must hold at the end of execution of a function. Because
arrays are passed by reference in Rely and can therefore be modiﬁed, one property
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

556
Carbin and Misailovic: Programming Unreliable Hardware
ρ ∈(Exp + BExp) →Q≥0 × P(Var)
ρ(n) = (1, ∅)
ρ(x) = (ψ(rd(Λ(x))), {x})
ρ(e1 iop e2) = (ρ1(e1) · ρ1(e2) · ψ(iop) , ρ2(e1) ∪ρ2(e2))
ρ1(e) = π1(ρ(e))
ρ2(e) = π2(ρ(e))
RPψ
∈
S × P →P
RPψ(return e, Q)
=
Q ∧Γ(ret) ≤ρ1(e) · R(ρ2(e))
RPψ(x = e, Q)
=
Q [(ρ1(e) · ψ(wr(Λ(x)))·
R(ρ2(e) ∪X))/R({x} ∪X)]
RPψ(x = a[e1, . . . , en], Q)
=
Q [ ((/
i
ρ1(ei)) · ψ(rd(Λ(a))) · ψ(wr(Λ(x)))·
R({a} ∪(
i
ρ2(ei)) ∪X))/R({x} ∪X)]
RPψ(a[e1, . . . , en] = e, Q)
=
Q [ (ρ1(e) · (/
i
ρ1(ei)) · ψ(wr(Λ(a)))·
R(ρ2(e) ∪(
i
ρ2(ei)) ∪{a} ∪X))/ R({a} ∪X)]
RPψ(skip, Q)
=
Q
RPψ(s1 ; s2, Q)
=
RPψ(s1, RPψ(s2, Q))
RPψ(ifℓℓs1 s2, Q)
=
RPψ(s1, Q) ∧RPψ(s2, Q)
RPψ(x = φ(ℓ, x1, x2), Q)
=
Q [R({ℓ, x1} ∪X)/R({x} ∪X)]∧
Q[R({ℓ, x2} ∪X)/R({x} ∪X)]
RPψ(whileℓb : 0 s, Q)
=
Q
RPψ(whileℓb : n s, Q)
=
RPψ(T(ifℓn b {s ; whileℓb : (n −1) s} skip), Q)
RPψ(int x = e in m, Q)
=
RPψ(x = e, Q)
RPψ(int a[n0, . . . , nk ] in m, Q)
=
Q [R(X)/R({a} ∪X)]
Figure 15.9 Reliability Precondition Generation
that must hold at the end of execution of a function is that each array must be at
least as reliable as implied by its speciﬁcation. The analysis captures this property
by setting the initial Q for the body of a function to
D
ai
Γ(ai) ≤R(a′
i)
where ai is the i-th array parameter of the function and a′
i is an SSA renamed
version of the array that contains the appropriate value of ai at the end of the function.
This constraint therefore states that the reliability implied by the speciﬁcations must
be less than or equal to the actual reliability of each input array at the end of the
function. As the precondition generator works backwards through the function, it
generates a new precondition that - if valid at the beginning of the function - ensures
that Q holds at the end.
Reasoning about Expressions
The topmost part of Figure 15.9 ﬁrst presents the rules for reasoning about the
reliability of evaluating an expression. The reliability of evaluating an expression
depends on two factors: (1) the reliability of the operations in the expression
and (2) the reliability of the variables referenced in the expression. The function
ρ ∈(Exp + BExp) →Q≥0 × P(Var) computes the core components of these two
factors. It returns a pair consisting of (1) the probability of correctly executing
all operations in the expression and (2) the set of variables referenced by the
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

15.5 Reliability Analysis
557
expression. The projections ρ1 and ρ2 return each component, respectively. Using
these projections, the reliability of an expression e - given any reliable environment
and unreliable environment distribution - is therefore at least ρ1(e)·R(ρ2(e)), where
R(ρ2(e)) is the joint reliability of all the variables referenced in e. The rules for
boolean and relational operations are deﬁned analogously.
Generation Rules for Statements
As in a precondition generator, the analysis works backwards from the end of
the program to the beginning. We have therefore structured the discussion of the
statements starting with function returns.
Function Returns When execution reaches a function return, return e, the
analysis must verify that the reliability of the return value is greater than the
reliability that the developer speciﬁed. To verify this, the analysis rule generates the
additional constraint Γ(ret) ≤ρ1(e) · R(ρ2(e)). This constrains the reliability of the
return value, where Γ(ret) is the reliability speciﬁcation for the return value.
Assignment For the program to satisfy a predicate Q after the execution of an
assignment statement x = e, then Q must hold given a substitution of the reliability
of the expression e for the reliability of x. The substitution Q[(ρ1(e) · ψ(wr(Λ(x))) ·
R(ρ2(e)∪X))/R({x}∪X)] binds each reliability factor in which x occurs - R({x}∪X)
- and replaces the factor with a new reliability factor R(ρ2(e) ∪X) where ρ2(e) is
the set of variables referenced by e.
The substitution also multiplies the reliability factor by ρ1(e)·ψ(wr(Λ(x))), which
is the probability that e evaluates fully reliably and its value is reliably written to the
memory location for x.
Array loads and stores The reliability of a load, x = a[e1,. . .,en], depends on
the reliability of the indices e1,. . .,en, the reliability of the values stored in a, and
the reliability of reading from a's memory region. The rule's implementation is
similar to that for assignment.
The reliability of an array store a[e1,. . .,en] = e depends on the reliability of the
source expression e, the reliability of the indices e1,. . .,en , and the reliability of
writing to a. Note that the rule preserves the presence of a within the reliability term.
By doing so, the rule ensures that it tracks the full reliability of all the elements
within a.
Conditional For the program to satisfy a predicate Q after a conditional statement
of the form ifℓb s1 s2, each branch must satisfy Q. The rule therefore generates a
precondition that is a conjunction of the results of the analysis of each branch.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

558
Carbin and Misailovic: Programming Unreliable Hardware
Phi-nodes The rule for a φ-node x = φ(ℓ, x1, x2) captures the implicit dependence
of the eﬀects of control ﬂow on the value of a variable x. For the merged value
x, the rule establishes Q by generating a precondition that ensures that Q holds
independently for both x1 and x2, given an appropriate substitution. Note that the
rule also includes ℓin the substitution; this explicitly captures x's dependence on ℓ.
The ﬂattening statement inserted before a conditional (Section 15.5.1), later replaces
the reliability of ℓwith that of its dependencies.
Bounded while and repeat Bounded while loops, whileℓb : n s, and repeat
loops, repeat n s, execute their bodies at most n times. Execution of such a loop
therefore satisﬁes Q if P holds beforehand, where P is the result of invoking the
analysis on n sequential copies of the body. The rule implements this approach via a
sequence of bounded recursive calls to transformed versions of itself.
Unbounded while We present the analysis for unbounded while loops in the
section that follows.
Function Calls The analysis for functions is modular and takes the reliability
speciﬁcation from the function declaration and substitutes the reliabilities of the
function's formal arguments with the reliabilities of the expressions that represent
the function's actual arguments. We presented the rule for function calls in Carbin
et al. (n.d.).
Unbounded while Loops
An unbounded loop, whileℓb s, may execute for a number of iterations that is not
bounded statically. The reliability of a variable that is modiﬁed unreliably within
a loop and has a loop-carried dependence is a monotonically decreasing function
of the number of loop iterations. The only sound approximation of the reliability
of such a variable is therefore zero. However, unbounded loops may also update a
variable reliably. In this case, the reliability of the variable is the joint reliability
of its dependencies. We have designed an analysis for unbounded while loops to
distinguish these two cases as follows:
Dependence Graph The analysis ﬁrst constructs a dependence graph for the loop.
Each node in the dependence graph corresponds to a variable that is read or written
within the condition or body of the loop. There is a directed edge from the node for
a variable x to the node for a variable y if the value of y depends on the value of x.
The analysis additionally classiﬁes each edge as reliable or unreliable meaning that
a reliable or unreliable operation creates the dependence.
There is an edge from the node for a variable x to the node for the variable y if
one of the following holds:
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

15.5 Reliability Analysis
559
• Assignment: there is an assignment to y where x occurs in the expression
on the right hand side of the assignment; this condition captures direct data
dependencies. The analysis classiﬁes such an edge as reliable if every opera-
tion in the assignment (i.e., the operations in the expression and the write to
memory) are reliable. Otherwise, the analysis marks the edge as unreliable. The
rules for array load and store statements are similar, and include dependencies
induced by the computation of array indices.
• Control Flow Side Eﬀects: y is assigned within an if statement and the if
statement's control ﬂow variable is named x; this condition captures control
dependencies. The analysis classiﬁes each such edge as reliable.
The analysis uses the dependence graph to identify the set of variables in the loop
that are reliably updated. A variable x is reliably updated if all simple paths (and
simple cycles) to x in the dependence graph contain only reliable edges.
Fixpoint Analysis Given a set of reliably updated variables Xr, the analysis next
splits the postcondition Q into two parts. For each predicate Ri ≤r · R(X) in Q
(where Ri is a developer-provided speciﬁcation), the analysis checks if the property
∀x ∈X. x ∈modset(s) ⇒x ∈Xr holds, where modset(s) computes the set of
variables that may be modiﬁed by s. If this holds, then all the variables in X are either
modiﬁed reliably or not modiﬁed at all within the body of the loop. The analysis
conjoins the set of predicates that satisfy this property to create the postcondition
Qr and conjoins the remaining predicates to create Qu.
The analysis next iterates the function F(A) starting from true, where F(A) =
Qr ∧RPψ(T(ifℓb s skip), A), until it reaches a ﬁxpoint. The resulting predicate
Q′
r is a translation of Qr such the joint reliability of a set of variables is replaced by
the joint reliability of its dependencies.
Lemma 15.6 (Termination). Iteration of F(A) terminates.
This follows from the monotonicity of RP and the fact that the range of F(A) is
ﬁnite (given a simpliﬁer that removes redundant predicates and produces a canonical,
symbolic predicate representation - which we present a subsumption-based variant
in Section 15.5.3) - together, forming ﬁnite descending chains. The key intuition is
that the set of rational constants in the precondition before and after an iteration does
not change (because all variables are reliably updated) and the set of variables that
can occur in a joint reliability factor is ﬁnite. Therefore, there are a ﬁnite number of
unique preconditions in the range of F(A).
Final Precondition In the last step, the analysis produces a ﬁnal precondition that
preserves the reliability of variables that are reliably updated by conjoining Q′
r
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

560
Carbin and Misailovic: Programming Unreliable Hardware
with the predicate Qu[(Ri ≤0)/(Ri ≤Rj)], where Ri and Rj are joint reliability
factors. The substitution on Qu sets the joint reliability factors that contain unreliably
updated variables to zero.
Properties
Rely's analysis is sound with respect to the transformer semantics presented in
Section 15.4.
Theorem 15.7 (Soundness). ψ |= {RPψ(s,Q)} s {Q}
This theorem states that if a conﬁguration ⟨ε, ϕ⟩satisﬁes a generated precondition
and the paired execution of s yields a conﬁguration ⟨ε′, ϕ′⟩, then ⟨ε′, ϕ′⟩satisﬁes Q.
Alternatively, s transforms the precondition generated by the analysis to Q.
We demonstrate the basic constructions for reasoning about soundness of the
analysis via a detailed presentation of the soundness of the rule for assignment.
Lemma 15.8 (Soundness of Assignment).
ψ |= {A ≤ρp(e) · ψ(wr(x)) · R(X/{x} ∪ρvar(e))}
x = e
{A ≤R(X)}
Outline By the deﬁnition of the reliability transformer, this judgment is equivalent
to proving that A ≤R(X)(ε′, ϕ′) given the two premises:
(1) A ≤ρp(e) · ψ(wr(x)) · R(Y)(ε, ϕ) and
(2) ⟨s,ε, ϕ⟩⇓ψ ⟨ε′, ϕ′⟩where Y = (X −{x}) ∪ρvar(e).
We establish this theorem by proving that
ρp(e) · ψ(wr(x)) · R(Y)(ε, ϕ) ≤R(X)(ε′, ϕ′)
and then using the transitivity of ≤, namely, that A ≤ρp(e)·ψ(wr(x))·R(Y)(ε, ϕ) ≤
R(X)(ε′, ϕ′) This follows from the following deﬁnitions and lemmas.
Lemma 15.9 (Initial Reliability).
If ins = {εu | equiv(ε,εu,Y)} then R(Y)(ε, ϕ) =
Σ
εu ∈insϕ(εu).
This lemma is a restatement of the semantics of joint reliability factors as laid out in
Section 15.4.
Lemma 15.10 (Final Reliability).
If outs ⊆{ε′
u | equiv(ε′,ε′
u, X)} then
Σ
εu ∈outsϕ′(εu) ≤R(X)(ε′, ϕ′).
This lemma is also a restatement of the semantics of joint reliability factors.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

15.5 Reliability Analysis
561
Deﬁnition 15.11 (Unreliable Execution Summary). An unreliable execution sum-
mary is a tuple (εu,τ, p,ε′
u) ∈U = {(εu,τ, p,ε′
u) | ⟨x = e,εu⟩
τ,p
=⇒ψ ε′
u} such that
from an environment εu, execution of the statement x = e under the reliability model
ψ proceeds following a trace τ with probability p and yields an environment ε′
u.
Unreliable execution summaries enable us to construct a conservative approxima-
tion of the paired execution semantics:
Lemma 15.12 (Paired Execution Approximation).
If execs ⊆U and ⟨s,ε, ϕ⟩⇓ψ ⟨ε′, ϕ′⟩then
 
Σ
ex∈execsϕ(πεu(ex)) · πp(ex)! ≤
Σ
ex∈(execs)ϕ′(πε′u(ex)).
This lemma states that for any set of execution summaries execs the sum - over
all summaries - of the product of the probability of each summary's initial state
(according to ϕ) and the probability of the execution's trace p is less than or equal to
the sum of the probability of each summary's ﬁnal state according to ϕ′.
This lemma follows from the deﬁnition of the paired execution semantics provided
in Section 15.4. According to the paired execution semantics, the probability of any
ﬁnal state ε′
u - i.e., ϕ′(ε′
u) - is the sum over all states εu of the aggregate probability
(as deﬁned by the aggregate big-step semantics) that the unreliable program reaches
ε′
u. Additionally, the aggregatate probability is the sum over all unreliable traces
that reach ε′
u from εu. This sum is therefore bounded from below by the sum over
any subset of all states and traces.
Deﬁnition 15.13 (Fully Reliable Execution Summaries). Let the set of fully reliable
execution summaries be
execsc = {(εu,τ, p,ε′
u) | (εu,τ, p,ε′
u) ∈U ∧εu ∈
{εu | equiv(ε,εu,Y)} ∧correct(τ)},
where correct(τ) is a predicate that is true only if the trace τ is a list of the form C+
(C transition label indicates that a transition executed reliably).
The set of fully reliable execution summaries characterizes the set of pairs of
environments εu and ε′
u where εu has the correct values for the set of variables Y
and execution from εu proceeds fully reliably to ε′
u.
Proof
Using the set of fully reliable executions, we can build our proof of the main
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

562
Carbin and Misailovic: Programming Unreliable Hardware
theorem. Via Lemma 15.9, we know that
ρp(e) · ψ(wr(x)) · R(Y)(ε, ϕ) = ρp(e) · ψ(wr(x)) ·
Σ
εu ∈insϕ(εu)
= Σ
εu ∈insϕ(εu) · ρp(e) · ψ(wr(x))
=
Σ
ex∈execscϕ(πεu(ex)) · πp(ex)
This fact is true because all initial environments εu have the same values for all
variables in Y and ρp(e) · ψ(wr(x)) is the probability that the statement executes
correctly.
Continuing on from this right-hand side, we use the paired execution approximation
and Lemma 15.10 to complete our proof:
Σ
ex∈execscϕ(πεu(ex)) · πp(ex) ≤
Σ
ex∈execscϕ′(πε′u(ex)).
≤R(X)(ε′, ϕ′)
The ﬁrst step follows from the fact that execsc ⊆U. The second step fact follows from
the fact that πε′u(execsc) ⊆{ε′
u | equiv(ε′,ε′
u, X)}. We know that πε′u(execsc) ⊆
{ε′
u | equiv(ε′,ε′
u, X)}. because if (1) all values referenced in e have the correct value
and (2) both e and the assignment to x execute reliably, then x has the correct value
(and the remaining variables in X have the same correct values as they have not been
modiﬁed). We can therefore conclude that A ≤ρp(e) · ψ(wr(x)) · R(Y)(ε, ϕ) ≤
R(X)(ε′, ϕ′)
□
15.5.3 Speciﬁcation Checking
As the last step of the analysis for a function, the analysis checks the developer-
provided reliability speciﬁcations for the function's outputs as captured by the
precondition generator's ﬁnal precondition. Because each speciﬁcation has the form
r · R(X) (Figure 15.1) the precondition is a conjunction of predicates of the form
r1 · R(X1) ≤r2 · R(X2). While these joint reliability factors represent arbitrary and
potentially complex distributions of the values of X1 and X2, there is a simple and
sound (though not complete) procedure to check the validity of each predicate in a
precondition that follows from the ordering of joint reliability factors.
Proposition 15.14 (Ordering). For two sets of variables X and Y, if X ⊆Y then
R(Y) ≤R(X).
The proposition states that the joint reliability of a set of variables Y is less than
or equal to the joint reliability of any subset of the variables - regardless of the
distribution of their values.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

15.6 Related Work
563
Proof
(Sketch) First, we consider the case when all variables in X and Y are scalars.
Let UY be the set passed as the argument at the base case of the recursion started by
the call rel(Y,ε, ϕ,E) and UX be the set passed as the argument at the base case of the
recursion started by the call rel(X,ε, ϕ,E). Then, if X ⊆Y, the set UY ⊆UX, since
the variables in Y\X provide additional restrictions on the states that are contained in
UY. The theorem statement follows from the inequality 	
v∈UX ϕ(v) ≥	
v∈UY ϕ(v).
If a is an array variable, then the function rel adds a constraint for each element
of a. Then, we can apply the same argument for each such obtained sets UX and
UY. This property holds for each array element, and is not aﬀected by the minimum
operator in the function rel.
□
As a consequence of the ordering of joint reliability factors, there is a simple and
sound method to check the validity of a predicate.
Corollary 15.15 (Predicate Validity). If r1 ≤r2 and X2 ⊆X1 then
|= r1 · R(X1) ≤r2 · R(X2).
The constraint r1 ≤r2 is a comparison of two rational numbers and the constraint
X2 ⊆X1 is an inclusion of ﬁnite sets. Note that both types of constraints are decidable
and eﬃciently checkable.
Checking Because the predicates in the precondition generator's output are mutually
independent, it is possible to use Corollary 15.15 to check the validity of the full
precondition by checking the validity of each predicate.
Our implementation performs simpliﬁcation transformations after each precondi-
tion generator step to simplify numerical expressions and remove predicates that are
trivially valid or subsumed by another predicate.
Proposition 15.16 (Predicate Subsumption).A predicate r1 · R(X1) ≤r2 · R(X2)
subsumes (i.e., soundly replaces) another predicate r′
1 · R(X′
1) ≤r′
2 · R(X′
2) if
r′
1 · R(X′
1) ≤r1 · R(X1) and r2 · R(X2) ≤r′
2 · R(X′
2).
This property follows directly from the ordering of joint reliability factors. We
provide the proof in Carbin et al. (n.d., Section C.3).
15.6 Related Work
Integrity Almost all approximate computations have critical regions that must
execute without error for the computation as a whole to execute acceptably. Dynamic
criticality analyses automatically change diﬀerent regions of the computation or
internal data structures, and observe how the change aﬀects the program's output,
e.g. Rinard (2006); Carbin and Rinard (2010); Misailovic et al. (2010). In addition,
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

564
Carbin and Misailovic: Programming Unreliable Hardware
speciﬁcation-based static criticality analyses let the developer identify and separate
critical and approximate program regions, e.g., Liu et al. (2011); Sampson et al.
(2011). Carbin et al. (2012) present a veriﬁcation system for relaxed approximate
programs based on a relational Hoare logic. The system enables rigorous reasoning
about the integrity and worst-case accuracy properties of a program's approximate
regions.
In contrast to the prior static analyses that focus on the binary distinction between
reliable and approximate computations, Rely allows a developer to specify and verify
that even approximate computations produce the correct result most of the time.
Overall, this additional information can help developers better understand the eﬀects
of deploying their computations on unreliable hardware and exploit the beneﬁts that
unreliable hardware oﬀers.
Accuracy In addition to reasoning about how often a computation may produce a
correct result, it may also be desirable to reason about the accuracy of the result
that the computation produces. Dynamic techniques observe the accuracy impact of
program transformations, e.g., Rinard (2006), Misailovic et al. (2010), Ansel et al.
(2011), Baek and Chilimbi (2010), Sidiroglou et al. (2011), or injected soft errors,
e.g., de Kruijf et al. (2010), Liu et al. (2011), Sampson et al. (2011). Empirical
techniques like Approxilyzer (Venkatagiri et al., 2015, 2019) present systematic
exploration of the impact of soft errors on individual program instructions, including
the accuracy of the result. Researchers have developed static techniques that use
probabilistic reasoning to characterize the accuracy impact of various sources of
uncertainty (Misailovic et al., 2011; Chaudhuri et al., 2011; Zhu et al., 2012). And
of course, the accuracy impact of the ﬂoating point approximation to real arithmetic
has been extensively studied in numerical analysis.
Fault Tolerance and Resilience Researchers have developed various software,
hardware, or mixed approaches for detection and recovery from speciﬁc types of
soft errors that guarantee a reliable program execution, e.g., Reis et al. (2005),
Perry et al. (2007), de Kruijf et al. (2010). For example, Reis et al. (2005) present a
compiler that replicates a computation to detect and recover from single event upsets.
These techniques are complementary to Rely - each can provide implementations
of operations that need to be reliable (as speciﬁed by the developer or required by
Rely) to preserve memory safety and control ﬂow integrity.
Follow up works Since publishing the original paper (Carbin et al., 2013b), we and
other researchers have extended this research in various directions. We developed
the Chisel optimization system to automate the placement of approximate operations
and data (Misailovic et al., 2014). Chisel extends the Rely reliability speciﬁcations
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

15.7 Conclusion
565
(that capture acceptable frequency of errors) with absolute error speciﬁcations (that
also capture acceptable magnitude of errors). It formulates an integer optimization
problem to automatically navigate the tradeoﬀspace and generate an approximate
computation that provides maximum energy savings while satisfying both the
reliability and absolute error speciﬁcations.
Several static analyses studied the interactions between safety and reliability.
Decaf (Boston et al., 2015) presents a type system that incorporates reliability
speciﬁcations with EnerJ type annotations. FlexJava (Park et al., 2015) presents a
static analysis for inferring annotations on approximate variables. Leto (Boston et al.,
2018) provides a ﬂexible interface for expressing custom hardware error models
and a veriﬁcation framework that can prove various properties about programs that
execute on such hardware. Aloe (Joshi et al., 2020) adds support for analyzing
recovery blocks to Rely.
More recently, researchers also extended the reliability analysis to other kinds of
computations. Hung et al. (2019) extend the reliability analysis to quantum programs.
Fernando et al. (2019) presented an approach for analyzing message-passing parallel
programs with unreliable computation and/or communication.
15.7 Conclusion
The software and hardware communities have grown accustomed to the digital
abstraction of computing: the computing substrate is designed to either faithfully
execute an operation or detect and report that an error has occurred. This abstraction
has enabled a process whereby increased performance capability in the substrate
enables the development of increasingly larger and more complicated computing
systems that are composed of less complicated, modularly-speciﬁed components.
Emerging trends in the scalability of existing hardware design techniques, however,
jeopardize the hope that future gains in computing performance will still be
accompanied by a digital abstraction. Instead, future high-performance computing
platforms may produce uncertain results and, therefore, it may no longer be possible
to use traditional techniques to modularly compose components to execute on these
platforms.
While there is an immediate opportunity for our work to enable the reasoning
needed to reliably achieve better performance in the face of uncertainty, the true
motivation for this work is that the nature of computing itself has changed. Emerging
applications, such as machine learning, multimedia, and data analytics are inherently
uncertain computations that operate over uncertain inputs. Moreover, emerging un-
certain computational substrates, such as intermittently powered devices, biological
devices, and quantum computing, create new possibilities for where computation
can take place and even what can be computed itself.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

566
References
Going forward, this work will enable the software and hardware communities to
discard the notion that they must rely on the digital abstraction to build computing
systems. Instead, emerging computing systems will use abstractions of acceptability
that will enable these systems to exploit not only the performance beneﬁts of
uncertain substrates, but also the new possibilities that these platforms oﬀer for
computation.
Acknowledgments
We thank Martin Rinard, our advisor and the co-authors of the conference version
of this chapter (Carbin et al., 2013b). We also thank Vimuth Fernando for proof-
reading the draft. This research was supported in part by the National Science
Foundation (Grants CCF-0905244, CCF-1036241, CCF-1138967, CCF-1138967,
and IIS-0835652), the United States Department of Energy (Grant DE-SC0008923),
and DARPA (Grants FA8650-11-C-7192, FA8750-12-2-0110).
References
Ansel, J., Wong, Y., Chan, C., Olszewski, M., Edelman, A., and Amarasinghe,
S. 2011. Language and compiler support for auto-tuning variable-accuracy
algorithms. CGO.
Baek, W., and Chilimbi, T. M. 2010. Green: a framework for supporting energy-
conscious programming using controlled approximation. PLDI.
Barthe, G., Demange, D., and Pichardie, D. 2012. A formally veriﬁed SSA-Based
middle-end: Static single assignment meets compcert. ESOP.
Blum, M., and Kanna, S. 1989. Designing programs that check their work. STOC.
Boston, Brett, Sampson, Adrian, Grossman, Dan, and Ceze, Luis. 2015. Probability
type inference for ﬂexible approximate programming. In: OOPSLA.
Boston, Brett, Gong, Zoe, and Carbin, Michael. 2018. Leto: verifying application-
speciﬁc hardware fault tolerance with programmable execution models. In:
OOPSLA.
Carbin, M., and Rinard, M. 2010. Automatically Identifying Critical Input Regions
and Code in Applications. ISSTA.
Carbin, M., Misailovic, S., and Rinard, M.
Verifying Quantitative Reli-
ability of Programs that Execute on Unreliable Hardware (Appendix).
http://groups.csail.mit.edu/pac/rely.
Carbin, M., Kim, D., Misailovic, S., and Rinard, M. 2012. Proving Acceptability
Properties of Relaxed Nondeterministic Approximate Programs. PLDI.
Carbin, M., Kim, D., Misailovic, S., and Rinard, M. 2013a. Veriﬁed integrity
properties for safe approximate program transformations. PEPM.
Carbin, M., Misailovic, S., and Rinard, M. 2013b. Verifying Quantitative Reliability
for Programs That Execute on Unreliable Hardware. OOPSLA.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

References
567
Chaudhuri, S., Gulwani, S., Lublinerman, R., and Navidpour, S. 2011. Proving
Programs Robust. FSE.
de Kruijf, M., Nomura, S., and Sankaralingam, K. 2010. Relax: an architectural
framework for software recovery of hardware faults. ISCA.
Dijkstra, Edsger W. 1975. Guarded commands, nondeterminacy and formal deriva-
tion of programs. Communications of the ACM, 18(August), 453-457.
Ernst, D., Kim, N. S., Das, S., Pant, S., Rao, R., Pham, T., Ziesler, C., Blaauw, D.,
Austin, T., Flautner, K., and Mudge, T. 2003. Razor: A low-power pipeline
based on circuit-level timing speculation. MICRO.
Esmaeilzadeh, H., Sampson, A., Ceze, L., and Burger, D. 2012. Architecture support
for disciplined approximate programming. ASPLOS.
Feng, S., Gupta, S., Ansari, A., and Mahlke, S. 2010. Shoestring: probabilistic soft
error reliability on the cheap. ASPLOS.
Fernando, V., Joshi, K., and Misailovic, S. 2019. Verifying Safety and Accuracy of
Approximate Parallel Programs via Canonical Sequentialization. OOPSLA.
Hiller, M., Jhumka, A., and Suri, N. 2002. On the placement of software mechanisms
for detection of data errors. DSN.
Hoﬀman, H., S. Sidiroglou, M. Carbin, S. Misailovic, A. Agarwal, and Rinard, M.
2011. Dynamic Knobs for Responsive Power-Aware Computing. ASPLOS.
Hung, Shih-Han, Hietala, Kesha, Zhu, Shaopeng, Ying, Mingsheng, Hicks, Michael,
and Wu, Xiaodi. 2019. Quantitative robustness analysis of quantum programs.
Proceedings of the ACM on Programming Languages, 3(POPL), 31.
Joshi, Keyur, Fernando, Vimuth, and Misailovic, Sasa. 2020. Aloe: Verifying
Reliability of Approximate Programs in the Presence of Recovery Mechanisms.
CGO. ACM.
Knobe, K., and Sarkar, V. 1998. Array SSA form and its use in parallelization.
POPL.
Kozen, D. 1981. Semantics of probabilistic programs. Journal of Computer and
System Sciences.
Leem, L., Cho, H., Bau, J., Jacobson, Q., and Mitra, S. 2010. ERSA: error resilient
system architecture for probabilistic applications. DATE.
Leveson, N., Cha, S., Knight, J. C., and Shimeall, T. 1990. The use of self checks
and voting in software error detection: An empirical study. IEEE TSE.
Liu, S., Pattabiraman, K., Moscibroda, T., and Zorn, B. 2011. Flikker: Saving
DRAM refresh-power through critical data partitioning. ASPLOS.
Misailovic, S., Sidiroglou, S., Hoﬀmann, H., and Rinard, M. 2010. Quality of
service proﬁling. ICSE.
Misailovic, S., Roy, D., and Rinard, M. 2011. Probabilistically Accurate Program
Transformations. SAS.
Misailovic, S., Kim, D., and Rinard, M. 2013. Parallelizing Sequential Programs
With Statistical Accuracy Tests. ACM TECS Special Issue on Probabilistic
Embedded Computing.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

568
References
Misailovic, S., Carbin, M., Achour, S., Qi, Z., and Rinard, M. 2014. Chisel:
Reliability- and Accuracy-aware Optimization of Approximate Computational
Kernels. OOPSLA.
Narayanan, S., Sartori, J., Kumar, R., and Jones, D. 2010. Scalable stochastic
processors. DATE.
Palem, K. 2005. Energy aware computing through probabilistic switching: A study
of limits. IEEE Transactions on Computers.
Park, Jongse, Esmaeilzadeh, Hadi, Zhang, Xin, Naik, Mayur, and Harris, William.
2015. Flexjava: Language support for safe and modular approximate program-
ming. In: FSE.
Pattabiraman, K., Grover, V., and Zorn, B. 2008. Samurai: protecting critical data in
unsafe languages. EuroSys.
Perry, F., Mackey, L., Reis, G.A., Ligatti, J., August, D.I., and Walker, D. 2007.
Fault-tolerant typed assembly language. PLDI.
Reis, G., Chang, J., Vachharajani, N., Rangan, R., and August, D. 2005. SWIFT:
Software Implemented Fault Tolerance. CGO.
Rinard, M. 2006. Probabilistic accuracy bounds for fault-tolerant computations that
discard tasks. ICS.
Rinard, M., Cadar, C., Dumitran, D., Roy, D.M., Leu, T., and Beebee Jr, W.S. 2004.
Enhancing server availability and security through failure-oblivious computing.
OSDI.
Sampson, A., Dietl, W., Fortuna, E., Gnanapragasam, D., Ceze, L., and Grossman,
D. 2011.
EnerJ: approximate data types for safe and general low-power
computation. PLDI.
Schlesinger, C., Pattabiraman, K., Swamy, N., Walker, D., and Zorn, B. 2011.
YARRA: An Extension to C for Data Integrity and Partial Safety. CSF.
Sidiroglou, S., Misailovic, S., Hoﬀmann, H., and Rinard, M. 2011. Managing
Performance vs. Accuracy Trade-oﬀs With Loop Perforation. FSE.
Thomas, A., and Pattabiraman, K. 2013.
Error Detector Placement for Soft
Computation. DSN.
Venkatagiri, Radha, Mahmoud, Abdulrahman, Hari, Siva Kumar Sastry, and Adve,
Sarita V. 2015. Approxilyzer: Towards a systematic framework for instruction-
level approximate computing and its application to hardware resiliency. In:
MICRO.
Venkatagiri, Radha, Ahmed, Khalique, Mahmoud, Abdulrahman, Misailovic, Sasa,
Marinov, Darko, Fletcher, Christopher W, and Adve, Sarita V. 2019. gem5-
Approxilyzer: An Open-Source Tool for Application-Level Soft Error Analysis.
In: DSN.
x264. 2013. http://www.videolan.org/x264.html.
Zhu, Z., Misailovic, S., Kelner, J., and Rinard, M. 2012. Randomized Accuracy-
Aware Program Transformations for Eﬃcient Approximate Computations.
POPL.
https://www.cambridge.org/core/terms. https://www.cambridge.org/core/product/819623B1B5B33836476618AC0621F0EE
Downloaded from https://www.cambridge.org/core. jcmbr, on 02 Mar 2021 at 14:30:19, subject to the Cambridge Core terms of use, available at

