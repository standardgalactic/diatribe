A Programming Language for Probabilistic Computation
Sungwoo Park
August 2005
CMU-CS-05-137
School of Computer Science
Carnegie Mellon University
Pittsburgh, PA 15213
Thesis Committee:
Frank Pfenning, co-chair
Sebastian Thrun, co-chair, Stanford University
Geoffrey Gordon
Robert Harper
Norman Ramsey, Harvard University
Submitted in partial fulﬁllment of the requirements
for the degree of Doctor of Philosophy
c⃝2005 Sungwoo Park
This research was sponsored by the US Navy under contract no. N6600101C6018, the US Air Force under contract nos.
F1962895C0050 and F306029820137, the US Army under contract no. DABT6300C1016, and through a generous grant from the
National Science Foundation. The views and conclusions contained in this document are those of the author and should not be
interpreted as representing the ofﬁcial policies, either expressed or implied, of any sponsoring institution, the U.S. government or
any other entity.

Keywords: Probabilistic language, Probability distribution, Sampling function, Robotics, Computa-
tional effect, Monad, Modal logic.

Abstract
As probabilistic computations play an increasing role in solving various problems, researchers have designed
probabilistic languages to facilitate their modeling. Most of the existing probabilistic languages, however,
focus only on discrete distributions, and there has been little effort to develop probabilistic languages whose
expressive power is beyond discrete distributions. This dissertation presents a probabilistic language, called
PTP (ProbabilisTic Programming), which supports all kinds of probability distributions.
The key idea behind PTP is to use sampling functions, i.e., mappings from the unit interval (0.0, 1.0] to
probability domains, to specify probability distributions. By using sampling functions as its mathematical
basis, PTP provides a uniﬁed representation scheme for probability distributions, without drawing a syntactic
or semantic distinction between different kinds of probability distributions.
Independently of PTP, we develop a linguistic framework, called λ⃝, to account for computational
effects in general. λ⃝extends a monadic language by applying the possible world interpretation of modal
logic. A characteristic feature of λ⃝is the distinction between stateful computational effects, called world
effects, and contextual computational effects, called control effects. PTP arises as an instance of λ⃝with a
language construct for probabilistic choices.
We use a sound and complete translator of PTP to embed it in Objective CAML. The use of PTP is
demonstrated with three applications in robotics: robot localization, people tracking, and robotic mapping.
Thus PTP serves as another example of high-level language applied to a problem domain where imperative
languages have been traditionally dominant.


Acknowledgments
I am grateful to my advisor Frank Pfenning for all the support he gave me during my graduate years. From
his unusual patience, hearty encouragement, and eternal cheerfulness, I witnessed the excellent leadership
of an academic advisor; from all the technical discussions we had together, I learned everything I know
about programming language theory. I am also grateful to my co-advisor Sebastian Thrun for suggesting to
me the thesis topic and teaching me robotics.
I thank my thesis committee for their time and involvement. Chapter 2 grew out of numerous discussions
with Bob Harper, which were always fun and are still a source of inspirations for me. I am particularly
indebted to Norman Ramsey for showing an interest in my work, carefully reading the draft, and writing
insightful comments even twice. I also thank Sharon Burks for her patience and assistance in completing
the dissertation for the last few months.
I thank my friends at Carnegie Mellon with whom I have shared the experience of graduate school:
Hakan Younes, Tiankai Tu, Jonathan Moody, Jeff Polakow, Joshua Dunﬁeld, and Amit Manjhi. I also thank
my high school friends who I never thought would live in Pittsburgh during my graduate years: Jaedong Kim,
Sunghong Park, and Wootae Kim. I express my sincere gratitude to Eunseok Cha who was unconditionally
supportive of me at all the hard times in Pittsburgh. She was also always with me at all the happy times,
which I deeply appreciate.
Lastly the dissertation would not have been written without the wholehearted support of my family for
the past six years. Ultimately the dissertation is for all of my family and it is our achievement.
v

vi
ACKNOWLEDGMENTS

Contents
1
Introduction
1
1.1
Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.2
Previous work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.3
Sampling functions as the mathematical basis . . . . . . . . . . . . . . . . . . . . . . . . .
4
1.4
Linguistic framework for PTP
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
1.5
Applications to robotics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
1.6
Outline
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9
2
Linguistic Framework
11
2.1
Computational effects in λ⃝
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
2.2
Logical preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
2.2.1
Curry-Howard isomorphism and judgmental formulation . . . . . . . . . . . . . . .
15
2.2.2
Semantics of modal logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
2.3
Language λ⃝. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
2.3.1
Logic for λ⃝. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
24
2.3.2
Language constructs of λ⃝. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
2.3.3
Substitutions
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
30
2.3.4
World terms and instructions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
32
2.3.5
Operational semantics
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
2.4
Examples of world effects
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
36
2.4.1
Probabilistic computations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
36
2.4.2
Sequential input/output . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
36
2.4.3
Mutable references . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
2.4.4
Supporting multiple notions of world effect . . . . . . . . . . . . . . . . . . . . . .
39
2.5
Fixed point constructs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
2.5.1
Unfolding semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
2.5.2
Backpatching semantics
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
43
2.6
Continuations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
47
2.6.1
Continuations for terms
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
47
2.6.2
Continuations for expressions
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
2.7
Summary
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
49
3
The Probabilistic Language PTP
51
3.1
Deﬁnition of PTP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
51
3.1.1
Syntax and type system . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
51
3.1.2
Operational semantics
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
3.1.3
Fixed point construct for expressions
. . . . . . . . . . . . . . . . . . . . . . . . .
54
vii

viii
CONTENTS
3.1.4
Distinguishing terms and expressions
. . . . . . . . . . . . . . . . . . . . . . . . .
55
3.2
Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
55
3.3
Proving the correctness of encodings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
60
3.4
Approximate Computation in PTP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
63
3.4.1
Expectation query
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
64
3.4.2
Bayes operation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
65
3.4.3
expectation and bayes as expression constructs . . . . . . . . . . . . . . . . . . . .
66
3.4.4
Cost of generating random numbers . . . . . . . . . . . . . . . . . . . . . . . . . .
66
3.5
Summary
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
67
4
Implementation
69
4.1
Representation of sampling functions
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
69
4.2
Translation of PTP in a call-by-value language . . . . . . . . . . . . . . . . . . . . . . . . .
70
4.3
Extended syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
75
4.4
Approximate computation
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
76
4.5
Simultaneous computation of multiple samples
. . . . . . . . . . . . . . . . . . . . . . . .
78
4.6
Summary
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
80
5
Applications
83
5.1
Sensor readings: action and measurement
. . . . . . . . . . . . . . . . . . . . . . . . . . .
83
5.2
Robot localization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
84
5.3
People tracking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
87
5.4
Robotic mapping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
89
5.5
Summary
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
6
Conclusion
99

List of Figures
2.1
Translation of inference rules for hypothetical judgments into typing rules.
. . . . . . . . .
19
2.2
Abstract syntax for λ⃝. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28
2.3
Typing rules of λ⃝. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28
2.4
A schematic view of ⟨E/x⟩F.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
2.5
Operational semantics of λ⃝which uses expression substitutions for expression computa-
tions.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
2.6
Operational semantics of λ⃝in the direct style.
. . . . . . . . . . . . . . . . . . . . . . . .
35
2.7
Typing rules and reduction rules for mutable references. . . . . . . . . . . . . . . . . . . . .
38
2.8
Syntax for continuations for terms. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
47
2.9
Reduction rules for continuations for terms. . . . . . . . . . . . . . . . . . . . . . . . . . .
48
2.10 Syntax for continuations for expressions. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
2.11 Reduction rules for continuations for expressions. . . . . . . . . . . . . . . . . . . . . . . .
49
3.1
Abstract syntax for PTP. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
52
3.2
Typing rules of PTP.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
52
3.3
Operational semantics of PTP. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
4.1
A fragment of PTP as the source language. . . . . . . . . . . . . . . . . . . . . . . . . . . .
70
4.2
A call-by-value language as the target language. . . . . . . . . . . . . . . . . . . . . . . . .
71
4.3
Typing rules of the target language. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
71
4.4
Operational semantics of the target language.
. . . . . . . . . . . . . . . . . . . . . . . . .
72
4.5
Translation of the source language. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
72
4.6
wset to prob truncate. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
77
4.7
Horizontal and vertical computations.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
78
4.8
Execution times (in seconds) for generating a total of 3,100,000 samples.
. . . . . . . . . .
80
5.1
Range readings produced by a laser range ﬁnder.
. . . . . . . . . . . . . . . . . . . . . . .
84
5.2
Samples from the action model.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
85
5.3
Points in the map that correspond to measurements when s is set to the true pose of the robot. 86
5.4
Points in the map that correspond to measurements when s is set to a hypothetical pose of
the robot.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
86
5.5
Approximating ms from measurement m and pose s. . . . . . . . . . . . . . . . . . . . . .
87
5.6
A grid map and its likelihood map. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
88
5.7
Probability distribution of robot pose after processing the ﬁrst batch of range readings in
Figure 5.1.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
89
5.8
Progress of a real-time robot localization run. . . . . . . . . . . . . . . . . . . . . . . . . .
93
5.9
Equations used in people tracking. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
94
ix

x
LIST OF FIGURES
5.10 Implementation of people tracking in PTP. . . . . . . . . . . . . . . . . . . . . . . . . . . .
94
5.11 Progress of a real-time people tracking run.
. . . . . . . . . . . . . . . . . . . . . . . . . .
95
5.12 Range readings and the area around the robot during a people tracking run.
. . . . . . . . .
96
5.13 Implementation of robotic mapping in PTP. . . . . . . . . . . . . . . . . . . . . . . . . . .
96
5.14 Raw odometry readings in the robotic mapping experiment.
. . . . . . . . . . . . . . . . .
97
5.15 Result of the robotic mapping experiment.
. . . . . . . . . . . . . . . . . . . . . . . . . .
97

Chapter 1
Introduction
This dissertation describes the design, implementation, and applications of a probabilistic language called
PTP (ProbabilisTic Programming). PTP uses sampling functions, i.e., mappings from the unit interval
(0.0, 1.0] to probability domains, to specify probability distributions. By using sampling functions in spec-
ifying probability distributions, PTP supports all kinds of probability distributions in a uniform manner.
The use of PTP is demonstrated with three applications in robotics: robot localization, people tracking, and
robotic mapping.
The contribution of this dissertation is three-fold:
• Sampling functions for specifying probability distributions. As most of the existing probabilistic lan-
guages focus only on discrete distributions, probabilistic computations involving non-discrete distri-
butions have usually been implemented in conventional languages. Sampling functions open a new
way to specify all kinds of probability distributions, and thus serve as a mathematical basis for prob-
abilistic languages whose expressive power is beyond discrete distributions.
• Linguistic framework for computational effects. We develop a new linguistic framework, called λ⃝,
to account for computational effects in general. λ⃝extends the monadic language of Pfenning and
Davies [60] by applying the possible world interpretation of modal logic. It distinguishes between
stateful computational effects (called world effects) and contextual computational effects (called con-
trol effects), and provides a different view on how to combine computational effects at the language
design level. PTP arises as an instance of λ⃝with a language construct for probabilistic choices.
• Applications of PTP in robotics. In order to execute PTP programs, we use a sound and complete
translator of PTP to embed it in Objective CAML. The use of PTP is then demonstrated with three
applications in robotics: robot localization, people tracking, and robotic mapping. Thus PTP serves
as another example of high-level language applied to a problem domain where imperative languages
have been traditionally dominant.
1.1
Motivation
A probabilistic computation is a computation which makes probabilistic choices or whose result is repre-
sented with probability distributions. As an alternative paradigm to deterministic computation, it has been
used successfully in diverse ﬁelds of computer science such as speech recognition [63, 29], natural language
processing [11], and robotics [72]. Its success lies in the fact that probabilistic approaches often overcome
the practical limitation of deterministic approaches. A trivial example is the problem of testing whether
a multivariate polynomial given by a program without branch statements is identically zero or not. It is
1

2
difﬁcult to ﬁnd a practical deterministic solution, but there is a simple probabilistic solution: evaluate the
polynomial on a randomly chosen input and check if the result is zero.
As probabilistic computations play an increasing role in solving various problems, researchers have
also designed probabilistic languages to facilitate their implementation [33, 24, 74, 59, 64, 43, 53]. A
probabilistic language treats probability distributions as built-in datatypes and thus abstracts from represen-
tation schemes, i.e., data structures for representing probability distributions. For example, a conventional
language may be extended with an abstract datatype for probability distributions, which is speciﬁed by a
certain choice of representation scheme and a set of operations on probability distributions. As a result,
it allows programmers to concentrate on how to formulate probabilistic computations at the level of prob-
ability distributions rather than representation schemes. When translated in a probabilistic language (by
programmers), such a formulation usually produces concise and elegant code.
A typical probabilistic language supports at least discrete distributions, for which there exists a represen-
tation scheme sufﬁcient for all practical purposes: a set of pairs consisting of a value from the probability
domain and its probability. We can use such a probabilistic language for those problems involving only
discrete distributions. If non-discrete distributions are involved, however, we usually use a conventional
language for the sake of efﬁciency, assuming a speciﬁc kind of probability distributions (e.g., Gaussian
distributions) or choosing a speciﬁc representation scheme (e.g., a set of samples from the probability dis-
tribution). For this reason, there has been little effort to develop probabilistic languages whose expressive
power is beyond discrete distributions.
The unavailability of such probabilistic languages means that when implementing a probabilistic com-
putation involving non-discrete distributions, we have to resort to a conventional language. Thus we wish to
develop a probabilistic language supporting all kinds of probability distributions — discrete distributions,
continuous distributions, and even those belonging to neither group. Furthermore we wish to draw no dis-
tinction between different kinds of probability distributions, both syntactically and semantically, so that we
can achieve a uniform framework for probabilistic computation. Such a probabilistic language can have a
signiﬁcant practical impact, since once formulated at the level of probability distributions, any probabilistic
computation can be directly translated into code.
Below we present an example that illustrates the disadvantage of conventional languages in implement-
ing probabilistic computations and also motivates the development of PTP.
Notation
If a variable x ranges over the domain of a probability distribution P, then P(x) means, depending on the
context, either the probability distribution itself (as in "probability distribution P(x)") or the probability of
a particular value x (as in "probability P(x)"). We write P(x) for probability distribution P when we want
to emphasize the use of variable x. If we do not need a speciﬁc name for a probability distribution, we use
Prob (as in "probability distribution Prob(x)").
Similarly P(x|y) means either the conditional probability P itself or the probability of x conditioned on
y. We write Py or P(·|y) for the probability distribution conditioned on y.
U(0.0, 1.0] denotes a uniform distribution over the unit interval (0.0, 1.0].
A motivating example for PTP
A Bayes ﬁlter [28] is a popular solution to a wide range of state estimation problems. It estimates the state
s of a system from a sequence of actions and measurements, where an action a induces a change to the
state and a measurement m gives information on the state. At its core, a Bayes ﬁlter computes a probability

3
distribution Bel(s) of the state according to the following update equations:
Bel(s)
←
R
A(s|a, s′)Bel(s′)ds′
(1.1)
Bel(s)
←
ηP(m|s)Bel(s)
(1.2)
A(s|a, s′) is the probability that the system transitions to state s after taking action a in another state s′,
P(m|s) the probability of measurement m in state s, and η a normalizing constant ensuring
R
Bel(s)ds =
1.0. The update equations are formulated at the level of probability distributions in the sense that they do
not assume a particular representation scheme.
Unfortunately the update equations are difﬁcult to implement for arbitrary probability distributions.
When it comes to implementation, therefore, we usually simplify the update equations by making additional
assumptions on the system or choosing a speciﬁc representation scheme. For example, with the assumption
that Bel is a Gaussian distribution, we obtain a variant of the Bayes ﬁlter called a Kalman ﬁlter [79]. If Bel
is approximated with a set of samples, we obtain another variant called a particle ﬁlter [15].
Even these variants of the Bayes ﬁlter are, however, not trivial to implement in conventional languages.
For example, a Kalman ﬁlter requires various matrix operations including matrix inversion. A particle
ﬁlter manipulates weights associated with individual samples, which often results in complicated code.
Since conventional languages can only simulate probability distributions, it is also difﬁcult to ﬁgure out the
intended meaning of the code, namely the update equations for the Bayes ﬁlter.
An alternative approach is to use an existing probabilistic language after discretizing all probability
distributions. This idea is appealing in theory, but impractical for two reasons. First, given a probability
distribution, it may not be easy to choose an appropriate subset of its support upon which discretization is
performed. For example, in order to discretize a Gaussian distribution (whose support is (−∞, ∞)), we need
to choose a threshold for probabilities so that discretization is conﬁned to an interval of ﬁnite length; for an
arbitrary probability distribution, such a threshold can be computed only by examining its entire probability
domain. Even when the subset of its support is ﬁxed in advance, the process of discretization may incur
a considerable amount of programming. For example, Fox et al. [20] develop two non-trivial techniques
(speciﬁc to their applications) for the sole purpose of efﬁciently manipulating discretized probability distri-
butions. Second some probability distributions cannot be discretized in any meaningful way. An example
is probability distributions over probability distributions or functions, which do occur in real applications
(Chapter 5 presents such an example).
If there were a probabilistic language supporting all kinds of probability distributions, we could imple-
ment the update equations with much less effort. PTP is a probabilistic language designed with these goals
in mind.
1.2
Previous work
There are a number of probabilistic languages that focus on discrete distributions. Such a language usually
provides a probabilistic construct that is equivalent to a binary choice construct. Saheb-Djahromi [69]
presents a probabilistic language with a binary choice construct (p1 →e1, p2 →e2) where p1 + p2 = 1.0.1
Koller, McAllester, and Pfeffer [33] present a ﬁrst order functional language with a coin toss construct ﬂip(p)
where p is a probability in (0.0, 1.0). Pfeffer [59] generalizes the coin toss construct to a multiple choice
construct dist [p1 : e1, · · · , pn : en] where P
i pi = 1.0. Gupta, Jagadeesan, and Panangaden [24] present
a stochastic concurrent constraint language with a probabilistic choice construct choose x from Dom in e
where Dom is a ﬁnite set of real numbers. Ramsey and Pfeffer [64] present a stochastic lambda calculus with
1In this section, p (with or without indices) stands for probabilities, e program fragments, and v values.

4
a binary choice construct choose p e1 e2. All these constructs, although in different forms, are equivalent to
a binary choice construct and have the same expressive power.
An easy way to process a binary choice construct (or an equivalent) during a computation is to generate
a sample from the probability distribution it denotes, as in the above probabilistic languages. Another way
is to return an accurate representation of the probability distribution itself, by enumerating all elements in
its support along with their probabilities. Pless and Luger [61] present an extended lambda calculus which
uses a probabilistic construct of the form P
i ei : pi where P
i pi = 1.0. A program denoting a probability
distribution computes to a normal form P
i vi : pi, which is an accurate representation of the probability
distribution. Jones [30] presents a metalanguage with a binary choice construct e1 orp e2. Its operational
semantics uses a judgment e ⇒P pivi. Mogensen [43] presents a language for specifying die-rolls. Its
denotational semantics (called probability semantics) is formulated in a similar style, directly in terms of
probability measures.
Jones and Mogensen also provide an equivalent of a recursion construct which enables programmers to
specify discrete distributions with inﬁnite support (e.g., geometric distribution). Such a probability distribu-
tion is, however, difﬁcult to represent accurately because of an inﬁnite number of elements in its support. For
this reason, Jones assumes P pi ≤1.0 in the judgment e ⇒P pivi and Mogensen uses partial probability
distributions in which the sum of probabilities may be less than 1.0. The intuition is that a ﬁnite recursion
depth is used so that some elements in the support are omitted in the enumeration.
There are a few probabilistic languages supporting continuous distributions. Kozen [34] investigates the
semantics of probabilistic while programs. A random assignment x := random assigns a random number
to variable x. Since it does not assume a speciﬁc probability distribution for the random number generator,
the language serves only as a framework for probabilistic languages. Thrun [73, 74] extends C++ with
probabilistic data types which are created from a template prob<type>. Although the language, called CES,
supports common continuous distributions, its semantics is not formally deﬁned. Our work is originally
motivated by the desire to develop a probabilistic language that is as expressive as CES and also has a
formal semantics.
1.3
Sampling functions as the mathematical basis
The expressive power of a probabilistic language is determined to a large extent by its mathematical basis.
That is, the set of probability distributions expressible in a probabilistic language is determined principally
by mathematical objects used in specifying probability distributions. Since we intend to support all kinds
of probability distributions without drawing a syntactic or semantic distinction, we cannot choose what is
applicable only to a speciﬁc kind of probability distributions. Examples are probability mass functions
which are speciﬁc to discrete distributions, probability density functions which are speciﬁc to continuous
distributions, and cumulative distribution functions which assume an ordering on each probability domain.
Probability measures [65] are a possibility because they are synonymous with probability distributions.
A probability measure µ over a domain D is a mapping satisfying the following conditions:
• µ(∅) = 0.
• µ(D) = 1.
• For a countable disjoint union ∪iDi of subsets Di of D,
µ(∪iDi) = P
iµ(Di)
where ∪iDi is required to be a subset of D.

5
Conceptually it maps the set of subsets of D (or, the set of events on D) to probabilities in [0.0, 1.0]. Prob-
ability measures are, however, not a practical choice as the mathematical basis because they are difﬁcult to
represent if the domain in inﬁnite. As an example, consider a continuous probability distribution P of the
position of a robot in a two-dimensional environment. (Since P is continuous, the domain is inﬁnite even
if the environment is physically ﬁnite.) The probability measure µ corresponding to P should be able to
calculate a probability for any given part of the environment (as opposed to a particular spot in the environ-
ment) — whether it is a contiguous region or a collection of disjoint regions, or whether it rectangular or
oval-shaped. Thus ﬁnding a suitable representation for µ involves the problem of representing an arbitrary
part of the environment, and is thus far from a routine task.
The main idea of our work is that we can specify a probability distribution by answering "How can we
generate samples from it?", or equivalently, by providing a sampling function for it. A sampling function is
deﬁned as a mapping from the unit interval (0.0, 1.0] to a probability domain D. Given a random number
drawn from U(0.0, 1.0], it returns a sample in D, and thus speciﬁes a unique probability distribution. In this
way, random numbers serve as the source of probabilistic choices.
In specifying how to generate samples, we wish to exploit sampling techniques developed in simulation
theory [10], most of which consume multiple (independent) random numbers to produce a single sample.
To this end, we use a generalized notion of sampling function which maps (0.0, 1.0]∞to D × (0.0, 1.0]∞
where (0.0, 1.0]∞denotes an inﬁnite product of (0.0, 1.0]. Operationally a sampling function now takes
as input an inﬁnite sequence of random numbers drawn independently from U(0.0, 1.0], consumes zero or
more random numbers, and returns a sample with the remaining sequence. This generalization of the notion
of sampling function is acceptable arithmetically (but not measure-theoretically). For example, we can use
the technique of expanding a single real number in (0.0, 1.0] into an inﬁnite sequence of real numbers in
(0.0, 1.0] by taking even and odd bits of a binary representation of a given real number to produce two real
numbers and repeating the procedure.
As the mathematical basis of PTP, we choose sampling functions, which overcome the problem with
probability measures: they are applicable to all kinds of probability distributions, and are also easy to rep-
resent because a global random number generator (which generates as many random numbers as necessary
from U(0.0, 1.0]) supplants the use of inﬁnite sequences of random numbers. As a comparison with prob-
ability measures, consider the probability distribution P of the position of a robot discussed above. In
devising a sampling function for P, we only have to construct an algorithm that probabilistically generates
possible positions of the robot; hence we do not need to consider the problem of representing an arbitrary
part of the environment (which is essential in the case of probability measures). Intuitively it is easier to
both formalize and answer "Where is the robot likely to be?" than "How likely is the robot to be in a given
region?".
The use of sampling functions as the mathematical basis leads to three desirable properties of PTP. First
it provides a uniﬁed representation scheme for probability distributions: we no longer distinguish between
discrete distributions, continuous distributions, and even those belonging to neither group. Such a uniﬁed
representation scheme is difﬁcult to achieve with other candidates for the mathematical basis. Second it en-
joys rich expressiveness: we can specify probability distributions over inﬁnite discrete domains, continuous
domains, and even unusual domains such as inﬁnite data structures (e.g., trees) and cyclic domains (e.g.,
angular values). Third it enjoys high versatility: there can be more than one way to specify a probability
distribution, and the more we know about it, the better we can encode it. Section 3.2 demonstrates these
properties with various examples written in PTP.

6
Data abstraction for probability distributions
In PTP, a sampling function is represented by a probabilistic computation that consumes zero or more
random numbers (rather than a single random number) drawn from U(0.0, 1.0]. In the context of data
abstraction, it means that a probability distribution is constructed from such a probabilistic computation. The
expressive power of PTP allows programmers to construct (or encode) all kinds of probability distributions
in a uniform way. Equally important is, however, the question of how to observe (or reason about) a given
probability distribution, i.e., how to get information out of it, through various queries. Since a probabilistic
computation in PTP only describes a procedure for generating samples, the only way to observe a probability
distribution is by generating samples from it. As a result, PTP is limited in its support for queries on
probability distributions. For example, it does not permit a precise implementation of such queries as means,
variances, and probabilities of speciﬁc events.
PTP alleviates this limitation by exploiting the Monte Carlo method [40], which approximately answers
a query on a probability distribution by generating a large number of samples and then analyzing them. As
an example, consider a (continuous) probability distribution P of the pose (i.e., position and orientation)
of a robot in a two-dimensional environment. Here are a few queries on P all of which can be answered
approximately:
• Draw a sample of robot pose at random.
• What is the expected (average) pose of the robot?
• What is the probability that the robot is facing within ﬁve degrees of due east?
• What is the probability that the robot is in Peter's ofﬁce?
• Under the assumption that the robot is in Peter's ofﬁce, what is the probability that the robot is within
two feet of the door?"
These queries can be answered approximately by repeatedly performing the probabilistic computation as-
sociated with P and then analyzing resultant samples. For example, the last query can be answered as
follows:
1. Generate samples from P.
2. Filter out those samples indicating that the robot is not in Peter's ofﬁce.
3. Count the number of samples indicating that the robot is within two feet of the door, and divide it by
the total number of remaining samples.
Certain queries on probability distributions are, however, difﬁcult to answer even approximately by the
Monte Carlo method. For example, the following queries are difﬁcult to answer approximately by a simple
analysis of samples:
• What is the most likely position of the robot?
• In what room is the robot most likely to be when the number of rooms is unknown?
Due to the nature of the Monte Carlo method, the cost of answering a query is proportional to the
number of samples used in the analysis. The cost of generating a single sample is determined by the speciﬁc
procedure chosen by programmers, rather than by the probability distribution itself from which to draw
samples. For example, a geometric distribution can be encoded with a recursive procedure which simulates

7
coin tosses until a certain outcome is observed, or by a simple transformation (called the inverse transform
method) which requires only a single random number. These two methods of encoding the same probability
distribution differ in the cost of generating a single sample and hence in the cost of answering the same query
by the Monte Carlo method. For a similar reason, the accuracy of the result of the Monte Carlo method,
which improves with the number of samples, is also affected by the procedure chosen by programmers.
Measure-theoretic view of sampling functions
The accepted mathematical basis of probability theory is measure theory [65], which associates every prob-
ability distribution with a unique probability measure. We give a summary of measure theory before dis-
cussing the connection between sampling functions and measure theory. In the discussion below, sampling
functions refer to those taking (0.0, 1.0] as input, rather than generalized ones taking (0.0, 1.0]∞as input.
• Measurable sets of a space D are subsets of D.
• A measurable space M(D) is a collection of measurable sets of D such that:
- D ∈M(D).
- If S ∈M(D), then D −S ∈M(D). That is, M(D) is closed under complement.
- For a countable collection of measurable sets Si ∈M(D), it holds ∪iSi ∈M(D). That is, M(D)
is closed under countable union.
• A measurable function f from D to E is a mapping from M(D) to M(E) such that if S ∈M(E), then
f −1(S) ∈M(D).
• A measure µ over M(D) is a mapping from M(D) to [0.0, ∞] such that:
- µ(∅) = 0.
- For a countable disjoint union ∪iSi of measurable sets Si ∈M(D), it holds µ(∪iSi) = Σiµ(Si).
• A probability measure µ over M(D) satisﬁes µ(D) = 1.
• A Lebesgue measure ν over the unit interval (0.0, 1.0] is a probability measure such that ν(S) is equal
to the total length of intervals in S.
Measure theory allows certain (but not all) sampling functions to specify probability distributions. Con-
sider a sampling function f from (0.0, 1.0] to D. While it is introduced primarily as a mathematical function,
f may be interpreted as a measurable function as well, in which case it deﬁnes a unique probability measure
µ over M(D) such that
µ(S) = ν(f −1(S))
where ν is a Lebesgue measure over the unit interval. The intuition is that S, as an event, is assigned a
probability equal to the size of it inverse image under f.
This dissertation does not investigate measure-theoretic properties of sampling functions deﬁnable in
PTP. If a probabilistic computation expressed in PTP consumes at most one random number (drawn from
U(0.0, 1.0]), it is easy to identify a corresponding sampling function. If more than one sample is consumed,
however, it is not always obvious how to construct such a sampling function. In fact, the presence of ﬁxed
point constructs in PTP (for recursive computations which can consume an arbitrary number of random
numbers) makes it difﬁcult even to deﬁne measurable spaces to which sampling functions map the unit in-
terval, since ﬁxed point constructs use domain-theoretic structures, rather than measure-theoretic structures,
in order to solve resultant recursive equations.

8
Every probabilistic computation expressed in PTP is easily translated into a generalized sampling func-
tion (which takes (0.0, 1.0]∞as input). It is, however, unknown if generalized sampling functions deﬁnable
in PTP are all measurable. Also unknown is if generalized sampling functions are measure-theoretically
equivalent to ordinary sampling functions (i.e., if a measurable function from (0.0, 1.0]∞to D ×(0.0, 1.0]∞
determines a unique measurable function from (0.0, 1.0] to D). Nevertheless generalized sampling func-
tions deﬁnable in PTP are shown to be closely connected with sampling techniques from simulation theory,
which, like measure theory, are widely agreed to be a form of probabilistic computation and PTP is designed
to support. A further discussion is found in Section 3.3.
1.4
Linguistic framework for PTP
We develop PTP as a functional language extending the λ-calculus, rather than an imperative language or a
library embedded in an existing conventional language. We decide to use a monadic syntax for probabilis-
tic computations. The decision is based upon two observations. First sampling functions are operationally
equivalent to probabilistic computations in that they describe procedures for generating samples from in-
ﬁnite sequences of random numbers. Second sampling functions form a state monad [44, 45, 64] whose
set of states is (0.0, 1.0]∞. These two observations imply that if we use a monadic syntax for probabilistic
computations, it becomes straightforward to interpret probabilistic computations in terms of sampling func-
tions. The monadic syntax treats probability distributions as ﬁrst-class values and offers a clean separation
between regular values and probabilistic computations.
Instead of designing a monadic syntax specialized for sampling functions, we begin by developing a
linguistic framework λ⃝which accounts for computational effects in general. λ⃝does not borrow its syntax
from Moggi's monadic metalanguage λml [44, 45]. Instead it extends the monadic language of Pfenning
and Davies [60], which is a reformulation of λml from a modal logic perspective. λ⃝may be thought of as
their monadic language combined with the possible world interpretation [35] of modal logic.
A characteristic feature of λ⃝is that it classiﬁes computational effects into two kinds: world effects and
control effects. World effects are stateful computational effects such as mutable references and input/output;
control effects are contextual computational effects such as exceptions and continuations. Probabilistic
choices are a particular case of world effect, and PTP arises as an instance of λ⃝with a language construct
for consuming (or drawing) random numbers from U(0.0, 1.0].
1.5
Applications to robotics
Instead of implementing PTP as a complete programming language of its own, we embed it in an existing
functional language by building a translator. Speciﬁcally we extend the syntax of Objective CAML [2] to
incorporate the syntax of PTP, and then translate language constructs of PTP back into the original syntax.
The translator is sound and complete in the sense that both type and reducibility of any program in PTP,
whether well-typed/reducible or ill-typed/irreducible, are preserved when translated in Objective CAML.
An important part of our work is to demonstrate the use of PTP by applying it to real problems. As
the main testbed, we choose robotics [72]. It offers a variety of real problems that necessitate probabilistic
computations over continuous distributions. We use PTP for three applications in robotics: robot localiza-
tion [72], people tracking [50], and robotic mapping [75]. In each case, the state of a robot is represented
with a probability distribution, whose update equation is formulated at the level of probability distributions
and translated directly in PTP. All experiments in our work have been carried out with real robots.
A comparison between our robot localizer and another written in C gives evidence that the beneﬁt of
implementing probabilistic computations in PTP, such as readability and conciseness of code, can outweigh

9
its disadvantage in speed (see Section 5.5 for details). Thus PTP serves as another example of high-level
language whose power is well exploited in a problem domain where imperative languages have been tradi-
tionally dominant.
1.6
Outline
The rest of this dissertation is organized as follows. Chapter 2 presents the linguistic framework λ⃝to
be used for PTP. Chapter 3 presents the syntax, type system, and operational semantics of PTP. Chapter 4
describes the translator of PTP in Objective CAML. Chapter 5 presents three applications of PTP in robotics.
Chapter 6 concludes.

10

Chapter 2
Linguistic Framework
This chapter presents our linguistic framework λ⃝to be used for PTP. λ⃝is an extension of the λ-calculus
(with a modality ⃝) which accounts for computational effects in general. In developing λ⃝, we are interested
in modeling such computational effects as input/output, mutable references, and continuations. We view
probabilistic choices as a particular case of computational effect, and PTP arises as an instance of λ⃝with a
language construct for probabilistic choices.
Key concepts used in the development of λ⃝are as follows:
• Segregation of world effects and control effects. λ⃝classiﬁes computational effects into two kinds:
stateful world effects and contextual control effects. The distinction makes it easy to combine com-
putational effects at the language design level.
• Possible world interpretation of modal logic. λ⃝uses modal logic [12] to characterize world effects,
and relates modal logic to world effects by the possible world interpretation [35]. As a result, the
notion of world in "world effects" coincides with the notion of world in the "possible world interpre-
tation." In formulating the logic for λ⃝, we use the judgmental style of Pfenning and Davies [60].
At its core, λ⃝applies the possible world interpretation to the monadic language of Pfenning and
Davies [60], which uses lax logic [19, 7] in the judgmental style to reformulate Moggi's monadic meta-
language λml [44, 45]. The monadic language of Pfenning and Davies analyzes computational effects only
at an abstract level from a proof-theoretic perspective, and does not readily extend to a programming lan-
guage with computational effects. λ⃝is an attempt to extend their monadic language with an operational
semantics so as to support concrete notions of computational effect. The key idea is to combine the possi-
ble world interpretation and the judgmental style in such a way that the accessibility relation (which is an
integral part of the possible world interpretation) is not used in inference rules (unlike the system of modal
logic of Simpson [71], for example).
Although λ⃝is not speciﬁc to probabilistic computations and the development of λ⃝is thus optional
for the purpose of designing PTP, we investigate λ⃝to better explain the logical foundation of PTP. As the
deﬁnition of PTP in Chapter 3 is self-contained, this chapter can be skipped without loss of continuity by
those readers who want to understand only PTP.
2.1
Computational effects in λ⃝
This section gives a deﬁnition of computational effects. The clariﬁcation of the notion of computational
effect may appear to be of little signiﬁcance (because we already know what is called computational effects
11

12
and how they work), but it has a profound impact on the overall design of λ⃝. This section also gives an
overview of λ⃝at an abstract level (i.e., without its syntax and semantics).
Deﬁnition of computational effects
In the context of functional languages, computation effects are usually deﬁned as what destroys the "pu-
rity" of functional languages. Informally the purity of a functional language means that every function in
it denotes a mathematical function, i.e., a black box converting a valid argument into a unique outcome.
For example, a function fn x => x + !y in ML does not denote a mathematical function because its
outcome depends on the content of reference y as well as argument x; hence we conclude that mutable refer-
ences are computational effects. Other examples of computational effects include input/output, exceptions,
continuations, non-determinism, concurrency, and probabilistic choices.
The notion of purity, however, is subtle and there is no universally accepted deﬁnition of purity. Sabry [67]
shows that common criteria for purity, such as soundness of the β-equational axiom, conﬂuence (the Church-
Rosser property or independence of order of evaluation), and preservation of observational equivalences,
are incomplete in that either they fail to hold in some pure functional languages or they continue to hold
in some impure functional languages (referential transparency is not considered because it does not have a
universally accepted deﬁnition). He proposes a deﬁnition of purity based upon independence of reduction
strategies, but this deﬁnition has a drawback that a given functional language must have implementations of
three reduction strategies, namely, call-by-value, call-by-need, and call-by-name.
As a result, the deﬁnition of computational effects as what destroys the purity of functional languages is
ambiguous, and some concepts are called computational effects without any justiﬁcation. For example, non-
termination is called a computational effect only by convention (as a special kind of computational effect
which is not observable). At the same time, one may argue that non-termination is not a computational effect
because the use of pointed types (i.e., types augmented with a bottom element ⊥denoting non-termination)
preserves the property of mathematical functions.
A deﬁnition of computational effects is not necessary in designing a functional language, such as ML
and Scheme, that allows any program fragment to produce computational effects. It is, however, crucial
to the design of a functional language, such as Haskell 981 [55] (and λ⃝), that subsumes a sublanguage
for computational effects, since a criterion for computational effects determines features supported by the
sublanguage. The case of Haskell illustrates the importance of a proper deﬁnition of computational effects,
and also inspires our deﬁnition of computational effects.
Computational effects in Haskell
Since their introduction to the programming language community, monads [44, 45] have been considered
as an elegant means of structuring functional programs and incorporating computational effects into func-
tional languages [76, 77]. A good example of a functional language that makes extensive use of monads
in its design is Haskell. At the programming level, it provides a type class Monad to facilitate modular
programming; at the language design level, it provides a built-in IO monad for producing computational
effects without compromising its properties as a pure functional language.
Haskell does not assume a particular deﬁnition of computational effects. Instead it implicitly identiﬁes
computational effects with monads and conﬁnes all kinds of computational effects to the IO monad [56, 58]
(or a similar one such as the ST monad). Thus Haskell conceptually consists of two sublanguages: a
functional sublanguage which never produces computational effects, and a monadic sublanguage which is
formed by the IO monad.
1Abbreviated as Haskell henceforth.

13
The identiﬁcation between computational effects and monads may appear to be innocuous, perhaps
because of the success of monads as a means of modeling different computational effects in a uniform
manner. When all kinds of computational effects are present together, however, the identiﬁcation becomes
problematic because monads do not combine well with each other [32, 31, 39]. Haskell uses the IO monad
for all kinds of computational effects without explicitly addressing this difﬁculty.
The identiﬁcation also enforces unconventional treatments of some computational effects. For example,
it disallows exceptions for the functional sublanguage, which would be useful for handling division by
zero or pattern-match failures. It also disallows continuations for the functional sublanguage, which would
be useful for implementing advanced control constructs such as non-local exits and co-routines. Hence
the identiﬁcation signiﬁcantly limits the practical utility of exceptions and continuations. For this reason, an
extension of Haskell proposed by Peyton Jones et al. [57] allows exceptions not for the monadic sublanguage
but for the functional sublanguage, thereby deviating from the identiﬁcation between computational effects
and monads.
Our view is that computational effects are not identiﬁed with monads and that the identiﬁcation between
computational effects and monads in Haskell is a consequence of lack of a proper deﬁnition of computational
effects. The capability of monads to model all kinds of computational effects may be the rationale for the
identiﬁcation, but it does not really warrant the identiﬁcation; rather it only implies that monads are a
particular tool for studying the denotational semantics of computational effects.
As an example, consider the set monad for modeling non-determinism [76].2 The set monad is suitable
for specifying the denotational semantics of a non-deterministic language (which has a non-deterministic
choice construct), since a program can be translated into a set enumerating all possible outcomes. The set
monad does not, however, lend itself to the operational design of a non-deterministic language, in which a
program returns a single outcome, instead of the set of all possible outcomes, after producing computational
effects. Therefore the set monad is useful for developing the denotational semantics (and also possibly
the syntax) of a non-deterministic language, but not for implementing it operationally. In fact, if the set
monad was enough for implementing a non-deterministic language operationally, we could argue that the
built-in IO monad is unnecessary in Haskell because we can instantiate the type class Monad to mimic
all computational effects supported by the IO monad. Thus the main lesson learned from Haskell is that
modeling a computational effect is a separate issue from implementing it operationally.
Another lesson learned from Haskell is that as its implementation is based upon a state monad, the
IO monad is suitable for stateful computational effects such as mutable references and input/output, but
not compatible with contextual computational effects such as exceptions and continuations. That is, while
stateful computational effects may well be identiﬁed with the IO monad, contextual computational effects
do not need to be restricted to the monadic sublanguage. Our deﬁnition of computational effects captures
the distinction between these two kinds of computational effects, calling the former world effects and the
latter control effects.
World effects and control effects
We directly deﬁne computational effects without relying on another notion such as purity of functional
languages. A central assumption is that the run-time system consists of a program and a world. A program
is subject to a set of reduction rules. For example, a program in the λ-calculus runs by applying the β-
reduction rule. A world is an object whose behavior is speciﬁed by the programming environment rather
than by reduction rules. For example, a keyboard buffer can be part of a world such that a keystroke or a
read operation changes its contents. In contrast, a heap is not part of a world because it is just a convenience
for implementing reduction rules. That is, we can implement all reduction rules without using heaps at all.
2If the reader holds the view that computational effects and monads are identiﬁed, this example may well be hard to follow!

14
When an external agent or a program interacts with a world and causes a transition to another world, we
say that a world effect occurs. For example, if a keyboard buffer is part of a world, a keystroke by a user or
a read operation by a program changes its contents and thus causes a world effect. As another example, if a
store for mutable references is part of a world, an operation to allocate, dereference, or deallocate references
interacts with the world and thus causes a world effect.
When a program undergoes a change that no sequence of reduction rules can induce, we say that a
control effect occurs. For example, if the β-reduction rule is the only reduction rule, raising an exception
causes a control effect because in general, it induces a change that is independent of the β-reduction rule.
For a similar reason, capturing and throwing continuations cause control effects. Note that the concept of
control effect is relative to the set of "basic" reduction rules assumed by the run-time system. One could
imagine a run-time system with built-in reduction rules for exceptions, in which case raising an exception
would not be regarded as a control effect.
Thus world effects and control effects have fundamentally different characteristics and are realized in
different ways. World effects are realized by specifying a world structure — empty world structure if there
are no world effects, keyboard buffer and display window for input/output, store for mutable references, and
so on. Control effects are realized by introducing program transformation rules (that cannot be deﬁned in
terms of existing reduction rules). Since world structures and program transformation rules are concerned
with different parts of the run-time system, world effects and control effects are treated in orthogonal ways.
The distinction between world effects and control effects makes it easy to combine computational ef-
fects at the language design level. Different world effects are combined by merging corresponding world
structures. For example, a world structure with a keyboard buffer and display window and a store realizes
both input/output and mutable references. There is no need to explicitly combine control effects with other
computational effects, since control effects become pervasive once corresponding program transformation
rules are introduced.
World effects are further divided into internal world effects and and external world effects. An internal
world effect is always caused by a program and is ephemeral in the sense that the change it makes to a
world can be undone by the run-time system. An example is to allocate new references, which can be later
reclaimed by the run-time system. An external world effect is caused either by an external agent, affecting
a program, or by a program, affecting an external agent. It is perpetual in the sense that the change it makes
to a world cannot be undone by the run-time system. An example is to use keyboard input or to send output
to a printer — once you type a password to a malicious program or print it on a public printer, there is no
going back from the catastrophic consequence!
While internal world effects occur within the run-time system, external world effects involve interactions
with external agents. In this regard, all external world effects are examples of concurrency in the presence
of external agents. λ⃝is not intended to model external agents, and we restrict ourselves to internal world
effects in developing λ⃝.
From Haskell to λ⃝
As mentioned earlier, Haskell conceptually consists of two sublanguages: 1) a functional sublanguage which
is essentially the λ-calculus and never produces computational effects; 2) a monadic sublanguage which is
formed by the IO monad and produces both world effects and control effects. Peyton Jones [58] clariﬁes
the distinction between the two sublanguages with a two-level semantics: an inner denotational semantics
for the functional sublanguage and an outer transition (operational) semantics for the monadic sublanguage.
As control effects do not need to be restricted to the monadic sublanguage, we consider a variant of
Haskell that allows both its functional and monadic sublanguages to produce control effects. In comparison
with Haskell, this variant has a disadvantage that a function may not denote a mathematical function, but it

15
overcomes the limitation of Haskell in dealing with control effects.
λ⃝can be thought of as a reformulation of the variant of Haskell from a logical perspective. It has
two syntactic categories: terms and expressions. Terms form a sublanguage which subsumes the λ-calculus
and is allowed to produce only control effects; expressions forms another sublanguage which is allowed to
produce both world effects and control effects. The logic behind the deﬁnition of expressions is the same
as the logic underlying monads, namely lax logic [7]. Thus, like the monadic sublanguage of Haskell,
expressions in λ⃝enforce the monadic syntax (with the modality ⃝).
2.2
Logical preliminaries
λ⃝has a ﬁrm logical foundation, providing a logical analysis of computational effects. This section explains
those concepts from logic that play key roles in the development of λ⃝.
2.2.1
Curry-Howard isomorphism and judgmental formulation
The Curry-Howard isomorphism [27] is a principle connecting logic and programming languages. It states
that propositions in logic correspond to types in programming languages (propositions-as-types correspon-
dence) and that proofs in logic correspond to programs in programming languages (proofs-as-programs
correspondence). Given a formulation of logic, it systematically derives the type system and reduction
rules of a corresponding programming language. The development of λ⃝follows the same pattern: we ﬁrst
formulate the logic for λ⃝, and then apply the Curry-Howard isomorphism to obtain the type system and
reduction rules.
The logic for λ⃝is formulated in the judgmental style of Pfenning and Davies [60]. A judgmental
formulation of logic adopts Martin-L¨of's methodology of distinguishing between propositions and judg-
ments [42]. It differs from a traditional formulation which relies solely on propositions. Below we review
results from Pfenning and Davies [60].
Propositions and judgments
In a judgmental formulation of logic, a proposition is an object of veriﬁcation whose truth is checked by
inference rules, whereas a judgment is an object of knowledge which becomes evident by a proof. Examples
of propositions are '1 + 1 is equal to 0' and '1 + 1 is equal to 2', both under inference rules based upon
arithmetic. Examples of judgments are "'1 + 1 is equal to 0' is true", for which there is no proof, and "'1 +
1 is equal to 2' is true", for which there is a proof.
To clarify the difference between propositions and judgments, consider a statement 'the moon is made
of cheese.' The statement is not yet an object of veriﬁcation, or a proposition, since there is no way to check
its truth. It becomes a proposition when an inference rule is given, for example, (written in a pedantic way)
"'the moon is made of cheese' is true if 'the moon is greenish white and has holes in it' is true." Now we
can attempt to verify the proposition, for example, by taking a picture of the moon. That is, we still do
not know whether the proposition is true or not, but by virtue of the inference rule, we know at least what
counts as a veriﬁcation of it. If the picture indeed shows that the moon is greenish white and has holes in
it, the inference rule makes evident the judgment "'the moon is made of cheese' is true." Now we know
"'the moon is made of cheese' is true" by the proof consisting of the picture and the inference rule. Thus
a proposition is an object of veriﬁcation which may or may not be true, whereas a judgment is an object of
knowledge which we either know or do not know.
As a more concrete example, consider the conjunction connective ∧. In order for A ∧B to be a propo-
sition, we need a way to check its truth. Since A ∧B is intended to be true whenever both A and B are true,

16
we use the following inference rule to explain A ∧B as a proposition; we assume that both A and B are
propositions, and abbreviate a truth judgment "A is true" as A true:
A true
B true
A ∧B true
∧I
The rule ∧I says that if A is true and B is true, then A ∧B is true. It follows the usual interpretation of an
inference rule: if the premises hold, then the conclusion holds. We use the rule ∧I to construct a proof D of
A ∧B true from a proof DA of A true and a proof DB of B true; we write
DA
A true to mean that DA is a
proof of A true:
D
=
DA
A true
DB
B true
A ∧B true
∧I
Thus A ∧B is a proposition because we can check its truth according to the rule ∧I, whereas A ∧B true is
a judgment because we either know it or do not know it, depending on the existence of a proof.
The rule ∧I above is called an introduction rule for the conjunction connective ∧, since its conclusion
deduces a truth judgment with ∧, or introduces ∧. A dual concept is an elimination rule, whose premises
exploit a truth judgment with ∧to prove another judgment in the conclusion, or eliminates ∧. In the case of
∧, there are two elimination rules, ∧EL and ∧ER:
A ∧B true
A true
∧EL
A ∧B true
B true
∧ER
These elimination rules make sense because A ∧B true implies both A true and B true. We will later
discuss their properties in a more formal way.
It is important that in a judgmental formulation of logic, the notion of judgment takes priority over the
notion of proposition. Speciﬁcally the notion of judgment does not depend on propositions, and a new
kind of judgment is deﬁned only in terms of existing judgments (but without using existing connectives or
modalities). On the other hand, propositions are always explained with existing judgments (including at least
truth judgments), and a new connective or modality is deﬁned so as to compactly represent the knowledge
expressed by existing judgments. For example, we could deﬁne a falsehood judgment A false as "A true
does not hold," and then use a new modality ¬ with the following introduction rule:
A false
¬A true ¬I
We say that the rule ¬I internalizes A false as a proposition ¬A.
If the deﬁnition of a connective or modality involves another connective or modality, we say that orthog-
onality is destroyed in the sense that the two connectives or modalities cannot be developed independently,
or orthogonally. In this dissertation, we use no connective or modality destroying orthogonality.
Categorical judgments and hypothetical judgments
A judgment such as "A is true" is called a categorical judgment because it involves no hypotheses and is
thus unconditional. Another judgment that we need is a hypothetical judgment, which involves hypotheses.
A general form of hypothetical judgment reads "if judgments J1, · · · , Jn hold, then a judgment J holds,"
written as J1, · · · , Jn ⊢J. We refer to Ji, 1 ≤i ≤n, as an antecedent and J as the succedent.
A hypothetical judgment J1, · · · , Jn ⊢J becomes evident by a proof of J in which J1, · · · , Jn are
assumed to be evident without proofs. Such a proof D is called a hypothetical proof and is written as

17
follows:
D
=
J1
· · ·
Jn
... ...
} inference rules
J
Inference rules here use judgment Ji without requiring a proof, that is, as a hypothesis. We say that a
hypothesis Ji is discharged when inference rules use it to deduce Ji. Note that a hypothetical proof of · ⊢J
(with no antecedent) is essentially a proof of judgment J and vice versa, since both proofs show that J holds
categorically.3
The notion of hypothetical proof is illustrated by the implication connective ⊃. In order for A ⊃B to
be a proposition, we need a way to check its truth. Since A ⊃B is intended to be true whenever A true
implies B true, the introduction rule uses a hypothetical proof in its premise:
[A true]
...
B true
A ⊃B true ⊃I
The elimination rule for ⊃exploits A ⊃B true in its premises to prove B true in its conclusion:
A ⊃B true
A true
B true
⊃E
The rule ⊃E makes sense because A ⊃B true licenses us to deduce B true if A true holds, which is the
case by the second premise.
Our deﬁnition of hypothetical judgments makes two implicit assumptions: 1) the order of antecedents
is immaterial; 2) an antecedent may be used zero or more times in a hypothetical proof. These assumptions
are formally stated in the three structural rules of hypothetical judgments:
(Exchange)
If J1, · · · , Ji, Ji+1, · · · , Jn ⊢J,
then J1, · · · , Ji+1, Ji, · · · , Jn ⊢J.
(Weakening)
If J1, · · · , Jn ⊢J,
then J1, · · · , Jn, Jn+1 ⊢J for any judgment Jn+1.
(Contraction)
If J1, · · · , Ji, Ji, · · · , Jn ⊢J,
then J1, · · · , Ji, · · · , Jn ⊢J.
A hypothetical proof can be combined with another hypothetical proof. For example, a hypothetical
proof D of J1, · · · , Jn ⊢J is combined with a hypothetical proof E1 of J2, · · · , Jn ⊢J1 to produce another
hypothetical proof, written as [E1/J1]D, of J2, · · · , Jn ⊢J:
[E1/J1]D
=
J2
· · ·
Jn
E1
...
...
J1
J2
· · ·
Jn
...
...
} D
J
3This equivalence does not mean that a hypothetical judgment · ⊢J is equivalent to judgment J. While the former states that
J holds categorically, the latter is unaware of whether there are hypotheses or not, and could be even a hypothesis in a hypothetical
proof. For example, from the assumption that J implies J′, we can show that · ⊢J implies · ⊢J′. The converse is not the case,
however.

18
Note that hypotheses J2, · · · , Jn may be used twice: when proving J1 in E1 and when proving J in D. This
property of hypothetical judgments that a hypothetical proof can be substituted into another hypothetical
proof is called the substitution principle:
• (Substitution principle) If Γ ⊢J and Γ, J ⊢J′, then Γ ⊢J′.
A convenient way to prove hypothetical judgments is to use inference rules for hypothetical judgments
without relying on hypothetical proofs. For example, we can explain the implication connective ⊃with the
following inference rules for hypothetical judgments; we abbreviate a collection of antecedents as Γ:
Γ, A true ⊢B true
Γ ⊢A ⊃B true
⊃I
Γ ⊢A ⊃B true
Γ ⊢A true
Γ ⊢B true
⊃E
Here the introduction rule ⊃I uses hypothetical judgments to express that a proposition A ⊃B is true
whenever A true implies B true; the elimination rule ⊃E uses hypothetical judgments to express that
A ⊃B true licenses us to deduce B true if A true holds. A proof of Γ ⊢J with these inference rules
guarantees the existence of a corresponding hypothetical proof of Γ ⊢J.
A special form of hypothetical judgment J1, · · · , Ji, · · · , Jn ⊢Ji (where the succedent matches an an-
tecedent) is evident by a vacuous proof. The following inference rule, called the hypothesis rule, expresses
this property of hypothetical judgments; it simply says that any hypothesis can be used:
Γ, J ⊢J Hyp
From now on, we assume that antecedents and succedents in hypothetical judgments are all basic judg-
ments. For example, we do not consider such hypothetical judgments as (Γ1 ⊢J1) ⊢J2 and Γ1 ⊢(Γ2 ⊢J).
The Curry-Howard isomorphism
The Curry-Howard isomorphism connects logic and programming languages by representing a proof of a
judgment with a program of a corresponding type. In other words, a well-typed program is a compact rep-
resentation of a valid proof under the Curry-Howard isomorphism. Typically we apply the Curry-Howard
isomorphism by translating inference rules of logic into typing rules of a programming language. By con-
vention, a typing rule is given the same name as the inference rule from which it is derived.
As an example, we consider the logic of truth with the conjunction connective ∧and the implication
connective ⊃. Under the Curry-Howard isomorphism, the logic corresponds to the type system of the λ-
calculus with product types. A proof D of A true is represented with a proof term M of type A. Note that
A is interpreted both as a proposition and as a type. We use a judgment M : A to mean that proof term M
represents a proof of A true, or that proof term M has type A. Thus we have the following correspondence:
D
A true
⇔
M : A
Now consider the use of the inference rule ∧I in constructing a proof D of A ∧B true from a proof DA
of A true and a proof DB of B true. When proof terms MA and MB represent DA and DB, respectively,
we use a product term (MA, MB) of product type A ∧B to represent D. Thus the inference rule ∧I is
translated into the following typing rule:
MA : A
MB : B
(MA, MB) : A ∧B ∧I

19
Γ, A true ⊢A true Hyp
Γ, x : A ⊢x : A Hyp
Γ ⊢A true
Γ ⊢B true
Γ ⊢A ∧B true
∧I
Γ ⊢M : A
Γ ⊢N : B
Γ ⊢(M, N) : A ∧B
∧I
Γ ⊢A ∧B true
Γ ⊢A true
∧EL
Γ ⊢M : A ∧B
Γ ⊢fst M : A ∧EL
Γ ⊢A ∧B true
Γ ⊢B true
∧ER
Γ ⊢M : A ∧B
Γ ⊢snd M : B ∧ER
Γ, A true ⊢B true
Γ ⊢A ⊃B true
⊃I
Γ, x : A ⊢M : B
Γ ⊢λx:A. M : A ⊃B ⊃I
Γ ⊢A ⊃B true
Γ ⊢A true
Γ ⊢B true
⊃E
Γ ⊢M : A ⊃B
Γ ⊢N : A
Γ ⊢M N : B
⊃E
Figure 2.1: Translation of inference rules for hypothetical judgments into typing rules.
We use projection terms fst M and snd M in translating the rules ∧EL and ∧ER:
M : A ∧B
fst M : A ∧EL
M : A ∧B
snd M : B ∧ER
When a hypothetical proof uses A true as a hypothesis, it assumes the existence of a proof. Since
such a proof is actually unknown, it cannot be represented with a concrete proof term. Hence it is repre-
sented with a variable x, a special proof term which can be replaced by another proof term. Then a proof
D of A1 true, · · · , An true ⊢A true is represented with a proof term M satisfying a hypothetical judg-
ment x1 : A1, · · · , xn : An ⊢M : A, which means that proof term M has type A under the assumption that
variable xi, 1 ≤i ≤n, has type Ai:
D
A1 true, · · · , An true ⊢A true
⇔
x1 : A1, · · · , xn : An ⊢M : A
We refer to a collection of judgments x1 : A1, · · · , xn : An as a typing context. As with collections of
antecedents, we abbreviate typing contexts as Γ; all variables in a typing context are assumed to be distinct.
With the correspondence of hypothetical judgments above, inference rules for hypothetical judgments
in logic are translated into typing rules for hypothetical judgments Γ ⊢M : A. For example, the inference
rules ⊃I and ⊃E are translated into the following typing rules, which use a lambda abstraction λx:A. M
and a lambda application M N as proof terms:
Γ, x : A ⊢M : B
Γ ⊢λx:A. M : A ⊃B ⊃I
Γ ⊢M : A ⊃B
Γ ⊢N : A
Γ ⊢M N : B
⊃E
Figure 2.1 shows inference rules for hypothetical judgments in logic (shown in the left column) and
their translation into typing rules (shown in the right column). The left column shows inference rules for
hypothetical judgments, and right column shows corresponding typing rules. The hypothesis rule Hyp is
translated into a typing rule, also called the hypothesis rule, that typechecks a variable. The typing rules in
the right column constitute the type system of the λ-calculus with product types.
As a hypothetical proof can be substituted into another hypothetical proof, a proof term can also be
substituted into another proof term. Suppose Γ ⊢M : A and Γ, x : A ⊢N : B. M and N represent hypo-
thetical proofs D and E of Γ ⊢A true and Γ, A true ⊢B true, respectively, where we use the same symbol
Γ for the collection of antecedents corresponding to the typing context Γ. If we replace all occurrences of x
in N by M, we obtain a proof term, written as [M/x]N, which contains no occurrence of x. The substitution
principle for proof terms states that [M/x]N represents the hypothetical proof [D/A true]E of Γ ⊢B true:

20
• (Substitution principle)
If Γ ⊢M : A and Γ, x : A ⊢N : B, then Γ ⊢[M/x]N : B.
A true and Γ ⊢A true are called synthetic judgments because no prior information on their proofs is
given and we search for, or synthesize, their proofs from inference rules. In contrast, M : A and Γ ⊢M : A
are called analytic judgments because their proofs are already represented in M and can be reconstructed
by analyzing M. To prove M : A or Γ ⊢M : A with typing rules, we only have to analyze M because it
determines which typing rule should be applied to deduce M : A or Γ ⊢M : A. For example, if M is a
product term (i.e., M = (M1, M2)), a deduction of Γ ⊢M : A always ends with an application of the typing
rule ∧I. For this reason, a deduction of M : A or Γ ⊢M : A is often called a derivation rather than a proof.
When we construct a (unique) derivation of M : A or Γ ⊢M : A, we check if M indeed represents a
proof of A true, rather than searching for a yet unknown proof. Such a derivation effectively typechecks M
by testing if M indeed has type A, and we call M : A and Γ ⊢M : A typing judgments.
Reduction and expansion rules
All the inference rules presented so far make sense intuitively, but their correctness is yet to be established
in a formal way. To this end, we show that the inference rules satisfy two properties: local soundness and
local completeness. Under the Curry-Howard isomorphism, the two properties correspond to reduction and
expansion rules for proof terms, thus culminating in a foundation for operational semantics of programming
languages.
An introduction rule compresses the knowledge expressed in its premises into a truth judgment in the
conclusion, whereas an elimination rule retrieves the knowledge compressed within a truth judgment in a
premise to deduce another judgment in the conclusion. The local soundness property states that the knowl-
edge retrieved from a judgment by an elimination rule is only part of the knowledge compressed within that
judgment. Therefore, if the local soundness property fails, the elimination rule is too strong in the sense
that it is capable of contriving some knowledge that cannot be justiﬁed by that judgment. The local com-
pleteness property states that the knowledge retrieved from a judgment by an elimination rule includes at
least the knowledge compressed within that judgment. Therefore, if the local completeness property fails,
the elimination rule is too weak in the sense that it is incapable of retrieving all the knowledge compressed
within that judgment. If an elimination rule satisﬁes both properties, it retrieves exactly the same knowledge
compressed within a judgment in a premise.
We verify the local soundness property by showing how to reduce a proof in which an introduction rule
is immediately followed by a corresponding elimination rule. As an example, consider the following proof
for the conjunction connective ∧:
D
A true
E
B true
A ∧B true
∧I
A true
∧EL
The elimination rule ∧EL is not too strong because what it deduces in the conclusion, namely A true, is one
of the two judgments used to deduce A ∧B true. Hence the whole proof reduces to a simpler proof D:
D
A true
E
B true
A ∧B true
∧I
A true
∧EL
=⇒R
D
A true
If the elimination rule was too strong (e.g., deducing A ⊃B true somehow), the proof would not be re-

21
ducible. As another example, consider the proof for the implication connective ⊃:
D
Γ, A true ⊢B true
Γ ⊢A ⊃B true
⊃I
E
Γ ⊢A true
Γ ⊢B true
⊃E
By the substitution principle, the whole proof reduces to a simpler proof [E/A true]D:
D
Γ, A true ⊢B true
Γ ⊢A ⊃B true
⊃I
E
Γ ⊢A true
Γ ⊢B true
⊃E
=⇒R
[E/A true]D
Γ ⊢B true
We refer to these reductions =⇒R as local reductions.
We verify the local completeness property by showing how to expand a proof of a judgment into another
proof in which one or more elimination rules are followed by an introduction rule for the same judgment.
As an example, consider a proof D of A ∧B true. The elimination rules ∧EL and ∧ER are not too weak
because what they deduce in their conclusions, namely A true and B true, are sufﬁcient to reconstruct
another proof of A ∧B true:
D
A ∧B true
=⇒E
D
A ∧B true
A true
∧EL
D
A ∧B true
B true
∧ER
A ∧B true
∧I
If the elimination rules were too weak (e.g., being unable to deduce A true somehow), the proof would not
be expandable. As another example, consider a proof D of Γ ⊢A ⊃B true. By the weakening property,
D is also a proof of Γ, A true ⊢A ⊃B true. Then we can reconstruct another proof of A ⊃B true by
expanding D:
D
Γ ⊢A ⊃B true
=⇒E
D
Γ, A true ⊢A ⊃B true
Γ, A true ⊢A true Hyp
Γ, A true ⊢B true
⊃E
Γ ⊢A ⊃B true
⊃I
We refer to these expansions =⇒E as local expansions.
Since proof terms are essentially proofs, local reductions and expansions induce reduction and expansion
rules for proof terms:
fst (M, N)
=⇒R
M
snd (M, N)
=⇒R
N
(λx:A. M) N
=⇒R
[N/x]M
M : A ∧B
=⇒E
(fst M, snd M)
M : A ⊃B
=⇒E
λx:A. M x
Note that these reduction and expansion rules preserve the type of a given proof term. That is, if M =⇒R N
or M =⇒E N, then Γ ⊢M : A implies Γ ⊢N : A. The reduction rules are called the β-reduction rules,
and the expansion rules are called the η-expansion rules.
In a programming language based upon the λ-calculus, a program is deﬁned as a well-typed closed
proof term, that is, a proof term M such that · ⊢M : A for a certain type A. Usually we run a program
by applying reduction rules under a speciﬁc reduction strategy. For example, the call-by-name reduction
strategy reduces a program (λx:A. M) N to [N/x]M (by the β-reduction rule) regardless of the form of
term N. In contrast, the call-by-value reduction strategy reduces (λx:A. M) N to [N/x]M only if no
reduction rule is applicable to N (i.e., N is a value). Thus the operational semantics of a programming
language based upon the λ-calculus is speciﬁed by the reduction strategy for applying reduction rules.

22
2.2.2
Semantics of modal logic
Modal logic is a form of logic in which truth may be qualiﬁed by modalities. Examples of modalities
common in the literature are the necessity modality □and the possibility modality ♦. Informally "□A is
true" means "A is necessarily true," and "♦A is true" means "A is possibly true." Thus modal logic is
more expressive than ordinary logic without modalities, and when applied to the design of a programming
language, it enables the type system to specify richer properties that would otherwise be difﬁcult to specify.
One popular way to explain the semantics of modal logic is the possible world interpretation [35, 71]. It
assumes a set of worlds and relativizes truth to worlds. That is, instead of ordinary truth "A is true," it uses
relative truth "A is true at world ω" as the primitive notion. Hence the same proposition may be true at one
world but not at another world.
The possible world interpretation also assumes an accessibility relation ≤between worlds to explain the
meaning of each modality. For example, the necessity and possibility modalities are deﬁned as follows:
• □A is true at world ω if for every world ω′ accessible from ω (i.e., ω ≤ω′), A is true at ω′.
• ♦A is true at world ω if A is true at some world ω′ accessible from ω (i.e., ω ≤ω′).
Ordinary connectives (such as ⊃and ∧) are explained locally at individual worlds, irrespective of ≤. For
example, A ⊃B is true at world ω if "A is true at ω" implies "B is true at ω."
With the above deﬁnition of the modalities □and ♦, some proposition becomes true at every world,
regardless of the accessibility relation ≤. For example, □(A ⊃B) ⊃(□A ⊃□B) is true at every world,
since □(A ⊃B) and □A are sufﬁcient to show that B is true at any accessible world. Moreover various
systems of modal logic are obtained by requiring ≤to satisfy certain properties. The following table shows
some properties of ≤and corresponding propositions that become true at every world:
property of ≤
proposition
reﬂexivity
∀ω. ω ≤ω
□A ⊃A
symmetry
∀ω.∀ω′. ω ≤ω′ implies ω′ ≤ω
A ⊃□♦A
transitivity
∀ω.∀ω′.∀ω′′. ω ≤ω′ and ω′ ≤ω′′ imply ω ≤ω′′
□A ⊃□□A
Euclideanness
∀ω.∀ω′.∀ω′′. ω ≤ω′ and ω ≤ω′′ imply ω′ ≤ω′′
♦A ⊃□♦A
For example, if ≤is reﬂexive and transitive, we obtain a system of modal logic, usually referred to as S4, in
which both □A ⊃A and □A ⊃□□A are true at every world.
The semantics of modal logic can also be explained without explicitly using the notion of world [62, 8,
60]. In their judgmental formulation of modal logic, Pfenning and Davies [60] deﬁne a validity judgment
A valid as · ⊢A true, and internalize A valid as a modal proposition □A:
A valid
□A true □I
Thus □A true is interpreted as A being true at a world about which we know nothing, or equivalently, at
every world. (Note that a judgment is deﬁned ﬁrst and then a corresponding modality is introduced.) A
possibility judgment A poss is based upon the interpretation of A poss as A being true at a certain world,
but still its deﬁnition does not use worlds explicitly:
1. If Γ ⊢A true, then Γ ⊢A poss.
2. If Γ ⊢A poss and A true ⊢B poss, then Γ ⊢B poss.

23
A possibility judgment A poss is internalized as a modal proposition ♦A:
A poss
♦A true ♦I
The possible world interpretation is richer than the judgmental formulation in that some proposition
is true in the possible world interpretation but not in the judgmental formulation. An example of such a
proposition is (♦A ⊃□B) ⊃□(A ⊃B). It is true in the possible world interpretation as follows; we write
A @ ω for A being true at world ω:
♦A ⊃□B @ ω, A @ ω′ ⊢♦A ⊃□B @ ω Hyp
♦A ⊃□B @ ω, A @ ω′ ⊢A @ ω′ Hyp
♦A ⊃□B @ ω, A @ ω′ ⊢♦A @ ω ♦I
♦A ⊃□B @ ω, A @ ω′ ⊢B @ ω′
⊃E
ω ≤ω′, ♦A ⊃□B @ ω ⊢A ⊃B @ ω′ ⊃I
♦A ⊃□B @ ω ⊢□(A ⊃B) @ ω
□I
· ⊢(♦A ⊃□B) ⊃□(A ⊃B) @ ω ⊃I
Its truth is, however, not provable in the judgmental formulation:
???
· ⊢A ⊃B true
♦A ⊃□B true ⊢□(A ⊃B) true □I
· ⊢(♦A ⊃□B) ⊃□(A ⊃B) true ⊃I
In a certain sense, the possible world interpretation is inherently more expressive than the judgmental
formulation because it explicitly speciﬁes the world at which a proposition is true. On the other hand, it may
not be a good basis for the type system of a programming language, since the use of the accessibility relation
in proofs implies that the type system also needs to reason about the relation between worlds, which can be
difﬁcult depending on the concrete notion of world chosen by the type system. The judgmental formulation
lends itself well to this purpose because it does not use worlds explicitly in the inference rules.
The logic for λ⃝combines the possible world interpretation and the judgmental style by assuming an
accessibility relation between worlds and relativizing all judgments to worlds. For example, it uses a truth
judgment of the form A true @ ω to mean that A is true at world ω. Its inference rules, however, do not
use judgments showing accessibility between two worlds, as is the case in the judgmental formulation of
modal logic (see Simpson [71] for a system of modal logic which uses such judgments in inference rules).
Instead it requires the accessibility relation to satisfy a certain condition (monotonicity), which eliminates
the need for such judgments in inference rules. Since the possible world interpretation in λ⃝is to use the
same worlds that are part of the run-time system, lack of such judgments in inference rules implies that the
type system of λ⃝does not explicitly model changes in the run-time system, as is the case in a typical type
system.
2.3
Language λ⃝
Pfenning and Davies [60] present a monadic language which reformulates Moggi's monadic metalanguage
λml [44, 45]. It applies the Curry-Howard isomorphism to lax logic formulated in the judgmental style (with
a lax truth judgment A lax):
1. If Γ ⊢A true, then Γ ⊢A lax.

24
2. If Γ ⊢A lax and Γ, A true ⊢B lax, then Γ ⊢B lax.
λ⃝is essentially the monadic language of Pfenning and Davies coalesced with the possible world in-
terpretation. The difference is that in λ⃝, the deﬁnition of each judgment relies only on truth and the
accessibility relation, instead of clauses describing its properties (such as the above two clauses). In other
words, the deﬁnition of each judgment directly conveys its intuitive meaning.
2.3.1
Logic for λ⃝
The development of λ⃝begins by formulating the logic for λ⃝. Since the logic for λ⃝uses the possible
world interpretation, we ﬁrst deﬁne an accessibility relation ≤between worlds. Now a world refers to the
same notion that describes part of the run-time system.
Deﬁnition 2.1. A world ω′ is accessible from another world ω, written as ω ≤ω′, if there exists a world
effect that causes a transition from ω to ω′.
As it describes transitions between worlds when world effects are produced, the accessibility relation ≤
is a temporal relation between worlds. If ω ≤ω′, we say that ω′ is a future world of ω and that ω is a past
world of ω′. Note that ≤is reﬂexive and transitive, since a vacuous world effect causes a transition to the
same world and the combination of two world effects can be regarded as a single world effect.
The logic for λ⃝uses two kinds of basic judgments, both of which are relativized to worlds:
• A truth judgment A true @ ω means that A is true at world ω.
• A computability judgment A comp @ ω means that A is true at some future world of ω, that is,
A true @ ω′ holds where ω ≤ω′.
A truth judgment A true @ ω represents a known fact about world ω. Since a future world can be reached
only by producing some world effect, a computability judgment A comp @ ω may be interpreted as meaning
that A becomes true after producing some world effect at world ω.
The following properties of hypothetical judgments characterize truth judgments, where J is either a
truth judgment or a computability judgment:
Characterization of truth judgments
1. Γ, A true @ ω ⊢A true @ ω.
2. If Γ ⊢A true @ ω and Γ, A true @ ω ⊢J, then Γ ⊢J.
The ﬁrst clause expresses that A true @ ω may be used as a hypothesis. The second clause expresses the
substitution principle for truth judgments.
The deﬁnition of computability judgments gives the following characterization, which is an adaptation
of the characterization of lax truth for the possible world interpretation:
Characterization of computability judgments
1. If Γ ⊢A true @ ω, then Γ ⊢A comp @ ω.
2. If Γ ⊢A comp @ ω and Γ, A true @ ω′ ⊢B comp @ ω′ for any world ω′ such that ω ≤ω′,
then Γ ⊢B comp @ ω.

25
The ﬁrst clause expresses that if A is true at ω, then A becomes true without producing any world effect at
ω. It follows from the reﬂexivity of ≤: if A true @ ω holds, then A is true at ω, which is accessible from ω
itself, and hence A comp @ ω holds. The second clause expresses that if A is true at ω′ after producing some
world effect at ω, we may use A true @ ω′ as a hypothesis in deducing a judgment at ω′. If the judgment at
ω′ is a computability judgment B comp @ ω′, the transitivity of ≤allows us to deduce B comp @ ω:
Proof of the second clause. Assume that A comp @ ω implies A true @ ω1 where ω ≤ω1. We prove B comp @ ω
from hypotheses Γ as follows:
A comp @ ω holds because Γ ⊢A comp @ ω.
A true @ ω1 holds by the assumption on A comp @ ω.
B comp @ ω1 holds because Γ, A true @ ω1 ⊢B comp @ ω1.
B true @ ω2 holds for some world ω2 such that ω1 ≤ω2 (by the deﬁnition of B comp @ ω1).
B comp @ ω holds because ω ≤ω2 by the transitivity of ≤(i.e., ω ≤ω1 ≤ω2).
We use the second clause as the substitution principle for computability judgments.
Monotonicity of the accessibility relation ≤
We intend to use world effects for accumulating more knowledge, but not for discarding existing knowledge.
Informally a world effect causes a transition to a world where more facts are known and more world effects
can be produced. The monotonicity of the accessibility relation ≤formalizes our intention to use world
effects only for accumulating more knowledge:
Deﬁnition 2.2. The accessibility relation ≤is monotonic if for two worlds ω and ω′ such that ω ≤ω′,
1) A true @ ω implies A true @ ω′;
2) A1 true @ ω, · · · , An true @ ω ⊢A comp @ ω implies A1 true @ ω′, · · · , An true @ ω′ ⊢A comp @ ω′.
The ﬁrst condition, monotonicity of truth, states that a future world inherits all facts known about its past
worlds. It proves two new properties of hypothetical judgments:
1. If Γ ⊢A true @ ω and ω ≤ω′, then Γ ⊢A true @ ω′.
2. If Γ, A true @ ω′ ⊢J and ω ≤ω′, then Γ, A true @ ω ⊢J.
The second condition, persistence of computation, states that a world effect that can be produced at world
ω under some facts (about ω) can be reproduced at any future world ω′ under equivalent facts (about ω′).
Unlike monotonicity of truth, it uses hypothetical judgments in which all antecedents are truth judgments at
the same world as the succedent. The reason is that a world effect may require some facts about the world
at which it is produced (e.g., allocating a new reference requires an argument for initializing a new heap
cell), and its corresponding computability judgments at different worlds can be compared for persistence
only under equivalent facts about individual worlds.
Note that monotonicity of truth does not imply persistence of computation. For example, if A comp @ ω
holds because A true @ ω′ where ω ≤ω′, monotonicity of truth allows us to conclude A comp @ ω′′ for
every world ω′′ accessible from ω′, but not for every world accessible from ω.
Simpliﬁed form of hypothetical judgment
In principle, a hypothetical judgment Γ ⊢J imposes no restriction on antecedents Γ and succedent J. That
is, if J is a judgment at world ω, then Γ may include both truth judgments and computability judgments
at world ω itself, past worlds of ω, future worlds of ω, or even those worlds unrelated to ω. Thus such a

26
general form of hypothetical judgment allows us to express reasoning about not only the present but also the
past and future.
Examples of reasoning about the past and future are:
• If there has been a transaction failure in a database system in the past, we create a log ﬁle now.
• If the program has produced no output yet, we stop taking input.
• If the heap cell is deallocated in the future and becomes no longer available, we make a copy of it
now.
• If the program is to open the ﬁle eventually, we do not close it.
Since we intend to use λ⃝only to reason about the present, the logic for λ⃝imposes restrictions on an-
tecedents in hypothetical judgments and uses a simpliﬁed form of hypothetical judgment as described below.
First the simpliﬁed form uses as antecedents only truth judgments. If a computability judgment is to
be exploited, we use as an antecedent a truth judgment that it asserts, as shown in the second clause of
the characterization of computability judgments. Second the simpliﬁed form uses only judgments at the
same world. In other words, a hypothetical proof reasons about one present world and does not consider
its relation to past and future worlds (or unrelated worlds). The rationale for the second simpliﬁcation is
two-fold:
1. Facts about past worlds automatically become facts about the present world by the monotonicity of
≤. Therefore there is no reason to consider facts about the past.
2. In general, facts about future worlds are unknown to the present world because of the temporal nature
of ≤. If we were to support reasoning about future worlds, the necessity and possibility modalities
would be necessary.
Thus the logic for λ⃝uses the following two forms of hypothetical judgments:
• A1 true @ ω, · · · , An true @ ω ⊢A true @ ω,
which is abbreviated as A1 true, · · · , An true ⊢s A true @ ω.
• A1 true @ ω, · · · , An true @ ω ⊢A comp @ ω,
which is abbreviated as A1 true, · · · , An true ⊢s A comp @ ω.
As the logic for λ⃝requires only the simpliﬁed form of hypothetical judgment, we simplify the charac-
terization of truth and computability judgments accordingly. The new characterization of truth judgments is
just a special case of the previous characterization:
Characterization of truth judgments with Γ ⊢s J
1. Γ, A true ⊢s A true @ ω.
2. If Γ ⊢s A true @ ω and Γ, A true ⊢s J, then Γ ⊢J, where J is a judgment at world ω.
The new characterization of computability judgments does not consider transitions between worlds:
Characterization of computability judgments with Γ ⊢s J
1. If Γ ⊢s A true @ ω, then Γ ⊢s A comp @ ω.
2. If Γ ⊢s A comp @ ω and Γ, A true ⊢s B comp @ ω, then Γ ⊢s B comp @ ω.

27
Proof of the second clause. Given Γ = A1 true, · · · , An true, we write Γ @ ω for A1 true @ ω, · · · ,
An true @ ω. Assume Γ @ ω ⊢A comp @ ω and Γ @ ω, A true @ ω ⊢B comp @ ω. For any world ω′
such that ω ≤ω′,
Γ @ ω′, A true @ ω′ ⊢B comp @ ω′ holds by persistence of computation;
Γ @ ω, A true @ ω′ ⊢B comp @ ω′ holds by monotonicity of truth.
Then Γ @ ω ⊢B comp @ ω, or Γ ⊢s B comp @ ω, holds by the substitution principle for computability
judgments.
Note that in the second clause, A comp @ ω leads to (as a new hypothesis) a truth judgment at the
same world instead of a future world. That is, even if A comp @ ω holds because A true @ ω′ where
ω ≤ω′, we use as a new hypothesis A true @ ω instead of A true @ ω′. Thus we reason as if the world
effect corresponding to A comp @ ω did not cause a transition to the future world ω′. By virtue of the
monotonicity of ≤, this reasoning provides a simple way to test B comp @ ω′′ for every future world ω′′ of
ω, as in the previous characterization of computability judgments. The second clause allows the type system
of λ⃝to typecheck a program producing a sequence of world effects without actually producing them, as
will be seen in the next subsection.
2.3.2
Language constructs of λ⃝
To represent proofs of judgments, we use two syntactic categories: terms M, N for truth judgments and
expressions E, F for computability judgments. Thus the Curry-Howard isomorphism gives the following
correspondence, where typing judgments are annotated with worlds where terms or expressions reside:
D
A true @ ω
⇔
M : A @ ω
E
A comp @ ω
⇔
E ÷ A @ ω
That is, we represent a proof D of A true @ ω as a term M of type A at world ω, written as M : A @ ω,
and a proof E of A comp @ ω as an expression E of type A at world ω, written as E ÷ A @ ω. Analogously
hypothetical judgments (of the form Γ ⊢s J) correspond to typing judgments with typing contexts:
Γ ⊢s M : A @ ω
Γ ⊢s E ÷ A @ ω
A typing context Γ is a set of bindings x : A:
typing context
Γ
::=
· | Γ, x : A
x : A in Γ means that variable x assumes a term that has type A at a given world (i.e., world ω in
Γ ⊢s M : A @ ω or Γ ⊢s E ÷ A @ ω) but may not typecheck at other worlds. Then a term typing judg-
ment Γ ⊢s M : A @ ω means that M has type A at world ω if Γ is satisﬁed at the same world; similarly an
expression typing judgment Γ ⊢s E ÷ A @ ω means that E has type A at world ω if Γ is satisﬁed at the same
world. Alternatively we may think of Γ ⊢s M : A @ ω or Γ ⊢s E ÷ A @ ω as typing judgments indexed by
worlds.
Terms and expressions form separate sublanguages of λ⃝. Their difference is manifest in the opera-
tional semantics of λ⃝, which draws a distinction between evaluations of terms, involving no worlds, and
computations of expressions, involving transitions between worlds:
M ⇀V
E @ ω ⇁V @ ω′
A term evaluation M ⇀V does not interact with the world where term M resides; hence the resultant
value V resides at the same world. In contrast, an expression computation E @ ω ⇁V @ ω′ may interact

28
type
A, B
::=
A ⊃A | ⃝A
term
M, N
::=
x | λx:A. M | M M | cmp E
expression
E, F
::=
M | letcmp x ◁M in E
value
V
::=
λx:A. M | cmp E
Figure 2.2: Abstract syntax for λ⃝.
Γ, x : A ⊢s x : A @ ω Hyp
Γ, x : A ⊢s M : B @ ω
Γ ⊢s λx:A. M : A ⊃B @ ω ⊃I
Γ ⊢s M1 : A ⊃B @ ω
Γ ⊢s M2 : A @ ω
Γ ⊢s M1 M2 : B @ ω
⊃E
Γ ⊢s E ÷ A @ ω
Γ ⊢s cmp E : ⃝A @ ω
⃝I
Γ ⊢s M : A @ ω
Γ ⊢s M ÷ A @ ω Term
Γ ⊢s M : ⃝A @ ω
Γ, x : A ⊢s E ÷ B @ ω
Γ ⊢s letcmp x ◁M in E ÷ B @ ω
⃝E
Figure 2.3: Typing rules of λ⃝.
with world ω where expression E resides, causing a transition to another world ω′; hence the resultant
value V may not reside at the same world. Thus term evaluations are always effect-free whereas expression
computations are potentially effectful (with respect to world effects).
Note that worlds are required by both the type system and the operational semantics of λ⃝. That is,
worlds are both compile-time objects and run-time objects in the deﬁnition of λ⃝. As worlds are involved
in expression computations and hence deﬁnitely serve as run-time objects, one could argue that abstractions
of worlds rather than worlds themselves (e.g., store typing contexts rather than stores) are more appropriate
for the type system. Our view is that worlds are acceptable to use in the type system for the same reason
that terms and expressions appear in both the type system and the operational semantics: the type system
determines static properties of terms and expressions, and the operational semantics describes how to reduce
terms and expressions; likewise the type system determines static properties of worlds (with respect to terms
and expressions), and the operational semantics describes transitions between worlds.
Incidentally the type system of λ⃝is designed in such a way that only an initial world at which the
run-time system starts (e.g., an empty store) is required for typechecking any program. Hence no practical
problem arises in implementing the type system as we can simply disregard worlds.
Below we introduce all term and expression constructs of λ⃝. Figure 2.2 summarizes the abstract syntax
for λ⃝. Figure 2.3 summarizes the typing rules of λ⃝. We use x, y, z for variables.
Term constructs
As terms represent proofs of truth judgments, the characterization of truth judgments gives properties of
terms when interpreted via the Curry-Howard isomorphism. The ﬁrst clause gives the following rule where
variable x is used as a term:
Γ, x : A ⊢s x : A @ ω Hyp
The second clause gives the substitution principle for terms:
Substitution principle for terms
If Γ ⊢s M : A @ ω and Γ, x : A ⊢s N : B @ ω, then Γ ⊢s [M/x]N : B @ ω.
If Γ ⊢s M : A @ ω and Γ, x : A ⊢s E ÷ B @ ω, then Γ ⊢s [M/x]E ÷ B @ ω.

29
[M/x]N and [M/x]E denote capture-avoiding term substitutions which substitute M for all occurrences
of x in N and E. We will give the deﬁnition of term substitution after introducing all term and expression
constructs.
We apply the Curry-Howard isomorphism to truth judgments by introducing an implication connective
⊃such that Γ ⊢s A ⊃B true @ ω expresses Γ, A true ⊢s B true @ ω. It gives the following introduction
and elimination rules, where we use a lambda abstraction λx:A. M and a lambda application M1 M2 as
terms:
Γ, x : A ⊢s M : B @ ω
Γ ⊢s λx:A. M : A ⊃B @ ω ⊃I
Γ ⊢s M1 : A ⊃B @ ω
Γ ⊢s M2 : A @ ω
Γ ⊢s M1 M2 : B @ ω
⊃E
We use a reduction relation ⇒β term in both the term reduction rule for ⊃and its corresponding proof
reduction:
(λx:A. N) M ⇒β term [M/x]N
(β⊃)
Γ, x : A ⊢s N : B @ ω
Γ ⊢s λx:A. N : A ⊃B @ ω ⊃I
Γ ⊢s M : A @ ω
Γ ⊢s (λx:A. N) M : B @ ω
⊃E ⇒β term
Γ ⊢s [M/x]N : B @ ω
Expression constructs
Similarly to truth judgments, we begin by interpreting the characterization of computability judgments in
terms of typing judgments. The ﬁrst clause means that a term of type A is also an expression of the same
type:
Γ ⊢s M : A @ ω
Γ ⊢s M ÷ A @ ω Term
The second clause gives the substitution principle for expressions:
Substitution principle for expressions
If Γ ⊢s E ÷ A @ ω and Γ, x : A ⊢s F ÷ B @ ω, then Γ ⊢s ⟨E/x⟩F ÷ B @ ω.
Unlike a term substitution [M/x]F which analyzes the structure of F, an expression substitution ⟨E/x⟩F
analyzes the structure of E instead of F. This is because ⟨E/x⟩F is intended to ensure that both E and
F are computed exactly once and in that order: ﬁrst we compute E to obtain a value; then we proceed to
compute F with x bound to the value. Therefore we should not replicate E within F (at those places where
x occurs), which would result in computing E multiple times. Instead we should conceptually replicate
F within E (at those places where the computation of E ﬁnishes) so that the whole computation ends up
computing both E and F only once. In this sense, an expression substitution ⟨E/x⟩F substitutes not E
into F, but F into E. We will give the deﬁnition of expression substitution after introducing all expression
constructs.
We apply the Curry-Howard isomorphism to computability judgments by internalizing A comp @ ω
with a modality ⃝so that Γ ⊢s ⃝A true @ ω expresses Γ ⊢s A comp @ ω. The introduction and elimination
rules use a computation term cmp E and a bind expression letcmp x ◁M in E:
Γ ⊢s E ÷ A @ ω
Γ ⊢s cmp E : ⃝A @ ω
⃝I
Γ ⊢s M : ⃝A @ ω
Γ, x : A ⊢s E ÷ B @ ω
Γ ⊢s letcmp x ◁M in E ÷ B @ ω
⃝E
We use a reduction relation ⇒β exp in both the expression reduction rule for ⃝and its corresponding proof
reduction:
letcmp x ◁cmp E in F ⇒β exp ⟨E/x⟩F
(β⃝)

30
Γ ⊢s E ÷ A @ ω
Γ ⊢s cmp E : ⃝A @ ω
⃝I
Γ, x : A ⊢s F ÷ B @ ω
Γ ⊢s letcmp x ◁cmp E in F ÷ B @ ω
⃝E ⇒β exp
Γ ⊢s ⟨E/x⟩F ÷ B @ ω
cmp E denotes the computation of E, but does not actually compute E; hence we say that cmp E encapsu-
lates the computation of E. letcmp x ◁M in E enables us to sequence two computations (if M evaluates to
a computation term).
Note that the typing rule ⃝E does not accurately reﬂect the operational behavior of letcmp x ◁M in E.
Speciﬁcally, while the rule ⃝E typechecks E at the same world ω that it typechecks M, the computation of
E may take place at a different world ω′ (where ω ≤ω′) because of an expression computation preceding
the computation of E. Nevertheless it is a sound typing rule because the monotonicity of the accessibility
relation ≤allows the type system to reason as if a world effect did not cause a transition to another world,
as clariﬁed in the characterization of computability judgments.
Computation terms and bind expressions may be thought of as monadic constructs, since the modality
⃝forms a monad. In Haskell syntax, the monad could be written as follows:
instance Monad ⃝where
return M
=
cmp M
M >>= N
=
cmp letcmp x ◁M in
letcmp y ◁N x in
y
The above deﬁnition satisﬁes the monadic laws [77], modulo the expression reduction rule β⃝and a term
expansion rule γ⃝for the modality ⃝:
M ⇒ηexp cmp letcmp x ◁M in x
(γ⃝)
However, once we introduce a ﬁxed point construct for terms, the rule γ⃝becomes invalid. For example,
if M is a ﬁxed point construct whose reduction never terminates, its expansion into cmp letcmp x ◁M in x
is not justiﬁed because the reduction of the expanded term immediately terminates. Hence the modality ⃝
ceases to form a monad, and we do not call λ⃝a monadic language.
2.3.3
Substitutions
Now that all term and expression constructs have been introduced, we deﬁne term and expression substitu-
tions. We ﬁrst consider term substitutions, which are essentially textual substitutions.
Term substitution
Term substitutions [M/x]N and [M/x]E are straightforward to deﬁne as they correspond to substituting
a proof of A true @ ω for a hypothesis in a hypothetical proof. To formally deﬁne term substitutions, we
need a mapping FV (·) for obtaining the set of free variables in a given term or expression; a free variable
is one that is not bound in lambda abstractions and bind expressions:
FV (x)
=
{x}
FV (λx:A. M)
=
FV (M) −{x}
FV (M1 M2)
=
FV (M1) ∪FV (M2)
FV (cmp E)
=
FV (E)
FV (letcmp x ◁M in E)
=
FV (M) ∪(FV (E) −{x})

31
A comp @ w
E
A true @ ω
M
B comp @ ω
F
[
x
A true @ ω]
B comp @ ω
F
A true @ ω
M
B comp @ ω
E
=⇒
Figure 2.4: A schematic view of ⟨E/x⟩F.
In the deﬁnition of [M/x]N and [M/x]E, we implicitly rename bound variables in N and E as necessary
to avoid the capture of free variables in M:4
[M/x]y = M
x = y
= y
otherwise
[M/x]λy:A. N
= λy:A. [M/x]N
x ̸= y, y ̸∈FV (M)
[M/x](N1 N2) = [M/x]N1 [M/x]N2
[M/x]cmp E
= cmp [M/x]E
[M/x]letcmp y ◁N in E
= letcmp y ◁[M/x]N in [M/x]E
x ̸= y, y ̸∈FV (M)
The above deﬁnition of term substitution conforms to the substitution principle for terms:
Proposition 2.3 (Substitution principle for terms).
If Γ ⊢s M : A @ ω and Γ, x : A ⊢s N : B @ ω, then Γ ⊢s [M/x]N : B @ ω.
If Γ ⊢s M : A @ ω and Γ, x : A ⊢s E ÷ B @ ω, then Γ ⊢s [M/x]E ÷ B @ ω.
Proof. By simultaneous induction on the structure of N and E.
Proposition 2.3 implies that term reductions by ⇒β term are indeed type-preserving:
Corollary 2.4 (Type preservation of ⇒β term).
If Γ ⊢s (λx:A. N) M : B @ ω, then Γ ⊢s [M/x]N : B @ ω.
4Hence a term substitution does not need to be deﬁned in all cases.

32
Expression substitution
Given Γ ⊢s E ÷ A @ ω and Γ, x : A ⊢s F ÷ B @ ω, an expression substitution combines the two typing
judgments by ﬁnding an expression ⟨E/x⟩F such that Γ ⊢s ⟨E/x⟩F ÷ B @ ω. It corresponds to substituting
a hypothetical proof using A true @ ω as a hypothesis into a proof of A comp @ ω.
Figure 2.4 shows a schematic view of an expression substitution ⟨E/x⟩F. Expression E contains a term
M of type A which ultimately determines its type. For example, E = letcmp x ◁N in M has the same
type as M, and if M is replaced by another expression E′ of type A′, the resultant expression also has type
A′. Operationally the computation of E ﬁnishes by evaluating M. Expression F contains variable x which
corresponds to a hypothesis A true @ ω in a hypothetical proof of B comp @ ω. ⟨E/x⟩F ﬁrst substitutes
M for x in F, which results in a new expression [M/x]F of type B; then it replaces M in E by [M/x]F.
In this way, ⟨E/x⟩F substitutes F into E, rather than E into F. Note that although ⟨E/x⟩F transforms the
structure of E, it has the same type as F because its type is ultimately determined by whatever expression
replaces M.
Thus ⟨E/x⟩F analyzes the structure of E, instead of F, to ﬁnd a term that ultimately determines the
type of E:
⟨M/x⟩F
=
[M/x]F
⟨letcmp y ◁M in E′/x⟩F
=
letcmp y ◁M in ⟨E′/x⟩F
The above deﬁnition of expression substitution conforms to the substitution principle for expressions:
Proposition 2.5 (Substitution principle for expressions).
If Γ ⊢s E ÷ A @ ω and Γ, x : A ⊢s F ÷ B @ ω, then Γ ⊢s ⟨E/x⟩F ÷ B @ ω.
Proof. By induction on the structure of E (not F).
Proposition 2.5 implies that expression reductions by ⇒β exp are indeed type-preserving:
Corollary 2.6 (Type preservation of ⇒β exp).
If Γ ⊢s letcmp x ◁cmp E in F ÷ B @ ω, then Γ ⊢s ⟨E/x⟩F ÷ B @ ω.
2.3.4
World terms and instructions
The operational semantics of λ⃝provides rules for term evaluations M ⇀V and expression computations
E @ ω ⇁V @ ω′. For term evaluations, we introduce a term reduction M 7→t N such that M 7→∗
t V is
identiﬁed with M ⇀V , where 7→∗
t is the reﬂexive and transitive closure of 7→t; for expression computations,
we introduce an expression reduction E @ ω 7→e F @ ω′ such that E @ ω 7→∗
e V @ ω′ is identiﬁed with
E @ ω ⇁V @ ω′, where 7→∗
e is the reﬂexive and transitive closure of 7→e:
M 7→∗
t V
iﬀ
M ⇀V
E @ ω 7→∗
e V @ ω′
iﬀ
E @ ω ⇁V @ ω′
At this point, there is no language construct for producing world effects and no typing rules and reduction
rules actually require worlds. That is, all language constructs introduced so far are purely logical in that their
deﬁnition is explained either by properties of judgments (e.g., variables, inclusion of terms into expressions)
or by introduction and elimination rules (e.g., lambda abstractions, lambda applications). In fact, if we erase
@ ω from typing judgments, λ⃝reverts to the monadic language of Pfenning and Davies [60]. Thus we
introduce language constructs for interacting with worlds before presenting the operational semantics.
We use instructions I as expressions for producing world effects. As an interface to worlds, they are
provided by the programming environment. For example, an instruction new M for allocating new refer-
ences produces a world effect by causing a change to the store, and returns a reference. An instruction may

33
have arguments, and term substitution on instructions with arguments is deﬁned in a structural way; hence
Proposition 2.3 continues to hold.
We refer to those objects originating from worlds, such as references, as world terms W. Since they
cannot be decomposed into ordinary terms, world terms are assumed to be atomic values (containing no
subterms) and are given special world term types W. For example, reference type ref A is a world term type
for references. Note that while world terms may not contain ordinary terms, world term types may contain
ordinary types (e.g., ref A).
The new abstract syntax for λ⃝is as follows:
type
A
::=
· · · | W
world term type
W
term
M
::=
· · · | W
world term
W
expression
E
::=
· · · | I
instruction
I
value
V
::=
· · · | W
The type of a world term may depend on the world where it resides. For example, a reference is a pointer
to a heap cell and its type depends on the store for which it is valid. Therefore typing rules for world terms
may have to analyze worlds. Since world terms are atomic values, typing judgments for world terms do
not require typing contexts. In contrast, typing judgments for instructions require typing contexts because
instructions may include terms as arguments:
W : W @ ω
Γ ⊢s I ÷ A @ ω
Note that an instruction does not necessarily have a world term type. For example, an instruction for deref-
erencing references can have any type because heap cells can contain values of any type.
If an instruction I whose arguments are all values typechecks at a world ω under an empty typing
context, we regard it as reducible at ω; moreover we require that an instruction reduction I @ ω 7→e V @ ω′
be type-preserving so that V has the same type as I:
Type-preservation/progress requirement on instructions
If · ⊢s I ÷ A @ ω and arguments to I are all values, then there exists a world ω′ satisfying
I @ ω 7→e V @ ω′ and · ⊢s V : A @ ω′.
We allow ω = ω′, which means that a world effect does not always causes a change to a world (e.g., reading
the contents of a store is still a world effect).
As I @ ω 7→e V @ ω′ means that instruction I computes to value V causing a transition of world from
ω to ω′, it implies ω ≤ω′. Now the accessibility relation ≤is fully speciﬁed by instruction reductions under
the assumption that it is reﬂexive and transitive. Note that without additional requirements on instructions,
there is no guarantee that the monotonicity of ≤is maintained. For example, an instruction for deallocating
an existing reference l violates monotonicity of truth if l no longer typechecks after it is deallocated, and
violates persistence of computation if its corresponding heap cell is discarded. In order to maintain the
monotonicity of ≤, we further require that all instruction reductions be designed in such a way that types of
world terms and instructions are unaffected by ≤:
Monotonicity requirement on instructions
1) If ω ≤ω′, then W : W @ ω implies W : W @ ω′.
2) If ω ≤ω′, then Γ ⊢s I ÷ A @ ω implies Γ ⊢s I ÷ A @ ω′, where for each argument M to I,
we assume that Γ ⊢s M : B @ ω implies Γ ⊢s M : B @ ω′.

34
M 7→t M′
M N 7→t M′ N TβL
(λx:A. M) N 7→t [N/x]M Tβ
M 7→t N
M @ ω 7→e N @ ω ETerm
M 7→t N
letcmp x ◁M in F @ ω 7→e letcmp x ◁N in F @ ω EBind
E ̸= I
letcmp x ◁cmp E in F @ ω 7→e ⟨E/x⟩F @ ω EBindβ
I @ ω 7→e V @ ω′
letcmp x ◁cmp I in F @ ω 7→e letcmp x ◁cmp V in F @ ω′ EBindI
Figure 2.5: Operational semantics of λ⃝which uses expression substitutions for expression computations.
The ﬁrst clause corresponds to monotonicity of truth, and the second clause to persistence of computa-
tion. Under the monotonicity requirement, instruction reductions never affect types of existing terms and
expressions:
Proposition 2.7 (Monotonicity of ≤).
If ω ≤ω′, then
Γ ⊢s M : A @ ω implies Γ ⊢s M : A @ ω′, and
Γ ⊢s E ÷ A @ ω implies Γ ⊢s E ÷ A @ ω′.
Proof. By simultaneous induction on the structure of M and E.
Unlike other expression constructs, instructions are not explained logically and no expression substi-
tution can be deﬁned on them. Intuitively ⟨I/x⟩E cannot be reduced into another expression because I
itself does not reveal a term that is evaluated at the end of its computation. Such a term (which is indeed
a value) becomes known only after an instruction reduction I @ ω 7→e V @ ω′. We should therefore never
attempt to directly reduce letcmp x ◁cmp I in E into ⟨I/x⟩E. For the sake of convenience and uniform
notation, however, we abuse the notation ⟨I/x⟩E with the following deﬁnition, which effectively prevents
letcmp x ◁cmp I in E from being reduced by ⇒β exp:
⟨I/x⟩E
=
letcmp x ◁cmp I in E
This deﬁnition of ⟨I/x⟩E allows ⇒β exp to be applied to any part of a given expression; Proposition 2.5 also
continues to hold.
2.3.5
Operational semantics
A term reduction by ⇒β term and an expression reduction by ⇒β exp are both proof reductions and may be
applied to any part of a given term or expression without affecting its type. An operational semantics of
λ⃝deﬁnes the term reduction relation 7→t and the expression reduction relation 7→e by specifying a strategy
for arranging reductions by ⇒β term and ⇒β exp. Below we consider two different styles of operational
semantics (both of which use the same syntax for reduction relations). For each instruction I, we assume an
instruction reduction I @ ω 7→e V @ ω′, which causes a transition of world from ω to ω′; if I has arguments,
we ﬁrst reduce them into values by applying 7→t repeatedly.
Figure 2.5 shows an operational semantics of λ⃝which uses expression substitutions ⟨E/x⟩F for ex-
pression computations; for term evaluations, we can choose any reduction strategy (Figure 2.5 uses a call-
by-name discipline). The rule Tβ is a shorthand for applying ⇒β term to (λx:A. M) N. The rules ETerm

35
M 7→t M′
M N 7→t M′ N TβL
N 7→t N ′
(λx:A. M) N 7→t (λx:A. M) N ′ TβR
(λx:A. M) V 7→t [V/x]M TβV
M 7→t N
M @ ω 7→e N @ ω ETerm
M 7→t N
letcmp x ◁M in F @ ω 7→e letcmp x ◁N in F @ ω EBind
E @ ω 7→e E′ @ ω′
letcmp x ◁cmp E in F @ ω 7→e letcmp x ◁cmp E′ in F @ ω′ EBindR
letcmp x ◁cmp V in F @ ω 7→e [V/x]F @ ω EBindV
Figure 2.6: Operational semantics of λ⃝in the direct style.
and EBind use a term reduction M 7→t N to reduce a term into a value. The rule EBindβ is a shorthand
for applying ⇒β exp to letcmp x ◁cmp E in F; in the case of E = M, it reduces letcmp x ◁cmp M in F
into ⟨M/x⟩F = [M/x]F without further reducing M. The rule EBindI perform an instruction reduction
I @ ω 7→e V @ ω′.
Figure 2.6 shows an alternative style of operational semantics, called the direct style, which requires
only term substitutions [V/x]E for expression computations; for term evaluations, we can choose any re-
duction strategy (Figure 2.6 uses a call-by-value discipline). The rules ETerm and EBind are the same as in
Figure 2.5. Given letcmp x ◁cmp E in F, we apply the rule EBindR repeatedly until E is reduced into a
value V ; then the rule EBindV reduces letcmp x ◁cmp V in F into ⟨V/x⟩F = [V/x]F. Thus a variable is
always replaced by a value (during both term evaluations and expression computations).
The direct style is more extensible than the ﬁrst style because it does not use expression substitutions.
That is, the introduction of a new expression construct requires only new reduction rules. In comparison,
the ﬁrst style hinges on expression substitutions, and requires not only new reduction rules but also an
augmented deﬁnition of expression substitution for each new expression construct. If expression substitution
cannot be deﬁned on a new expression construct, we may have to further specialize existing reduction rules.
For example, the rules EBindβ and EBindI can be thought of as derived from a common reduction rule when
instructions are introduced.
The type safety of λ⃝consists of two properties: type preservation and progress. The proof of type
preservation uses Corollaries 2.4 and 2.6, the type-preservation/progress requirement on instructions, and
Proposition 2.7. The proof of progress requires a canonical forms lemma. In either style of the operational
semantics, all proofs proceed in the same way.
Theorem 2.8 (Type preservation).
If M 7→t N and · ⊢s M : A @ ω, then · ⊢s N : A @ ω.
If E @ ω 7→e F @ ω′ and · ⊢s E ÷ A @ ω, then · ⊢s F ÷ A @ ω′.
Proof. By induction on the structure of M and E.
Lemma 2.9 (Canonical forms).
If V is a value of type A ⊃B, then V is a lambda abstraction λx:A. M.
If V is a value of type ⃝A, then V is a computation term cmp E.
Proof. By inspection of the typing rules.

36
Theorem 2.10 (Progress).
If · ⊢s M : A @ ω, then either M is a value or there exists N such that M 7→t N.
If · ⊢s E ÷ A @ ω, then either E is a value or there exist F and ω′ such that E @ ω 7→e F @ ω′.
Proof. By induction on the structure of M and E.
Since expressions may produce world effects, they cannot be converted into terms. In contrast, terms
can always be lifted to expressions by the typing rule Term. Therefore we deﬁne a program as a closed
expression E that typechecks at a certain initial world ωinitial, i.e., · ⊢s E ÷ A @ ωinitial. We choose ωinitial
according to the world structure being employed. To run a program E, we compute it at ωinitial.
2.4
Examples of world effects
In order to implement a speciﬁc notion of world effect in λ⃝, we specify a world structure and provide
instructions to interact with worlds. In this section, we discuss three speciﬁc notions of world effect.
2.4.1
Probabilistic computations
In order to facilitate the coding of sampling techniques developed in simulation theory, we model a proba-
bilistic computation as a computation that returns a value after consuming real numbers drawn independently
from U(0.0, 1.0], rather than a single such real number. A real number r is a world term of type real. A
world, the source of probabilistic choices, is represented as an inﬁnite sequence of real numbers drawn
independently from U(0.0, 1.0]. We use an instruction S for consuming the ﬁrst real number of a given
world.
world term type
W
::=
real
world term
W
::=
r
instruction
I
::=
S
world
ω
::=
r1r2 · · · ri · · ·
where ri ∈(0.0, 1.0]
r : real @ ω Real
Γ ⊢s S ÷ real @ ω Sampling
S @ r1r2r3 · · · 7→e r1 @ r2r3 · · · Sampling
It is easy to show that instruction S satisﬁes the type-preservation/progress requirement. Since a world
does not affect types of world terms and instructions, the monotonicity of ≤also holds trivially. We can use
any world as an initial world. As we will see in Chapter 3, λ⃝with the above constructs for probabilistic
computations serves as the core of PTP.
2.4.2
Sequential input/output
We model sequential input/output with a computation that consumes an inﬁnite input character stream is
and outputs to a ﬁnite output character stream os, where a character is a world term of type char. We use
two instructions: read c for reading a character from the input stream and write c M for writing a character
to the output stream.
world term type
W
::=
char
world term
W
::=
c
instruction
I
::=
read c | write c M
world
ω
::=
(is, os)
is
::=
c1c2c3 · · ·
os
::=
nil | c :: os

37
c : char @ ω Char
Γ ⊢s read c ÷ char @ ω Read c
Γ ⊢s M : char @ ω
Γ ⊢s write c M ÷ char @ ω Write c
read c @ (c1c2c3 · · · , os) 7→e c1 @ (c2c3 · · · , os) Read c
M 7→t N
write c M @ ω 7→e write c N @ ω Write c
write c c @ (is, os) 7→e c @ (is, c :: os) Write c′
It is easy to show that both instructions satisfy the type-preservation/progress requirement. As in prob-
abilistic computations, a world does not affect types of world terms and instructions, and the monotonicity
of ≤holds trivially. We use an empty output character stream nil in an initial world.
2.4.3
Mutable references
Probabilistic computations and sequential input/output are easy to model because worlds do not affect types
of world terms and instructions. Mutable references, however, require world terms whose type depends on
worlds, namely references. Consequently worlds should be designed in such a way that they provide enough
information on a given reference to correctly determine its type.
We use ref A as world term types for references.
A world is represented as a collection of pairs
[l 7→V : A] of a reference l and a closed value V annotated with its type A. It may be thought of as a
well-typed store: if [l 7→V : A] ∈ω, then V has type A at world ω (i.e., · ⊢s V : A @ ω) and references in it
are all distinct. We use three instructions: new M : A for initializing a fresh reference, read M for reading
the contents of a world, and write M M for updating a world. Reading the contents of a world is a world
effect, even though it does not cause a change to the world.
world term type
W
::=
ref A
world term
W
::=
l
instruction
I
::=
new M : A | read M | write M M
world
ω
::=
· | ω, [l 7→V : A]
Figure 2.7 shows new typing rules and reduction rules:
To prove the type-preservation/progress requirement on instructions, we ﬁrst show that well-typed in-
structions never generate corrupt worlds (Corollaries 2.12 and 2.14). In Lemma 2.11, we do not postulate
that ω, [l 7→V : A] is a world (i.e., it possesses the structure of a store, but may not be well-typed).
Lemma 2.11. If ω is a world and · ⊢s V : A @ ω, then
Γ ⊢s M : B @ ω implies Γ ⊢s M : B @ ω, [l 7→V : A], and
Γ ⊢s E ÷ B @ ω implies Γ ⊢s E ÷ B @ ω, [l 7→V : A], where l is a fresh reference.
Proof. By simultaneous induction on the structure of M and E. An interesting case is when M = l′ ̸= l.
If M = l′, then Γ ⊢s M : B @ ω implies B = ref B′ and [l′ 7→V ′ : B′] ∈ω by the rule Ref. Since
[l′ 7→V ′ : B′] ∈ω, [l 7→V : A], we have Γ ⊢s M : B @ ω, [l 7→V : A].
Corollary 2.12. If · ⊢s V : A @ ω where ω is a world, then ω, [l 7→V : A] is also a world for any fresh
reference l.
Proof. For each [l′ 7→V ′ : A′] ∈ω, we have · ⊢s V ′ : A′ @ ω because ω is a world. By Lemma 2.11, we
have · ⊢s V ′ : A′ @ ω, [l 7→V : A]. From · ⊢s V : A @ ω and Lemma 2.11, · ⊢s V : A @ ω, [l 7→V : A] also
follows.

38
[l 7→V : A] ∈ω
l : ref A @ ω
Ref
Γ ⊢s M : A @ ω
Γ ⊢s new M : A ÷ ref A @ ω New
Γ ⊢s M : ref A @ ω
Γ ⊢s read M ÷ A @ ω Read
Γ ⊢s M : ref A @ ω
Γ ⊢s N : A @ ω
Γ ⊢s write M N ÷ A @ ω
Write
M 7→t N
new M : A @ ω 7→e new N : A @ ω New
fresh l such that [l 7→V ′ : A′] ̸∈ω
new V : A @ ω 7→e l @ ω, [l 7→V : A] New′
M 7→t N
read M @ ω 7→e read N @ ω Read
[l 7→V : A] ∈ω
read l @ ω 7→e V @ ω Read ′
M 7→t M′
write M N @ ω 7→e write M′ N @ ω Write
N 7→t N ′
write l N @ ω 7→e write l N ′ @ ω Write′
[l 7→V ′ : A] ∈ω
write l V @ ω 7→e V @ ω −[l 7→V ′ : A], [l 7→V : A] Write′′
Figure 2.7: Typing rules and reduction rules for mutable references.
In Lemma 2.13, we do not postulate that ω −[l 7→V ′ : A], [l 7→V : A] is a world.
Lemma 2.13.
If · ⊢s V : A @ ω and [l 7→V ′ : A] ∈ω where ω is a world, then
Γ ⊢s M : B @ ω implies Γ ⊢s M : B @ ω −[l 7→V ′ : A], [l 7→V : A] and
Γ ⊢s E ÷ B @ ω implies Γ ⊢s E ÷ B @ ω −[l 7→V ′ : A], [l 7→V : A].
Proof. By simultaneous induction on the structure of M and E. An interesting case is when M = l.
Corollary 2.14.
If · ⊢s V : A @ ω and [l 7→V ′ : A] ∈ω where ω is a world, then
ω −[l 7→V ′ : A], [l 7→V : A] is also a world.
Proof. Similarly to the proof of Corollary 2.12.
Proposition 2.15 (Type-preservation/progress requirement on instructions). If · ⊢s I ÷ A @ ω and ar-
guments to I are all values, then there exists a world ω′ satisfying I @ ω 7→e V @ ω′ and · ⊢s V : A @ ω′.
Proof. By case analysis of I. We use Corollaries 2.12 and 2.14.
For the monotonicity requirement on instructions, we directly prove Proposition 2.7 exploiting Lem-
mas 2.11 and 2.13.
Proof of Proposition 2.7. Since the accessibility relation ≤is speciﬁed by instruction reductions, ω ≤ω′
implies that
ω = ω1 ≤· · · ≤ωi ≤· · · ≤ωn = ω′,
where ωi+1 is equal to either ωi, [l 7→V : A] or ωi −[l 7→V ′ : A], [l 7→V : A] for 1 ≤i < n. We proceed
by induction on n.

39
In order to maintain the monotonicity of ≤, all references in a world must be persistent, since once a
reference is deallocated, its type can no longer be determined. This means that an explicit instruction for
deallocating references (e.g., delete M) is not allowed in λ⃝. In the present framework of λ⃝, even garbage
collections are not allowed because they destroy the monotonicity of ≤: a garbage collection transition
from ω to ω′ must ensure that l : ref A @ ω implies l : ref A @ ω′ for every possible reference l, including
those references not found in a given program, which are precisely what it deallocates. (In practice, garbage
collections do not interfere with evaluations and computations, and are safe to implement.) We use an empty
store as an initial world.
2.4.4
Supporting multiple notions of world effect
Since a world structure realizes a speciﬁc notion of world effect and instructions provide an interface to
worlds, we can support multiple notions of world effect by combining individual world structures and letting
each instruction interact with its relevant part of worlds. For example, we can use all the above instructions
if a world consists of three sub-worlds: an inﬁnite sequence of real numbers, input/output streams, and a
well-typed store. This is how λ⃝combines world effects at the language design level.
We may think of λ⃝as providing a built-in implementation of a state monad whose states are worlds.
Then the ease of combining world effects in λ⃝reﬂects the fact that state monads combine well with each
other (by combining individual states).
2.5
Fixed point constructs
In this section, we investigate an extension of λ⃝with ﬁxed point constructs. We ﬁrst consider those based
upon the unfolding semantics, in which a ﬁxed point construct reduces by unrolling itself. Next we consider
those based upon the backpatching semantics, as used in Scheme [3]. For expressions, we assume the
operational semantics in the direct style in Figure 2.6.
For a uniform treatment of types, we choose to allow ﬁxed point constructs for all types. An alternative
approach would be to conﬁne ﬁxed point constructs only to lambda abstractions (as in ML), but it would be
inadequate for our purpose because recursive computations require ﬁxed point constructs for computation
terms (of type ⃝A) anyway.
2.5.1
Unfolding semantics
We use ﬁx x:A. M as a term ﬁxed point construct for recursive evaluations. Its typing rule and reduction
rule are as usual:
term
M
::=
· · · | ﬁx x:A. M
Γ, x : A ⊢s M : A @ ω
Γ ⊢s ﬁx x:A. M : A @ ω Fix
ﬁx x:A. M 7→t [ﬁx x:A. M/x]M TFix
In the presence of term ﬁxed point constructs, any truth judgment A true holds vacuously, since ﬁx x:A. x
typechecks for every type A and represents a proof of A true. Now a term M of type A does not always
represent a constructive proof of A true; rather it may contain nonsensical proofs such as ﬁx x:B. x. The
deﬁnition of a computability judgment A comp, however, remains the same because it is deﬁned relative to
a truth judgment A true.
In conjunction with computation terms cmp E, term ﬁxed point constructs enable us to encode recursive
computations: we ﬁrst build a term ﬁxed point construct M of type ⃝A and then convert it into an expression
letcmp x ◁M in x, which denotes a recursive computation. Generalizing this idea, we deﬁne syntactic sugar

40
for recursive computations. We introduce an expression variable x and an expression ﬁxed point construct
eﬁx x÷A. E; a new form of binding x ÷ A for expression variables is used in typing contexts:
expression
E
::=
· · · | x | eﬁx x÷A. E
typing context
Γ
::=
· · · | Γ, x ÷ A
New typing rules and reduction rule are as follows:
Γ, x ÷ A ⊢s x ÷ A @ ω Evar
Γ, x ÷ A ⊢s E ÷ A @ ω
Γ ⊢s eﬁx x÷A. E ÷ A @ ω Eﬁx
eﬁx x÷A. E @ ω 7→e [eﬁx x÷A. E/x]E @ ω Eﬁx
In the rule Eﬁx, [eﬁx x÷A. E/x]E denotes a capture-avoiding substitution of eﬁx x÷A. E for expression
variable x. Thus eﬁx x ÷ A. E behaves like term ﬁxed point constructs except that it unrolls itself by
substituting an expression for an expression variable, instead of a term for an ordinary variable.
To simulate expression ﬁxed point constructs, we deﬁne a function (·)⋆which translates (eﬁx x÷A. E)⋆
into:
letcmp yr ◁ﬁx xp:⃝A. cmp [letcmp yv ◁xp in yv/x]E⋆in yr
That is, we introduce a variable xp to encapsulate eﬁx x÷A. E and expand x to a bind expression letcmp yv ◁xp in yv.
The translation of other terms and expressions is structural; for the sake of simplicity, we do not consider
world terms and instructions:
x⋆
=
x
(λx:A. M)⋆
=
λx:A. M⋆
(M1 M2)⋆
=
M1⋆M2⋆
(cmp E)⋆
=
cmp E⋆
(ﬁx x:A. M)⋆
=
ﬁx x:A. M⋆
(letcmp x ◁M in E)⋆
=
letcmp x ◁M⋆in E⋆
x⋆
=
x
Proposition 2.17 shows that when translated via the function (·)⋆, the typing rules Evar and Eﬁx are
sound with respect to the original type system (without the rules Evar and Eﬁx).
Lemma 2.16.
If Γ ⊢s F ÷ A @ ω and Γ, x ÷ A ⊢s M : B @ ω, then Γ ⊢s [F/x]M : B @ ω.
If Γ ⊢s F ÷ A @ ω and Γ, x ÷ A ⊢s E ÷ B @ ω, then Γ ⊢s [F/x]E ÷ B @ ω.
Proof. By simultaneous induction on the structure of M and E.
Proposition 2.17.
If Γ ⊢s M : A @ ω, then Γ ⊢s M⋆: A @ ω.
If Γ ⊢s E ÷ A @ ω, then Γ ⊢s E⋆÷ A @ ω.
Proof. By simultaneous induction on the structure of the derivation of Γ ⊢s M : A @ ω and Γ ⊢s E ÷ A @ ω.
An interesting case is when E = eﬁx x÷A. F.
Case E = eﬁx x÷A. F:
Γ, x ÷ A ⊢s F ÷ A @ ω
by Eﬁx
Γ, x ÷ A ⊢s F ⋆÷ A @ ω
by induction hypothesis

41
Γ, xp : ⃝A, x ÷ A ⊢s F ⋆÷ A @ ω
by weakening
Γ, xp : ⃝A ⊢s letcmp yv ◁xp in yv ÷ A @ ω
(typing derivation)
Γ, xp : ⃝A ⊢s [letcmp yv ◁xp in yv/x]F ⋆÷ A @ ω
by Lemma 2.16
Γ ⊢s letcmp yr ◁ﬁx xp:⃝A. cmp [letcmp yv ◁xp in yv/x]F ⋆in yr ÷ A @ ω
(typing derivation)
Γ ⊢s (eﬁx x÷A. F)⋆÷ A @ ω
by the deﬁnition of (·)⋆
Since M⋆and E⋆do not contain expression ﬁxed point constructs, the rule Eﬁx is not used in Γ ⊢s M⋆: A @ ω
and Γ ⊢s E⋆÷ A @ ω. Neither is the rule Evar used unless M or E contains free expression variables.
Therefore, given a term or expression with no free expression variable, the function (·)⋆returns another
term or expression of the same type which does not need the rules Evar and Eﬁx.
Propositions 2.22 and 2.23 show that the reduction rule Eﬁx is sound and complete with respect to the
operational semantics (in the direct style) in Section 2.3.5. We use the fact that the computation of E⋆does
not require the rule Eﬁx.
Proposition 2.18.
For any term N, we have ([N/x]M)⋆= [N ⋆/x]M⋆and ([N/x]E)⋆= [N ⋆/x]E⋆.
For any expression F, we have ([F/x]M)⋆= [F ⋆/x]M⋆and ([F/x]E)⋆= [F ⋆/x]E⋆.
Proof. By simultaneous induction on the structure of M and E.
Lemma 2.19. If M 7→t N, then M⋆7→t N ⋆.
Proof. By induction on the structure of the derivation of M 7→t N.
Lemma 2.20.
If M⋆7→t N ′, then there exists N such that N ′ = N ⋆and M 7→t N.
Proof. By induction on the structure of the derivation of M⋆7→t N ′.
We introduce an equivalence relation ≡e on expressions to state that two expressions compute to the
same value.
Deﬁnition 2.21.
E ≡e F if and only if E @ ω 7→∗
e V @ ω′ implies F @ ω 7→∗
e V @ ω′, and vice versa.
The following equivalences are used in proofs below:
letcmp x ◁cmp E in x
≡e
E
letcmp x ◁cmp E in F
≡e
letcmp x ◁cmp E′ in F
where
E ≡e E′
(eﬁx x÷A. E)⋆
≡e
[(eﬁx x÷A. E)⋆/x]E⋆
The third equivalence follows from an expression reduction
(eﬁx x÷A. E)⋆@ ω 7→e letcmp yr ◁cmp [(eﬁx x÷A. E)⋆/x]E⋆in yr @ ω.
Proposition 2.22.
If E @ ω 7→e F @ ω′ with the rule Eﬁx, then E⋆@ ω 7→e F ′ @ ω′ and F ′ ≡e F ⋆.

42
Proof. By induction on the structure of the derivation of E @ ω 7→e F @ ω′. We consider the case E =
letcmp x ◁M in E0 where M ̸= cmp E′.
If letcmp x ◁M in E0 @ ω 7→e letcmp x ◁N in E0 @ ω by the rule EBind, then M 7→t N.
By Lemma 2.19, M⋆7→t N ⋆.
Since (letcmp x ◁M in E0)⋆= letcmp x ◁M⋆in E0⋆and (letcmp x ◁N in E0)⋆= letcmp x ◁N ⋆in E0⋆,
we have (letcmp x ◁M in E0)⋆@ ω 7→e (letcmp x ◁N in E0)⋆@ ω.
Then we let F ′ = (letcmp x ◁N in E0)⋆.
Proposition 2.23.
If E⋆@ ω 7→e F ′ @ ω′, then there exists F such that F ′ ≡e F ⋆and E @ ω 7→e F @ ω′.
Proof. By induction on the structure of the derivation of E⋆@ ω 7→e F ′ @ ω′. An interesting case is when
the rule EBind is applied last in a given derivation.
If E = letcmp x ◁M in E0, then E⋆= letcmp x ◁M⋆in E0⋆.
By Lemma 2.20, there exists N such that M 7→t N and M⋆7→t N ⋆.
Hence we have E @ ω 7→e letcmp x ◁N in E0 @ ω′ and E⋆@ ω 7→e letcmp x ◁N ⋆in E0⋆@ ω′ (where
ω = ω′).
Then we let F = letcmp x ◁N in E0.
If E = eﬁx x÷A. E0, then F ′ ≡e ([eﬁx x÷A. E0/x]E0)⋆(and ω = ω′)
because (eﬁx x÷A. E0)⋆≡e [(eﬁx x÷A. E0)⋆/x]E0⋆= ([eﬁx x÷A. E0/x]E0)⋆.
Then we let F = [eﬁx x÷A. E0/x]E0.
As seen in the deﬁnition of expression ﬁxed point constructs, term ﬁxed point constructs can leak into
expressions to give rise to recursive computations. Note that non-terminating computations in λ⃝are not
necessarily due to (term or expression) ﬁxed point constructs, since mutable references can also be ex-
ploited to encode recursive computations. For example, the following expression initiates a non-terminating

43
computation in which reference x stores a computation term which dereferences itself:
letcmp x ◁cmp new cmp 0 in
letcmp y ◁cmp write x cmp ( letcmp y ◁cmp read x in
letcmp z ◁y in
z )
in
letcmp z ◁y in
z


@ ·
7→∗
e
letcmp y ◁cmp write l cmp ( letcmp y ◁cmp read l in
letcmp z ◁y in
z )
in
letcmp z ◁y in
z


@ [l 7→cmp 0 : ⃝int]
7→∗
e
letcmp z ◁cmp ( letcmp y ◁cmp read l in
letcmp z ◁y in
z )
in
z


@ [l 7→cmp ( letcmp y ◁cmp read l in
letcmp z ◁y in
z )
: ⃝int]
7→∗
e
letcmp z ◁
cmp ( letcmp z ◁cmp ( letcmp y ◁cmp read l in
letcmp z ◁y in
z )
in
z )
in
z


@ [l 7→cmp ( letcmp y ◁cmp read l in
letcmp z ◁y in
z )
: ⃝int]
7→∗
e
· · ·
2.5.2
Backpatching semantics
Unlike the unfolding semantics, the backpatching semantics evaluates or computes a ﬁxed point construct
by ﬁrst ﬁnishing the reduction of its body and then "tying a recursive knot", or "backpatching" the result.
For term evaluations, the two semantics are equivalent except that when the unfolding semantics gives rise
to an inﬁnite loop, the backpatching semantics generates an error.
We investigate a ﬁxed point construct vﬁx z :A. E for expressions that is based upon the backpatching
semantics. Unlike eﬁx x÷A. E which computes a ﬁxed point over both values and world effects and thus
x is interpreted as an expression, it computes a ﬁxed point only over values and z in it is a term.5 For
this reason, the computation is usually referred to as value recursion [18]. Similar constructs are found in
Erk¨ok and Launchbury [18] (ﬁxed point construct mﬁx in Haskell) and Launchbury and Peyton Jones [37]
(recursive state transformer ﬁxST in Haskell).
5In this regard, the two ﬁxed point constructs for expressions cannot be compare directly.

44
Syntax and type system
We introduce a recursion variable z (with an underscore) as a term and a value recursion construct vﬁx z :A. E
as an expression:
term
M
::=
· · · | z
expression
E
::=
· · · | vﬁx z :A. E
A substitution for z is deﬁned in a standard way. To simplify the presentation of the type preservation
theorem (Theorem 2.25), we separate recursion variables from ordinary variables in the type system by
introducing a value recursion context Σ for recursion variables:
value recursion context
Σ
::=
· | Σ, z : A
A typing judgment now includes a value recursion context to record the type of each recursion variable:
term typing judgment
Γ; Σ ⊢s M : A @ ω
expression typing judgment
Γ; Σ ⊢s E ÷ A @ ω
Typing rules for judgments Γ ⊢s M : A @ ω and Γ ⊢s E ÷ A @ ω induce those for judgments Γ; Σ ⊢s M : A @ ω
and Γ; Σ ⊢s E ÷ A @ ω in a straightforward way (by adding Σ to every judgment). We also need additional
rules for recursion variables and value recursion constructs:
Γ; Σ, z : A ⊢s z : A @ ω Vvar
Γ; Σ, z : A ⊢s E ÷ A @ ω
Γ; Σ ⊢s vﬁx z :A. E ÷ A @ ω Vﬁx
The monotonicity of the accessibility relation ≤(in Proposition 2.7) is now stated with new typing
judgments.
Proposition 2.24.
If ω ≤ω′, then
Γ; Σ ⊢s M : A @ ω implies Γ; Σ ⊢s M : A @ ω′, and
Γ; Σ ⊢s E ÷ A @ ω implies Γ; Σ ⊢s E ÷ A @ ω′.
Operational semantics
Conceptually we compute vﬁx z :A. E as follows: ﬁrst we bind z to a black hole so that any premature
attempt to read it results in a value recursion error; next we compute E to obtain a value V ; ﬁnally we
"backpatch" every occurrence of z in V with V itself and return the backpatched value as the result.
One approach to backpatching z with V is by replacing z by a ﬁxed point construct ﬁx z :A. V (as in
[47]). A problem with this approach is that z may appear at the resultant world after computing E. That is, if
E at a world ω computes to V at another world ω′, z may be used by ω′. Then we would need substitutions
on worlds as well (e.g., [ﬁx z :A. V /z]ω′), which should be deﬁned for each kind of world effect and thus
we want to avoid; besides the type preservation property becomes difﬁcult to prove.
To eliminate the need for substitutions on worlds, we maintain a recursion store σ. It associates each
recursion variable with a value V :
recursion store
σ
::=
· | σ, z = V
Now we reformulate the operational semantics with two reduction judgments:
• A term reduction M  σ 7→t N means that M with recursion store σ reduces to N.

45
• An expression reduction E @ ω  σ 7→e F @ ω′  σ′ means that E at world ω with recursion store σ
reduces to F at world ω′ with recursion store σ′.
A term reduction requires (but does not update) a recursion store because it may read recursion variables. An
expression reduction may update both a world (by reducing instructions) and a recursion store (by reducing
value recursion constructs). Reduction rules for judgments M 7→t N and E @ ω 7→e F @ ω′ induce those
for judgments M  σ 7→t N and E @ ω  σ 7→e F @ ω′  σ′ in a straightforward way (by adding σ to every
judgment).
Instead of directly modeling black holes with certain special values, we indirectly model black holes by
reducing vﬁx z :A. E to an intermediate value recursion construct vﬁx• z : A. E. That is, the presence of
vﬁx• z :A. E means that z is assumed to be bound to a black hole and that E is currently being reduced; if
a term in E attempts to read z, it results in a value recursion error and the whole reduction gets stuck. The
typing rule for vﬁx• z :A. E is the same as for vﬁx z :A. E:
expression
E
::=
· · · | vﬁx• z :A. E
Γ; Σ, z : A ⊢s E ÷ A @ ω
Γ; Σ ⊢s vﬁx• z :A. E ÷ A @ ω Vﬁx•
The rules for reducing recursion variables and value recursion constructs are as follows:
z = V ∈σ
z  σ 7→t V Vvar
vﬁx z :A. E @ ω  σ 7→e vﬁx• z :A. E @ ω  σ Vﬁxinit
E @ ω  σ 7→e F @ ω′  σ′
vﬁx• z :A. E @ ω  σ 7→e vﬁx• z :A. F @ ω′  σ′ Vﬁxred
z = V ′ ̸∈σ
vﬁx• z :A. V @ ω  σ 7→e V @ ω  σ, z = V Vﬁxbpatch
These rules ensure that any premature attempt to read a recursion variable bound to a black hole results in a
value recursion error and the whole reduction gets stuck. The rule Vvar implies that z is not a value in itself.
The rule Vﬁxinit initiates the computation of vﬁx z :A. E by reducing it to vﬁx• z : A. E; the rule Vﬁxred
reduces the body E of vﬁx• z :A. E; the rule Vﬁxbpatch backpatches z with V . Note that α-conversion is
freely applicable even to vﬁx• z :A. E.
The reduction rule Vﬁxbpatch assumes dynamic renaming of recursion variables so that all recursion
variables in a recursion store remain distinct. As an example, consider the following expression:
letcmp x1 ◁cmp vﬁx z :A. E1 in letcmp x2 ◁cmp vﬁx z :A. E2 in F
Although we do not need to rename either instance of z during typechecking, we have to rename the second
instance after computing vﬁx z :A. E2 because the recursion store already contains a recursion variable of
the same name.
Since the result of an evaluation or a computation may contain recursion variables, we need to incorpo-
rate recursion stores or their abstractions in stating the type preservation property. We use value recursion
contexts for this purpose as they are essentially the result of typing recursion stores. Formally we write
|= σ : Σ @ ω if there exists a one-to-one correspondence between z = V ∈σ and z : A ∈Σ such that
·; Σ ⊢s V : A @ ω holds. Now type preservation property is stated as follows:

46
Theorem 2.25 (Type preservation). Suppose |= σ : Σ @ ω.
If M  σ 7→t N and ·; Σ ⊢s M : A @ ω, then ·; Σ ⊢s N : A @ ω.
If E @ ω  σ 7→e F @ ω′  σ′ and ·; Σ ⊢s E ÷ A @ ω, then there exists Σ′ such that ·; Σ′ ⊢s F ÷ A @ ω′
and |= σ′ : Σ′ @ ω′.
Proof. By induction on the structure of the derivation of M  σ 7→t N and E @ ω  σ 7→e F @ ω′  σ′. In-
teresting cases are when one of the rules Vvar, Vﬁxinit, Vﬁxred, and Vﬁxbpatch is applied last in a given
derivation. We consider two representative cases below.
Case z = V ∈σ
z  σ 7→t V Vvar :
·; Σ ⊢s z : A @ ω implies z : A ∈Σ by the rule Vvar.
From |= σ : Σ @ ω, z = V ∈σ, and z : A ∈Σ,
we have ·; Σ ⊢s V : A @ ω.
Case
z = V ′ ̸∈σ
vﬁx• z :A. V @ ω  σ 7→e V @ ω  σ, z = V Vﬁxbpatch
Since |= σ : Σ @ ω,
for any z′ = V ′ ∈σ, we have ·; Σ ⊢s V ′ ÷ A′ @ ω and z′ : A′ ∈Σ for some type A′.
We let Σ′ = Σ, z : A.
Then, for any z′ = V ′ ∈σ, we have ·; Σ′ ⊢s V ′ ÷ A′ @ ω and z′ : A′ ∈Σ′ for some type A′.
The rule Vﬁx• implies ·; Σ ⊢s vﬁx• z :A. V ÷ A @ ω and ·; Σ, z : A ⊢s V ÷ A @ ω.
Then ·; Σ′ ⊢s V ÷ A @ ω and z : A ∈Σ′.
Therefore |= σ, z = V : Σ′ @ ω.
Since the type system does not detect value recursion errors, the computation of a well-typed expression
may end up with a value recursion error. To catch value recursion errors statically, we can adopt advanced
type systems for value recursion in [9, 16].
Simulating value recursion constructs
Section 2.5.1 has shown that eﬁx x ÷ A. E can be simulated with ﬁx x:A. M.
Can we also simulate
vﬁx z :A. E with ﬁx x:A. M? In Haskell, a value recursion construct mﬁx for a speciﬁc monad can be
deﬁned in terms of the ordinary ﬁxed point construct ﬁx. For example, Moggi and Sabry [47] show that for
a state monad M A = S →(A × S) where M is a type constructor and S is the type of states, mﬁx can be
deﬁned as follows:
mﬁx x:A. M = λs:S. ﬁx p:A × S. (λx:A. M) (fst p) s
Here we use a product type A × S and a projection term fst p; both M and mﬁx x : A. M have type
M A = S →(A × S). Since the type constructor ⃝in λ⃝essentially forms a state monad, it may appear
that we can deﬁne vﬁx z :A. E in terms of ﬁx x:A. M. Unlike the state monad M A, however, we cannot
access states (i.e., worlds) as terms. Therefore we cannot exploit the above idea to simulate vﬁx z :A. E with
ﬁx x:A. M.
Another idea to simulate vﬁx z :A. E is to use instructions for mutable references: to compute vﬁx z :A. E,
we initialize a fresh reference for z; to backpatch z, we update the store. In this case, z can no longer be a
term because its evaluation requires an access to the store. In other words, z should now be deﬁned as an
expression.

47
term
M
::=
· · · | contt κ | callcct x. M | throwt M M
value
V
::=
· · · | contt κ
evaluation context
κ
::=
[] | κ M | (λx:A. M) κ | throwt κ M | throwt (contt κ) κ
Figure 2.8: Syntax for continuations for terms.
2.6
Continuations
So far, we have restricted ourselves to world effects, i.e., transitions between worlds. λ⃝conﬁnes world
effects to expressions so that terms are free of world effects. When we extend λ⃝with control effects,
however, it is not immediately clear which syntactic category should be permitted to produce control effects.
On one hand, we could choose to conﬁne control effects to expressions so that terms remain free of any kind
of effect. Then the distinction between effect-free evaluations and effectful computations is drawn in a
conventional sense. On the other hand, in order to develop λ⃝into a practical programming language, it
is desirable to allow control effects in terms. For example, exceptions for terms would be an easy way to
handle division by zero or pattern-match failures occurring during evaluations. At the same time, however,
exceptions for expressions are also useful for those instructions whose execution does not always succeed.
We hold the view that expressions are in principle a syntactic category specialized for world effects,
and allow control effects in both terms and expressions. The decision does not prevent us from developing
control effects orthogonally to world effects, since control effects are realized with reduction rules whereas
world effects are realized with world structures. In fact, there is no reason to conﬁne control effects only to
one syntactic category, since the concept of control effect is relative to what constitutes the "basic" reduction
rules anyway.
As an example of control effect, we consider continuations. We consider two kinds: one for terms
and another for expressions. A continuation for terms denotes an evaluation parameterized over terms; a
continuation for expressions denotes a computation parameterized over terms. The two are independent
notions, and we discuss them separately. Since we are primarily interested in how continuations change the
state of the run-time system, we focus on the operational semantics only; for the type system, we refer the
reader to the literature (e.g., [25]).
In the syntax, we assume value recursion constructs which interact with continuations for expres-
sions in an interesting way.
Hence we continue to use the two reduction judgments M  σ 7→t N and
E @ ω  σ 7→e F @ ω′  σ′ in Section 2.5.2 (but in a different style).
2.6.1
Continuations for terms
Figure 2.8 shows the syntax for continuations for terms. An evaluation context κ is a term with a hole []
which can be ﬁlled with a term M to produce another term κ[M]; it assumes a call-by-value discipline.
contt κ lifts an evaluation context κ to a value and is called a term continuation. callcct and throwt are
constructs for capturing and throwing term continuations, respectively.
The operational semantics in Figure 2.9 uses a reduction judgment in the form of κ[M]  σ 7→t κ′[N]
where σ is a recursion store. Note that it is the same term reduction judgment as in Section 2.5.2 because both
κ[M] and κ′[N] are terms. The rule CTred uses a term reduction M ⇒β term N. The rule CTcallcc binds
variable x to a term continuation containing the current evaluation context κ; the rule CTthrow nulliﬁes the
current evaluation context κ to activate a new evaluation context κ′.
The formulation of continuations for terms is standard. What is interesting is that from a logical perspec-
tive, continuations for terms change the meaning of A true from intuitionistic truth to classical truth [23].
The change in the meaning of A true, however, does not mean that we have to change the deﬁnition of

48
M ⇒β term N
κ[M]  σ 7→t κ[N] CTred
z = V ∈σ
κ[z]  σ 7→t κ[V ] CTvvar
κ[callcct x. M]  σ 7→t κ[[contt κ/x]M] CTcallcc
κ[throwt (contt κ′) V ]  σ 7→t κ′[V ] CTthrow
Figure 2.9: Reduction rules for continuations for terms.
term
M
::=
· · · | conte φ
value
V
::=
· · · | conte φ
expression
E
::=
· · · | callcce x. E | throwe M E
computation context
φ
::=
[]e | []t | letcmp x ◁[]t in E | letcmp x ◁cmp φ in E |
vﬁx• z :A. φ | throwe []t E | throwe (conte φ) φ
Figure 2.10: Syntax for continuations for expressions.
expressions accordingly, since our deﬁnition of A comp is not subject to a particular deﬁnition of A true.
In other words, even if we change the meaning of A true, the same deﬁnition of A comp remains valid with
respect to the new deﬁnition of A true; hence the previous deﬁnition of expressions also remains valid.
2.6.2
Continuations for expressions
Figure 2.10 shows the syntax for continuations for expressions. A computation context φ is an expression
with a hole []t or []e. []t can be ﬁlled only with a term, and []e only with an expression. conte φ lifts a
computation context φ to a value and is called an expression continuation. callcce and throwe are constructs
for capturing and throwing expression continuations, respectively.
The
operational
semantics
in
Figure
2.11
uses
a
reduction
judgment
in
the
form
of
φ[E] @ ω  σ 7→e φ′[F] @ ω′  σ′. Note that it is the same expression reduction judgment as in Section 2.5.2
because both φ[E] and φ′[F] are expressions. The rule CEcallcc binds variable x to a expression con-
tinuation containing the current computation context φ; the rule CEthrow nulliﬁes the current computation
context φ to activate a new computation context φ′. By the rule CEvﬁxo, a computation context vﬁx• z :A. φ
marks that z is bound to a black hole.
It is important that the rule CEvﬁxc does not require z = V ′ ̸∈σ in the premise; if z = V ′ is already
in σ, it is removed in σ, z = V (so that all recursion variables remain distinct). The reason is that an
expression continuation that has been captured before the completion of the computation of vﬁx• z : A. E
may be thrown after its completion. In this case, recursion variable z is already bound to the value that the
previous computation of vﬁx• z :A. E has returned. We can exploit this property to show that, for example,
vﬁx z :A. letcmp x ◁M in E and letcmp x ◁M in vﬁx z :A. E behave differently even when z is not free in
M.6
Consider an expression
vﬁx z :A. letcmp x ◁cmp callcce y. E in F
where z is not free in E. The expression continuation captured by callcce y. E may escape the scope of the
whole value recursion construct. When it is thrown later, z is already bound to a value and every attempt to
6Erk¨ok and Launchbury [18] call the equivalence between the two expressions the left-shrinking property of value recursion.

49
M  σ 7→t N
φ[M] @ ω  σ 7→e φ[N] @ ω  σ CEtred
φ[letcmp x ◁cmp V in E] @ ω  σ 7→e φ[[V/x]E] @ ω  σ CEbind
φ[callcce x. E] @ ω  σ 7→e φ[[conte φ/x]E] @ ω  σ CEcallcc
φ[throwe (conte φ′) V ] @ ω  σ 7→e φ′[V ] @ ω  σ CEthrow
φ[vﬁx z :A. E] @ ω  σ 7→e φ[vﬁx• z :A. E] @ ω  σ CEvﬁxo
φ[vﬁx• z :A. V ] @ ω  σ 7→e φ[V ] @ ω  σ, z = V CEvﬁxc
Figure 2.11: Reduction rules for continuations for expressions.
read z in F succeeds without raising a value recursion error. This is not the case for the following expression:
letcmp x ◁cmp callcce y. E in vﬁx z :A. F
During the computation of F, z is bound to a black hole by the rule CEvﬁxo. Consequently any attempt to
read z in F results in a value recursion error.
In general, value recursion is unsafe in the presence of expression continuations because a value recur-
sion construct may compute to a value containing unresolved recursion variables, that is, recursion variables
bound to black holes (the counter-example in [47] can be rewritten in λ⃝). An error resulting from reading
an unresolved recursion variable is similar to a value recursion error in that both result from an attempt to
read a recursion variable bound to a black hole. The difference is that while a value recursion error results
from a premature attempt to read a recursion variable that will be eventually bound to a value, an unresolved
recursion variable remains bound to a black hole forever.
2.7
Summary
Moggi's monadic metalanguage λml [44, 45] has served as the de facto standard for subsequent monadic
languages [36, 37, 6, 70, 46, 78, 47]. Benton, Biermann, and de Paiva [7] show that from a type-theoretic
perspective, λml is connected to lax logic via the Curry-Howard isomorphism. Pfenning and Davies [60]
reformulate λml by applying Martin-L¨of's methodology of distinguishing between propositions and judg-
ments [42] to lax logic. The new formulation of λml draws a syntactic distinction between values and com-
putations, and uses the modality ⃝for computations. It is used in the design of a security-typed monadic
language [13]; its underlying modal type theory inspires type systems in [4, 5] and effect systems in [51, 52].
The idea of the syntactic distinction but without an explicit modality for computations is used by Petersen
et al. [54]. The same idea is also used by Mandelbaum, Walker, and Harper [41]. Their language is similar to
λ⃝in that the operational semantics (but not the type system) uses an accessibility relation between worlds.
The meaning of a world is, however, slightly different: a world in their language is a collection of facts on a
world in λ⃝.
λ⃝extends the new formulation of λml by Pfenning and Davies with an operational semantics to support
concrete notions of computational effect. Compared with those monadic languages based upon λml, it
does not strictly increase the expressive power — it is straightforward to devise a translation from λ⃝to
a typical monadic language based upon λml and vice versa. In this regard, the syntactic distinction in
λ⃝may be thought of as a cosmetic change to the syntax of monadic languages. It, however, inspires a

50
new approach to incorporating computational effects into monadic languages by allowing control effects
both in terms and in expressions while conﬁning world effects to expressions. In a monadic language
based upon λml, this (unorthodox) approach would mean that its pure functional sublanguage is allowed to
produce control effects. The syntactic distinction also leads to the interpretation of terms and expressions
as complete languages of their own, which makes λ⃝a candidate for a uniﬁed framework under which to
study two languages that have traditionally been studied separately: Haskell (corresponding to terms) and
ML (corresponding to expressions). Ultimately we believe that the idea of the syntactic distinction conveys
a design principle not found in other monadic languages.

Chapter 3
The Probabilistic Language PTP
This chapter presents the syntax, type system, and operational semantics of PTP. We give examples to
demonstrate properties of PTP, and show how to verify that a program correctly encodes a target probability
distribution. We propose the Monte Carlo method [40] as a means of overcoming a limitation of PTP,
namely lack of support for precise reasoning about probability distributions.
For the reader who has read the previous chapter, PTP may be viewed as a simpliﬁed account of λ⃝
with language constructs for probabilistic computations in Section 2.4.1. A source of simpliﬁcation is that
a world, which is an inﬁnite sequence of random numbers, does not affect types of terms and expressions;
hence typing judgments in PTP do not require worlds. The following table show judgments in λ⃝and their
corresponding judgments in PTP:
Judgments in λ⃝
Judgments in PTP
Γ ⊢s M : A @ ω
Γ ⊢p M : A
Γ ⊢s E ÷ A @ ω
Γ ⊢p E ÷ A
M 7→t N
(same)
M ⇀V
(same)
E @ ω 7→e F @ ω′
(same)
E @ ω ⇁V @ ω′
(same)
The syntax of PTP uses type constructors familiar from programming languages (rather than logic) and more
speciﬁc keywords specialized to probability distributions:
Syntax of λ⃝
Syntax of PTP
A ⊃B
A→B
A ∧B
A × B
cmp E
prob E
letcmp x ◁M in E
sample x from M in E
The deﬁnition of PTP in this chapter is self-contained, but should be supplemented by the previous
chapter for its logical foundation.
3.1
Deﬁnition of PTP
3.1.1
Syntax and type system
PTP augments the lambda calculus, consisting of terms, with a separate syntactic category, consisting of
expressions in a monadic syntax. Terms denote regular values and expressions denote probabilistic compu-
tations. We say that a term evaluates to a value and an expression computes to a sample.
51

52
type
A, B
::=
A→A | A × A | ⃝A | real
term
M, N
::=
x | λx:A. M | M M | (M, M) | fst M |
snd M | ﬁx x:A. M | prob E | r
expression
E, F
::=
M | sample x from M in E | S
value/sample
V
::=
λx:A. M | (V, V ) | prob E | r
real number
r
sampling sequence
ω
::=
r1r2 · · · ri · · ·
where ri ∈(0.0, 1.0]
typing context
Γ
::=
· | Γ, x : A
Figure 3.1: Abstract syntax for PTP.
Γ, x : A ⊢p x : A Hyp
Γ, x : A ⊢p M : B
Γ ⊢p λx:A. M : A→B Lam
Γ ⊢p M1 : A→B
Γ ⊢p M2 : A
Γ ⊢p M1 M2 : B
App
Γ ⊢p M1 : A1
Γ ⊢p M2 : A2
Γ ⊢p (M1, M2) : A1 × A2
Prod
Γ ⊢p M : A1 × A2
Γ ⊢p fst M : A1
Fst
Γ ⊢p M : A1 × A2
Γ ⊢p snd M : A2
Snd
Γ, x : A ⊢p M : A
Γ ⊢p ﬁx x:A. M : A Fix
Γ ⊢p E ÷ A
Γ ⊢p prob E : ⃝A Prob
Γ ⊢p r : real Real
Γ ⊢p M : A
Γ ⊢p M ÷ A Term
Γ ⊢p M : ⃝A
Γ, x : A ⊢p E ÷ B
Γ ⊢p sample x from M in E ÷ B Bind
Γ ⊢p S ÷ real Sampling
Figure 3.2: Typing rules of PTP.
Figure 3.1 shows the abstract syntax for PTP. We use x for variables. λx:A. M is a lambda abstraction,
and M M is an application term. (M, M) is a product term, and fst M and snd M are projection terms; we
include these terms to support joint distributions. ﬁx x:A. M is a ﬁxed point construct for recursive evalu-
ations. A probability term prob E encapsulates expression E; it is a ﬁrst-class value denoting a probability
distribution. r is a real number.
There are three kinds of expressions: term M, bind expression sample x from M in E, and sampling ex-
pression S. As an expression, M returns (with probability 1) the result of evaluating M. sample x from M in E
sequences two probabilistic computations (if M evaluates to a probability term). S consumes a random num-
ber in a sampling sequence, an inﬁnite sequence of random numbers drawn independently from U(0.0, 1.0].
The type system employs two kinds of typing judgments:
• Term typing judgment Γ ⊢p M : A, meaning that M evaluates to a value of type A under typing
context Γ.
• Expression typing judgment Γ ⊢p E ÷ A, meaning that E computes to a sample of type A under
typing context Γ.
A typing context Γ is a set of bindings x : A. Figure 3.2 shows the typing rules of PTP. The rule Prob
is the introduction rule for the type constructor ⃝; it means that type ⃝A denotes probability distributions
over type A. The rule Bind is the elimination rule for the type constructor ⃝. The rule Term means that

53
M 7→t M′
M N 7→t M′ N TβL
N 7→t N ′
(λx:A. M) N 7→t (λx:A. M) N ′ TβR
(λx:A. M) V 7→t [V/x]M TβV
M 7→t M′
(M, N) 7→t (M′, N) TPL
N 7→t N ′
(V, N) 7→t (V, N ′) TPR
M 7→t N
fst M 7→t fst N TFst
fst (V, V ′) 7→t V TFst′
M 7→t N
snd M 7→t snd N TSnd
snd (V, V ′) 7→t V ′ TSnd′
ﬁx x:A. M 7→t [ﬁx x:A. M/x]M TFix
M 7→t N
M @ ω 7→e N @ ω ETerm
M 7→t N
sample x from M in F @ ω 7→e sample x from N in F @ ω EBind
E @ ω 7→e E′ @ ω′
sample x from prob E in F @ ω 7→e sample x from prob E′ in F @ ω′ EBindR
sample x from prob V in F @ ω 7→e [V/x]F @ ω EBindV
S @ rω 7→e r @ ω Sampling
Figure 3.3: Operational semantics of PTP.
every term converts into a probabilistic computation that involves no probabilistic choice. The rule Real
shows that real is the type of real numbers. A sampling expression S has also type real, as shown in the rule
Sampling, because it computes to a real number.
3.1.2
Operational semantics
Since PTP draws a syntactic distinction between regular values and probabilistic computations, its opera-
tional semantics needs two kinds of judgments:
• Term evaluation judgment M ⇀V , meaning that term M evaluates to value V .
• Expression computation judgment E @ ω ⇁V @ ω′, meaning that expression E with sampling se-
quence ω computes to sample V with remaining sampling sequence ω′. Conceptually E @ ω ⇁V @ ω′
consumes random numbers in ω −ω′. Properties of the consumed sequence ω −ω′ (e.g., its length)
are not directly observable.
For term evaluations, we introduce a term reduction M 7→t N in a call-by-value discipline (we could
equally choose call-by-name or call-by-need). We identify M 7→∗
t V with M ⇀V , where 7→∗
t is the re-
ﬂexive and transitive closure of 7→t. For expression computations, we introduce an expression reduction
E @ ω 7→e F @ ω′ such that E @ ω 7→∗
e V @ ω′ is identiﬁed with E @ ω ⇁V @ ω′, where 7→∗
e is the re-
ﬂexive and transitive closure of 7→e. Both reductions use capture-avoiding term substitutions [M/x]N and
[M/x]E deﬁned in a standard way, as in Section 2.3.3.
Figure 3.3 shows the reduction rules in the operational semantics of PTP. Expression reductions may
invoke term reductions (e.g., to reduce M in sample x from M in E). The rules EBindR and EBindV mean
that given a bind expression sample x from prob E in F, we ﬁnish computing E before substituting a value

54
for x in F. Note that like a term evaluation, an expression computation itself is deterministic; it is only when
we vary sampling sequences that an expression exhibits probabilistic behavior.
An expression computation E @ ω 7→∗
e V @ ω′ means that E takes a sampling sequence ω, consumes a
ﬁnite preﬁx of ω in order, and returns a sample V with the remaining sampling sequence ω′:
Proposition 3.1. If E @ ω 7→∗
e V @ ω′, then ω = r1r2 · · · rnω′ (n ≥0) where
E @ ω 7→∗
e · · · 7→∗
e Ei @ ri+1 · · · rnω′ 7→∗
e · · · 7→∗
e En @ ω′ 7→∗
e V @ ω′
for a sequence of expressions E1, · · · , En.
Thus an expression computation coincides with the operational description of a sampling function when
applied to a sampling sequence, which implies that an expression represents a sampling function. (Here we
use a generalized notion of sampling function mapping (0.0, 1.0]∞to A × (0.0, 1.0]∞for a certain type A.)
The type safety of PTP consists of two properties: type preservation and progress. Their proofs are
omitted as they are special cases of Theorems 2.8 and 2.10, except for S which satisﬁes the type-preservation
and monotonicity requirements on instructions.
Theorem 3.2 (Type preservation).
If M 7→t N and · ⊢p M : A, then · ⊢p N : A.
If E @ ω 7→e F @ ω′ and · ⊢p E ÷ A, then · ⊢p F ÷ A.
Theorem 3.3 (Progress).
If · ⊢p M : A, then either M is a value (i.e., M = V ), or there exists N such that M 7→t N.
If · ⊢p E ÷ A, then either E is a sample (i.e., E = V ), or for any sampling sequence ω, there exist F
and ω′ such that E @ ω 7→e F @ ω′.
3.1.3
Fixed point construct for expressions
In PTP, expressions describe non-recursive probabilistic computations. Since some probability distributions
are deﬁned in a recursive way (e.g., geometric distributions), it is desirable to be able to describe recursive
probabilistic computations as well. To this end, we introduce an expression variable x and an expression
ﬁxed point construct eﬁx x÷A. E; a new form of binding x ÷ A for expression variables is used in typing
contexts:
expression
E
::=
· · · | x | eﬁx x÷A. E
typing context
Γ
::=
· · · | Γ, x ÷ A
New typing rules and reduction rule are as follows:
Γ, x ÷ A ⊢p x ÷ A Evar
Γ, x ÷ A ⊢p E ÷ A
Γ ⊢p eﬁx x÷A. E ÷ A Eﬁx
eﬁx x÷A. E @ ω 7→e [eﬁx x÷A. E/x]E @ ω Eﬁx
In the rule Eﬁx, [eﬁx x÷A. E/x]E denotes a capture-avoiding substitution of eﬁx x÷A. E for expression
variable x.
Expression ﬁxed point constructs are syntactic sugar as they can be simulated with ﬁxed point constructs
for terms. See Section 2.5.1 for details.

55
3.1.4
Distinguishing terms and expressions
The syntactic distinction between terms and expressions in PTP is optional in the sense that the grammar
does not need to distinguish expressions as a separate non-terminal. On the other hand, the semantic dis-
tinction, both statically (in the form of term and expression typing judgments) and dynamically (in the form
of evaluation and computation judgments) appears to be essential for a clean formulation of PTP.
PTP is a conservative extension of a conventional language because terms constitute a conventional
language of their own. In essence, term evaluations are always deterministic and we need only terms when
writing deterministic programs. As a separate syntactic category, expressions provide a framework for
probabilistic computation that abstracts from the deﬁnition of terms. For example, the addition of a new
term construct does not change the deﬁnition of expressions. When programming in PTP, therefore, the
syntactic distinction between terms and expressions aids us in deciding which of deterministic evaluations
and probabilistic computations we should focus on. In the next section, we show how to encode various
probability distributions and further investigate properties of PTP.
3.2
Examples
When encoding a probability distribution in PTP, we naturally concentrate on a method of generating sam-
ples, rather than calculating the probability assigned to each event. If the probability distribution itself is
deﬁned in terms of a process of generating samples, we simply translate the deﬁnition. If, however, the
probability distribution is deﬁned in terms of a probability measure or an equivalent, we may not always de-
rive a sampling function in a mechanical manner. Instead we have to exploit its unique properties to devise
a sampling function.
Below we show examples of encoding various probability distributions in PTP. These examples demon-
strate three properties of PTP: a uniﬁed representation scheme for probability distributions, rich expressive-
ness, and high versatility in encoding probability distributions. The sampling methods used in the examples
are all found in simulation theory [10]. Thus PTP is a programming language in which sampling methods
developed in simulation theory can be formally expressed in a fashion that is concise and readable while
remaining as efﬁcient as the originals.
We assume primitive types int and bool (with boolean values True and False), arithmetic and comparison
operators, and a conditional term construct if M then N1 else N2. We also assume standard let-binding, re-
cursive let rec-binding, and pattern matching when it is convenient for the examples.1 We use the following
syntactic sugar for expressions:
unprob M
≡
sample x from M in x
eif M then E1 else E2
≡
unprob (if M then prob E1 else prob E2)
unprob M chooses a sample from the probability distribution denoted by M (we choose the keyword unprob
to suggest that it does the opposite of what prob does.) eif M then E1 else E2 branches to either E1 or E2
depending on the result of evaluating M.
1If type inference and polymorphism are ignored, let-binding and recursive let rec-binding may be interpreted as follows, where
is a wildcard pattern for types:
let x = M in N
≡
(λx: . N) M
let rec x = M in N
≡
let x = ﬁx x: . M in N

56
Uniﬁed representation scheme
PTP provides a uniﬁed representation scheme for probability distributions. While its type system distin-
guishes between different probability domains, its operational semantics does not distinguish between dif-
ferent kinds of probability distributions, such as discrete, continuous, or neither. We show an example for
each case.
We encode a Bernoulli distribution over type bool with parameter p as follows:
let bernoulli = λp:real. prob sample x from prob S in
x ≤p
bernoulli can be thought of as a binary choice construct. It is expressive enough to specify any discrete
distribution with ﬁnite support. In fact, bernoulli 0.5 sufﬁces to specify all such probability distributions,
since it is capable of simulating a binary choice construct [21] (if the probability assigned to each element
in the domain is computable).
As an example of continuous distribution, we encode a uniform distribution over a real interval (a, b] by
exploiting the deﬁnition of the sampling expression:
let uniform = λa:real. λb:real. prob sample x from prob S in
a + x ∗(b −a)
We also encode a combination of a point-mass distribution and a uniform distribution over the same domain,
which is neither a discrete distribution nor a continuous distribution:
let point uniform = prob sample x from prob S in
if x < 0.5 then 0.0 else x
Rich expressiveness
We now demonstrate the expressive power of PTP with a number of examples.
We encode a binomial distribution with parameters p and n0 by exploiting probability terms:
let binomial = λp:real. λn0 :int.
let bernoulli p = bernoulli p in
let rec binomialp = λn:int.
if n = 0 then prob 0
else prob sample x from binomial p (n −1) in
sample b from bernoulli p in
if b then 1 + x else x
in
binomial p n0
Here binomial p takes an integer n as input and returns a binomial distribution with parameters p and n.
If a probability distribution is deﬁned in terms of a recursive process of generating samples, we can trans-
late the deﬁnition into a recursive term. For example, we encode a geometric distribution with parameter p,

57
which is a discrete distribution with inﬁnite support, as follows:
let geometric rec = λp:real.
let bernoulli p = bernoulli p in
let rec geometric = prob sample b from bernoulli p in
eif b then 0
else sample x from geometric in
1 + x
in
geometric
Here we use a recursive term geometric of type ⃝int. Equivalently we can use an expression ﬁxed point
construct:
let geometric eﬁx = λp:real. let bernoullip = bernoulli p in
prob eﬁx geometric÷int.
sample b from bernoullip in
eif b then 0
else sample x from prob geometric in
1 + x
We encode an exponential distribution by using the inverse of its cumulative distribution function as a
sampling function, which is known as the inverse transform method:
let exponential 1.0 = prob sample x from S in
−log x
The rejection method, which generates a sample from a probability distribution by repeatedly generating
samples from other probability distributions until they satisfy a certain termination condition, can be imple-
mented with a recursive term. For example, we encode a Gaussian distribution with mean m and variance
σ2 by the rejection method with respect to exponential distributions:
let bernoulli 0.5 = bernoulli 0.5
let gaussian rejection = λm:real. λσ:real.
let rec gaussian = prob sample y1 from exponential 1.0 in
sample y2 from exponential 1.0 in
eif y2 ≥(y1 −1.0)2/2.0 then
sample b from bernoulli 0.5 in
if b then m + σ ∗y1 else m −σ ∗y1
else unprob gaussian
in
gaussian
Since the probability p of y2 ≥(y1 −1.0)2/2.0 (the termination condition) is positive, the rejection method
above terminates with probability p + (1 −p)p + (1 −p)2p + · · · =
p
1−(1−p) = 1. In this way, programmers
can ensure that a particular sampling strategy by the rejection method terminates with probability 1.
We encode the joint distribution between two independent probability distributions using a product term.
If MP denotes P(x) and MQ denotes Q(y), the following term denotes the joint distribution Prob(x, y) ∝
P(x)Q(y):
prob sample x from MP in
sample y from MQ in
(x, y)

58
For the joint distribution between two interdependent probability distributions, we use a conditional
probability, which we represent as a lambda abstraction taking a regular value and returning a probability
distribution. If MP denotes P(x) and MQ denotes a conditional probability Q(y|x), the following term
denotes the joint distribution Prob(x, y) ∝P(x)Q(y|x):
prob sample x from MP in
sample y from MQ x in
(x, y)
By returning y instead of (x, y), we compute the integration Prob(y) =
R
P(x)Q(y|x)dx:
prob sample x from MP in
sample y from MQ x in
y
Due to lack of semantic constraints on sampling functions, we can specify probability distributions over
unusual domains such as inﬁnite data structures (e.g., trees), function spaces, cyclic spaces (e.g., angular
values), and even probability distributions themselves. For example, we add two probability distributions
over angular values in a straightforward way:
let add angle = λa1 :⃝real. λa2 :⃝real. prob sample s1 from a1 in
sample s2 from a2 in
(s1 + s2) mod (2.0 ∗π)
With the modulo operation mod, we take into account the fact that an angle θ is identiﬁed with θ + 2π.
As a simple application, we implement a belief network [66]:
We assume that Palarm|burglary denotes the probability distribution that the alarm goes off when a burglary
happens; other variables of the form P·|· are interpreted in a similar way.
let alarm = λ(burglary, earthquake):bool × bool.
if burglary then Palarm|burglary
else if earthquake then Palarm|¬burglary∧earthquake
else Palarm|¬burglary∧¬earthquake
let john calls = λalarm :bool.
if alarm then PJohn calls|alarm
else PJohn calls|¬alarm
let mary calls = λalarm :bool.
if alarm then PMary calls|alarm
else PMary calls|¬alarm

59
The conditional probabilities alarm, john calls, and mary calls do not answer any query on the
belief network and only describe its structure. In order to answer a speciﬁc query, we have to imple-
ment a corresponding probability distribution. For example, in order to answer "What is the probability
pMary calls|John calls that Mary calls when John calls?", we use QMary calls|John calls below, which essen-
tially implements logic sampling [26]:
let rec QMary calls|John calls = prob sample b from Pburglary in
sample e from Pearthquake in
sample a from alarm (b, e) in
sample j from john calls a in
sample m from mary calls a in
eif j then m else unprob QMary calls|John calls
in
QMary calls|John calls
Pburglary denotes the probability distribution that a burglary happens, and Pearthquake the probability distri-
bution that an earthquake happens. Then the mean of QMary calls|John calls gives pMary calls|John calls. We
will see how to calculate pMary calls|John calls in Section 3.4.
We can also implement most of the common operations on probability distributions. An exception is
the Bayes operation ♯(which is used in the second update equation of the Bayes ﬁlter). P ♯Q results in
a probability distribution R such that R(x) = ηP(x)Q(x) where η is a normalization constant ensuring
R
R(x)dx = 1.0; if P(x)Q(x) is zero for every x, then P ♯Q is undeﬁned. Since it is difﬁcult to achieve
a general implementation of P ♯Q, we usually make an additional assumption on P and Q to achieve
a specialized implementation. For example, if we have a function p and a constant c such that p(x) =
kP(x) ≤c for a certain constant k, we can implement P ♯Q by the rejection method:
let bayes rejection = λp:A→real. λc:real. λQ:⃝A.
let rec bayes = prob sample x from Q in
sample u from prob S in
eif u < (p x)/c then x else unprob bayes
in
bayes
We will see another implementation in Section 3.4.
High versatility
PTP allows high versatility in encoding probability distributions: given a probability distribution, we can
exploit its unique properties and encode it in many different ways. For example, exponential 1.0 uses a
logarithm function to encode an exponential distribution, but there is also an ingenious method (due to von

60
Neumann) that requires only addition and subtraction operations:
let exponential von Neumann1.0 =
let rec search = λk:real. λu:real. λu1 :real.
prob sample u′ from prob S in
eif u < u′ then k + u1
else
sample u from prob S in
eif u ≤u′ then unprob (search k u u1)
else
sample u from prob S in
unprob (search (k + 1.0) u u)
in
prob sample u from prob S in
unprob (search 0.0 u u)
The recursive term in gaussian rejection consumes at least three random numbers. We can encode a
Gaussian distribution with only two random numbers:
let gaussian Box Muller = λm:real. λσ:real.
prob sample u from prob S in
sample v from prob S in
m + σ ∗√−2.0 ∗log u ∗cos (2.0 ∗π ∗v)
We can also approximate a Gaussian distribution by exploiting the central limit theorem:
let gaussian central = λm:real. λσ:real.
prob sample x1 from prob S in
sample x2 from prob S in
· · ·
sample x12 from prob S in
m + σ ∗(x1 + x2 + · · · + x12 −6.0)
The three examples above serve as evidence of high versatility of PTP: the more we know about a
probability distribution, the better we can encode it.
All the examples in this section just rely on our intuition on sampling functions and do not actually prove
the correctness of encodings. For example, we still do not know if bernoulli indeed encodes a Bernoulli
distribution, or equivalently, if the expression in it generates True with probability p. In the next section, we
investigate how to formally prove the correctness of encodings.
3.3
Proving the correctness of encodings
When programming in PTP, we often ask "What probability distribution characterizes outcomes of comput-
ing a given expression?" The operational semantics of PTP does not directly answer this question because
an expression computation returns only a single sample from a certain, yet unknown, probability distribu-
tion. Therefore we need a different methodology for interpreting expressions directly in terms of probability
distributions.
We take a simple approach that appeals to our intuition on the meaning of expressions. We write E ∼
Prob if outcomes of computing E are distributed according to Prob. To determine Prob from E, we

61
supply an inﬁnite sequence of independent random variables from U(0.0, 1.0] and analyze the result of
computing E in terms of these random variables. If E ∼Prob, then E denotes a probabilistic computation
for generating samples from Prob and we regard Prob as the denotation of prob E.
We illustrate the above approach with a few examples. In each example, Ri means the i-th random
variable and R∞
i
means the inﬁnite sequence of random variables beginning from Ri (i.e., RiRi+1 · · · ). A
random variable is regarded as a value because it represents real numbers in (0.0, 1.0].
As a trivial example, consider prob S. The computation of S proceeds as follows:
S @ R∞
1 7→e R1 @ R∞
2
Since the outcome is a random variable from U(0.0, 1.0], we have S ∼U(0.0, 1.0].
As an example of discrete distribution, consider bernoulli p. The expression in it computes as follows:
sample x from prob S in x ≤p
@ R∞
1
7→e
sample x from prob R1 in x ≤p
@ R∞
2
7→e
R1 ≤p
@ R∞
2
7→e
True
@ R∞
2
if R1 ≤p;
False
@ R∞
2
otherwise.
Since R1 is a random variable from U(0.0, 1.0], the probability of R1 ≤p is p. Thus the outcome is True
with probability p and False with probability 1.0 −p, and bernoulli p denotes a Bernoulli distribution with
parameter p.
As an example of continuous distribution, consider uniform a b. The expression in it computes as
follows:
sample x from prob S in a + x ∗(b −a)
@ R∞
1
7→∗
e
a + R1 ∗(b −a)
@ R∞
2
Since we have
a + R1 ∗(b −a) ∈(a0, b0]
iﬀ
R1 ∈(a0 −a
b −a , b0 −a
b −a ],
the probability that the outcome lies in (a0, b0] is
b0 −a
b −a −a0 −a
b −a = b0 −a0
b −a
∝b0 −a0
where we assume (a0, b0] ⊂(a, b]. Thus uniform a b denotes a uniform distribution over (a, b].
The following proposition shows that binomial p n denotes a binomial distribution with parameters p
and n, which we write as Binomialp,n:
Proposition 3.4. If binomialp n 7→∗
t prob Ep,n, then Ep,n ∼Binomial p,n.
Proof. By induction on n.
Base case n = 0. We have Ep,n = 0. Since Binomial p,n is a point-mass distribution centered on 0, we
have Ep,n ∼Binomialp,n.

62
Inductive case n > 0. The computation of Ep,n proceeds as follows:
sample x from binomialp (n −1) in
sample b from bernoulli p in
if b then 1 + x else x
@ R∞
1
7→∗
e
sample x from prob xp,n−1 in
sample b from bernoulli p in
if b then 1 + x else x
@ R∞
i
7→∗
e
sample b from prob bp in
if b then 1 + xp,n−1 else xp,n−1
@ R∞
i+1
7→∗
e
1 + xp,n−1
@ R∞
i+1
if bp = True;
xp,n−1
@ R∞
i+1
otherwise.
By induction hypothesis, binomialp (n −1) generates a sample xp,n−1 from Binomial p,n−1 after consum-
ing R1 · · · Ri−1 for some i (which is actually n). Since Ri is an independent random variable, bernoullip
generates a sample bp that is independent of xp,n−1. Then we obtain an outcome k with the probability of
bp = True and xp,n−1 = k −1 or
bp = False and xp,n−1 = k,
which is equal to p ∗Binomial p,n−1(k −1) + (1.0 −p) ∗Binomial p,n−1(k) = Binomial p,n(k). Thus we
have Ep,n ∼Binomialp,n.
As a ﬁnal example, we show that geometric rec p denotes a geometric distribution with parameter p.
Suppose geometric 7→∗
t prob E and E ∼Prob. The computation of E proceeds as follows:
E
@ R∞
1
7→∗
e
sample b from prob bp in
eif b then 0
else sample x from geometric in
1 + x
@ R∞
2
7→∗
e
0
@ R∞
2
if bp = True;
sample x from prob E in 1 + x
@ R∞
2
otherwise.
The ﬁrst case happens with probability p and we get Prob(0) = p. In the second case, we compute the
same expression E with R∞
2 . Since all random variables are independent, R∞
2 can be thought of as a fresh
sequence of random variables. Therefore the computation of E with R∞
2 returns samples from the same
probability distribution Prob and we get Prob(1 + k) = (1.0 −p) ∗Prob(k). Solving the two equations,
we get Prob(k) = p ∗(1.0 −p)k−1, which is the probability mass function for a geometric distribution with
parameter p.
The above approach can be thought of as an adaption of the methodology established in simulation
theory [10]. The proof of the correctness of a sampling method in simulation theory is easily transcribed
into a proof similar to those shown in this section by interpreting random numbers in simulation theory
as random variables in PTP. Thus PTP serves as a programming language in which sampling methods
developed in simulation theory can be not only formally expressed but also formally reasoned about. All
this is possible in part because an expression computation in PTP is provided with an inﬁnite sequence of
random numbers to consume, or equivalently, because of the use of generalized sampling functions as the
mathematical basis.
An alternative approach would be to develop a denotational semantics based upon measure theory [65]
by translating expressions into a measure-theoretic structure. Such a denotational semantics would be useful
in answering such questions as:

63
• Does every expression in PTP result in a measurable sampling function? Or is it possible to write a
pathological expression that corresponds to no measurable sampling function?
• Does every expression in PTP deﬁne a probability distribution? Or is it possible to write a pathological
expression that deﬁnes no probability distribution?
If we ignore ﬁxed point constructs of PTP, it is straightforward to translate expressions even directly
into probability measures, since probability measures form a monad [22, 64] and expressions already follow
a monadic syntax; a sampling expression S is translated into a Lebesgue measure over the unit interval
(0.0, 1.0]. Let us write [M]term for the denotation of term M. Then we can translate each expression E into
a probability measure [E]exp as follows:
• [prob E]term = [E]exp.
• [M]exp(S) = 1 if [M]term is in S.
[M]exp(S) = 0 if [M]term is not in S.
• [sample x from M in E]exp =
R
fd[M]term where a function f is deﬁned as f(x) = [E]exp and
R
fd[M]term is an integral of f over measure [M]term.
• [S]exp is a Lebesgue measure over the unit interval (0.0, 1.0].
Note that the translation does not immediately reveal the probability measure corresponding to a given
expression because it returns a formula for the probability measure rather than the probability measure itself.
Hence, in order to obtain the probability measure, we have to go through essentially the same analysis as
in the above approach. Ultimately we have to invert a sampling function represented by a given expression
(because an event is assigned a probability proportional to the size of its inverse image under the sampling
function), which may not be easy to do in a mechanical way in the presence of various operators.
Once we add ﬁxed point constructs to PTP, expressions should be translated into a domain-theoretic
structure because of recursive equations. Speciﬁcally a term ﬁx x:⃝A. M gives rise to a recursion equation
on type ⃝A, and if a measure-theoretic structure is used for the denotation of terms of type ⃝A, it is
difﬁcult to solve the recursive equation; only with a domain-theoretic structure, the recursive equation can
be given a theoretical treatment. The work by Jones [30] suggests that such a domain-theoretic structure
could be constructed from a domain-theoretic model of real numbers [17], and we leave the development of
a denotational semantics of PTP based upon domain theory as future work.
3.4
Approximate Computation in PTP
We have explored both how to encode probability distributions in PTP and how to interpret PTP in terms
of probability distributions. In this section, we discuss another important aspect of probabilistic languages:
reasoning about probability distributions.
The expressive power of a probabilistic language is an important factor affecting its practicality. Another
important factor is its support for reasoning about probability distributions to determine their properties. In
other words, it is important not only to be able to encode various probability distributions but also to be
able to determine their properties such as means, variances, and probabilities of speciﬁc events. Unfortu-
nately PTP does not support precise reasoning about probability distributions. That is, it does not permit
a precise implementation of queries on probability distributions. Intuitively we must be able to calculate
probabilities of speciﬁc events, but this is tantamount to inverting sampling functions. Hence, for example,
we cannot calculate pMary calls|John calls in the belief network example in Section 3.2 unless we analyze
QMary calls|John calls to compute its mean in a similar way to the previous section.

64
Given that we cannot hope for precise reasoning in PTP, we choose to support approximate reasoning by
the Monte Carlo method [40]. It approximately answers a query on a probability distribution by generating
a large number of samples and then analyzing them. For example, we can approximate pMary calls|John calls,
which is equal to the proportion of True's among an inﬁnite number of samples from QMary calls|John calls,
by generating a large number of samples and counting the number of True's. Although the Monte Carlo
method gives only an approximate answer, its accuracy improves with the number of samples. Moreover it
is applicable to all kinds of probability distributions and is therefore particularly suitable for PTP.
In this section, we use the Monte Carlo method to implement the expectation query. We also show
how to exploit the Monte Carlo method in implementing the Bayes operation. Both implementations are
provided as primitive constructs of PTP.
3.4.1
Expectation query
Among common queries on probability distributions, the most important is the expectation query. The
expectation of a function f with respect to a probability distribution P is the mean of f over P, which we
write as
R
fdP. Other queries may be derived as special cases of the expectation query. For example, the
mean of a probability distribution over real numbers is the expectation of an identity function; the probability
of an event Event under a probability distribution P is
R
IEventdP where IEvent(x) is 1 if x is in Event
and 0 if not.
The Monte Carlo method states that we can approximate
R
fdP with a set of samples V1, · · · , Vn from
P:
lim
n→∞
f(V1) + · · · + f(Vn)
n
=
R
fdP
We introduce a term construct expectation which exploits the above equation:
term
M
::=
· · · | expectation Mf MP
Γ ⊢p Mf : A→real
Γ ⊢p MP : ⃝A
Γ ⊢p expectation Mf MP : real
Exp
Mf 7→∗
t f
MP 7→∗
t prob EP
for i = 1, · · · , n
new sampling sequence ωi
EP @ ωi 7→∗
e Vi @ ω′
i
f Vi 7→∗
t vi
expectation Mf MP 7→t
P
i vi
n
Exp
The rule Exp says that if Mf evaluates to a lambda abstraction denoting f and MP evaluates to a prob-
ability term denoting P, then expectation Mf MP reduces to an approximation of
R
fdP. A run-time
variable n (to be chosen by programmers) speciﬁes the number of samples to generate from P. To eval-
uate expectation Mf MP , the run-time system initializes sampling sequence ωi to generate sample Vi for
i = 1, · · · , n (as indicated by new sampling sequence ωi).
In the rule Exp, the accuracy of
P
i vi
n
is controlled not by PTP but solely by programmers. That is, PTP
is not responsible for choosing a value of n (e.g., by analyzing EP) to guarantee a certain level of accuracy
in estimating
R
fdP. Rather it is programmers that decide a suitable value of n to achieve a desired level
of accuracy (as well as an expression EP for encoding P). Programmers are also allowed to pick up a
particular value of n for each expectation query, rather than using the same value of n for all expectation
queries. We do not consider this as a weakness of PTP, since EP itself, chosen by programmers, affects the
accuracy of
P
i vi
n
after all.
Although PTP provides no concrete guidance in choosing a value of n in the rule Exp, programmers
can empirically determine a suitable value of n, namely the largest value of n that ﬁnishes an expectation

65
query within a given time constraint. (A large value of n is better because it results in a more faithful
approximation of P by samples Vi and a smaller difference between
P
i vi
n
and the true expectation
R
fdP.)
Ideally the time to evaluate expectation Mf MP should be directly proportional to n, but in practice, the
computation of the same expression EP may take a different time, especially if EP expresses a recursive
computation. Therefore programmers can try different values of n and ﬁnd the largest one that ﬁnishes the
expectation query within a given time constraint.
A problem with the above deﬁnition is that although expectation is a term construct, its reduction is
probabilistic because of sampling sequence ωi in the rule Exp. This violates the principle that a term
evaluation is always deterministic, and now the same term may evaluate to different values if it contains
expectation. In order not to violate the principle, we assume that sampling sequence ωi in the rule Exp is
uniquely determined by expression EP .
Now we can calculate pMary calls|John calls as:
expectation (λx:bool. if x then 1.0 else 0.0) QMary calls|John calls
3.4.2
Bayes operation
The previous implementation of the Bayes operation P ♯Q assumes a function p and a constant c such that
p(x) = kP(x) ≤c for a certain constant k. It is, however, often difﬁcult to ﬁnd the optimal value of c (i.e.,
the maximum value of p(x)) and we have to take a conservative estimate of c. The Monte Carlo method,
in conjunction with importance sampling [40], allows us to dispense with c by approximating Q with a set
of samples and P ♯Q with a set of weighted samples. We introduce a term construct bayes for the Bayes
operation and an expression construct importance for importance sampling:
term
M
::=
· · · | bayes Mp MQ
expression
E
::=
· · · | importance {(Vi, wi)|1 ≤i ≤n}
In the spirit of data abstraction, importance represents only an internal data structure and is not directly
available to programmers.
Γ ⊢p Mp : A→real
Γ ⊢p MQ : ⃝A
Γ ⊢p bayes Mp MQ : ⃝A
Bayes
Γ ⊢p Vi : A
Γ ⊢p wi : real
1 ≤i ≤n
Γ ⊢p importance {(Vi, wi)|1 ≤i ≤n} ÷ A Imp
Mp 7→∗
t p
MQ 7→∗
t prob EQ
for i = 1, · · · , n
new sampling sequence ωi
EQ @ ωi 7→∗
e Vi @ ω′
i
p Vi 7→∗
t wi
bayes Mp MQ 7→t prob importance {(Vi, wi)|1 ≤i ≤n}
Bayes
Pk−1
i=1 wi
S
< r ≤
Pk
i=1 wi
S
where
S = Pn
i=1 wi
importance {(Vi, wi)|1 ≤i ≤n} @ rω 7→e Vk @ ω Imp
The rule Bayes uses sampling sequences ω1, · · · , ωn initialized by the run-time system and approximates
Q with n samples V1, · · · , Vn, where n is a run-time variable as in the rule Exp. Then it applies p to each
sample Vi to calculates its weight wi and creates a set {(Vi, wi)|1 ≤i ≤n} of weighted samples as an
argument to importance. The rule Imp implements importance sampling: we use a random number r to
probabilistically select a sample Vk by taking into account the weights associated with all the samples. As
with expectation, we decide to deﬁne bayes as a term construct with the assumption that sampling sequence
ωi in the rule Bayes is uniquely determined by expression EQ.

66
3.4.3
expectation and bayes as expression constructs
Since their reduction involves sampling sequences, expectation and bayes could be deﬁned as expression
constructs so that the assumption on sampling sequence ωi (in the rules Exp and Bayes) would be unneces-
sary. Still we choose to deﬁne expectation and bayes as term constructs for pragmatic reasons. Consider a
probability distribution P(s) deﬁned in terms of probability distributions Q(s) and R(u):
P(s) = ηQ(s)
R
f(s, u)R(u)du
(A similar example is found in Section 5.3.) P(s) is obtained by the Bayes operation between Q(s) and
Prob(s) =
R
f(s, u)R(u)du, and is encoded in PTP as
bayes (λs: . expectation (λu: . Mf(s, u)) MQ) MP
where MP and MQ are probability terms denoting P and Q, respectively, and Mf is a lambda abstrac-
tion denoting f. If expectation was an expression construct, however, it would be difﬁcult to encode P(s)
because expression expectation (λu: . Mf(s, u)) MQ cannot be converted into a term. In essence, math-
ematically the expectation of a function with respect to a probability distribution and the result of a Bayes
operation are always unique (if they exist), which in turn implies that if expectation and bayes are deﬁned
as expression constructs, we cannot write code involving expectations and Bayes operations in the same
manner that we reason mathematically.
The actual implementation of PTP (to be presented in the next chapter) does not enforce the assumption
on sampling sequence ωi in the rules Exp and Bayes, which is unrealistic in practice and required only
for the semantic clarity of PTP. Strictly speaking, therefore, term evaluations are not necessarily deter-
ministic and there is no clear separation between terms and expressions in this regard. Since terms are not
protected from computational effects (such as input/output and mutable references) and term evaluations
do not always result in unique values anyway, non-deterministic term evaluations should not be regarded
as a new problem. Thus expressions are best interpreted as a syntactic category dedicated to probabilistic
computations only in the mathematical sense — strict adherence at the implementation level to the semantic
distinction between terms and expressions (e.g., deﬁning expectation and bayes as expression constructs)
would cost code readability without any apparent beneﬁt.
3.4.4
Cost of generating random numbers
The essence of the Monte Carlo method is to trade accuracy for cost — it only gives approximate answers,
but relieves programmers of the cost of exact computation (which can be even impossible in certain prob-
lems). Since PTP relies on the Monte Carlo method to reason about probability distributions, it is important
for programmers to be able to determine the cost of the Monte Carlo method.
We decide to deﬁne the cost of the Monte Carlo method as proportional to the number of random num-
bers consumed. The decision is based upon the assumption that random number generation can account for
a signiﬁcant portion of the total computation time. (If the cost of random number generation was negligible,
the number of random numbers consumed would be of little importance.) Under our implementation of PTP,
random number generation for the following examples from Section 3.2 accounts for an average of 74.85%
of the total computation time. The following table shows execution times (in seconds) and percentages of
random number generation when generating 100,000 samples (on a Pentium III 500Mhz with 384 MBytes
memory):

67
test case
execution time
random number generation (%)
uniform 0.0 1.0
0.25
78.57
binomial 0.25 16
4.65
64.84
geometric eﬁx 0.25
1.21
63.16
gaussian rejection 2.5 5.0
1.13
77.78
exponential von Neumann1.0
1.09
80.76
gaussian Box Muller 2.0 4.0
0.57
77.27
gaussian central 0.0 1.0
2.79
83.87
QMary calls|John calls
21.35
72.57
In PTP, it is the programmers' responsibility to reason about the cost of generating random numbers,
since for an expression computation judgment E @ ω ⇁V @ ω′, the length of the consumed sequence
ω −ω′ is not observable. A analysis similar to those in Section 3.3 can be used to estimate the cost of
obtaining a sample in terms of the number of random numbers consumed. In the case of geometric rec p,
for example, the expected number n of random numbers consumed is calculated by solving the equation
n = 1 + (1 −p) ∗n
where 1 accounts for the random number generated from the Bernoulli distribution and (1 −p) is the
probability that another attempt is made to generate a sample from the same probability distribution. The
same technique applies equally to the rejection method (e.g., gaussian rejection).
3.5
Summary
Although conceptually simple, the idea of using sampling functions in specifying probability distributions
is new in the history of probabilistic languages. PTP is an example of probabilistic language that indirectly
expresses sampling functions in a monadic syntax. We could also choose a different syntax for expressing
sampling functions. For example, the author [53] extends the lambda calculus with a sampling construct γe
to directly encodes sampling functions (γ is a formal argument and e denotes the body of a sampling func-
tion). The computation of γe proceeds by generating a random number from U(0.0, 1.0] and substituting it
for γ in e. Compared with PTP, the resultant calculus facilitates the encoding of some probability distribu-
tion (e.g., γγ for U(0.0, 1.0]), but it also reduces code readability because every program fragment denotes
a probability distribution and there is no separation between regular values and probabilistic computations.
The idea of using a monadic syntax for PTP was inspired by the stochastic lambda calculus of Ramsey
and Pfeffer [64], whose denotational semantics is based upon the monad of probability measures, or the
probability monad [22]. In implementing a query for generating samples from probability distributions,
they note that the probability monad can also be interpreted in terms of sampling functions, both denota-
tionally and operationally. In designing PTP, we take the opposite approach: ﬁrst we use a monadic syntax
for probabilistic computations and relate it directly to sampling functions; then we interpret it in terms of
probability distributions.
The operational semantics of PTP can be presented in different styles. For example, expression compu-
tations could use a judgment of the form E r1r2···rn
⇁
V , meaning that expression E computes to sample V by
consuming a ﬁnite sequence of random numbers r1, r2, · · · , rn. Although the new judgment better reﬂects
the actual implementation of expression computation, we stick to the formulation given in this chapter to
emphasize the logical foundation of PTP.

68

Chapter 4
Implementation
This chapter describes the implementation of PTP. Instead of implementing PTP as a complete programming
language of its own, we choose to embed it in an existing functional language for two pragmatic reasons.
First the conceptual basis of probabilistic computations in PTP is simple enough that it is easy to simulate all
language constructs of PTP without any modiﬁcation to the run-time system. Second we intend to use PTP
for real applications in robotics, for which we wish to exploit advanced features such as a module system,
an interface to foreign languages, and a graphics library. Hence building a complete compiler for PTP is not
justiﬁed when extending an existing functional language is sufﬁcient for examining the practicality of PTP.
We emphasize that embedding PTP in an existing functional language is different from adding a library
to the host language. For example, the syntax of the host language is extended with the syntax of PTP,
which is not the case when a library is added. Since the type system of PTP is also faithfully reﬂected in the
host language, programmers can beneﬁt from the type system of PTP even when programming in the host
language environment. (A library can also partially reﬂect the type system of PTP through type abstraction,
but not completely because of different syntax in the library.)
In our implementation, we use Objective CAML [2] as the host language. First we formulate a sound
and complete translation of PTP in a simple call-by-value language which can be thought of a sublanguage
of Objective CAML. Then we extend the syntax of Objective CAML using CAMLP4, a preprocessor for
Objective CAML, to incorporate the syntax of PTP. The extended syntax is translated back in the original
syntax.
4.1
Representation of sampling functions
Since a probability term denotes a probability distribution speciﬁed by a sampling function, the imple-
mentation of PTP translates probability terms into representations of sampling functions. We translate a
probability term of type ⃝A into a value of type A prob, where the type constructor prob is conceptually
deﬁned as follows:
type A prob = real∞−> A ∗real∞
real is the type of real numbers, and we use real∞for the type of inﬁnite sequences of random numbers.
We simplify the deﬁnition of prob in two steps. First we implement real numbers of type real as
ﬂoating point numbers of type float (as in Objective CAML). Second we dispense with inﬁnite sequences
of random numbers by using a global random number generator whenever fresh random numbers are needed
to compute sampling expressions. Thus we use the following deﬁnition of prob:
type A prob = unit −> A
69

70
type
A, B
::=
A→A | ⃝A | real
term
M, N
::=
x | λx:A. M | M M | prob E | r
expression
E, F
::=
M | sample x from M in E | S | x |
eﬁx x÷A. E
value/sample
V
::=
λx:A. M | prob E | r
ﬂoating point number
r
sampling sequence
ω
::=
r1r2 · · · ri · · ·
where ri ∈(0.0, 1.0]
typing context
Γ
::=
· | Γ, x : A | Γ, x ÷ A
Figure 4.1: A fragment of PTP as the source language.
Here unit is the unit type which is inhabited only by a unit value ().
The use of type float instead of type real means that we use ﬁnite precision in representing sampling
functions. Although the overhead of exact real arithmetic is not justiﬁed in those applications (e.g., robotics)
where we work with samples and approximations, programmers may demand higher precision than is sup-
ported by type float. As a contrived example, consider a binary distribution assigning probability 0.25 to
True and probability 0.75 to False:
prob sample x from prob S in
2.0 ∗x ≤0.5
If type float uses only one bit in mantissa part (and S computes to either 0.5 or 1.0), the above probability
term denotes a wrong probability distribution (namely a point-mass distribution centered on False); only
with two or more bits in the mantissa part, it denotes the intended probability distribution. Therefore, while
the ﬁnite precision supported by the implementation of PTP (64 bits ﬂoating point numbers in Objective
CAML) is adequate for typical applications, it should also be noted that there can be sampling functions
demanding higher precision and that errors induced by ﬂoating point numbers can be problematic in some
applications.
We use the type constructor prob as an abstract datatype. That is, the deﬁnition of prob is not exposed to
PTP and values of type A prob are accessed only via member functions. We provide two member functions:
prb and app. prb builds a value of type A prob from a function of type unit −> A; it is actually deﬁned
as an identity function. app generates a sample from a value of type A prob; it applies its argument to a
unit value. The interface and implementation of the abstract datatype prob are given as follows:
type A prob
type A prob = unit −> A
val prb : (unit −> A) −> A prob
let prb = fun f :unit −> A. f
val app : A prob −> A
let app = fun f :A prob. f ()
We use prb in translating probability terms and app in translating bind expressions. In conjunction with
the use of the type constructor prob as an abstract data type, they provide a sound and complete translation
of PTP, as shown in the next section.
4.2
Translation of PTP in a call-by-value language
We translate a fragment of PTP shown in Figure 4.1 in a call-by-value language shown in Figure 4.2. The
source language excludes product types, which are straightforward to translate if the target language is
extended with product types. We directly translate expression ﬁxed point constructs without simulating

71
type
A, B
::=
A −> A | A prob | float | unit
expression
e, f
::=
x | fun x:A. e | e e | prb e | app e | r |
() | random | fix x:A. u
value
v
::=
fun x:A. e | prb v | r | ()
function
u
::=
fun x:A. e
ﬂoating point number
r
sampling sequence
ω
::=
r1r2 · · · ri · · ·
where ri ∈(0.0, 1.0]
typing context
Γ
::=
· | Γ, x : A
Figure 4.2: A call-by-value language as the target language.
Γ, x : A ⊢v x : A Hyp
Γ, x : A ⊢v e : B
Γ ⊢v fun x:A. e : A −> B Lam
Γ ⊢v e1 : A −> B
Γ ⊢v e2 : A
Γ ⊢v e1 e2 : B
App
Γ ⊢v e : unit −> A
Γ ⊢v prb e : A prob Prb
Γ ⊢v e : A prob
Γ ⊢v app e : A Papp
Γ ⊢v r : float Float
Γ ⊢v () : unit Unit
Γ ⊢v random : float Random
Γ, x : A ⊢v u : A
Γ ⊢v fix x:A. u : A Fix
Figure 4.3: Typing rules of the target language.
them with ﬁxed point constructs for terms. As the target language supports only ﬂoating point numbers, r
in the source language is restricted to ﬂoating point numbers.
The target language is a call-by-value language extended with the abstract datatype prob. It has a single
syntactic category consisting of expressions (because it does not distinguish between effect-free evalua-
tions and effectful computations). As in PTP, every expression denotes a probabilistic computation and we
say that an expression computes to a value. Note that ﬁxed point constructs fix x:A. u allow recursive
expressions only over function types.
The type system of the target language is shown in Figure 4.3. It employs a typing judgment Γ ⊢v e : A,
meaning that expression e has type A under typing context Γ. The rules Prb and Papp conform to the
interface of the abstract datatype prob.
The operational semantics of the target language is shown in Figure 4.4. It employs an expression
reduction judgment e @ ω 7→v e′ @ ω′, meaning that the computation of e with sampling sequence ω
reduces to the computation of e′ with sampling sequence ω′. A capture-avoiding substitution [e/x]f is
deﬁned in a standard way. The rule EAppPrb is deﬁned according to the implementation of the abstract
datatype prob. The rule ERandom shows that random, like sampling expressions in PTP, consumes a random
number in a given sampling sequence. We write 7→∗
v for the reﬂexive and transitive closure of 7→v.
Figure 4.5 shows the translation of the source language in the target language.1 We overload the function
[·]v for types, typing contexts, terms, and expressions. Both terms and expressions of type A in the source
language are translated into expressions of type [A]v in the target language. [prob E]v suspends the com-
putation of [E]v by building a function fun :unit. [E]v, just as prob E suspends the computation of E.
Since the target language allows recursive expressions only over function types, an expression variable x of
type A (i.e., x ÷ A) is translated into xx () where xx is a special variable of type unit −> [A]v annotated
1 is a wildcard pattern for variables and types.

72
e @ ω 7→v e′ @ ω′
e f @ ω 7→v e′ f @ ω′ EβL
f @ ω 7→v f ′ @ ω′
(fun x:A. e) f @ ω 7→v (fun x:A. e) f ′ @ ω′ EβR
(fun x:A. e) v @ ω 7→v [v/x]e @ ω EβV
e @ ω 7→v e′ @ ω′
prb e @ ω 7→v prb e′ @ ω′ EPrb
e @ ω 7→v e′ @ ω′
app e @ ω 7→v app e′ @ ω′ EApp
app prb v @ ω 7→v v () @ ω EAppPrb
random @ rω 7→v r @ ω ERandom
fix x:A. u @ ω 7→v [fix x:A. u/x]u @ ω EFix
Figure 4.4: Operational semantics of the target language.
[A→B]v
=
[A]v −> [B]v
[⃝A]v
=
[A]v prob
[real]v
=
float
[·]v
=
·
[Γ, x : A]v
=
[Γ]v, x : [A]v
[Γ, x ÷ A]v
=
[Γ]v, xx : unit −> [A]v
[x]v
=
x
[λx:A. M]v
=
fun x:[A]v. [M]v
[M N]v
=
[M]v [N]v
[prob E]v
=
prb (fun :unit. [E]v)
[r]v
=
r
[sample x from M in E]v
=
(fun x: . [E]v) (app [M]v)
[S]v
=
random
[x]v
=
xx ()
[eﬁx x÷A. E]v
=
(fix xx :unit −> [A]v. fun :unit. [E]v) ()
Figure 4.5: Translation of the source language.
with x; if the target language allowed recursive expressions over any type, x and eﬁx x÷A. E could be
translated into xx and fix xx :[A]v. [E]v, respectively.2
Propositions 4.1 and 4.2 show that the translation is faithful to the type system of the source language.
Proposition 4.1 proves the soundness of the translation: a well-typed term or expression in the source lan-
guage is translated into a well-typed expression in the target language. Proposition 4.2 proves the com-
pleteness of the translation: only a well-typed term or expression in the source language is translated into a
well-type expression in the target language.
Proposition 4.1.
If Γ ⊢p M : A, then [Γ]v ⊢v [M]v : [A]v.
If Γ ⊢p E ÷ A, then [Γ]v ⊢v [E]v : [A]v.
Proof. By simultaneous induction on the structure of M and E.
Proposition 4.2.
2In the Objective CAML syntax, [eﬁx x÷A. E]v can be rewritten as let rec xx () = [E]v in xx ().

73
If [Γ]v ⊢v [M]v : A, then there exists B such that A = [B]v and Γ ⊢p M : B.
If [Γ]v ⊢v [E]v : A, then there exists B such that A = [B]v and Γ ⊢p E ÷ B.
Proof. By simultaneous induction on the structure of M and E. The conclusion in the ﬁrst clause also
implies Γ ⊢p M ÷ B. An interesting case is when E = x.
Case E = x:
[Γ]v ⊢v [x]v : A
by assumption
[Γ]v ⊢v xx () : A
because [x]v = xx ()
xx : unit −> A ∈[Γ]v
by App and Unit
Since xx is a special variable annotated with expression variable x,
xx ÷ B ∈Γ and A = [B]v for some B.
A = [B]v and Γ ⊢p E ÷ B.
The translation is also faithful to the operational semantics of the source language. We ﬁrst show that the
translation is sound: a term reduction in the source language is translated into a corresponding expression
reduction which consumes no random number (Proposition 4.6); an expression reduction in the source
language is translated into a corresponding sequence of expression reductions which consumes the same
sequence of random numbers (Proposition 4.7). Note that in Proposition 4.7, [E]v does not directly reduce
to [F]v; instead it reduces to an expression e to which [F]v eventually reduces without consuming random
numbers.
Lemma 4.3. [[M/x]N]v = [[M]v/x][N]v and [[M/x]E]v = [[M]v/x][E]v.
Proof. By simultaneous induction on the structure of N and E.
Lemma 4.4.
[[eﬁx x÷A. E/x]M]v = [(fix xx :unit −> [A]v. fun :unit. [E]v)/xx][M]v.
[[eﬁx x÷A. E/x]F]v = [(fix xx :unit −> [A]v. fun :unit. [E]v)/xx][F]v.
Proof. By simultaneous induction on the structure of M and F.
Corollary 4.5.
[[eﬁx x÷A. E/x]E]v = [(fix xx :unit −> [A]v. fun :unit. [E]v)/xx][E]v.
Proposition 4.6.
If M 7→t N, then [M]v @ ω 7→v [N]v @ ω for any sampling sequence ω.
Proof. By induction on the structure of the derivation of M 7→t N.
Case
M 7→t M′
M N 7→t M′ N TβL :
[M]v @ ω 7→v [M′]v @ ω
by induction hypothesis
[M N]v = [M]v [N]v
[M]v [N]v @ ω 7→v [M′]v [N]v @ ω
by EβL
[M′]v [N]v = [M′ N]v
Case
N 7→t N ′
(λx:A. M) N 7→t (λx:A. M) N ′ TβR
:
[N]v @ ω 7→v [N ′]v @ ω
by induction hypothesis
[(λx:A. M) N]v = (fun x:[A]v. [M]v) [N]v
(fun x:[A]v. [M]v) [N]v @ ω 7→v (fun x:[A]v. [M]v) [N ′]v @ ω
by EβR
(fun x:[A]v. [M]v) [N ′]v = [(λx:A. M) N ′]v
Case (λx:A. M) V 7→t [V/x]M TβV :

74
[(λx:A. M) V ]v = (fun x:[A]v. [M]v) [V ]v
(fun x:[A]v. [M]v) [V ]v @ ω 7→v [[V ]v/x][M]v @ ω
by EβV
[[V ]v/x][M]v = [[V/x]M]v
by Lemma 4.3
Proposition 4.7.
If E @ ω 7→e F @ ω′, there exists e such that [E]v @ ω 7→∗
v e @ ω′ and [F]v @ ω′ 7→∗
v e @ ω′.
Proof. By induction on the structure of the derivation of E @ ω 7→e F @ ω′. We consider two interesting
cases.
Case
E @ ω 7→e E′ @ ω′
sample x from prob E in F @ ω 7→e sample x from prob E′ in F @ ω′ EBindR :
[E]v @ ω 7→∗
v e @ ω′ where [E′]v @ ω′ 7→∗
v e @ ω′
by induction hypothesis
[sample x from prob E in F]v = (fun x: . [F]v) (app (prb (fun :unit. [E]v)))
(fun x: . [F]v) (app (prb (fun :unit. [E]v))) @ ω
7→v (fun x: . [F]v) ((fun :unit. [E]v) ()) @ ω
by EAppPrb
7→v (fun x: . [F]v) [E]v @ ω
by EβV
7→∗
v (fun x: . [F]v) e @ ω′
by [E]v @ ω 7→∗
v e @ ω′
[sample x from prob E′ in F]v = (fun x: . [F]v) (app (prb (fun :unit. [E′]v)))
(fun x: . [F]v) (app (prb (fun :unit. [E′]v))) @ ω′
7→∗
v (fun x: . [F]v) [E′]v @ ω′
by EAppPrb and EβV
7→∗
v (fun x: . [F]v) e @ ω′
by [E′]v @ ω′ 7→∗
v e @ ω′
Case eﬁx x÷A. E @ ω 7→e [eﬁx x÷A. E/x]E @ ω Eﬁx :
[eﬁx x÷A. E]v = (fix xx :unit −> [A]v. fun :unit. [E]v) ()
(fix xx :unit −> [A]v. fun :unit. [E]v) () @ ω
7→v (fun :unit. [fix xx :unit −> [A]v. fun :unit. [E]v/xx][E]v) () @ ω
by EFix
7→∗
v [fix xx :unit −> [A]v. fun :unit. [E]v/xx][E]v @ ω
by EβV
[[eﬁx x÷A. E/x]E]v = [fix xx :unit −> [A]v. fun :unit. [E]v/xx][E]v
by Corollary 4.5
The completeness of the translation states that only a valid term or expression reduction in the source
language is translated into a corresponding sequence of expression reductions in the target language. In
other words, a term or expression that cannot be further reduced in the source language is translated into
an expression whose reduction eventually gets stuck. To simplify the presentation, we introduce three
judgments, all of which express that a term or expression does not further reduces.
• M 7→t • means that there exists no term to which M reduces.
• E @ ω 7→e • means that there exists no expression to which E reduces.
• e @ ω 7→v • means that there exists no expression to which e reduces (in the target language).
Corollary 4.9 proves the completeness of the translation for terms; Proposition 4.10 proves the com-
pleteness of the translation for expressions.
Proposition 4.8. If [M]v @ ω 7→v e @ ω′, then e = [N]v, ω = ω′, and M 7→t N.
Proof. By induction on the structure of M. We only need to consider the case M = M1 M2. There are
three cases of the structure of [M1 M2]v @ ω 7→v e @ ω′ (corresponding to the rules EβL, EβR, and EβV). The
case for the rule EβV uses Lemma 4.3.

75
Corollary 4.9. If M 7→t •, then [M]v @ ω 7→v • for any sampling sequence ω.
Proposition 4.10. If E @ ω 7→e •, then there exists e such that [E]v @ ω 7→∗
v e @ ω 7→v •.
Proof. By induction on the structure of E. We consider two cases E = M and E = sample x from M in F;
the remaining cases are all trivial.
Case E = M, [E]v = [M]v:
M 7→t •
by ETerm
[M]v @ ω 7→v •
by Corollary 4.9
We let e = [M]v.
Case E = sample x from M in F, [E]v = (fun x: . [F]v) app [M]v:
If M ̸= prob ·,
M 7→t •
by EBind
[M]v @ ω 7→v •
by Corollary 4.9
The rule EApp does not apply to [E]v.
The rule EAppPrb does not apply to [E]v.
[M]v ̸= prb ·
We let e = [E]v.
If M = prob E′, E′ ̸= V ,
E′ @ ω 7→e •
by EBindR
There exists e′ such that [E′]v @ ω 7→∗
v e′ @ ω 7→v • by induction hypothesis.
[E]v @ ω
7→∗
v (fun x: . [F]v) [E′]v @ ω
[M]v = prb fun :unit. [E′]v
7→∗
v (fun x: . [F]v) e′ @ ω
[E′]v @ ω 7→∗
v e′ @ ω
7→v •
e′ @ ω 7→v •
We let e = (fun x: . [F]v) e′.
If M = prob V , then E @ ω 7→e • does not hold because of the rule EBindV .
The target language can be thought of as a sublanguage of Objective CAML in which the abstract
datatype prob is built-in and random is implemented as Random.float 1.0.3 Since Objective CAML
also serves as the host language for PTP, we need to extend the syntax of Objective CAML to incorporate
the syntax of PTP. The extended syntax is then translated back in the original syntax of Objective CAML
using the function [·]v. The next section gives the deﬁnition of the extended syntax.
4.3
Extended syntax
We use CAMLP4 to conservatively extend the syntax of Objective CAML, which is assumed to be speciﬁed
by a non-terminal ⟨term⟩(corresponding to terms in PTP), with a new non-terminal ⟨expr⟩(corresponding
to expressions in PTP); ⟨patt⟩is a non-terminal for patterns and ⟨id⟩for identiﬁers:
⟨term⟩
::=
· · · | PROB { ⟨expr⟩}
probability term
⟨expr⟩
::=
[⟨term⟩] |
term as an expr.
sample ⟨patt⟩from ⟨term⟩in ⟨expr⟩|
bind expr.
UNIFORM |
sampling expr.
efix ⟨id⟩-> ⟨expr⟩|
expr. ﬁxed.p.c.
#⟨id⟩|
expr. variable
unprob ⟨term⟩|
unprob
eif ⟨term⟩then ⟨expr⟩else ⟨expr⟩
eif
3To be strict, random would be implemented as 1.0 -. Random.float 1.0.

76
[⟨term⟩] explicitly marks a term as an instance of expression. #⟨id⟩refers to an expression variable ⟨id⟩.
All other expression constructs resemble their counterparts in Chapter 3.
As an example, we encode a Bernoulli distribution over type bool as follows:
let bernoulli = fun p ->
PROB { sample x from PROB { UNIFORM } in
[if x <= p then true else false] }
A geometric distribution is encoded with an expression ﬁxed point construct as follows:
let geometric = fun p ->
let bernoulli_p = bernoulli p in
PROB {
efix geo ->
sample b from bernoulli_p in
eif b then [0]
else
sample x from PROB { #geo } in
[1 + x]
}
All other examples in Section 3.2 can be encoded in a similar way.
4.4
Approximate computation
In PTP, reasoning about a probability distribution is accomplished by generating multiple samples and
analyzing them. The implementation of PTP provides two functions for generating independent samples
from a given probability distribution:
type 'a set
type 'a wset
val prob_to_set : 'a prob -> 'a set
val prob_to_wset : 'a prob -> ('a -> float) -> 'a wset
• 'a set is a datatype for sets of samples of type 'a.
• 'a wset is a datatype for sets of weighted samples of type 'a. Each sample is assigned a weight of
type float and 'a wset may be thought of as ('a * float) set. All weights are normalized
(i.e., their sum is 1.0).
• prob_to_set p generates samples from p by evaluating app p repeatedly.
• prob_to_wset p f generates samples from p and assigns to each sample V a weight of f V .
Programmers can specify the number of samples generated from prob_to_set and prob_to_wset,
thereby controlling the accuracy in approximating probability distributions.
The implementation of PTP provides two functions for applying the Monte Carlo method:
val set_monte_carlo : 'a set -> ('a -> float) -> float
val wset_monte_carlo : 'a wset -> ('a -> float) -> float

77
wset to prob truncate ws
sample
sample
ws
weight
weight
Figure 4.6: wset to prob truncate.
• set_monte_carlo s f returns
P
V ∈s f V
|s|
.
• wset_monte_carlo ws f returns P
(V,w)∈ws(f V ) · w.
The following two functions convert sets and weighted sets back to probability distributions:
val set_to_prob_resample : 'a set -> 'a prob
val wset_to_prob_resample : 'a wset -> 'a prob
• set_to_prob_resample s returns a uniform distribution over s.
• wset_to_prob_resample ws returns prob importance ws which performs importance sampling
on ws to select samples.
Now the expectation query (in Section 3.4.1) and the Bayes operation (in Section 3.4.2) are implemented by
composing these functions:
expectation f p = set_monte_carlo (prob_to_set p) f
bayes f p = wset_to_prob_resample (prob_to_wset p f)
The implementation of PTP also provides a function for approximating the support of a given probability
distribution. Since the support of an arbitrary probability distribution cannot be calculated accurately, we
represent it as a uniform distribution:
val wset_to_prob_truncate : 'a wset -> 'a prob
wset_to_prob_truncate ws returns a uniform distribution over n samples of highest weights in ws,
where n is the parameter specifying the number of samples generated by prob_to_setand prob_to_wset.
Figure 4.6 illustrates how wset_to_prob_truncate works.
ws has ﬁve samples in it, and
wset_to_prob_truncate is invoked when the parameter n is set to three. The two samples with
lowest weights perish, and all the surviving samples are assigned the same weight.
wset_to_prob_truncate is useful particularly when we want to extract a small number of sam-
ples of high weights from a probability distribution. For (an approximation of) the uniform distribution over
the support of p, we use wset_to_prob_truncate (prob_to_wset p (fun _ -> 1.0)),
where (fun _ -> 1.0) is a constant Objective CAML function returning 1.0.

78
horizontal computation {V1, · · · , Vn}
vertical computations
expression
Vn
V2
· · ·
Vn−1
V1
Figure 4.7: Horizontal and vertical computations.
4.5
Simultaneous computation of multiple samples
The implementation of PTP uses a simple strategy to generate multiple samples from a given probabil-
ity distribution: compute the same expression repeatedly. An alternative strategy is to perform a single
parallel computation that simulates multiple independent computations. To distinguish the two kinds of
computations, we refer to the former strategy as vertical computations and the latter strategy as a horizontal
computation, as shown in Figure 4.7.
A horizontal computation can be potentially faster than an equivalent number of vertical computations.
For example, a horizontal computation of sample x from M in E avoids the overhead of evaluating the same
term M more than once; thus the advantage of a horizontal computation becomes pronounced if M takes a
long time to evaluate. The cost associated with each language construct also remains constant in a horizontal
computation. For example, a horizontal computation of sample x from M in E performs a substitution for
x only once, but vertical computations perform as many substitutions for x.
To examine the potential beneﬁt of horizontal computations, we implement a translator of PTP for hori-
zontal computations. Conceptually an expression now computes to an ordered set of samples in such a way
that each sample corresponds to the result of an independent vertical computation of the same expression.
We may think of the translator as implementing an operational semantics based upon the judgment
E @ [ω1, · · · , ωn] ⇁⇁{V1, · · · , Vn} @ [ω′
1, · · · , ω′
n]
which means E @ ωi ⇁Vi @ ω′
i for 1 ≤i ≤n.
The translator is implemented in a similar way to the operational semantics for vertical computations:
the syntax of Objective CAML is extended using CAMLP4, and terms and expressions of the extended
syntax are translated back in Objective CAML. The deﬁnition of the type constructor prob, however, is
more complex because of conditional constructs (if · then · else · and eif · then · else ·). To motivate our
deﬁnition of prob, consider the following expression:
sample x from prob S in
sample y from prob E in
eif x ≤0.5 then E1 else E2
A vertical computation reduces the whole expression to either E1 or E2 and needs to keep only one reduced
expression. A horizontal computation, however, may have to keep both E1 and E2 because multiple samples
are generated from U(0.0, 1.0] for variable x. For example, if an ordered set {0.1, 0.6, 0.3, 0.9} is generated
for variable x, the horizontal computation reduces to two smaller horizontal computations: one of E1 with
x bound to {0.1, −, 0.3, −} and another of E2 with x bound to {−, 0.6, −, 0.9}. Note that we may not

79
compress {0.1, −, 0.3, −} to {0.1, 0.3} and {−, 0.6, −, 0.9} to {0.6, 0.9} because the ordered set to which
variable y is bound may be correlated to variable x.
Thus we are led to deﬁne the type constructor prob using bit vectors and ordered sets:
type bflag
type 'a oset
type 'a prob = bflag -> 'a oset
• bflag is the type of bit vectors of ﬁxed size.
• 'a oset is a datatype for ordered sets of element type 'a. An ordered set of element type 'a may
contain not only ordinary values of type 'a but also null values ('−' in the above example). Ordinary
values correspond to values of 1 and null values to values of 0 in bit vectors.
• 'a prob is a datatype for both probability distributions over type 'a and expressions of type 'a.
It is deﬁned as the type of a function that takes a bit vector, performs a horizontal computation for
values of 1 in the given bit vector, and returns the resultant ordered set.
Since variables from bind expressions are always bound to ordered sets, we distinguish between terms
manipulating ordinary values and terms manipulating ordered sets. The new syntax, further augmenting the
extended syntax in Section 4.3, introduces a non-terminal ⟨pterm⟩for those terms manipulating ordered
sets; the deﬁnition of the non-terminal ⟨expr⟩uses ⟨pterm⟩in place of ⟨term⟩:
⟨term⟩
::=
· · · | ⟨pterm⟩
⟨pterm⟩
::=
lam ⟨patt⟩-> ⟨pterm⟩|
lambda abstraction
app ⟨pterm⟩to ⟨pterm⟩|
application term
pif ⟨pterm⟩then ⟨pterm⟩
else ⟨pterm⟩|
cond. term construct
@⟨id⟩|
variable
const ⟨term⟩|
constants
ptrue | pfalse | @+ | CMP <=. | · · ·
built-in constants
In the new syntax, a Bernoulli distribution and a geometric distribution are encoded as follows:
let bernoulli = fun p ->
PROB { sample x from PROB { UNIFORM } in
[pif @x CMP <=. const p then ptrue else pfalse] }
let geometric = fun p ->
let bernoulli_p = bernoulli_prob p in
PROB {
efix geo ->
sample b from bernoulli_p in
eif @b then [const 0]
else
sample x from PROB { #geo } in
[const 1 @+ @x]
}
Compared with the examples in Section 4.3, the code is the same except that all terms within expressions
manipulate ordered sets rather than ordinary values.

80
test case
vertical
horizontal
overhead (%)
bernoulli 0.25
0.922
1.188
28.85
uniform 0.0 1.0
0.906
1.078
18.98
binomial 0.25 16
16.563
23.187
39.99
geometric eﬁx 0.25
3.937
7.157
81.78
gaussian rejection 2.5 5.0
4.688
7.593
61.96
exponential von Neumann1.0
4.031
6.922
71.71
gaussian Box Muller 2.0 4.0
4.796
5.031
4.89
gaussian central 0.0 1.0
10.594
12.157
14.75
QMary calls|John calls
90.063
138.922
54.24
Figure 4.8: Execution times (in seconds) for generating a total of 3,100,000 samples.
Experimental results
We compare execution times for generating the same number of samples in vertical and horizontal com-
putations. The type bflag uses 31-bit integers (of type int in Objective CAML), which means that a
single horizontal computation performs up to 31 independent vertical computations; the datatype 'a oset
uses arrays of 31 elements of type 'a. We use an AMD Athlon XP 1.67GHz with 512MB memory for all
experiments.
Figure 4.8 shows execution times for various test cases from Chapter 3. In all test cases, horizontal
computations are slower than vertical computations, as indicated by their overhead relative to vertical com-
putations. The overhead of horizontal computations is especially high in those test cases involving condi-
tional constructs (namely, binomial, geometric eﬁx, gaussian rejection, exponential von Neumann1.0,
and QMary calls|John calls). The high overhead can be attributed to the fact that a horizontal computation
allocates an array of size 31 for every expression, regardless of the number of ordinary values from it. For
example, even when a horizontal computation is simulating just a single vertical computation (after en-
countering several conditional constructs), the computation of an expression still requires an array of size
31.
The experimental results show that the overhead for maintaining ordered sets and handling conditional
constructs exceeds the gain from simulating multiple vertical computations with a single horizontal compu-
tation. Our implementation is just a translator which does not rely on support from the compiler. In order
to fully realize the potential of horizontal computations, it seems necessary to integrate the implementa-
tion within the compiler and the run-time system. As a speculation, horizontal computations can be up to
twice faster than vertical computations: random number generation, which costs the same in both vertical
and horizontal computations, accounts for about half the total computation time; hence, with no overhead
other than random number generation, horizontal computations would be about twice faster than vertical
computations.
4.6
Summary
Although PTP is implemented indirectly via a translation in Objective CAML, both its type system and its
operational semantics are faithfully mirrored through the use of an abstract datatype. Besides all existing
features of Objective CAML are available when programming in PTP, and we may think of the implemen-
tation of PTP as a conservative extension of Objective CAML. The translation is easily generalized to any
monadic language, thus complementing the well-established result that a call-by-value language is translated

81
in a monadic language (e.g., see [68]).
The translator of PTP does not protect terms from computational effects already available in Objective
CAML such as input/output, mutable references, and even direct uses of Random.float. Thus, for
example, term M in a bind expression sample x from M in E is supposed to produce no world effect, but
the translator has no way to verify that the evaluation of M is effect-free. Therefore the translator of PTP
relies on programmers to ensure that every term denotes a regular value.
Since the linguistic framework for PTP is a reformulation of Moggi's monadic metalanguage λml (see
Chapter 2), Haskell is also a good choice as a host language for embedding PTP. To embed PTP in Haskell,
one would deﬁne a Haskell monad, say Prob, for probabilistic choices and translate an expression of
type A into a program fragment of type Prob A, while ignoring the keyword prob in probability terms.
Alternatively one could exploit the global random number generator maintained by the IO monad and
translate ⃝A of PTP into IO A of Haskell. (Our choice of Objective CAML is due to personal preference.)
We could directly implement PTP by extending the compiler and the run-time system of Objective
CAML. An immediate beneﬁt is that type error messages are more informative because type errors are
detected at the level of PTP. (Our implementation detects type errors in the translated code rather than in
the source code; hence programmers should analyze type error messages to locate type errors in the source
code.) As for execution speed, we conjecture that the gain is negligible, since the only overhead incurred
by the abstract datatype prob is to invoke two tiny functions when its member functions are invoked: an
identity function (for prb) and a function applying its argument to a unit value (for app).

82

Chapter 5
Applications
This chapter presents three applications of PTP in robotics: robot localization, people tracking, and robotic
mapping, all of which are popular topics in robotics. Although different in goal, all these applications share
a common characteristic: the state of a robot is estimated from sensor readings, where the deﬁnition of state
differs in each case. A key element of these applications is uncertainty in sensor readings, due to limitations
of sensors and noise from the environment. It makes the problem of estimating the state of a robot both
interesting and challenging: if all sensor readings were accurate, the state of a robot could be accurately
traced by a simple (non-probabilistic) analysis of sensor readings. In order to cope with uncertainty in
sensor readings, we estimate the state of a robot with probability distributions.
As a computational framework, we use Bayes ﬁlters. In each case, we formulate the update equations
at the level of probability distributions and translate them in PTP. All implementations are tested using data
collected with real robots.
5.1
Sensor readings: action and measurement
To update the state of a robot, we use two kinds of sensor readings: action and measurement. As in a Bayes
ﬁlter, an action induces a state change whereas a measurement gives information on the state:
• An action a is represented as an odometer reading which returns the pose (i.e., position (x, y) and
orientation θ) of the robot relative to its initial pose. It is given as a tuple (∆x, ∆y, ∆θ).
• A measurement m consists of range readings which return distances to objects visible at certain an-
gles. It is given as an array [d1; · · · ; dn] where each di, 1 ≤i ≤n, denotes the distance between the
robot and the closest object visible at a certain angle.
Figure 5.1 shows a typical example of measurement. It displays range readings produced by a laser range
ﬁnder covering 180 degrees. The robot is shown in the center; occluded regions are colored in grey.
Odometers and range ﬁnders are prone to errors because of their mechanical nature. An odometer
usually tends to drift in one direction over time. Its accumulated error becomes manifest especially when
the robot closes a loop after taking a circular route. Range ﬁnders occasionally fail to recognize obstacles and
report the maximum distance measurable. In order to correct these errors, we use a probabilistic approach
by representing the state of the robot with a probability distribution.
In the probabilistic approach, an action increases the set of possible states of the robot because it induces
a state change probabilistically. In contrast, a measurement decreases the set of possible states of the robot
because it gives negative information on unlikely states (and positive information on likely states). We now
demonstrate how to probabilistically update the state of the robot in three different applications.
83

84
Figure 5.1: Range readings produced by a laser range ﬁnder. The robot faces a person on its right, visible as the
shadows of two legs.
5.2
Robot localization
Robot localization [72] is the problem of estimating the pose of a robot when a map of the environment is
available. If the initial pose is given, the problem becomes pose tracking which keeps track of the robot
pose by compensating errors in sensor readings. If the initial pose is not given, the problem becomes global
localization which begins with multiple hypotheses on the robot pose (and is therefore more involved than
pose tracking).
We consider robot localization under the assumption (called the Markov assumption) that the past and
the future are independent if the current pose is known, or equivalently that the environment is static. This
assumption allows us to use a Bayes ﬁlter in estimating the robot pose. Speciﬁcally the state in the Bayes
ﬁlter is the robot pose s = (x, y, θ), and we estimate s with a probability distribution Bel(s) over three-
dimensional real space. We compute Bel(s) according to the following update equations (which are the
same as shown in Section 1.1):
Bel(s)
←
R
A(s|a, s′)Bel(s′)ds′
(5.1)
Bel(s)
←
ηP(m|s)Bel(s)
(5.2)
η a normalizing constant ensuring
R
Bel(s)ds = 1.0. We use the following interpretation of A(s|a, s′) and
P(m|s):
• A(s|a, s′) is the probability that the robot moves to pose s after taking action a at another pose s′. A
is called an action model.
• P(m|s) is the probability that measurement m is taken at pose s. P is called a perception model.
Given an action a and a pose s′, a new pose s can be generated from the action model A(·|a, s′) by
adding a noise to a and applying it to s′. In our implementation, A(·|a, s′) assumes constant translational
and rotational velocities while action a is taken from pose s′. It also assumes that errors in translational and

85
Figure 5.2: Samples from the action model.
rotational velocities obey Gaussian distributions. Figure 5.2 shows samples of the new pose after taking a
curved trajectory.
Given a measurement m and a pose s, we can also compute κP(m|s) where κ is an unknown constant:
the map determines a unique (accurate) measurement ms for pose s, and the squared Euclidean distance
between m and ms is assumed to be proportional to P(m|s). Figures 5.3 and 5.4 illustrate how to compute
κP(m|s). Figure 5.3 shows points in the map that correspond to measurement m when s is set to the true
pose of the robot, in which case the unique measurement ms for pose s coincides with m (recall that a
measurement consists of not points in the map but range readings). Hence each point is projected on the
contour of the map and is assigned a high likelihood as indicated by the dark color. Figure 5.4 shows points
in the map that correspond to the same measurement m, but when s is set to a hypothetical pose of the robot;
the unique measurement ms for pose s is represented by points with crosses. Since the measurement is not
taken at the hypothetical pose, no point is correctly aligned along the contour of the map. Thus each point
is assigned a relatively low likelihood as indicated by the grey color (the degree of darkness indicates its
likelihood). We compute κP(m|s) as the product of all individual likelihoods.1
Our implementation simpliﬁes the computation of κP(m|s) by approximating ms with those points on
the contour of the map that are closest to the points corresponding to measurement m; Figure 5.5 shows how
to approximate ms with those points with crosses. This simpliﬁcation allows us to precompute the likelihood
of every point in the map, since its closest point on the contour of the map is ﬁxed. Our implementation uses
a grid map at 10 centimeter resolution and generates a likelihood map which stores the likelihood of each
cell in the map; see Figures 5.6 for a grid map and its likelihood map.
Now, if MA denotes conditional probability A and MP m returns a function f(s) = κP(m|s), we
implement update equations (5.1) and (5.2) as follows:
let Belnew = prob sample s′ from Bel in
sample s from MA (a, s′) in
s


(5.1)
let Belnew = bayes (MP m) Bel
} (5.2)
Both pose tracking and global localization are achieved by specifying an appropriate initial probability
distribution of robot pose. For pose tracking, we use a point-mass distribution or a Gaussian distribution;
1Our implementation ﬁlters out outlier range readings in m before computing κP(m|s).

86
Figure 5.3: Points in the map that correspond to measurements when s is set to the true pose of the robot.
Figure 5.4: Points in the map that correspond to measurements when s is set to a hypothetical pose of the robot.
for global localization, we use a uniform distribution over the open space in the map.
Experimental results
To test the robot localizer, we use a Nomad XR4000 mobile robot in Wean Hall at Carnegie Mellon Univer-
sity. The robot is equipped with 180 laser range ﬁnders (one for each degree so as to cover 180 degrees).
The robot localizer uses every ﬁfth range reading, and thus a measurement consists of a batch of 180
5
= 36
range readings. We use CARMEN [49] for controlling the robot and collecting sensor readings. The robot
localizer runs on a Pentium III 500Mhz with 384 MBytes memory.
We test the robot localizer for global localization. The initial probability distribution of robot pose is
a uniform distribution over the open space in the map, which is approximated with 100,000 samples. The
ﬁrst batch of range readings is processed according to update equation (5.2). The resultant probability
distribution, which is still approximated with 100,000 samples, is then replaced by its support approximated
with 500 samples. The number of samples, 100,000 or 500, is chosen empirically — both too many and too
few samples prevent the probability distribution from converging to a correct pose.
Figure 5.7 shows a probability distribution of robot pose after processing the ﬁrst batch of range readings
in Figure 5.1; pluses represent samples generated from the probability distribution. The robot starts right
below character A, but there are relatively few samples around the true position of the robot. Figure 5.8
shows the progress of a real-time robot localization run that continues with the probability distribution in
Figure 5.7. The ﬁrst two pictures show that the robot localizer is still performing global localization. The
last picture shows that the robot localizer has started pose tracking as the probability distribution of robot

87
Figure 5.5: Approximating ms from measurement m and pose s.
pose has converged to a single hypothesis.
We test the robot localizer with 8 runs, each of which takes a different path. In a test experiment, it
succeeds to localize the robot on 5 runs and fails on 3 runs. (The result should not be considered statistically
signiﬁcant.) As a comparison, the CARMEN robot localizer, which uses particle ﬁlters and is written in C,
succeeds on 3 runs and fails on 5 runs under the same condition (100,000 samples during initialization, 500
samples during localization, and 36 range readings in each measurement). Note that the same sequence of
sensor readings does not guarantee the same result because of the probabilistic nature of the robot localizer.
In the worst scenario, for example, the initial probability distribution of robot pose may have no samples
around the true pose, in which case the robot localizer is unlikely to recover from errors. Hence it is difﬁcult
to precisely quantify the performance of the robot localizer; the goal is to convince that our implementation
in PTP is reasonably acceptable, not totally fake.
5.3
People tracking
People tracking [50] is an extension of robot localization in that it estimates not only the robot pose but
also positions of people (or unmapped objects). As in robot localization, the robot takes an action to change
its pose. Unlike in robot localization, however, the robot categorizes sensor readings in a measurement
by deciding whether they correspond with objects in the map or with people. Those sensor readings that
correspond with objects in the map are used to update the robot pose; the rest of sensor readings are used to
update positions of people.
A simple approach is to maintain a probability distribution Bel(s, ⃗u) of robot pose s and positions ⃗u
of people. Although it works well for pose tracking, this approach is not a general solution for global
localization. The reason is that sensor readings from people are correctly interpreted only with a correct
hypothesis on the robot pose, but during global localization, there may be incorrect hypotheses that lead
to incorrect interpretation of sensor readings. For example, the two objects in the upper right region in
Figure 5.1 are interpreted as a person only with a correct hypothesis on the robot pose. This means that
during global localization, there exists a dependence between the robot pose and positions of people, which
is not captured by Bel(s, ⃗u).
Hence we maintain a probability distribution Bel(s, Ps(⃗u)) of robot pose s and probability distribution
Ps(⃗u) of positions ⃗u of people conditioned on robot pose s.2 Ps(⃗u) captures the dependence between the
2Our implementation assumes that people move independently of each other, and represents Ps(⃗u) as a set of independent
probability distributions each of which keeps track of the position of an individual person.

88
Figure 5.6: A grid map and its likelihood map.
robot pose and positions of people. Bel(s, Ps(⃗u)) can be thought of as a probability distribution over
probability distributions.
As in robot localization, we update Bel(s, Ps(⃗u)) with a Bayes ﬁlter. The difference from robot local-
ization is that the state is a pair of s and Ps(⃗u) and that the action model takes as input both an action a and
a measurement m. We use update equations (5.3) and (5.4) in Figure 5.9 (which are obtained by replacing
s by s, Ps(⃗u) and a by a, m in update equations (1.1) and (1.2)).
The action model A(s, Ps(⃗u)|a, m, s′, Ps′(⃗u′)) generates s, Ps(⃗u) from s′, Ps′(⃗u′) utilizing action a and
measurement m. We ﬁrst generate s and then Ps(⃗u) according to equation (5.5) in Figure 5.9. We write
the ﬁrst Prob in equation (5.5) as Arobot(s|a, m, s′, Ps′(⃗u′)). The second Prob in equation (5.5) indicates
that we generate Ps(⃗u) from Ps′(⃗u′) utilizing action a and measurement m, which is exactly a situation
where we can use another Bayes ﬁlter. For this inner Bayes ﬁlter, we use update equations (5.6) and (5.7)
in Figure 5.9. We write Prob in equation (5.6) as Apeople(⃗u|a, ⃗u′, s, s′); we simplify Prob in equation (5.7)
into Prob(m|⃗u, s) because m does not depend on s′ if s is given, and write it as Ppeople(m|⃗u, s).
Figure 5.10 shows the implementation of people tracking in PTP. MArobot and MApeople denote condi-
tional probabilities Arobot and Apeople, respectively. MPpeople m s returns a function f(⃗u) = κPpeople(m|⃗u, s)
for a constant κ. Since both m and s are ﬁxed when computing f(⃗u), we consider only those range readings
in m that correspond with people. In implementing update equation (5.4), we use the fact that P(m|s, Ps(⃗u))
is the expectation of a function g(⃗u) = Ppeople(m|⃗u, s) with respect to Ps(⃗u):
(5.8)
P(m|s, Ps(⃗u)) =
R
Ppeople(m|⃗u, s)Ps(⃗u)d⃗u
Our implementation further simpliﬁes the models used in the update equations. We use Arobot(s|a, s′)
instead of Arobot(s|a, m, s′, Ps′(⃗u′)) as in robot localization. That is, we ignore the interaction between
the robot and people when generating new poses of the robot. Similarly we use Apeople(⃗u|⃗u′) instead of

89
Figure 5.7: Probability distribution of robot pose after processing the ﬁrst batch of range readings in Figure 5.1.
Apeople(⃗u|a, ⃗u′, s, s′) on the assumption that positions of people are not affected by the robot pose; ⃗u is
obtained by adding a random noise to ⃗u′. We also simplify P(m|s, Ps(⃗u)) in update equation (5.4) into
P(m|s), which is computed in the same way as in robot localization; hence equation (5.8) is not actually
exploited in our implementation.
Experimental results
We test the people tracker on the same robot and machine that are used in robot localization. The people
tracker uses the implementation in Figure 5.10 during global localization, but once it succeeds to localize
the robot and starts pose tracking, it maintains a probability distribution Bel(s, ⃗u) as there is no longer a
dependence between the robot pose and positions of people. Like the robot localizer, we do not intend to
quantitatively measure the success rate of people tracking; rather the focus is on ensuring that our imple-
mentation in PTP is not completely useless.
Figure 5.11 shows the progress of a real-time people tracking run which uses the same sequence of
sensor readings as Figure 5.8. The ﬁrst picture is taken after processing the ﬁrst batch of range readings
in Figure 5.1; pluses (+) represent robot poses and crosses (×) represent positions of people. The second
picture shows that the people tracker is still performing global localization. The last picture shows that the
people tracker has started pose tracking; the position of each person in sight is indicated by a grey dot.
Figure 5.12 shows range readings when the third picture in Figure 5.11 is taken; the right picture shows
a magniﬁed view of the area around the robot. Note that a person may be occluded by another person or
objects in the map, so grey dots do not always reﬂect the movement of people instantly. A reﬁned action
model for people (e.g., Apeople(⃗u|a, ⃗u′, s, s′) or one estimating not only the position but also the velocity of
each person) would alleviate the problem.
5.4
Robotic mapping
Robotic mapping [75] is the problem of building a map (or a spatial model) of the environment from sensor
readings. Since measurements are a sequence of inaccurate local snapshots of the environment, a robot
simultaneously localizes itself as it explores the environment so that it corrects and aligns local snapshots to
construct a global map. For this reason, robotic mapping is also referred to as simultaneous localization and
mapping (or SLAM).

90
Taking a probabilistic approach, we formulate the robotic mapping problem with a Bayes ﬁlter which
maintains a probability distribution Bel(s, g) of robot pose s and map g. Given an action a and a measure-
ment m, we update Bel(s, g) as follows:
Bel(s, g)
←
R
s′,g′A(s, g|a, s′, g′)Bel(s′, g′)d(s′, g′)
(5.9)
Bel(s, g)
←
ηP(m|s, g)Bel(s, g)
(5.10)
We assume that an action is independent of the map and does not change the environment; that is, A(s, g|a, s′, g′)
= A(s|a, s′) if g = g′, and A(s, g|a, s′, g′) = 0 if g ̸= g′. Then we can simplify update equation (5.9) as
follows:
Bel(s, g)
←
R
s′A(s|a, s′)Bel(s′, g)ds′
(5.11)
Therefore the action model becomes the same as in robot localization. We implement the new update
equation (5.11) as follows:
let Belnew = prob sample (s′, g) from Belold in sample s from MA (a, s′) in (s, g)
The update equation (5.10) is implemented with a Bayes operation as before.
Unfortunately the space of maps has a huge dimension, which makes it impossible to maintain Bel(s, g)
without simplifying their representation. Therefore we usually make additional assumptions on maps to
derive a speciﬁc representation. For example, assuming that a map consists of a set of landmarks whose
locations are estimated with Gaussian distributions, we can use a Kalman ﬁlter instead of a general Bayes
ﬁlter. If measurements, or local snapshots of the environment, are assumed to be accurate relative to robot
poses, we can represent a map by the sequence of robot poses when the measurements are taken, as in [38].
We can also exploit expectation maximization [14], in which we perform hill climbing in the space of maps
to ﬁnd the most likely map. This approach does not maintain a probability distribution over maps because it
keeps only one (most likely) map at each iteration.
Here we assume that the environment consists of an unknown number of stationary landmarks. Then
the goal is to estimate positions of landmarks as well as the robot pose. The key observation is that we
may think of landmarks as people who never move in an empty environment. It means that the problem is
a special case of people tracking and we can use all the equations in Figure 5.9. Below we use subscript
landmark instead of people for the sake of clarity.
As in people tracking, we maintain a probability distribution Bel(s, Ps(⃗u)) of robot pose s and prob-
ability distribution Ps(⃗u) of positions ⃗u of landmarks conditioned on robot pose s. Since landmarks are
stationary and Alandmark(⃗u|a, ⃗u′, s, s′) is non-zero if and only if ⃗u = ⃗u′, we skip update equation (5.6) in
implementing update equation (5.3). Arobot in equation (5.5) uses Plandmark(m|⃗u′, s) to test the likelihood
of each new robot pose s with respect to old positions ⃗u′ of landmarks, as in FastSLAM 2.0 [48]:
Arobot(s|a, m, s′, Ps′(⃗u′))
(5.12)
=
R
Prob(s|a, m, s′, u′)Ps′(⃗u′)d⃗u′
=
Z Prob(s|a, ⃗u′)Prob(m, s′|s, a, ⃗u′)
Prob(m, s′|a, ⃗u′)
Ps′(⃗u′)d⃗u′
=
R
η′′Prob(m, s′|s, a, ⃗u′)Ps′(⃗u′)d⃗u′
where
η′′ =
Prob(s|a, ⃗u′)
Prob(m, s′|a, ⃗u′)
=
R
η′′Prob(s′|s, a, ⃗u′, m)Prob(m|s, a, ⃗u′)Ps′(⃗u′)d⃗u′
=
R
η′′Prob(s′|s, a)Prob(m|s, ⃗u′)Ps′(⃗u′)d⃗u′
=
η′′Arobot(s|a, s′)
R
Plandmark(m|⃗u′, s)Ps′(⃗u′)d⃗u′

91
Given a and s′, we implement equation (5.12) with a Bayes operation on Arobot(·|a, s′).
Figure 5.13 shows the implementation of robotic mapping in PTP. Compared with the implementation
of people tracking in Figure 5.10, it omits update equation (5.6) and incorporates equation (5.12). MArobot
and MPlandmark denote conditional probabilities Arobot and Plandmark, respectively, as in people tracking.
Since landmarks are stationary, we no longer need MAlandmark. If we approximate Bel(s, Ps(⃗u)) with a
single sample (i.e., with one most likely robot pose and an associated map), update equation (5.4) becomes
unnecessary.
Experimental results
To test the mapper, we use a data set collected with an outdoor vehicle in Victoria Park, Sydney [1]. The
mapper runs on the same machine that is used in robot localization and people tracking (Pentium III 500Mhz
with 384 MBytes memory). The data set is collected while the vehicle moves approximately 323.42 meters
(according to the odometry readings) in 128.8 seconds. Since the vehicle is driving over uneven terrain, raw
odometry readings are noisy and do not reﬂect the true path of the vehicle, in particular when the vehicle
follows a loop.
Figure 5.14 shows raw odometry readings in the data set. The true positions of the vehicle measured
by a GPS sensor are represented by crosses, which are available only for part of the entire traverse and
are not exploited by the mapper. Note that the odometry readings eventually diverge from the true path
of the vehicle. Figure 5.15 shows the result of the robotic mapping experiment in which we approximate
Bel(s, Ps(⃗u)) with a single sample and use 1,000 samples for the expectation query and the Bayes operation.
The circles represent landmark positions (mean of their probability distributions). The mapper successfully
closes the loop, building a map of the landmarks around the path. The experiment, however, takes 145.89
seconds, which is 13.26% longer than it takes to collect the data set (128.8 seconds).
5.5
Summary
PTP is a probabilistic language which allows programmers to concentrate on how to formulate probabilistic
computations at the level of probability distributions, regardless of the kind of probability distributions
involved. The three applications in robotics substantiate the practicality of PTP by illustrating how to directly
translate a probabilistic computation into code and providing experimental results on real robots.
Our ﬁnding is that the beneﬁt of implementing probabilistic computations in PTP, such as improved
readability and conciseness of code, can outweigh its disadvantage in speed. For example, our robot localizer
is 1307 lines long (826 lines of Objective CAML/PTP code for probabilistic computations and 481 lines of
C code for interfacing with CARMEN) whereas the CARMEN robot localizer, which uses particle ﬁlters
and is written in C, is 3397 lines long. (Our robot localizer also uses the translator of PTP which is 306 lines
long: 53 lines of CAMLP4 code and 253 lines of Objective CAML code.) The comparison is, however,
not conclusive because not every piece of code in CARMEN contributes to robot localization. Moreover
the reduction in code size is also attributed to the use of Objective CAML as the host language. Hence the
comparison should not be taken as indicative of reduction in code size due to PTP alone. The speed loss is
also not signiﬁcant. For example, while the CARMEN robot localizer processes 100.0 sensor readings, our
robot localizer processes on average 54.6 sensor readings (and nevertheless shows comparable accuracy).
On the other hand, PTP does not allow programmers to exploit a particular representation scheme for
probability distributions, which is inevitable for achieving high scalability in some applications. In the
robotic mapping problem, for example, one may choose to approximate the position of each landmark with a
Gaussian distribution. As the cost of representing a Gaussian distribution is relatively low, the approximation
makes it possible to build a highly scalable mapper. For example, Montemerlo [48] presents a FastSLAM

92
2.0 mapper which handles maps with over 1,000,000 landmarks. For such a problem, PTP would be useful
for quickly building a prototype implementation to test the correctness of a probabilistic computation.

93
Figure 5.8: Progress of a real-time robot localization run. Taken at 20 seconds, 40 seconds, and 80 seconds after
processing the ﬁrst batch of sensor readings in Figure 5.1.

94
Bel(s, Ps(⃗u))
←
R
A(s, Ps(⃗u)|a, m, s′, Ps′(⃗u′))Bel(s′, Ps′(⃗u′))d(s′, Ps′(⃗u′))
(5.3)
Bel(s, Ps(⃗u))
←
ηP(m|s, Ps(⃗u))Bel(s, Ps(⃗u))
(5.4)
=
ηBel(s, Ps(⃗u))
R
Ppeople(m|⃗u, s)Ps(⃗u)d⃗u
A(s, Ps(⃗u)|a, m, s′, Ps′(⃗u′))
=
Prob(s|a, m, s′, Ps′(⃗u′)) Prob(Ps(⃗u)|a, m, s′, Ps′(⃗u′), s)
(5.5)
=
Arobot(s|a, m, s′, Ps′(⃗u′)) Prob(Ps(⃗u)|a, m, s′, Ps′(⃗u′), s)
Ps(⃗u)
←
R
Prob(⃗u|a, ⃗u′, s, s′)Ps′(⃗u′)d⃗u′
(5.6)
=
R
Apeople(⃗u|a, ⃗u′, s, s′)Ps′(⃗u′)d⃗u′
Ps(⃗u)
←
η′Prob(m|⃗u, s, s′)Ps(⃗u)
(5.7)
=
η′Ppeople(m|⃗u, s)Ps(⃗u)
Figure 5.9: Equations used in people tracking. (5.3) and (5.4) for the Bayes ﬁlter computing Bel(s, Ps(⃗u)). (5.5) for
decomposing the action model. (5.6) and (5.7) for the inner Bayes ﬁlter computing Ps(⃗u).
let Belnew =
prob sample (s′, Ps′(⃗u′)) from Bel in
sample s from MArobot (a, m, s′, Ps′(⃗u′)) in
let Ps(⃗u) = prob sample ⃗u′ from Ps′(⃗u′) in
sample ⃗u from MApeople (a, ⃗u′, s, s′) in
⃗u


(5.6)
in
let Ps(⃗u) = bayes (MPpeople m s) Ps(⃗u) in
} (5.7)
(s, Ps(⃗u))





















(5.5)





























(5.3)
let Belnew =
bayes λ(s, Ps(⃗u)): . (expectation (MPpeople m s) Ps(⃗u)) Bel
} (5.4)
Figure 5.10: Implementation of people tracking in PTP. Numbers on the right-hand side show corresponding equa-
tions in Figure 5.9.

95
Figure 5.11: Progress of a real-time people tracking run. Taken at 0 seconds, 20 seconds, and 70 seconds after
processing the ﬁrst batch of sensor readings in Figure 5.1.

96
Figure 5.12: Range readings and the area around the robot during a people tracking run.
let Belnew =
prob sample (s′, Ps′(⃗u′)) from Bel in
sample s from
bayes λs: . (expectation (MPlandmark m s) Ps′(⃗u′))
(MArobot (a, s′)) in


(5.12)
let Ps(⃗u) = bayes (MPlandmark m s) Ps′(⃗u′) in
} (5.7)
(s, Ps(⃗u))











(5.5)





















(5.3)
let Belnew = bayes λ(s, Ps(⃗u)): . (expectation (MPlandmark m s) Ps(⃗u)) Bel
} (5.4)
Figure 5.13: Implementation of robotic mapping in PTP.

97
Figure 5.14: Raw odometry readings in the robotic mapping experiment.
Figure 5.15: Result of the robotic mapping experiment.

98

Chapter 6
Conclusion
We have presented a probabilistic language PTP whose mathematical basis is sampling functions. PTP sup-
ports all kinds of probability distributions — discrete distributions, continuous distributions, and even those
belonging to neither group — without drawing a syntactic or semantic distinction. We have developed a lin-
guistic framework λ⃝for PTP and demonstrated the use of PTP with three applications in robotics. To the
best of our knowledge, PTP is the only probabilistic language with a formal semantics that has been applied
to real problems involving continuous distributions. There are a few other probabilistic languages that are
capable of simulating continuous distributions (by combining an inﬁnite number of discrete distributions),
but they require a special treatment such as the lazy evaluation strategy in [33, 59] and the limiting process
in [24].
PTP does not support precise reasoning about probability distributions.
Note, however, that this is
not an inherent limitation of PTP due to its use of sampling functions as the mathematical basis; rather
this is a necessary feature of PTP because precise reasoning about probability distributions is impossible in
general. In other words, if PTP supported precise reasoning, it would support a smaller number of probability
distributions and operations.
The utility of a probabilistic language depends on each problem to which it is applied. PTP is a good
choice for those problems in which all kinds of probability distributions are used or precise reasoning is
unnecessary. Robotics is a good example, since all kinds of probability distributions are used (even those
probability distributions similar to point uniform in Section 3.2 are used in modeling laser range ﬁnders)
and also precise reasoning is unnecessary (sensor readings are inaccurate at any rate). On the other hand,
PTP may not be the best choice for those problems involving only discrete distributions, since its rich
expressiveness is not fully exploited and approximate reasoning may be too weak for discrete distributions.
Although we have presented only an operational semantics of PTP (which sufﬁces for all practical
purposes), a denotational semantics can also be used to argue that PTP is a probabilistic language. It may
also answer important questions about PTP such as:
• What is exactly the expressive power of PTP?
• Can we encode any probability distribution in PTP?
• If not, what kinds of probability distributions are impossible to encode in PTP?
The challenge is that in the presence of ﬁxed point constructs, measure theory does not come to our rescue
because of recursive equations. Hence a domain-theoretic structure for probability distributions should be
constructed to properly handle recursive equations. The work by Jones [30] suggests that such a structure
could be constructed from a domain-theoretic model of real numbers [17].
99

100
The development of PTP is an effort to marry, in one of many possible ways, two seemingly unrelated
disciplines: programming language theory and robotics. To programming language theory, it contributes a
new linguistic framework λ⃝and another installment in the series of probabilistic languages. To robotics,
it sets a precedent that a high level formulation of a problem does not always have to be discarded when it
comes to implementation. It remains to be seen in what other ways the two disciplines can be married.

Bibliography
[1] Experimental data. http://www.acfr.usyd.edu.au/homepages/academic/enebot/
dataset.htm. Australian Centre for Field Robotics, The University of Sydney.
[2] Objective CAML. http://caml.inria.fr.
[3] H. Abelson, R. K. Dybvig, C. T. Haynes, G. J. Rozas, N. I. A. IV, D. P. Friedman, E. Kohlbecker, G. L.
Steele Jr., D. H. Bartley, R. Halstead, D. Oxley, G. J. Sussman, G. Brooks, C. Hanson, K. M. Pitman,
and M. Wand. Revised report on the algorithmic language Scheme.
Higher-Order and Symbolic
Computation, 11(1):7-105, Aug. 1998.
[4] U. A. Acar, G. E. Blelloch, and R. Harper. Adaptive functional programming. In Proceedings of the
29th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages 247-259.
ACM Press, 2002.
[5] U. A. Acar, G. E. Blelloch, and R. Harper. Selective memoization. In Proceedings of the 30th ACM
SIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages 14-25. ACM Press,
2003.
[6] Z. M. Ariola and A. Sabry. Correctness of monadic state: an imperative call-by-need calculus. In Pro-
ceedings of the 25th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,
pages 62-73, New York, NY, 1998.
[7] P. N. Benton, G. M. Bierman, and V. C. V. de Paiva. Computational types from a logical perspective.
Journal of Functional Programming, 8(2):177-193, 1998.
[8] G. M. Bierman and V. de Paiva. Intuitionistic necessity revisited. Technical Report CSR-96-10, Uni-
versity of Birmingham, School of Computer Science, June 1996.
[9] G. Boudol. The recursive record semantics of objects revisited. Lecture Notes in Computer Science,
2028:269+, 2001.
[10] P. Bratley, B. Fox, and L. Schrage. A guide to simulation. Springer Verlag, 2nd edition, 1996.
[11] E. Charniak. Statistical Language Learning. MIT Press, Cambridge, Massachusetts, 1993.
[12] B. F. Chellas. Modal Logic: An Introduction. Cambridge University Press, 1980.
[13] K. Crary, A. Kliger, and F. Pfenning. A monadic analysis of information ﬂow security with mutable
state. Technical Report CMU-CS-03-164, School of Computer Science, Carnegie Mellon University,
2003.
101

102
[14] A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum likelihood from incomplete data via the EM
algorithm. Journal of the Royal Statistical Society (Series B), 39(1):1-38, 1977.
[15] A. Doucet, N. de Freitas, and N. Gordon. Sequential Monte Carlo Methods in Practice. Springer
Verlag, New York, 2001.
[16] D. Dreyer. A type system for well-founded recursion. In Proceedings of the 31st ACM SIGPLAN-
SIGACT Symposium on Principles of Programming Languages. ACM Press, 2004.
[17] A. Edalat and P. J. Potts. A new representation for exact real numbers. In S. Brookes and M. Mislove,
editors, Electronic Notes in Theoretical Computer Science, volume 6. Elsevier Science Publishers,
2000.
[18] L. Erk¨ok and J. Launchbury. Recursive monadic bindings. In Proceedings of the Fifth ACM SIGPLAN
International Conference on Functional Programming, pages 174-185. ACM Press, 2000.
[19] M. Fairtlough and M. Mendler. Propositional lax logic. Information and Computation, 137(1):1-33,
1997.
[20] D. Fox, W. Burgard, and S. Thrun. Markov localization for mobile robots in dynamic environments.
Journal of Artiﬁcial Intelligence Research, 11:391-427, 1999.
[21] J. Gill. Computational complexity of probabilistic Turing machines. SIAM Journal on Computing,
6(4):675-695, 1977.
[22] M. Giry. A categorical approach to probability theory. In B. Banaschewski, editor, Categorical Aspects
of Topology and Analysis, volume 915 of Lecture Notes In Mathematics, pages 68-85. Springer Verlag,
1981.
[23] T. G. Grifﬁn. A formulae-as-type notion of control. In Proceedings of the 17th ACM SIGPLAN-
SIGACT Symposium on Principles of Programming Languages, pages 47-58. ACM Press, 1990.
[24] V. Gupta, R. Jagadeesan, and P. Panangaden. Stochastic processes as concurrent constraint programs.
In Proceedings of the 26th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Lan-
guages, pages 189-202. ACM Press, 1999.
[25] R. Harper, B. Duba, and D. MacQueen. Typing ﬁrst-class continuations in ML. Journal of Functional
Programming, 3(4):465-484, October 1993.
[26] M. Henrion. Propagation of uncertainty in Bayesian networks by probabilistic logic sampling. In
J. F. Lemmer and L. N. Kanal, editors, Uncertainty in Artiﬁcial Intelligence 2, pages 149-163.
Elsevier/North-Holland, 1988.
[27] W. Howard. The formulas-as-types notion of construction. In J. P. Seldin and J. R. Hindley, editors,
To H. B. Curry: Essays on Combinatory Logic, Lambda-Calculus, and Formalism, pages 479-490.
Academic Press, NY, 1980.
[28] A. H. Jazwinski. Stochastic Processes and Filtering Theory. Academic Press, New York, 1970.
[29] F. Jelinek. Statistical Methods for Speech Recognition (Language, Speech, and Communication). MIT
Press, Boston, MA, 1998.

103
[30] C. Jones. Probabilistic Non-Determinism. PhD thesis, Department of Computer Science, University
of Edinburgh, 1990.
[31] M. P. Jones and L. Duponcheel. Composing monads. Technical Report YALEU/DCS/RR-1004, De-
partment of Computer Science, Yale University, December 1993.
[32] D. J. King and P. Wadler. Combining monads. In J. Launchbury and P. M. Sansom, editors, Glasgow
Functional Programming Workshop, Glasgow, 1992. Springer Verlag.
[33] D. Koller, D. McAllester, and A. Pfeffer. Effective Bayesian inference for stochastic programs. In
Proceedings of the 14th National Conference on Artiﬁcial Intelligence and 9th Innovative Applications
of Artiﬁcial Intelligence Conference (AAAI-97/IAAI-97), pages 740-747. AAAI Press, 1997.
[34] D. Kozen. Semantics of probabilistic programs. Journal of Computer and System Sciences, 22(3):328-
350, 1981.
[35] S. A. Kripke. Semantic analysis of modal logic. I: Normal propositional calculi. Zeitschrift f¨ur Math-
ematische Logik und Grundlagen der Mathematik, 9:67-96, 1963.
[36] J. Launchbury and S. L. Peyton Jones. Lazy functional state threads. In Proceedings of the ACM
SIGPLAN 1994 Conference on Programming Language Design and Implementation, pages 24-35.
ACM Press, 1994.
[37] J. Launchbury and S. L. Peyton Jones. State in Haskell. Lisp and Symbolic Computation, 8(4):293-
341, Dec. 1995.
[38] F. Lu and E. Milios. Globally consistent range scan alignment for environment mapping. Autonomous
Robots, 4:333-349, 1997.
[39] C. L¨uth and N. Ghani. Composing monads using coproducts. In Proceedings of the Seventh ACM
SIGPLAN International Conference on Functional Programming, pages 133-144. ACM Press, 2002.
[40] D. J. C. MacKay. Introduction to Monte Carlo methods. In M. I. Jordan, editor, Learning in Graphical
Models, NATO Science Series, pages 175-204. Kluwer Academic Press, 1998.
[41] Y. Mandelbaum, D. Walker, and R. Harper. An effective theory of type reﬁnements. In Proceedings
of the Eighth ACM SIGPLAN International Conference on Functional Programming, pages 213-225.
ACM Press, 2003.
[42] P. Martin-L¨of. On the meanings of the logical constants and the justiﬁcations of the logical laws.
Nordic Journal of Philosophical Logic, 1(1):11-60, 1996. Text of lectures originally given in 1983
and distributed in 1985.
[43] T. Mogensen. Roll: A language for specifying die-rolls. In V. Dahl and P. Wadler, editors, 5th In-
ternational Symposium on Practical Aspects of Declarative Languages, volume 2562 of LNCS, pages
145-159. Springer, 2002.
[44] E. Moggi. Computational lambda-calculus and monads. In Proceedings, Fourth Annual Symposium
on Logic in Computer Science, pages 14-23. IEEE Computer Society Press, 1989.
[45] E. Moggi. Notions of computation and monads. Information and Computation, 93:55-92, 1991.

104
[46] E. Moggi and A. Sabry. Monadic encapsulation of effects: a revised approach (extended version).
Journal of Functional Programming, 11(6):591-627, Nov. 2001.
[47] E. Moggi and A. Sabry. An abstract monadic semantics for value recursion. Theoretical Informatics
and Applications, 38(4):375-400, 2004.
[48] M. Montemerlo. FastSLAM: A Factored Solution to the Simultaneous Localization and Mapping Prob-
lem with Unknown Data Association. PhD thesis, Robotics Institute, Carnegie Mellon University,
2003.
[49] M. Montemerlo, N. Roy, and S. Thrun.
CARMEN: Carnegie Mellon Robot Navigation Toolkit.
http://www.cs.cmu.edu/˜carmen/.
[50] M. Montemerlo, W. Whittaker, and S. Thrun. Conditional particle ﬁlters for simultaneous mobile
robot localization and people-tracking. In IEEE International Conference on Robotics and Automation
(ICRA), pages 695-701, Washington, DC, 2002. ICRA.
[51] A. Nanevski. From dynamic binding to state via modal possibility. In Proceedings of the 5th ACM
SIGPLAN International Conference on Principles and Practice of Declaritive Programming, pages
207-218. ACM Press, 2003.
[52] A. Nanevski. A modal calculus for effect handling. Technical Report CMU-CS-03-149, School of
Computer Science, Carnegie Mellon University, 2003.
[53] S. Park. A calculus for probabilistic languages. In Proceedings of the 2003 ACM SIGPLAN Interna-
tional Workshop on Types in Language Design and Implementation, pages 38-49. ACM Press, 2003.
[54] L. Petersen, R. Harper, K. Crary, and F. Pfenning. A type theory for memory allocation and data
layout. In Proceedings of the 30th ACM SIGPLAN-SIGACT Symposium on Principles of Programming
Languages, pages 172-184. ACM Press, 2003.
[55] S. Peyton Jones, editor. Haskell 98 Language and Libraries: The Revised Report. Cambridge Univer-
sity Press, 2003.
[56] S. Peyton Jones, A. Gordon, and S. Finne. Concurrent haskell. In Proceedings of the 23rd ACM
SIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages 295-308. ACM
Press, 1996.
[57] S. Peyton Jones, A. Reid, F. Henderson, T. Hoare, and S. Marlow. A semantics for imprecise excep-
tions. In Proceedings of the ACM SIGPLAN 1999 Conference on Programming Language Design and
Implementation, pages 25-36. ACM Press, 1999.
[58] S. L. Peyton Jones. Tackling the awkward squad: monadic input/output, concurrency, exceptions,
and foreign-language calls in Haskell. In C. A. R. Hoare, M. Broy, and R. Steinbr¨uggen, editors,
Engineering Theories of Software Construction. IOS Press, Amsterdam, 2001.
[59] A. Pfeffer. IBAL: A probabilistic rational programming language. In B. Nebel, editor, Proceedings of
the Seventeenth International Joint Conference on Artiﬁcial Intelligence (IJCAI-01), pages 733-740.
Morgan Kaufmann Publishers, Inc., 2001.
[60] F. Pfenning and R. Davies. A judgmental reconstruction of modal logic. Mathematical Structures in
Computer Science, 11(4):511-540, 2001.

105
[61] D. Pless and G. Luger. Toward general analysis of recursive probability models. In J. Breese and
D. Koller, editors, Proceedings of the Seventeenth Conference on Uncertainty in Artiﬁcial Intelligence
(UAI-01), pages 429-436. Morgan Kaufmann Publishers, 2001.
[62] D. Prawitz. Natural Deduction. Almquist and Wiksell, Stockholm, 1965.
[63] L. R. Rabiner. A tutorial on hidden Markov models and selected applications in speech recognition.
Proceedings of the IEEE, 77(2):257-285, Feb. 1989.
[64] N. Ramsey and A. Pfeffer. Stochastic lambda calculus and monads of probability distributions. In Pro-
ceedings of the 29th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,
pages 154-165. ACM Press, 2002.
[65] W. Rudin. Real and Complex Analysis. McGraw-Hill, New York, 3 edition, 1986.
[66] S. Russell and P. Norvig. Artiﬁcial Intelligence: A Modern Approach. Prentice Hall, 1995.
[67] A. Sabry. What is a purely functional language?
Journal of Functional Programming, 8(1):1-22,
1998.
[68] A. Sabry and P. Wadler. A reﬂection on call-by-value. ACM Transactions on Programming Languages
and Systems, 19(6):916-941, 1997.
[69] N. Saheb-Djahromi. Probabilistic LCF. In J. Winkowski, editor, Proceedings of the 7th Symposium on
Mathematical Foundations of Computer Science, volume 64 of LNCS, pages 442-451. Springer, 1978.
[70] M. Semmelroth and A. Sabry. Monadic encapsulation in ML. In Proceedings of the Fourth ACM
SIGPLAN International Conference on Functional Programming, pages 8-17. ACM Press, 1999.
[71] A. K. Simpson. The Proof Theory and Semantics of Intuitionistic Modal Logic. PhD thesis, Department
of Philosophy, University of Edinburgh, 1994.
[72] S. Thrun. Probabilistic algorithms in robotics. AI Magazine, 21(4):93-109, 2000.
[73] S. Thrun. A programming language extension for probabilistic robot programming. In Workshop notes
of the IJCAI Workshop on Uncertainty in Robotics (RUR), 2000.
[74] S. Thrun. Towards programming tools for robots that integrate probabilistic computation and learning.
In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA). IEEE,
2000.
[75] S. Thrun. Robotic mapping: A survey. In G. Lakemeyer and B. Nebel, editors, Exploring Artiﬁcial
Intelligence in the New Millenium. Morgan Kaufmann, 2002.
[76] P. Wadler. Comprehending monads. Mathematical Structures in Computer Science, 2:461-493, 1992.
[77] P. Wadler.
The essence of functional programming.
In Proceedings of the 19th ACM SIGPLAN-
SIGACT Symposium on Principles of Programming Languages, pages 1-14. ACM Press, 1992.
[78] P. Wadler and P. Thiemann. The marriage of effects and monads. ACM Transactions on Computational
Logic, 4, 2003.
[79] G. Welch and G. Bishop. An introduction to the Kalman ﬁlter. Technical Report TR95-041, Depart-
ment of Computer Science, University of North Carolina - Chapel Hill, 1995.

106

